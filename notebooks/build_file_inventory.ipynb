{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 1.0.1: 09/26/2022 01:41pm - Nate Calvanese - Fixed bug when MD5 was not available\n"
     ]
    }
   ],
   "source": [
    "# Version History\n",
    "#print('Version 1.0.0: 09/08/2022 07:56pm - Nate Calvanese - Initial Version')\n",
    "#print('Version 1.0.1: 09/26/2022 01:41pm - Nate Calvanese - Fixed bug when MD5 was not available')\n",
    "print('Version 1.0.1: 09/26/2022 09:26pm - Nate Calvanese - Updated to be able to point to multiple buckets at once')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports and environment variables\n",
    "\n",
    "# Imports\n",
    "from firecloud import api as fapi\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from io import StringIO\n",
    "from google.cloud import storage\n",
    "import re\n",
    "import uuid\n",
    "\n",
    "# workspace environment variables\n",
    "ws_name = os.environ[\"WORKSPACE_NAME\"]\n",
    "ws_project = os.environ[\"WORKSPACE_NAMESPACE\"]\n",
    "ws_bucket = os.environ[\"WORKSPACE_BUCKET\"]\n",
    "ws_bucket_name = re.sub('^gs://', '', ws_bucket)\n",
    "\n",
    "# print(f\"workspace name = {ws_name}\")\n",
    "# print(f\"workspace project = {ws_project}\")\n",
    "# print(f\"workspace bucket = {ws_bucket}\")\n",
    "# print(f\"workspace bucket name = {ws_bucket_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions\n",
    "\n",
    "# Function to return objects in specified bucket\n",
    "def get_objects_list(bucket_name, user_proj, dirs_to_exclude=[], dirs_to_include=[]):\n",
    "    \n",
    "    # Collect list of objects/blobs from bucket \n",
    "    obj_list = []\n",
    "    storage_client = storage.Client()\n",
    "    storage_bucket = storage_client.bucket(bucket_name, user_project=user_proj)\n",
    "    objects = list(storage_client.list_blobs(storage_bucket))\n",
    "    \n",
    "    # Loop through list of objects and append names to final list based on the directories to include and exclude\n",
    "    for obj in objects:\n",
    "        if len(dirs_to_include) > 0:\n",
    "            for entry in dirs_to_include:\n",
    "                if entry in obj.name:\n",
    "                    obj_list.append(obj.name)\n",
    "        elif len(dirs_to_exclude) > 0:\n",
    "            for entry in dirs_to_exclude:\n",
    "                if entry not in obj.name:\n",
    "                    obj_list.append(obj.name)\n",
    "        else:\n",
    "            obj_list.append(obj.name)\n",
    "    return obj_list\n",
    "\n",
    "# Function to return object metadata\n",
    "def get_object(bucket_name, user_proj, object_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name, user_project=user_proj)\n",
    "    obj = bucket.get_blob(object_name)\n",
    "    return obj\n",
    "\n",
    "# Function to pull full file extension (including compression extensions)\n",
    "def get_full_file_ext(filepath):\n",
    "    full_ext_string = filepath\n",
    "    compression_extension = ''\n",
    "    compression_extensions = ['.7z', '.zip', '.gz', '.tar.gz', '.tgz']\n",
    "    for item in compression_extensions:\n",
    "        pattern = item + '$'\n",
    "        if re.search(pattern, full_ext_string):\n",
    "            full_ext_string = re.sub(pattern, '', full_ext_string)\n",
    "            compression_extension = item\n",
    "            break\n",
    "    full_ext_string = os.path.splitext(full_ext_string)[1] + compression_extension\n",
    "    return full_ext_string\n",
    "\n",
    "# Function to build file inventory\n",
    "def build_inventory(params):\n",
    "\n",
    "    # Collect parameters\n",
    "    data_files_src_buckets = params[\"data_files_src_buckets\"]\n",
    "    data_files_src_dirs = params[\"data_files_src_dirs\"]\n",
    "    data_files_src_dirs_exclude = params[\"data_files_src_dirs_exclude\"]\n",
    "    user_project = params[\"google_project\"]\n",
    "    file_inventory_dir = params[\"file_inventory_dir\"]\n",
    "    \n",
    "    # Define record list\n",
    "    record_list = []\n",
    "\n",
    "    # Loop through object list to construct inventory entry for each non-directory object \n",
    "    if data_files_src_buckets == None:\n",
    "        data_files_src_buckets = [ws_bucket_name]\n",
    "    for bucket in data_files_src_buckets:\n",
    "        object_list = get_objects_list(bucket, user_project, data_files_src_dirs_exclude, data_files_src_dirs)\n",
    "        for entry in object_list:\n",
    "            if not re.search('/$', entry):\n",
    "                # Collect information for inventory entry record\n",
    "                entry_obj_record = []\n",
    "                entry_obj = get_object(bucket, user_project, entry)\n",
    "                entry_obj_uri = \"gs://\" + bucket + \"/\" + entry_obj.name\n",
    "                entry_obj_id_str = \"\".join(filter(None, [entry_obj_uri, entry_obj.md5_hash]))\n",
    "                entry_obj_id = str(uuid.uuid5(uuid.NAMESPACE_OID, str(entry_obj_id_str)))\n",
    "                entry_obj_file_name = os.path.split(entry_obj.name)[1]\n",
    "                entry_obj_full_ext = get_full_file_ext(entry_obj_file_name)\n",
    "                # Construct fileref object\n",
    "                fileref_obj = {}\n",
    "                fileref_obj['sourcePath'] = entry_obj_uri\n",
    "                fileref_obj['targetPath'] = ('/' + entry_obj.name).replace('//', '/')\n",
    "                fileref_obj['description'] = f'Ingest of {entry_obj_uri}'\n",
    "                fileref_obj['mimeType'] = entry_obj.content_type\n",
    "                # Construct inventory entry record and append to record list\n",
    "                entry_obj_record = [entry_obj_id, entry_obj_file_name, entry_obj.name, entry_obj_uri, entry_obj.content_type, entry_obj_full_ext, entry_obj.size, entry_obj.crc32c, entry_obj.md5_hash, fileref_obj]  \n",
    "                record_list.append(entry_obj_record)\n",
    "\n",
    "    # Build inventory dataframe, drop duplicates, and build JSON object\n",
    "    column_list = ['file_id', 'name', 'path', 'uri', 'content_type', 'full_extension', 'size_in_bytes', 'crc32c', 'md5_hash', 'file_ref']\n",
    "    df_file_inventory = pd.DataFrame(record_list, columns = column_list)\n",
    "    df_file_inventory.drop_duplicates(['name', 'md5_hash'], keep='first', inplace=True, ignore_index=True)\n",
    "    file_inventory = df_file_inventory.to_dict(orient='records')\n",
    "    \n",
    "    # Write out inventory as file\n",
    "    destination_file = \"file_inventory.tsv\"\n",
    "    df_file_inventory.to_csv(destination_file, index=False, sep='\\t')\n",
    "    !gsutil cp $destination_file $ws_bucket/$file_inventory_dir/ 2> stdout\n",
    "    \n",
    "    return file_inventory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test\n",
    "# params = {}\n",
    "# params[\"data_files_src_buckets\"] = [\"fc-secure-34f13712-8698-47cb-9b1e-a1b87fae14fa\", \"fc-secure-4859bab0-bf7e-4eb0-8ded-c6caeb89feba\"]\n",
    "# params[\"data_files_src_dirs\"] = []  # Leave empty to include all\n",
    "# params[\"data_files_src_dirs_exclude\"] = [] \n",
    "# params[\"google_project\"] = \"terra-349c8d95\"\n",
    "# params[\"file_inventory_dir\"] = \"ingest_pipeline/input/test/data_files/file_inventory\"\n",
    "# inventory = build_inventory(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
