{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade data_repo_client\n",
    "# !pip install --upgrade xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     15,
     27
    ]
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "import json\n",
    "import google.auth\n",
    "import xmltodict\n",
    "import data_repo_client\n",
    "import pandas as pd\n",
    "import re\n",
    "from time import sleep\n",
    "import ast\n",
    "import datetime\n",
    "import os\n",
    "ws_bucket = os.environ[\"WORKSPACE_BUCKET\"]\n",
    "\n",
    "# Function to refresh TDR API client\n",
    "def refresh_tdr_api_client():\n",
    "    creds, project = google.auth.default()\n",
    "    auth_req = google.auth.transport.requests.Request()\n",
    "    creds.refresh(auth_req)\n",
    "    config = data_repo_client.Configuration()\n",
    "    config.host = \"https://data.terra.bio\"\n",
    "    config.access_token = creds.token\n",
    "    api_client = data_repo_client.ApiClient(configuration=config)\n",
    "    api_client.client_side_validation = False\n",
    "    return api_client\n",
    "\n",
    "# Function to pull existing AnVIL data from DUOS\n",
    "def get_anvil_datasets_from_duos(duos_token, duos_env):\n",
    "    # Determine the target URL from the env variable\n",
    "    if duos_env == \"prod\":\n",
    "        url = \"https://consent.dsde-prod.broadinstitute.org\"\n",
    "    else:\n",
    "        url = \"https://consent.dsde-dev.broadinstitute.org\"\n",
    "\n",
    "    # Pull a list of existing AnVIL studies and datasets from DUOS\n",
    "    results = []\n",
    "    datasets = requests.get(\n",
    "        url=f\"{url}/api/dataset/v3\",\n",
    "        headers={\"Authorization\": f\"Bearer {duos_token}\"}\n",
    "    ).json()\n",
    "    datasets_to_process = len(datasets)\n",
    "    datasets_processed = 0\n",
    "    for dataset_entry in datasets:\n",
    "        datasets_processed += 1\n",
    "        print(f\"Processing dataset {datasets_processed} of {datasets_to_process}...\")\n",
    "        dataset_id = dataset_entry[\"dataset_id\"]\n",
    "        dataset_details = requests.get(\n",
    "            url=f\"{url}/api/dataset/v2/{dataset_id}\",\n",
    "            headers={\"Authorization\": f\"Bearer {duos_token}\"}\n",
    "        ).json() \n",
    "        if dataset_details.get(\"study\"):\n",
    "            study_id = dataset_details[\"study\"][\"studyId\"]\n",
    "            if dataset_details[\"study\"].get(\"description\") and \"Platform: AnVIL\" in dataset_details[\"study\"][\"description\"]: \n",
    "                study_name = dataset_details[\"study\"][\"name\"]\n",
    "                study_phs = \"\"\n",
    "                for prop_entry in dataset_details[\"study\"][\"properties\"]:\n",
    "                    if prop_entry[\"key\"] == \"dbGaPPhsID\":\n",
    "                        study_phs = prop_entry[\"value\"]\n",
    "                        break\n",
    "                dataset_name = dataset_details[\"name\"]\n",
    "                dataset_identifier = dataset_details[\"datasetIdentifier\"]\n",
    "                dac_id = dataset_details.get(\"dacId\") if dataset_details.get(\"dacId\") else \"\"\n",
    "                data_use = dataset_details.get(\"dataUse\")\n",
    "                du_gru = data_use.get(\"generalUse\") if data_use.get(\"generalUse\") else False\n",
    "                du_hmb = data_use.get(\"hmbResearch\") if data_use.get(\"hmbResearch\") else False\n",
    "                du_disease = data_use.get(\"diseaseRestrictions\") if data_use.get(\"diseaseRestrictions\") else []\n",
    "                du_poa = data_use.get(\"populationOriginsAncestry\") if data_use.get(\"populationOriginsAncestry\") else False\n",
    "                du_ethics = data_use.get(\"ethicsApprovalRequired\") if data_use.get(\"ethicsApprovalRequired\") else False\n",
    "                du_collab = data_use.get(\"collaboratorRequired\") if data_use.get(\"collaboratorRequired\") else False\n",
    "                du_geog = data_use.get(\"geographicalRestrictions\") if data_use.get(\"geographicalRestrictions\") else \"\"\n",
    "                du_genetic = data_use.get(\"geneticStudiesOnly\") if data_use.get(\"geneticStudiesOnly\") else False\n",
    "                du_pub = data_use.get(\"publicationResults\") if data_use.get(\"publicationResults\") else False\n",
    "                du_nmds = data_use.get(\"methodsResearch\") if data_use.get(\"methodsResearch\") else False\n",
    "                du_npu = data_use.get(\"nonProfitUse\") if data_use.get(\"nonProfitUse\") else False\n",
    "                du_other = data_use.get(\"other\") if data_use.get(\"other\") else \"\"\n",
    "                access_management = \"\"\n",
    "                snapshot_id = \"\"\n",
    "                for prop_entry in dataset_details[\"properties\"]:\n",
    "                    if prop_entry[\"propertyName\"] == \"URL\":\n",
    "                        snapshot_url = prop_entry[\"propertyValue\"]\n",
    "                        if snapshot_url and \"https://data.terra.bio/snapshots/\" in snapshot_url:\n",
    "                                snapshot_id = snapshot_url.replace(\"https://data.terra.bio/snapshots/\", \"\")\n",
    "                    elif prop_entry[\"propertyName\"] == \"Access Management\":\n",
    "                        access_management = prop_entry[\"propertyValue\"]\n",
    "                results.append([study_id, study_name, study_phs, dataset_id, dataset_identifier, dataset_name, dac_id, access_management, du_gru, du_hmb, du_disease, du_poa, du_ethics, du_collab, du_geog, du_genetic, du_pub, du_nmds, du_npu, du_other, snapshot_id])\n",
    "\n",
    "    # Return results\n",
    "    return results\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Step 0: Review Existing AnVIL DUOS Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# Token for use in DUOS (use gcloud auth print-access-token to get this)\n",
    "duos_token = \"\"\n",
    "\n",
    "# DUOS Environment\n",
    "duos_env = \"prod\"\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "\n",
    "# Fetch results\n",
    "results = get_anvil_datasets_from_duos(duos_token, duos_env)\n",
    "\n",
    "# Display results\n",
    "df_results = pd.DataFrame(results, columns = [\"Study ID\", \"Study Name\", \"Study PHS\", \"Dataset ID\", \"Dataset Identifier\", \"Dataset Name\", \"DAC ID\", \"Access\", \"GRU\", \"HMB\", \"DS\", \"POA\", \"IRB\", \"COL\", \"GS\", \"GSO\", \"PUB\", \"NMDS\", \"NPU\", \"OTHER\", \"Snapshot ID\"])\n",
    "df_results_sorted = df_results.sort_values(by=[\"Study ID\", \"Dataset ID\"], ascending=[True, True], ignore_index=True)\n",
    "print(\"\\nResults:\")\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Step 1: Collect AnVIL Metadata for Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4,
     22,
     32,
     43,
     49,
     52,
     55,
     58,
     61,
     64,
     70,
     73,
     82,
     771
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Functions\n",
    "#############################################\n",
    "\n",
    "def coalesce(*arg): \n",
    "    remove_list = [\"\", \"NA\", \"N/A\", \"NONE\", \"TBD\", \"UNKNOWN\", \"UNSPECIFIED\"]\n",
    "    # update to remove N/A, None, Null, TBD\n",
    "    for input_item in arg:\n",
    "        if input_item is False or input_item == []:\n",
    "            return input_item\n",
    "        elif input_item:\n",
    "            if isinstance(input_item, list):\n",
    "                temp_list = [ele for ele in input_item if ele is not None and ele.upper() not in remove_list]\n",
    "                if temp_list:\n",
    "                    return temp_list\n",
    "                else:\n",
    "                    return []\n",
    "            else:\n",
    "                if str(input_item).upper() not in remove_list:\n",
    "                    return input_item\n",
    "    return None\n",
    "\n",
    "def format_description(input_string):\n",
    "    output_string = str(input_string) if input_string else \"\"\n",
    "    output_string = re.sub(\"\\n\\n\\t\", \" \", output_string)\n",
    "    output_string = re.sub(\"\\t\", \" \", output_string)\n",
    "    output_string = output_string.replace(\"\\t\", \" \")\n",
    "    output_string = re.sub(\"\\n\", \"\\\\n\", output_string)\n",
    "    output_string = output_string.replace(\"\\n\", \"\\\\n\")\n",
    "    output_string = re.sub(\"study.cgi\\?study_id=|.\\/study.cgi\\?study_id=\", \"https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=\", output_string)\n",
    "    return output_string\n",
    "\n",
    "def format_phs_id(input_str):\n",
    "    try:\n",
    "        num = re.search(\"phs0*([0-9]+)\", input_str, re.IGNORECASE).group(1)\n",
    "    except:\n",
    "        num = \"\"\n",
    "    if num:\n",
    "        output_str = \"phs\" + str(num).zfill(6)\n",
    "    else:\n",
    "        output_str = \"\"\n",
    "    return output_str\n",
    "\n",
    "def try_join(l):\n",
    "    try:\n",
    "        if isinstance(l, list):\n",
    "            return ', '.join(map(str, l))\n",
    "        else:\n",
    "            return l\n",
    "    except TypeError:\n",
    "        return l\n",
    "    \n",
    "def val_study_type_enum(l):\n",
    "    if l and l not in [\"Observational\", \"Interventional\", \"Descriptive\", \"Analytical\", \"Prospective\", \"Retrospective\", \"Case report\", \"Case series\", \"Cross-sectional\", \"Cohort study\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def val_nih_inst_center_sub_enum(l):\n",
    "    if l and l not in [\"NCI\", \"NEI\", \"NHLBI\", \"NHGRI\", \"NIA\", \"NIAAA\", \"NIAID\", \"NIAMS\", \"NIBIB\", \"NICHD\", \"NIDCD\", \"NIDCR\", \"NIDDK\", \"NIDA\", \"NIEHS\", \"NIGMS\", \"NIMH\", \"NIMHD\", \"NINDS\", \"NINR\", \"NLM\", \"CC\", \"CIT\", \"CSR\", \"FIC\", \"NCATS\", \"NCCIH\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def val_nih_ic_supp_study_enum(l):\n",
    "    if l and isinstance(l, list):\n",
    "        for item in l:\n",
    "            if item not in [\"NCI\", \"NEI\", \"NHLBI\", \"NHGRI\", \"NIA\", \"NIAAA\", \"NIAID\", \"NIAMS\", \"NIBIB\", \"NICHD\", \"NIDCD\", \"NIDCR\", \"NIDDK\", \"NIDA\", \"NIEHS\", \"NIGMS\", \"NIMH\", \"NIMHD\", \"NINDS\", \"NINR\", \"NLM\", \"CC\", \"CIT\", \"CSR\", \"FIC\", \"NCATS\", \"NCCIH\"]:\n",
    "                return 1\n",
    "        return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def val_file_type_enum(l):\n",
    "    if l and isinstance(l, list):\n",
    "        for item in l:\n",
    "            if item not in [\"Arrays\", \"Genome\", \"Exome\", \"Survey\", \"Phenotype\"]:\n",
    "                return 1\n",
    "        return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def fetch_dataset_details(snapshot_id, ds_consent_map, duos_token, duos_env, match_existing):\n",
    "    \n",
    "    # Initialize variables\n",
    "    dataset_details_records = []\n",
    "\n",
    "    # Determine the DUOS URL from the duos_env variable\n",
    "    if duos_env == \"prod\":\n",
    "        url = \"https://consent.dsde-prod.broadinstitute.org\"\n",
    "    else:\n",
    "        url = \"https://consent.dsde-dev.broadinstitute.org\"\n",
    "\n",
    "    # Build DUOS lookups\n",
    "    print(f\"Building DUOS dataset and study lookups...\")\n",
    "    study_lookup = {}\n",
    "    study_name_lookup = {}\n",
    "    dataset_lookup = []\n",
    "    datasets = requests.get(\n",
    "        url=f\"{url}/api/dataset/v3\",\n",
    "        headers={\"Authorization\": f\"Bearer {duos_token}\"}\n",
    "    ).json()\n",
    "    study_ids_processed = set()\n",
    "    for dataset_entry in datasets:\n",
    "        dataset_id = dataset_entry.get(\"dataset_id\")\n",
    "        dataset_name = dataset_entry.get(\"dataset_name\")\n",
    "        identifier = dataset_entry.get(\"identifier\")\n",
    "        study_id = dataset_entry.get(\"study_id\")\n",
    "        try:\n",
    "            base_consent_group_name = re.search(r'(.*)_[0-9]{8}_ANV[0-9]+_[0-9]{12}$', dataset_name).group(1)\n",
    "        except:\n",
    "            base_consent_group_name = dataset_name\n",
    "        if study_id:\n",
    "            # Build dataset lookup\n",
    "            dataset_lookup.append({\n",
    "                \"dataset_id\": dataset_id,\n",
    "                \"consent_group_name\": dataset_name, \n",
    "                \"base_consent_group_name\": base_consent_group_name,\n",
    "                \"identifier\": identifier,\n",
    "                \"study_id\": study_id\n",
    "            })\n",
    "            # Build study lookups\n",
    "            if study_id not in study_ids_processed:\n",
    "                study_ids_processed.add(study_id)\n",
    "                study_details = requests.get(\n",
    "                    url=f\"{url}/api/dataset/registration/{identifier}\",\n",
    "                    headers={\"Authorization\": f\"Bearer {duos_token}\"}\n",
    "                ).json()\n",
    "                study_desc = study_details.get(\"studyDescription\")\n",
    "                if study_desc and \"Platform: AnVIL\" in study_desc:\n",
    "                    study_phs = study_details.get(\"dbGaPPhsID\")\n",
    "                    if study_phs:\n",
    "                        id_in_lookup = study_lookup.get(study_phs)\n",
    "                        if id_in_lookup and id_in_lookup != study_id:\n",
    "                            print(f\"Warning: PHS ID {study_phs} tied to multiple studies in DUOS: {id_in_lookup}, {study_id}. Please review.\")\n",
    "                        else:\n",
    "                            study_lookup[study_phs] = str(study_id)\n",
    "                    study_name = study_details.get(\"studyName\")\n",
    "                    if study_name:\n",
    "                        id_in_lookup = study_name_lookup.get(study_name)\n",
    "                        if id_in_lookup and id_in_lookup != study_id:\n",
    "                            print(f\"Warning: Study Name '{study_name}' tied to multiple studies in DUOS: {id_in_lookup}, {study_id}. Please review.\")\n",
    "                        else:\n",
    "                            study_name_lookup[study_name] = str(study_id)\n",
    "                    \n",
    "    # Loop through and process snapshots\n",
    "    for snapshot_id in snapshot_id_list:\n",
    "        \n",
    "        # Initialize variables\n",
    "        terra_dict = {}\n",
    "        dbgap_xml_dict = {}\n",
    "        dbgap_study_api_dict = {}\n",
    "        dbgap_fhir_dict = {}\n",
    "        final_results_dict = {}\n",
    "        snapshot_phs_id = \"\"\n",
    "\n",
    "        # Retrieve snapshot details\n",
    "        print(f\"Processing snapshot_id: {snapshot_id}...\")\n",
    "        final_results_dict = {}\n",
    "        api_client = refresh_tdr_api_client()\n",
    "        datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "        snapshots_api = data_repo_client.SnapshotsApi(api_client=api_client)\n",
    "        attempt_counter = 0\n",
    "        snapshot_details = {}\n",
    "        while attempt_counter <= 2:\n",
    "            try:\n",
    "                snapshot_details = snapshots_api.retrieve_snapshot(id=snapshot_id).to_dict()\n",
    "                break\n",
    "            except:\n",
    "                sleep(5)\n",
    "                attempt_counter += 1  \n",
    "        snapshot_name = snapshot_details[\"name\"]\n",
    "        dataset_id = snapshot_details[\"source\"][0][\"dataset\"][\"id\"]\n",
    "        snapshot_phs_id = format_phs_id(snapshot_details[\"source\"][0][\"dataset\"][\"phs_id\"])\n",
    "        if snapshot_details[\"source\"][0][\"dataset\"][\"secure_monitoring_enabled\"] == True:\n",
    "            access_management = \"controlled\"\n",
    "        else:\n",
    "            access_management = \"open\"\n",
    "        if snapshot_details[\"source\"][0][\"dataset_properties\"].get(\"source_workspaces\"):  \n",
    "            source_workspace = snapshot_details[\"source\"][0][\"dataset_properties\"][\"source_workspaces\"][0]\n",
    "        else:\n",
    "            source_workspace = None\n",
    "        if snapshot_details[\"source\"][0][\"dataset_properties\"].get(\"consent_name\"):\n",
    "            snapshot_consent_code = snapshot_details[\"source\"][0][\"dataset_properties\"][\"consent_name\"]\n",
    "        else:\n",
    "            if access_management == \"open\":\n",
    "                snapshot_consent_code = \"NRES\"\n",
    "            else:\n",
    "                snapshot_consent_code = None\n",
    "        if snapshot_details[\"duos_firecloud_group\"] != None:\n",
    "            duos_id = snapshot_details[\"duos_firecloud_group\"][\"duos_id\"]\n",
    "        else:\n",
    "            duos_id = None\n",
    "        try:\n",
    "            base_consent_group_name = re.search(r'(.*)_[0-9]{8}_ANV[0-9]+_[0-9]{12}$', snapshot_name).group(1)\n",
    "        except:\n",
    "            base_consent_group_name = snapshot_name\n",
    "        if access_management == \"open\":\n",
    "            consent_group_name = base_consent_group_name + \" (NRES)\"\n",
    "        elif snapshot_consent_code:\n",
    "            consent_group_name = base_consent_group_name + f\" ({snapshot_consent_code})\"\n",
    "        else:\n",
    "            consent_group_name = base_consent_group_name\n",
    "        \n",
    "        print(\"\\tSnapshot PHS_ID: \" + str(snapshot_phs_id))\n",
    "        print(\"\\tSnapshot Consent Code: \" + str(snapshot_consent_code))\n",
    "        print(\"\\tSource Workspace: \" + str(source_workspace))\n",
    "        print(\"\\tDUOS ID: \" + str(duos_id))\n",
    "        print(\"\\tConsent Group Name: \" + str(consent_group_name))\n",
    "        \n",
    "        # Derive study name for use in matching logic\n",
    "        studyName = \"\"\n",
    "        ws_study_name = \"\"\n",
    "        xml_study_name = \"\"\n",
    "        api_study_name = \"\"\n",
    "        fhir_study_name = \"\"\n",
    "        attempt_counter = 0\n",
    "        while attempt_counter <= 2:\n",
    "            creds, project = google.auth.default()\n",
    "            auth_req = google.auth.transport.requests.Request()\n",
    "            creds.refresh(auth_req)\n",
    "            try:\n",
    "                ws_attributes = requests.get(\n",
    "                    url=f\"https://api.firecloud.org/api/workspaces/anvil-datastorage/{source_workspace}?fields=workspace.attributes,workspace.authorizationDomain,workspace.googleProject,workspace.bucketName\",\n",
    "                    headers={\"Authorization\": f\"Bearer {creds.token}\"}\n",
    "                ).json()\n",
    "                if ws_attributes.get(\"workspace\"):\n",
    "                    ws_study_name = coalesce(ws_attributes[\"workspace\"][\"attributes\"].get(\"library:projectName\"), source_workspace)\n",
    "                break\n",
    "            except:\n",
    "                sleep(5)\n",
    "                attempt_counter += 1\n",
    "        if snapshot_phs_id:\n",
    "            phs_short = snapshot_phs_id.replace(\"phs\", \"\")\n",
    "            study_uid = \"\"\n",
    "            dbgap_url = \"https://dbgap.ncbi.nlm.nih.gov/ss/dbgapssws.cgi?request=Study&phs=\" + phs_short\n",
    "            attempt_counter = 0\n",
    "            while attempt_counter <= 2:\n",
    "                try:\n",
    "                    response = requests.get(url=dbgap_url)\n",
    "                    xml_data = xmltodict.parse(response.text)\n",
    "                    if xml_data[\"dbgapss\"].get(\"Study\"):\n",
    "                        if isinstance(xml_data[\"dbgapss\"][\"Study\"], list):\n",
    "                            study_data = xml_data[\"dbgapss\"][\"Study\"][0]\n",
    "                        else:\n",
    "                            study_data = xml_data[\"dbgapss\"][\"Study\"] \n",
    "                        study_uid = study_data.get(\"@uid\")\n",
    "                        xml_study_name = study_data[\"StudyInfo\"].get(\"StudyNameEntrez\")\n",
    "                    break\n",
    "                except:\n",
    "                    sleep(5)\n",
    "                    attempt_counter += 1\n",
    "            if study_uid:\n",
    "                dbgap_study_url = \"https://submit.ncbi.nlm.nih.gov/dbgap/api/v1/study_config/\" + str(study_uid)\n",
    "                attempt_counter = 0\n",
    "                while attempt_counter <= 2:\n",
    "                    try:\n",
    "                        response = requests.get(url=dbgap_study_url)\n",
    "                        study_api_data = json.loads(response.text)\n",
    "                        if study_api_data.get(\"error\") == None:\n",
    "                            api_study_name = study_api_data[\"data\"].get(\"report_name\")\n",
    "                        break\n",
    "                    except:\n",
    "                        sleep(5)\n",
    "                        attempt_counter += 1 \n",
    "            dbgap_fhir_url = \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/ResearchStudy?_format=json&_id=\" + snapshot_phs_id\n",
    "            attempt_counter = 0\n",
    "            while attempt_counter <= 2:\n",
    "                try:\n",
    "                    response = requests.get(url=dbgap_fhir_url)\n",
    "                    fhir_data = json.loads(response.text)\n",
    "                    if fhir_data.get(\"entry\"):\n",
    "                        fhir_study_name = fhir_data[\"entry\"][0][\"resource\"].get(\"title\")\n",
    "                    break\n",
    "                except:\n",
    "                    sleep(5)\n",
    "                    attempt_counter += 1\n",
    "        studyName = coalesce(fhir_study_name, xml_study_name, api_study_name, ws_study_name)\n",
    "        if snapshot_phs_id and studyName and f\" ({snapshot_phs_id})\" not in studyName:\n",
    "            studyName = studyName + f\" ({snapshot_phs_id})\"\n",
    "        \n",
    "        # Attempt to match the dataset to a DUOS Dataset ID based on consent group name\n",
    "        match_duos_id = \"\"\n",
    "        target_dataset_id = \"\"\n",
    "        for dataset in dataset_lookup:\n",
    "            if dataset[\"base_consent_group_name\"] == base_consent_group_name or dataset[\"consent_group_name\"] == consent_group_name:\n",
    "                match_duos_id = dataset[\"identifier\"]\n",
    "                break\n",
    "        match_study_id = \"\"\n",
    "        \n",
    "        # Attempt to match the dataset to a DUOS Study ID based on PHS ID or Study Name\n",
    "        if snapshot_phs_id:\n",
    "            match_study_id = study_lookup.get(snapshot_phs_id)\n",
    "        else:\n",
    "            match_study_id = study_name_lookup.get(studyName)\n",
    "\n",
    "        # If a snapshot or match DUOS ID is present, use this to build the final result dictionary\n",
    "        if match_existing and (duos_id or match_duos_id):\n",
    "\n",
    "            # Pull existing DUOS study registration\n",
    "            duos_id_to_use = coalesce(duos_id, match_duos_id)\n",
    "            for dataset in dataset_lookup:\n",
    "                if dataset[\"identifier\"] == duos_id_to_use:\n",
    "                    target_dataset_id = dataset[\"dataset_id\"]\n",
    "                    break\n",
    "            duos_dict = {}\n",
    "            duos_dict = requests.get(\n",
    "                url=f\"{url}/api/dataset/registration/{duos_id_to_use}\",\n",
    "                headers={\"Authorization\": f\"Bearer {duos_token}\"}\n",
    "            ).json()\n",
    "            #print(duos_dict)\n",
    "\n",
    "            # Pull dataset details from DUOS (to get data use info) \n",
    "            if not duos_dict.get(\"consentGroups\"):\n",
    "                duos_dict[\"consentGroups\"] = [{\"datasetId\": None}]\n",
    "            duos_dataset_id = duos_dict[\"consentGroups\"][0].get(\"datasetId\")\n",
    "            duos_data_use_dict = {}\n",
    "            dac_id = \"\"\n",
    "            if duos_dataset_id:\n",
    "                dataset_details = requests.get(\n",
    "                    url=f\"{url}/api/dataset/v2/{duos_dataset_id}\",\n",
    "                    headers={\"Authorization\": f\"Bearer {duos_token}\"}\n",
    "                ).json()\n",
    "                duos_data_use_dict = dataset_details.get(\"dataUse\")\n",
    "                dac_id = dataset_details.get(\"dacId\") if dataset_details.get(\"dacId\") else \"\"\n",
    "\n",
    "            # Build final results dictionary\n",
    "            if snapshot_consent_code:\n",
    "                consent_code = snapshot_consent_code.upper().replace(\"_\", \"-\")\n",
    "            else:\n",
    "                consent_code = \"\"\n",
    "            final_results_dict[\"snapshot_id\"] = snapshot_id\n",
    "            final_results_dict[\"snapshot_phs_id\"] = snapshot_phs_id\n",
    "            final_results_dict[\"snapshot_duos_id\"] = duos_id\n",
    "            final_results_dict[\"match_duos_id\"] = match_duos_id\n",
    "            final_results_dict[\"target_dataset_id\"] = target_dataset_id\n",
    "            final_results_dict[\"target_study_id\"] = match_study_id\n",
    "            studyName = duos_dict.get(\"studyName\")\n",
    "            dbGaP_study_name = duos_dict.get(\"dbGaPStudyRegistrationName\")\n",
    "            if snapshot_phs_id and studyName and f\" ({snapshot_phs_id})\" not in studyName:\n",
    "                final_results_dict[\"studyName\"] = studyName + f\" ({snapshot_phs_id})\"\n",
    "            else:\n",
    "                final_results_dict[\"studyName\"] = studyName\n",
    "            final_results_dict[\"studyType\"] = duos_dict.get(\"studyType\")\n",
    "            final_results_dict[\"studyDescription\"] = duos_dict.get(\"studyDescription\")\n",
    "            final_results_dict[\"dataTypes\"] = duos_dict.get(\"dataTypes\")\n",
    "            final_results_dict[\"phenotypeIndication\"] = duos_dict.get(\"phenotypeIndication\")\n",
    "            final_results_dict[\"species\"] = duos_dict.get(\"species\")\n",
    "            final_results_dict[\"piName\"] = duos_dict.get(\"piName\")\n",
    "            final_results_dict[\"dataCustodianEmail\"] = duos_dict.get(\"dataCustodianEmail\")\n",
    "            final_results_dict[\"publicVisibility\"] = duos_dict.get(\"publicVisibility\")\n",
    "            final_results_dict[\"nihAnvilUse\"] = \"I am NHGRI funded and I have a dbGaP PHS ID already\" if duos_dict.get(\"nihAnvilUse\") and 'already' in duos_dict.get(\"nihAnvilUse\").lower() else \"I am NHGRI funded and I do not have a dbGaP PHS ID\"\n",
    "            final_results_dict[\"submittingToAnvil\"] = duos_dict.get(\"submittingToAnvil\")\n",
    "            if snapshot_phs_id:\n",
    "                final_results_dict[\"dbGaPPhsID\"] = snapshot_phs_id\n",
    "            else:\n",
    "                final_results_dict[\"dbGaPPhsID\"] = duos_dict.get(\"dbGaPPhsID\")\n",
    "            if snapshot_phs_id and dbGaP_study_name and f\" ({snapshot_phs_id})\" in dbGaP_study_name:\n",
    "                final_results_dict[\"dbGaPStudyRegistrationName\"] = dbGaP_study_name.replace(f\" ({snapshot_phs_id})\", \"\")\n",
    "            else:\n",
    "                final_results_dict[\"dbGaPStudyRegistrationName\"] = duos_dict.get(\"dbGaPStudyRegistrationName\")\n",
    "            final_results_dict[\"embargoReleaseDate\"] = duos_dict.get(\"embargoReleaseDate\")\n",
    "            final_results_dict[\"sequencingCenter\"] = duos_dict.get(\"sequencingCenter\")\n",
    "            final_results_dict[\"piEmail\"] = duos_dict.get(\"piEmail\")\n",
    "            final_results_dict[\"piInstitution\"] = duos_dict.get(\"piInstitution\")\n",
    "            final_results_dict[\"nihGrantContractNumber\"] = duos_dict.get(\"nihGrantContractNumber\")\n",
    "            final_results_dict[\"nihICsSupportingStudy\"] = duos_dict.get(\"nihICsSupportingStudy\")\n",
    "            final_results_dict[\"nihProgramOfficerName\"] = duos_dict.get(\"nihProgramOfficerName\")\n",
    "            final_results_dict[\"nihInstitutionCenterSubmission\"] = duos_dict.get(\"nihInstitutionCenterSubmission\")\n",
    "            final_results_dict[\"nihInstitutionalCertificationFileName\"] = duos_dict.get(\"nihInstitutionalCertificationFileName\")\n",
    "            final_results_dict[\"nihGenomicProgramAdministratorName\"] = duos_dict.get(\"nihGenomicProgramAdministratorName\")\n",
    "            final_results_dict[\"multiCenterStudy\"] = duos_dict.get(\"multiCenterStudy\")\n",
    "            final_results_dict[\"collaboratingSites\"] = duos_dict.get(\"collaboratingSites\")\n",
    "            final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSR\"] = duos_dict.get(\"controlledAccessRequiredForGenomicSummaryResultsGSR\")\n",
    "            final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation\"] = duos_dict.get(\"controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation\")\n",
    "            final_results_dict[\"alternativeDataSharingPlan\"] = duos_dict.get(\"alternativeDataSharingPlan\")\n",
    "            final_results_dict[\"alternativeDataSharingPlanReasons\"] = duos_dict.get(\"alternativeDataSharingPlanReasons\")\n",
    "            final_results_dict[\"alternativeDataSharingPlanExplanation\"] = duos_dict.get(\"alternativeDataSharingPlanExplanation\")\n",
    "            final_results_dict[\"alternativeDataSharingPlanFileName\"] = duos_dict.get(\"alternativeDataSharingPlanFileName\")\n",
    "            final_results_dict[\"alternativeDataSharingPlanDataSubmitted\"] = duos_dict.get(\"alternativeDataSharingPlanDataSubmitted\")\n",
    "            final_results_dict[\"alternativeDataSharingPlanDataReleased\"] = duos_dict.get(\"alternativeDataSharingPlanDataReleased\")\n",
    "            final_results_dict[\"alternativeDataSharingPlanTargetDeliveryDate\"] = duos_dict.get(\"alternativeDataSharingPlanTargetDeliveryDate\")\n",
    "            final_results_dict[\"alternativeDataSharingPlanTargetPublicReleaseDate\"] = duos_dict.get(\"alternativeDataSharingPlanTargetPublicReleaseDate\")\n",
    "            final_results_dict[\"alternativeDataSharingPlanAccessManagement\"] = duos_dict.get(\"alternativeDataSharingPlanAccessManagement\")\n",
    "            final_results_dict[\"consentGroups.consentGroupName\"] = consent_group_name\n",
    "            final_results_dict[\"consentGroups.accessManagement\"] = access_management\n",
    "            final_results_dict[\"dacId\"] = dac_id\n",
    "            final_results_dict[\"consentGroups.numberOfParticipants\"] = duos_dict[\"consentGroups\"][0].get(\"numberOfParticipants\")\n",
    "            final_results_dict[\"consentCode\"] = consent_code\n",
    "            final_results_dict[\"consentGroups.generalResearchUse\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"generalResearchUse\"), duos_data_use_dict.get(\"generalUse\"), False)\n",
    "            final_results_dict[\"consentGroups.hmb\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"hmb\"), duos_data_use_dict.get(\"hmbResearch\"), False)\n",
    "            final_results_dict[\"consentGroups.diseaseSpecificUse\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"diseaseSpecificUse\"), duos_data_use_dict.get(\"diseaseRestrictions\"), [])\n",
    "            final_results_dict[\"consentGroups.gs\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"gs\"), duos_data_use_dict.get(\"geographicalRestrictions\"))\n",
    "            final_results_dict[\"consentGroups.poa\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"poa\"), duos_data_use_dict.get(\"populationOriginsAncestry\"), False)\n",
    "            final_results_dict[\"consentGroups.nmds\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"nmds\"), False)\n",
    "            final_results_dict[\"consentGroups.gso\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"gso\"), duos_data_use_dict.get(\"geneticStudiesOnly\"), False)\n",
    "            final_results_dict[\"consentGroups.pub\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"pub\"), duos_data_use_dict.get(\"publicationResults\"), False)\n",
    "            final_results_dict[\"consentGroups.col\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"col\"), duos_data_use_dict.get(\"collaboratorRequired\"), False)\n",
    "            final_results_dict[\"consentGroups.irb\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"irb\"), duos_data_use_dict.get(\"ethicsApprovalRequired\"), False)\n",
    "            final_results_dict[\"consentGroups.npu\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"npu\"), False)\n",
    "            final_results_dict[\"consentGroups.otherPrimary\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"otherPrimary\"), duos_data_use_dict.get(\"other\"))\n",
    "            final_results_dict[\"consentGroups.otherSecondary\"] = duos_dict[\"consentGroups\"][0].get(\"otherSecondary\")\n",
    "            final_results_dict[\"consentGroups.mor\"] = duos_dict[\"consentGroups\"][0].get(\"mor\")\n",
    "            final_results_dict[\"consentGroups.morDate\"] = duos_dict[\"consentGroups\"][0].get(\"morDate\")\n",
    "            final_results_dict[\"consentGroups.dataLocation\"] = \"TDR Location\"\n",
    "            final_results_dict[\"consentGroups.url\"] = \"https://data.terra.bio/snapshots/\" + snapshot_id\n",
    "            if duos_dict[\"consentGroups\"][0].get(\"fileTypes\") and duos_dict[\"consentGroups\"][0][\"fileTypes\"].get(\"fileType\"):\n",
    "                final_results_dict[\"consentGroups.fileTypes.fileType\"] = duos_dict[\"consentGroups\"][0][\"fileTypes\"][0].get(\"fileType\")\n",
    "            else:\n",
    "                final_results_dict[\"consentGroups.fileTypes.fileType\"] = None\n",
    "            if duos_dict[\"consentGroups\"][0].get(\"fileTypes\") and duos_dict[\"consentGroups\"][0][\"fileTypes\"].get(\"functionalEquivalence\"):\n",
    "                final_results_dict[\"consentGroups.fileTypes.functionalEquivalence\"] = duos_dict[\"consentGroups\"][0][\"fileTypes\"][0].get(\"functionalEquivalence\")\n",
    "            else:\n",
    "                final_results_dict[\"consentGroups.fileTypes.functionalEquivalence\"] = None\n",
    "            collab_site = duos_dict.get(\"collaboratingSites\")\n",
    "            if collab_site:\n",
    "                final_results_dict[\"consortium\"] = collab_site[0]\n",
    "            else:\n",
    "                final_results_dict[\"consortium\"] = None\n",
    "            dataset_details_records.append(final_results_dict)\n",
    "            continue\n",
    "\n",
    "        # Pull information from original workspace (if listed)\n",
    "        workspace_phs_id = \"\"\n",
    "        if source_workspace:\n",
    "            # Establish credentials\n",
    "            creds, project = google.auth.default()\n",
    "            auth_req = google.auth.transport.requests.Request()\n",
    "            creds.refresh(auth_req)\n",
    "\n",
    "            # Pull workspace attributes\n",
    "            attempt_counter = 0\n",
    "            while attempt_counter <= 2:\n",
    "                try:\n",
    "                    ws_attributes = requests.get(\n",
    "                        url=f\"https://api.firecloud.org/api/workspaces/anvil-datastorage/{source_workspace}?fields=workspace.attributes,workspace.authorizationDomain,workspace.googleProject,workspace.bucketName\",\n",
    "                        headers={\"Authorization\": f\"Bearer {creds.token}\"}\n",
    "                    ).json()\n",
    "                    break\n",
    "                except:\n",
    "                    sleep(5)\n",
    "                    attempt_counter += 1\n",
    "\n",
    "            # Map to schema\n",
    "            if ws_attributes.get(\"workspace\"):\n",
    "                terra_dict[\"studyType\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:studyDesign\")\n",
    "                terra_dict[\"studyDescription\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"description\")\n",
    "                if ws_attributes[\"workspace\"][\"attributes\"].get(\"library:dataCategory\"):\n",
    "                    terra_dict[\"dataTypes\"] = []\n",
    "                    for item in ws_attributes[\"workspace\"][\"attributes\"][\"library:dataCategory\"][\"items\"]:\n",
    "                        inner_list = item.split(\",\")\n",
    "                        for inner_item in inner_list:\n",
    "                            inner_item = inner_item.replace(\"'\", \"\").strip()\n",
    "                            terra_dict[\"dataTypes\"].append(inner_item)\n",
    "                terra_dict[\"phenotypeIndication\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:indication\")\n",
    "                terra_dict[\"species\"] = \"Homo sapiens\"\n",
    "                terra_dict[\"piName\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:datasetOwner\")\n",
    "                terra_dict[\"dataCustodianEmail\"] = [ws_attributes[\"workspace\"][\"attributes\"].get(\"library:contactEmail\")]\n",
    "                if ws_attributes[\"workspace\"][\"attributes\"].get(\"tag:tags\"):\n",
    "                    for tag in ws_attributes[\"workspace\"][\"attributes\"].get(\"tag:tags\")[\"items\"]:\n",
    "                        if \"Consortium:\" in tag:\n",
    "                            terra_dict[\"consortium\"] = tag.split(\":\")[1].strip()\n",
    "                        elif \"dbGaP:\" in tag:\n",
    "                            terra_dict[\"dbGaPPhsID\"] = format_phs_id(tag.split(\":\")[1].strip())\n",
    "                            if not snapshot_phs_id:\n",
    "                                workspace_phs_id = format_phs_id(tag.split(\":\")[1].strip()) \n",
    "                                print(f\"Warning: PHS ID ({workspace_phs_id}) found on workspace but not snapshot! Please resolve.\")\n",
    "                terra_dict[\"consentGroups.consentCode\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:dataUseRestriction\")\n",
    "                if ws_attributes[\"workspace\"][\"attributes\"].get(\"library:datatype\"):\n",
    "                    terra_dict[\"consentGroups.fileTypes.fileType\"] = ws_attributes[\"workspace\"][\"attributes\"][\"library:datatype\"][\"items\"]\n",
    "                if ws_attributes[\"workspace\"][\"attributes\"].get(\"library:numSubjects\"):\n",
    "                    terra_dict[\"consentGroups.numberOfParticipants\"] = ws_attributes[\"workspace\"][\"attributes\"][\"library:numSubjects\"]\n",
    "        #         print(\"------------------------------------------------------\")\n",
    "        #         print(\"terra_dict\")\n",
    "        #         print(terra_dict)\n",
    "\n",
    "        # Pull study information from DUOS (if matched to DUOS Study based on PHS ID)\n",
    "        if not match_study_id and workspace_phs_id:\n",
    "            match_study_id = study_lookup.get(workspace_phs_id)\n",
    "        duos_study_dict = {}\n",
    "        if match_existing and match_study_id:\n",
    "            duos_study_dict = requests.get(\n",
    "                    url=f\"{url}/api/dataset/study/registration/{match_study_id}\",\n",
    "                    headers={\"Authorization\": f\"Bearer {duos_token}\"}\n",
    "                ).json()\n",
    "            collab_site = duos_study_dict.get(\"collaboratingSites\")\n",
    "            if collab_site:\n",
    "                duos_study_dict[\"consortium\"] = collab_site[0]\n",
    "        \n",
    "        # Pull information from dbGaP (if phs_id listed)\n",
    "        dac_names = \"\"\n",
    "        dbgap_phs_id = coalesce(snapshot_phs_id, workspace_phs_id)\n",
    "        if dbgap_phs_id:\n",
    "            # Pull and parse XML\n",
    "            phs_short = dbgap_phs_id.replace(\"phs\", \"\")\n",
    "            dbgap_url = \"https://dbgap.ncbi.nlm.nih.gov/ss/dbgapssws.cgi?request=Study&phs=\" + phs_short\n",
    "            attempt_counter = 0\n",
    "            while attempt_counter <= 2:\n",
    "                try:\n",
    "                    response = requests.get(url=dbgap_url)\n",
    "                    xml_data = xmltodict.parse(response.text)\n",
    "                    break\n",
    "                except:\n",
    "                    sleep(5)\n",
    "                    attempt_counter += 1\n",
    "            study_uid = \"\"\n",
    "\n",
    "            # Map to schema\n",
    "            if xml_data[\"dbgapss\"].get(\"Study\"):\n",
    "                if isinstance(xml_data[\"dbgapss\"][\"Study\"], list):\n",
    "                    study_data = xml_data[\"dbgapss\"][\"Study\"][0]\n",
    "                else:\n",
    "                    study_data = xml_data[\"dbgapss\"][\"Study\"] \n",
    "                study_uid = study_data.get(\"@uid\")\n",
    "                dbgap_xml_dict[\"studyDescription\"] = study_data[\"StudyInfo\"].get(\"Description\")\n",
    "                dbgap_xml_dict[\"dbGaPPhsID\"] = dbgap_phs_id\n",
    "                dbgap_xml_dict[\"dbGaPStudyRegistrationName\"] = study_data[\"StudyInfo\"].get(\"StudyNameEntrez\")\n",
    "                if study_data[\"Authority\"][\"Persons\"].get(\"Person\"):\n",
    "                    for ap_entry in study_data[\"Authority\"][\"Persons\"][\"Person\"]:\n",
    "                        if ap_entry[\"Role\"] == \"PI\":\n",
    "                            dbgap_xml_dict[\"piName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "                            dbgap_xml_dict[\"piEmail\"] = ap_entry[\"@email\"]\n",
    "                            dbgap_xml_dict[\"piInstitution\"] = ap_entry[\"Organization\"]\n",
    "                        elif ap_entry[\"Role\"] == \"PO\" and ap_entry[\"Organization\"] == \"NIH\":\n",
    "                            dbgap_xml_dict[\"nihProgramOfficerName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "                        elif ap_entry[\"Role\"] == \"GPA\" and ap_entry[\"Organization\"] == \"NIH\":\n",
    "                            dbgap_xml_dict[\"nihGenomicProgramAdministratorName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "                ic_list = []\n",
    "                if isinstance(study_data[\"Authority\"][\"ICs\"][\"IC\"], list):\n",
    "                    for ic_entry in study_data[\"Authority\"][\"ICs\"][\"IC\"]:\n",
    "                        ic_list.append(ic_entry[\"@name\"])\n",
    "                else:\n",
    "                    ic_list.append(study_data[\"Authority\"][\"ICs\"][\"IC\"][\"@name\"])\n",
    "                dbgap_xml_dict[\"nihICsSupportingStudy\"] = ic_list\n",
    "                dbgap_xml_dict[\"consentGroups.numberOfParticipants\"] = study_data.get(\"@num_participants\")\n",
    "                dbgap_xml_dict[\"embargoReleaseDate\"] = study_data[\"Policy\"].get(\"@pub-embargo\")\n",
    "                if study_data[\"Policy\"].get(\"ConsentGroup\"):\n",
    "                    if isinstance(study_data[\"Policy\"][\"ConsentGroup\"], list):\n",
    "                        dac_name_set = set()\n",
    "                        for idx, consent in enumerate(study_data[\"Policy\"][\"ConsentGroup\"]):\n",
    "                            tmp_dac = consent[\"@dac_name\"]\n",
    "                            dac_name_set.add(tmp_dac)\n",
    "                        dac_name_list = list(dac_name_set)\n",
    "                        dac_names = \", \".join(dac_name_list)\n",
    "                    else:\n",
    "                        dac_names = study_data[\"Policy\"][\"ConsentGroup\"][\"@dac_name\"]     \n",
    "        #             print(\"------------------------------------------------------\")\n",
    "        #             print(\"dbgap_xml_dict\")\n",
    "        #             print(dbgap_xml_dict)\n",
    "\n",
    "            # Pull and parse Study API JSON\n",
    "            if study_uid:\n",
    "                dbgap_study_url = \"https://submit.ncbi.nlm.nih.gov/dbgap/api/v1/study_config/\" + str(study_uid)\n",
    "                attempt_counter = 0\n",
    "                while attempt_counter <= 2:\n",
    "                    try:\n",
    "                        response = requests.get(url=dbgap_study_url)\n",
    "                        study_api_data = json.loads(response.text)\n",
    "                        break\n",
    "                    except:\n",
    "                        sleep(5)\n",
    "                        attempt_counter += 1\n",
    "\n",
    "                # Map to schema\n",
    "                if study_api_data.get(\"error\") == None:\n",
    "                    dbgap_study_api_dict[\"studyDescription\"] = study_api_data[\"data\"].get(\"description\")\n",
    "                    dbgap_study_api_dict[\"phenotypeIndication\"] = study_api_data[\"data\"].get(\"primary_disease\")\n",
    "                    dbgap_study_api_dict[\"studyType\"] = study_api_data[\"data\"].get(\"study_design\")\n",
    "                    dbgap_study_api_dict[\"dbGaPPhsID\"] = dbgap_phs_id\n",
    "                    dbgap_study_api_dict[\"dbGaPStudyRegistrationName\"] = study_api_data[\"data\"].get(\"report_name\")\n",
    "                    for attr_entry in study_api_data[\"data\"].get(\"attribution\"):\n",
    "                        if attr_entry.get(\"title\") == \"Principal Investigator\":\n",
    "                            dbgap_study_api_dict[\"piName\"] = attr_entry.get(\"name\")\n",
    "                            dbgap_study_api_dict[\"piInstitution\"] = attr_entry.get(\"institute\")\n",
    "                            break\n",
    "        #             print(\"------------------------------------------------------\")\n",
    "        #             print(\"dbgap_study_api_dict\")\n",
    "        #             print(dbgap_study_api_dict)\n",
    "\n",
    "            # Pull and parse FHIR API JSON\n",
    "            dbgap_fhir_url = \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/ResearchStudy?_format=json&_id=\" + dbgap_phs_id\n",
    "            attempt_counter = 0\n",
    "            while attempt_counter <= 2:\n",
    "                try:\n",
    "                    response = requests.get(url=dbgap_fhir_url)\n",
    "                    fhir_data = json.loads(response.text)\n",
    "                    break\n",
    "                except:\n",
    "                    sleep(5)\n",
    "                    attempt_counter += 1\n",
    "\n",
    "            # Map to schema\n",
    "            if fhir_data.get(\"entry\"):\n",
    "                dbgap_fhir_dict[\"studyDescription\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"description\")\n",
    "                dbgap_fhir_dict[\"dbGaPPhsID\"] = dbgap_phs_id\n",
    "                dbgap_fhir_dict[\"dbGaPStudyRegistrationName\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"title\")\n",
    "                # NIH ICs\n",
    "                if \"Organization/\" in fhir_data[\"entry\"][0][\"resource\"][\"sponsor\"].get(\"reference\"):\n",
    "                    dbgap_fhir_dict[\"nihICsSupportingStudy\"] = [fhir_data[\"entry\"][0][\"resource\"][\"sponsor\"].get(\"reference\")[13:]]\n",
    "                else:\n",
    "                    ic_display = fhir_data[\"entry\"][0][\"resource\"][\"sponsor\"].get(\"display\")\n",
    "                    if ic_display == \"National Human Genome Research Institute\":\n",
    "                        dbgap_fhir_dict[\"nihICsSupportingStudy\"] = [\"NHGRI\"]\n",
    "                    else:\n",
    "                        dbgap_fhir_dict[\"nihICsSupportingStudy\"] = [ic_display]\n",
    "                # studyType\n",
    "                if fhir_data[\"entry\"][0][\"resource\"].get(\"category\"):\n",
    "                    for cat_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"category\"):\n",
    "                        if cat_entry.get(\"coding\"):\n",
    "                            for coding_entry in cat_entry.get(\"coding\"):\n",
    "                                if coding_entry.get(\"system\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/CodeSystem/ResearchStudy-StudyDesign\":\n",
    "                                    value = coding_entry.get(\"display\") if coding_entry.get(\"display\") else coding_entry.get(\"code\")\n",
    "                                    if dbgap_fhir_dict.get(\"studyType\") and value:\n",
    "                                        dbgap_fhir_dict[\"studyType\"] += f\", {value}\"\n",
    "                                    elif value:\n",
    "                                        dbgap_fhir_dict[\"studyType\"] = value\n",
    "                # dataTypes\n",
    "                dt_list = []\n",
    "                if fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"): \n",
    "                    for ext_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "                        if ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-MolecularDataTypes\":\n",
    "                            for inner_ext_entry in ext_entry.get(\"extension\"):\n",
    "                                if inner_ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-MolecularDataTypes-MolecularDataType\":\n",
    "                                    for coding_entry in inner_ext_entry[\"valueCodeableConcept\"].get(\"coding\"):\n",
    "                                        dt_list.append(coding_entry.get(\"code\"))\n",
    "                dbgap_fhir_dict[\"dataTypes\"] = dt_list\n",
    "                # phenotypeIndication\n",
    "                if fhir_data[\"entry\"][0][\"resource\"].get(\"focus\"):\n",
    "                    for focus_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"focus\"):\n",
    "                        if focus_entry.get(\"coding\"):\n",
    "                            for coding_entry in focus_entry.get(\"coding\"):\n",
    "                                value = coding_entry.get(\"display\") if coding_entry.get(\"display\") else coding_entry.get(\"code\")\n",
    "                                if dbgap_fhir_dict.get(\"phenotypeIndication\") and value:\n",
    "                                    dbgap_fhir_dict[\"phenotypeIndication\"] += f\", {value}\"\n",
    "                                elif value:\n",
    "                                    dbgap_fhir_dict[\"phenotypeIndication\"] = value\n",
    "                # numberOfParticipants\n",
    "                if fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "                    for ext_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "                        if ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-Content\":\n",
    "                            for inner_ext_entry in ext_entry.get(\"extension\"):\n",
    "                                if inner_ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-Content-NumSubjects\":\n",
    "                                    dbgap_fhir_dict[\"consentGroups.numberOfParticipants\"] = inner_ext_entry[\"valueCount\"].get(\"code\")\n",
    "        #         print(\"------------------------------------------------------\")\n",
    "        #         print(\"dbgap_fhir_dict\")\n",
    "        #         print(dbgap_fhir_dict)\n",
    "\n",
    "        # Reconcile information and create final results\n",
    "        consent_code = coalesce(snapshot_consent_code, terra_dict.get(\"consentGroups.consentCode\"), dbgap_fhir_dict.get(\"consentGroups.consentCode\"), dbgap_xml_dict.get(\"consentGroups.consentCode\"), dbgap_study_api_dict.get(\"consentGroups.consentCode\"))\n",
    "        if consent_code:\n",
    "            consent_code = consent_code.upper().replace(\"_\", \"-\")\n",
    "        else:\n",
    "            consent_code = \"\"\n",
    "        consortium = coalesce(duos_study_dict.get(\"consortium\"), terra_dict.get(\"consortium\"), dbgap_fhir_dict.get(\"consortium\"), dbgap_xml_dict.get(\"consortium\"), dbgap_study_api_dict.get(\"consortium\"))\n",
    "        dbGaPPhsID = coalesce(duos_study_dict.get(\"dbGaPPhsID\"), dbgap_fhir_dict.get(\"dbGaPPhsID\"), dbgap_xml_dict.get(\"dbGaPPhsID\"), dbgap_study_api_dict.get(\"dbGaPPhsID\"), terra_dict.get(\"dbGaPPhsID\"))\n",
    "        dbGaPStudyRegistrationName = coalesce(duos_study_dict.get(\"dbGaPStudyRegistrationName\"), dbgap_fhir_dict.get(\"dbGaPStudyRegistrationName\"), dbgap_xml_dict.get(\"dbGaPStudyRegistrationName\"), dbgap_study_api_dict.get(\"dbGaPStudyRegistrationName\"), terra_dict.get(\"dbGaPStudyRegistrationName\"))\n",
    "        if dbGaPPhsID and consent_code:\n",
    "            study_consent = dbGaPPhsID + \":\" + consent_code\n",
    "            purl_doid = ds_consent_map.get(study_consent)\n",
    "            if purl_doid:\n",
    "                if not isinstance(purl_doid, list):\n",
    "                    purl_doid = [purl_doid]\n",
    "            else:\n",
    "                purl_doid = []\n",
    "        else:\n",
    "            purl_doid = []\n",
    "        final_results_dict[\"snapshot_id\"] = snapshot_id\n",
    "        final_results_dict[\"snapshot_phs_id\"] = snapshot_phs_id\n",
    "        final_results_dict[\"snapshot_duos_id\"] = duos_id\n",
    "        final_results_dict[\"match_duos_id\"] = match_duos_id\n",
    "        final_results_dict[\"target_dataset_id\"] = target_dataset_id\n",
    "        final_results_dict[\"target_study_id\"] = match_study_id\n",
    "        studyName = coalesce(duos_study_dict.get(\"studyName\"), studyName)\n",
    "        if dbGaPPhsID and studyName and f\" ({dbGaPPhsID})\" not in studyName:\n",
    "            final_results_dict[\"studyName\"] = studyName + f\" ({dbGaPPhsID})\"\n",
    "        else:\n",
    "            final_results_dict[\"studyName\"] = studyName\n",
    "        final_results_dict[\"studyType\"] = coalesce(duos_study_dict.get(\"studyType\"), dbgap_fhir_dict.get(\"studyType\"), dbgap_xml_dict.get(\"studyType\"), dbgap_study_api_dict.get(\"studyType\"), terra_dict.get(\"studyType\"))\n",
    "        final_results_dict[\"studyDescription\"] = format_description(coalesce(duos_study_dict.get(\"studyDescription\"), dbgap_fhir_dict.get(\"studyDescription\"), dbgap_xml_dict.get(\"studyDescription\"), dbgap_study_api_dict.get(\"studyDescription\"), terra_dict.get(\"studyDescription\")))\n",
    "        if final_results_dict[\"studyDescription\"]:\n",
    "            if \"Platform: AnVIL\" not in final_results_dict[\"studyDescription\"]:\n",
    "                final_results_dict[\"studyDescription\"] = final_results_dict[\"studyDescription\"] + \"\\nPlatform: AnVIL\"\n",
    "        else:\n",
    "            final_results_dict[\"studyDescription\"] = \"Platform: AnVIL\"\n",
    "        final_results_dict[\"dataTypes\"] = coalesce(duos_study_dict.get(\"dataTypes\"), terra_dict.get(\"dataTypes\"), dbgap_fhir_dict.get(\"dataTypes\"), dbgap_xml_dict.get(\"dataTypes\"), dbgap_study_api_dict.get(\"dataTypes\"))\n",
    "        final_results_dict[\"phenotypeIndication\"] = coalesce(duos_study_dict.get(\"phenotypeIndication\"), terra_dict.get(\"phenotypeIndication\"), dbgap_fhir_dict.get(\"phenotypeIndication\"), dbgap_xml_dict.get(\"phenotypeIndication\"), dbgap_study_api_dict.get(\"phenotypeIndication\"))\n",
    "        final_results_dict[\"species\"] = \"Human\"\n",
    "        final_results_dict[\"piName\"] = coalesce(duos_study_dict.get(\"piName\"), dbgap_fhir_dict.get(\"piName\"), dbgap_xml_dict.get(\"piName\"), dbgap_study_api_dict.get(\"piName\"), terra_dict.get(\"piName\"), \"None\")\n",
    "        final_results_dict[\"dataCustodianEmail\"] = [\"help@lists.anvilproject.org\"]\n",
    "        final_results_dict[\"publicVisibility\"] = True\n",
    "        final_results_dict[\"nihAnvilUse\"] = \"I am NHGRI funded and I have a dbGaP PHS ID already\" if dbGaPPhsID else \"I am NHGRI funded and I do not have a dbGaP PHS ID\"\n",
    "        final_results_dict[\"submittingToAnvil\"] = True\n",
    "        final_results_dict[\"dbGaPPhsID\"] = dbGaPPhsID\n",
    "        if dbGaPPhsID and dbGaPStudyRegistrationName and f\" ({dbGaPPhsID})\" in dbGaPStudyRegistrationName:\n",
    "            final_results_dict[\"dbGaPStudyRegistrationName\"] = dbGaPStudyRegistrationName.replace(f\" ({dbGaPPhsID})\", \"\")\n",
    "        else:\n",
    "            final_results_dict[\"dbGaPStudyRegistrationName\"] = dbGaPStudyRegistrationName\n",
    "        final_results_dict[\"embargoReleaseDate\"] = coalesce(duos_study_dict.get(\"embargoReleaseDate\"), dbgap_fhir_dict.get(\"embargoReleaseDate\"), dbgap_xml_dict.get(\"embargoReleaseDate\"), dbgap_study_api_dict.get(\"embargoReleaseDate\"), terra_dict.get(\"embargoReleaseDate\"))\n",
    "        final_results_dict[\"sequencingCenter\"] = None\n",
    "        final_results_dict[\"piEmail\"] = coalesce(duos_study_dict.get(\"piEmail\"), dbgap_fhir_dict.get(\"piEmail\"), dbgap_xml_dict.get(\"piEmail\"), dbgap_study_api_dict.get(\"piEmail\"), terra_dict.get(\"piEmail\"))\n",
    "        final_results_dict[\"piInstitution\"] = coalesce(duos_study_dict.get(\"piInstitution\"), dbgap_fhir_dict.get(\"piInstitution\"), dbgap_xml_dict.get(\"piInstitution\"), dbgap_study_api_dict.get(\"piInstitution\"), terra_dict.get(\"piInstitution\"))\n",
    "        final_results_dict[\"nihGrantContractNumber\"] = None\n",
    "        final_results_dict[\"nihICsSupportingStudy\"] = coalesce(duos_study_dict.get(\"nihICsSupportingStudy\"), dbgap_fhir_dict.get(\"nihICsSupportingStudy\"), dbgap_xml_dict.get(\"nihICsSupportingStudy\"), dbgap_study_api_dict.get(\"nihICsSupportingStudy\"), terra_dict.get(\"nihICsSupportingStudy\"))\n",
    "        final_results_dict[\"nihProgramOfficerName\"] = coalesce(duos_study_dict.get(\"nihProgramOfficerName\"), dbgap_fhir_dict.get(\"nihProgramOfficerName\"), dbgap_xml_dict.get(\"nihProgramOfficerName\"), dbgap_study_api_dict.get(\"nihProgramOfficerName\"), terra_dict.get(\"nihProgramOfficerName\"))\n",
    "        final_results_dict[\"nihInstitutionCenterSubmission\"] = \"NHGRI\"\n",
    "        final_results_dict[\"nihInstitutionalCertificationFileName\"] = None\n",
    "        final_results_dict[\"nihGenomicProgramAdministratorName\"] = coalesce(duos_study_dict.get(\"nihGenomicProgramAdministratorName\"), dbgap_fhir_dict.get(\"nihGenomicProgramAdministratorName\"), dbgap_xml_dict.get(\"nihGenomicProgramAdministratorName\"), dbgap_study_api_dict.get(\"nihGenomicProgramAdministratorName\"), terra_dict.get(\"nihGenomicProgramAdministratorName\"))\n",
    "        final_results_dict[\"multiCenterStudy\"] = None\n",
    "        final_results_dict[\"collaboratingSites\"] = [consortium] if consortium else []\n",
    "        final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSR\"] = None\n",
    "        final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlan\"] = False\n",
    "        final_results_dict[\"alternativeDataSharingPlanReasons\"] = []\n",
    "        final_results_dict[\"alternativeDataSharingPlanExplanation\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlanFileName\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlanDataSubmitted\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlanDataReleased\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlanTargetDeliveryDate\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlanTargetPublicReleaseDate\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlanAccessManagement\"] = None\n",
    "        final_results_dict[\"consentGroups.consentGroupName\"] = consent_group_name\n",
    "        if access_management == \"controlled\" and 'NHGRI' not in dac_names:\n",
    "            final_results_dict[\"consentGroups.accessManagement\"] = \"external\"\n",
    "        else:\n",
    "            final_results_dict[\"consentGroups.accessManagement\"] = access_management\n",
    "        final_results_dict[\"dacId\"] = dac_names\n",
    "        final_results_dict[\"consentGroups.numberOfParticipants\"] = coalesce(terra_dict.get(\"consentGroups.numberOfParticipants\"), dbgap_fhir_dict.get(\"consentGroups.numberOfParticipants\"), dbgap_xml_dict.get(\"consentGroups.numberOfParticipants\"), dbgap_study_api_dict.get(\"consentGroups.numberOfParticipants\"), \"0\")\n",
    "        final_results_dict[\"consentCode\"] = consent_code\n",
    "        final_results_dict[\"consentGroups.generalResearchUse\"] = True if access_management == \"controlled\" and \"GRU\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.hmb\"] = True if access_management == \"controlled\" and \"HMB\" in consent_code else False\n",
    "        if purl_doid:\n",
    "            final_results_dict[\"consentGroups.diseaseSpecificUse\"] = purl_doid\n",
    "        else:\n",
    "            final_results_dict[\"consentGroups.diseaseSpecificUse\"] = []\n",
    "        final_results_dict[\"consentGroups.gs\"] = consent_code if access_management == \"controlled\" and \"GS-\" in consent_code else None\n",
    "        final_results_dict[\"consentGroups.poa\"] = True if access_management == \"controlled\" and \"POA\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.nmds\"] = True if access_management == \"controlled\" and \"NMDS\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.gso\"] = True if access_management == \"controlled\" and \"GSO\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.pub\"] = True if access_management == \"controlled\" and \"PUB\" in consent_code else False \n",
    "        final_results_dict[\"consentGroups.col\"] = True if access_management == \"controlled\" and \"COL-\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.irb\"] = True if access_management == \"controlled\" and \"IRB\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.npu\"] = True if access_management == \"controlled\" and \"NPU\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.otherPrimary\"] = consent_code if (consent_code and access_management == \"controlled\" and not (final_results_dict[\"consentGroups.generalResearchUse\"] or final_results_dict[\"consentGroups.hmb\"] or final_results_dict[\"consentGroups.diseaseSpecificUse\"] or final_results_dict[\"consentGroups.gs\"] or final_results_dict[\"consentGroups.poa\"] or final_results_dict[\"consentGroups.nmds\"] or final_results_dict[\"consentGroups.gso\"] or final_results_dict[\"consentGroups.pub\"] or final_results_dict[\"consentGroups.col\"] or final_results_dict[\"consentGroups.irb\"] or final_results_dict[\"consentGroups.npu\"])) else None\n",
    "        final_results_dict[\"consentGroups.otherSecondary\"] = None\n",
    "        final_results_dict[\"consentGroups.mor\"] = None\n",
    "        final_results_dict[\"consentGroups.morDate\"] = None\n",
    "        final_results_dict[\"consentGroups.dataLocation\"] = \"TDR Location\"\n",
    "        final_results_dict[\"consentGroups.url\"] = \"https://data.terra.bio/snapshots/\" + snapshot_id\n",
    "        final_results_dict[\"consentGroups.fileTypes.fileType\"] = coalesce(terra_dict.get(\"consentGroups.fileTypes.fileType\"), dbgap_fhir_dict.get(\"consentGroups.fileTypes.fileType\"), dbgap_xml_dict.get(\"consentGroups.fileTypes.fileType\"), dbgap_study_api_dict.get(\"consentGroups.fileTypes.fileType\"))\n",
    "        final_results_dict[\"consentGroups.fileTypes.functionalEquivalence\"] = None\n",
    "        final_results_dict[\"consortium\"] = consortium\n",
    "        dataset_details_records.append(final_results_dict)\n",
    "\n",
    "    # Return results\n",
    "    return dataset_details_records\n",
    "\n",
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# Specify the snapshots to pull data for:\n",
    "snapshot_id_list = [\n",
    "    '29ec75f0-53ac-405f-a973-b034126ae457',\n",
    "    '9393d37f-8c9d-43fa-a42a-52536a24236d',\n",
    "    '175d510a-b8e3-4e43-86da-0aec15ba1ce0',\n",
    "    '8afa7677-ce77-4ff4-9968-04f8794f26bf',\n",
    "    '69d0762d-8acd-4962-86eb-b924630858d0',\n",
    "    '48417de5-c3b9-4a1b-807b-f7cb5ba05fea',\n",
    "]\n",
    "\n",
    "# Specify a mapping from phs-consent to DOID for DS consent codes (replace \"_\" with \"-\" in consent first)\n",
    "ds_consent_map = {\n",
    "    'phs000298:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs000693:DS-BDIS': 'http://purl.obolibrary.org/obo/DOID_936',\n",
    "    'phs000693:DS-EP': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs000744:DS-RD': 'http://purl.obolibrary.org/obo/DOID_15',\n",
    "    'phs000744:DS-THAL-IRB': 'http://purl.obolibrary.org/obo/DOID_10241',\n",
    "    'phs001222:DS-DRC-IRB-NPU': 'http://purl.obolibrary.org/obo/DOID_9351',\n",
    "    'phs001227:DS-ATHSCL-IRB-MDS': 'http://purl.obolibrary.org/obo/DOID_1936',\n",
    "    'phs001259:DS-CARD-MDS-GSO': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001487:DS-MULTIPLE-DISEASES-IRB-COL-NPU-RD': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001489:DS-EAED-IRB-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EAED-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EARET-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EP': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EP-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPASM-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPI-ADULT-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPI-MULTI-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPASM-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EP-NPU': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPCOM-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBA-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBACID-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBACID-NPU-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBAID-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-MBND-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'phs001489:DS-NSD-ADULTS-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_863',\n",
    "    'phs001489:DS-NSD-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_863',\n",
    "    'phs001506:DS-CVD-IRB': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001592:DS-CVD': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001642:DS-GR-IRB-MDS': 'http://purl.obolibrary.org/obo/DOID_77',\n",
    "    'phs001642:DS-DSDI-MDS': 'http://purl.obolibrary.org/obo/DOID_77',\n",
    "    'phs001642:DS-GID': 'http://purl.obolibrary.org/obo/DOID_77',\n",
    "    'phs001642:DS-IBD': 'http://purl.obolibrary.org/obo/DOID_0050589',\n",
    "    'phs001642:DS-IBD-MDS': 'http://purl.obolibrary.org/obo/DOID_0050589',\n",
    "    'phs001676:DS-AONDD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001740:DS-ASD-RD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001741:DS-ASD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001766:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001766:DS-ASD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001871:DS-CAD-IRB': 'http://purl.obolibrary.org/obo/DOID_3393',\n",
    "    'phs001894:DS-EAC-PUB-GSO': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001901:DS-CVD-MDS': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs002004:DS-AUT': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002032:DS-SMA-MDS': 'http://purl.obolibrary.org/obo/DOID_12377',\n",
    "    'phs002032:DS-MBND-MDS': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'phs002041:DS-MLHLTH-MDS': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'phs002041:DS-SZ-MDS': 'http://purl.obolibrary.org/obo/DOID_5419',\n",
    "    'phs002041:DS-SZRD-MDS': 'http://purl.obolibrary.org/obo/DOID_5419',\n",
    "    'phs002042:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002043:DS-AASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002044:DS-ASD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002206:DS-PEDD-IRB': 'http://purl.obolibrary.org/obo/DOID_4',\n",
    "    'phs002282:DS-CVDRF': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs002502:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002502:DS-ASD-MDS': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002502:DS-ASD-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002502:DS-ASD-NPU': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'ph2002502:DS-MLHLTH-IRB-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'ph2002502:DS-MH': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'phs002502:DS-MBND-MDS': 'http://purl.obolibrary.org/obo/DOID_1289',\n",
    "    'phs003200:DS-MSC-MDS': ['http://purl.obolibrary.org/obo/DOID_1909', 'http://purl.obolibrary.org/obo/DOID_4159']\n",
    "}\n",
    "\n",
    "# Token for use in DUOS (use gcloud auth print-access-token to get this)\n",
    "duos_token = \"\"\n",
    "\n",
    "# DUOS Environment\n",
    "duos_env = \"prod\"\n",
    "\n",
    "# Specify whether results should be written out to a file in the workspace bucket\n",
    "write_to_bucket = True\n",
    "\n",
    "# Set the below to \"False\" to turn off matching to existing dataset/study information in DUOS (to see what the original values would have been)\n",
    "match_existing = False\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "dataset_details_records = fetch_dataset_details(snapshot_id_list, ds_consent_map, duos_token, duos_env, match_existing)\n",
    "output = pd.DataFrame(dataset_details_records)\n",
    "output_sorted = output.sort_values(by=[\"studyName\", \"consentGroups.consentGroupName\"], ascending=[True, True], ignore_index=True)\n",
    "\n",
    "#############################################\n",
    "## Validation and Output\n",
    "#############################################\n",
    "# Create copy of dataframe for unique value validation\n",
    "output_unique_val = output_sorted.copy()\n",
    "\n",
    "# Convert study list fields to strings\n",
    "list_fields = [\"dataTypes\", \"dataCustodianEmail\", \"nihICsSupportingStudy\", \"collaboratingSites\", \"alternativeDataSharingPlanReasons\"]\n",
    "for field in list_fields:\n",
    "    output_unique_val[field] = [try_join(l) for l in output_unique_val[field]]\n",
    "\n",
    "# Get unique values per study-level field, by study\n",
    "study_level_col_list = []\n",
    "for col in output_unique_val.columns:\n",
    "    if \"consentGroups.\" not in col and col not in [\"studyName\", \"snapshot_id\", \"consortium\", \"consentCode\", \"snapshot_duos_id\", \"match_duos_id\"]:\n",
    "        study_level_col_list.append(col)\n",
    "df_unique = output_unique_val.groupby(\"studyName\")[study_level_col_list].nunique()\n",
    "df_unique[\"unique_value_validation\"] = df_unique.max(axis=1)\n",
    "df_unique[\"unique_value_validation\"] = [\"Pass\" if l <= 1 else \"Fail\" for l in df_unique[\"unique_value_validation\"]]\n",
    "\n",
    "# Create copy of dataframe for enum validation\n",
    "output_enum_val = output_sorted.copy()\n",
    "\n",
    "# Validate enum fields\n",
    "output_enum_val[\"studyType\"] = [val_study_type_enum(l) for l in output_enum_val[\"studyType\"]]\n",
    "output_enum_val[\"nihInstitutionCenterSubmission\"] = [val_nih_inst_center_sub_enum(l) for l in output_enum_val[\"nihInstitutionCenterSubmission\"]]\n",
    "output_enum_val[\"nihICsSupportingStudy\"] = [val_nih_ic_supp_study_enum(l) for l in output_enum_val[\"nihICsSupportingStudy\"]]\n",
    "output_enum_val[\"consentGroups.fileTypes.fileType\"] = [val_file_type_enum(l) for l in output_enum_val[\"consentGroups.fileTypes.fileType\"]]\n",
    "study_enum_cols = [\"studyType\", \"nihInstitutionCenterSubmission\", \"nihICsSupportingStudy\"]\n",
    "df_study_enum = output_enum_val.groupby(\"studyName\")[study_enum_cols].sum()\n",
    "df_study_enum[\"study_enum_value_validation\"] = df_study_enum.max(axis=1)\n",
    "df_study_enum[\"study_enum_value_validation\"] = [\"Pass\" if l < 1 else \"Fail\" for l in df_study_enum[\"study_enum_value_validation\"]]\n",
    "consent_group_enum_cols = [\"consentGroups.fileTypes.fileType\"]\n",
    "df_consent_group_enum = output_enum_val.groupby(\"consentGroups.consentGroupName\")[consent_group_enum_cols].sum()\n",
    "df_consent_group_enum[\"consent_group_enum_value_validation\"] = df_consent_group_enum.max(axis=1)\n",
    "df_consent_group_enum[\"consent_group_enum_value_validation\"] = [\"Pass\" if l < 1 else \"Fail\" for l in df_consent_group_enum[\"consent_group_enum_value_validation\"]]\n",
    "\n",
    "# Join validation dataframes to original dataframe\n",
    "output_sorted_validated = output_sorted.join(df_unique[\"unique_value_validation\"], on=\"studyName\", how=\"left\")\n",
    "output_sorted_validated = output_sorted_validated.join(df_study_enum[\"study_enum_value_validation\"], on=\"studyName\", how=\"left\")\n",
    "output_sorted_validated = output_sorted_validated.join(df_consent_group_enum[\"consent_group_enum_value_validation\"], on=\"consentGroups.consentGroupName\", how=\"left\")\n",
    "\n",
    "# Write out output\n",
    "current_datetime_string = datetime.datetime.now().strftime(\"%Y%m%d%H:%M:%S\")\n",
    "output_file = f\"dataset_metadata_{current_datetime_string}.tsv\"\n",
    "output_sorted_validated.to_csv(output_file, index=False, sep=\"\\t\")\n",
    "!gsutil cp $output_file $ws_bucket/dataset_metadata/output/ 2> stdout\n",
    "\n",
    "# Display outputs\n",
    "print(\"----------------------------------------------------------------------------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------------\")\n",
    "print(\"Validated Metadata Output:\")\n",
    "display(output_sorted_validated.style.hide(axis=\"index\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Step 2: Load Reviewed Metadata into DUOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4,
     23,
     38
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Functions\n",
    "#############################################\n",
    "\n",
    "def format_list(input_list, min_items):\n",
    "    if input_list:\n",
    "        if isinstance(input_list, list):\n",
    "            return input_list\n",
    "        elif isinstance(input_list, str):\n",
    "            return format_list(ast.literal_eval(input_list), min_items)\n",
    "        else:\n",
    "            return []\n",
    "    else:\n",
    "        if min_items > 0:\n",
    "            i = 0\n",
    "            temp_list = []\n",
    "            while i < min_items:\n",
    "                temp_list.append(\"Unknown\")\n",
    "                i += 1\n",
    "            return temp_list\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "def format_file_types(ft_list, fe):\n",
    "    if ft_list:\n",
    "        output_list = []\n",
    "        formatted_ft_list = format_list(ft_list, 0)\n",
    "        for ft in formatted_ft_list:\n",
    "            ft_dict = {\"fileType\": ft}\n",
    "            if fe:\n",
    "                ft_dict[\"functionalEquivalence\"] = fe\n",
    "            else:\n",
    "                ft_dict[\"functionalEquivalence\"] = \"Unknown\"\n",
    "            output_list.append(ft_dict)\n",
    "        return output_list\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "def upload_to_duos(input_file, token, env, study_upload_list, preview_only, include_anvil_in_preview):\n",
    "    \n",
    "    # Determine the target URL from the env variable\n",
    "    if env == \"prod\":\n",
    "        url = \"https://consent.dsde-prod.broadinstitute.org\"\n",
    "    else:\n",
    "        url = \"https://consent.dsde-dev.broadinstitute.org\"\n",
    "    \n",
    "    # Pull down specified file from the cloud\n",
    "    results_log = []\n",
    "    print(f\"Downloading input file {input_file}...\")\n",
    "    try:\n",
    "        input_df = pd.read_csv(input_file, delimiter = \"\\t\", encoding='unicode_escape')\n",
    "        input_df = input_df.astype(object).where(pd.notnull(input_df),None)\n",
    "        input_df.fillna(\"\",inplace=True)\n",
    "        input_dict = input_df.to_dict(orient=\"records\")\n",
    "        results_log.append([\"Input File Download\", \"Succeeded\", \"\"])\n",
    "    except Exception as e:\n",
    "        msg = f\"Error downloading input file ({input_file}): {str(e)}\"\n",
    "        results_log.append([\"Input File Download\", \"Failed\", msg])\n",
    "        print(msg)\n",
    "        return results_log\n",
    "\n",
    "    # Parse and build DUOS schema for inputted file\n",
    "    print(\"Parsing input file and formatting into DUOS schema...\")\n",
    "    upload_dict = {}\n",
    "    study_lookup = {}\n",
    "    try:\n",
    "        # Determine data submitter id\n",
    "        response = requests.get(\n",
    "            url=f\"{url}/api/user/me\",\n",
    "            headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "        ).json()\n",
    "        data_submitter_id = response[\"userId\"]\n",
    "        # Build dictionary for upload\n",
    "        existing_dataset_cnt = 0\n",
    "        new_dataset_cnt = 0\n",
    "        for input_entry in input_dict:\n",
    "            snapshot_id = input_entry[\"snapshot_id\"]\n",
    "            dataset_id = str(int(input_entry[\"target_dataset_id\"])) if input_entry[\"target_dataset_id\"] else input_entry[\"target_dataset_id\"]\n",
    "            dataset_name = input_entry[\"consentGroups.consentGroupName\"]\n",
    "            study_id = str(int(input_entry[\"target_study_id\"])) if input_entry[\"target_study_id\"] else input_entry[\"target_study_id\"]\n",
    "            study_name = input_entry[\"studyName\"]\n",
    "            if study_id:\n",
    "                study_lookup[study_name] = study_id\n",
    "            tar_ds_id = dataset_id if dataset_id else \"ID_TBD\"\n",
    "            tar_st_id = study_id if study_id else \"ID_TBD\"\n",
    "            access_type = input_entry[\"consentGroups.accessManagement\"]\n",
    "            file_types_dict = []\n",
    "            if input_entry.get(\"consentGroups.fileTypes\"):\n",
    "                file_types_dict = json.loads(input_dict[0][\"consentGroups.fileTypes\"])\n",
    "            print(f\"Parsing and formatting metadata for snapshot {snapshot_id} from the input file. Target study is: {study_name} ({tar_st_id}). Target consent group is: {dataset_name} ({tar_ds_id})\")\n",
    "\n",
    "            # If this is an existing dataset in the specified existing study, provide limited consent group information (for updates only)\n",
    "            if dataset_id:\n",
    "                existing_dataset_cnt += 1\n",
    "                consent_group_dict = {\n",
    "                            \"consentGroupName\": dataset_name,\n",
    "                            \"datasetId\": dataset_id,\n",
    "                            \"numberOfParticipants\": input_entry[\"consentGroups.numberOfParticipants\"],\n",
    "                            \"dataLocation\": input_entry[\"consentGroups.dataLocation\"],\n",
    "                            \"url\": input_entry[\"consentGroups.url\"],\n",
    "                            \"fileTypes\": []\n",
    "                            #\"fileTypes\": format_file_types(input_entry[\"consentGroups.fileTypes.fileType\"], input_entry[\"consentGroups.fileTypes.functionalEquivalence\"]) --> Enumeration, exclude for now\n",
    "                    }\n",
    "            # If this is a new dataset that is open access, provide limited consent group information\n",
    "            elif access_type == \"open\":\n",
    "                new_dataset_cnt += 1\n",
    "                consent_group_dict = {\n",
    "                            \"consentGroupName\": dataset_name,\n",
    "                            \"accessManagement\": access_type,\n",
    "                            \"numberOfParticipants\": input_entry[\"consentGroups.numberOfParticipants\"],\n",
    "                            \"dataLocation\": input_entry[\"consentGroups.dataLocation\"],\n",
    "                            \"url\": input_entry[\"consentGroups.url\"],\n",
    "                            \"fileTypes\": []\n",
    "                            #\"fileTypes\": format_file_types(input_entry[\"consentGroups.fileTypes.fileType\"], input_entry[\"consentGroups.fileTypes.functionalEquivalence\"]) --> Enumeration, exclude for now\n",
    "                    }\n",
    "            # If this is a new dataset that is external access, provide consent group information (minus the dac_id)\n",
    "            elif access_type == \"external\":\n",
    "                new_dataset_cnt += 1\n",
    "                consent_group_dict = {\n",
    "                            \"consentGroupName\": dataset_name,\n",
    "                            \"accessManagement\": access_type,\n",
    "                            \"numberOfParticipants\": input_entry[\"consentGroups.numberOfParticipants\"],\n",
    "                            \"generalResearchUse\": input_entry[\"consentGroups.generalResearchUse\"],\n",
    "                            \"hmb\": input_entry[\"consentGroups.hmb\"],\n",
    "                            \"diseaseSpecificUse\": format_list(input_entry[\"consentGroups.diseaseSpecificUse\"], 0),\n",
    "                            \"gs\": input_entry[\"consentGroups.gs\"],\n",
    "                            \"poa\": input_entry[\"consentGroups.poa\"],\n",
    "                            \"nmds\": input_entry[\"consentGroups.nmds\"],\n",
    "                            \"gso\": input_entry[\"consentGroups.gso\"],\n",
    "                            \"pub\": input_entry[\"consentGroups.pub\"],\n",
    "                            \"col\": input_entry[\"consentGroups.col\"],\n",
    "                            \"irb\": input_entry[\"consentGroups.irb\"],\n",
    "                            \"npu\": input_entry[\"consentGroups.npu\"],\n",
    "                            \"otherPrimary\": input_entry[\"consentGroups.otherPrimary\"],\n",
    "                            #\"otherSecondary\": input_entry[\"consentGroups.otherSecondary\"], --> Excluding for now, per JL's request\n",
    "                            #\"mor\": input_entry[\"consentGroups.mor\"], --> Date formatting validation for morDate, exclude for now\n",
    "                            #\"morDate\": input_entry[\"consentGroups.morDate\"], --> Date formatting validation, exclude for now\n",
    "                            \"dataLocation\": input_entry[\"consentGroups.dataLocation\"],\n",
    "                            \"url\": input_entry[\"consentGroups.url\"],\n",
    "                            \"fileTypes\": []\n",
    "                            #\"fileTypes\": format_file_types(input_entry[\"consentGroups.fileTypes.fileType\"], input_entry[\"consentGroups.fileTypes.functionalEquivalence\"]) --> Enumeration, exclude for now\n",
    "                    }\n",
    "            # If this is a new dataset that is NOT open or external access, provide the full consent group information\n",
    "            else:\n",
    "                new_dataset_cnt += 1\n",
    "                consent_group_dict = {\n",
    "                            \"consentGroupName\": dataset_name,\n",
    "                            \"dataAccessCommitteeId\": input_entry[\"dacId\"],\n",
    "                            \"accessManagement\": access_type,\n",
    "                            \"numberOfParticipants\": input_entry[\"consentGroups.numberOfParticipants\"],\n",
    "                            \"generalResearchUse\": input_entry[\"consentGroups.generalResearchUse\"],\n",
    "                            \"hmb\": input_entry[\"consentGroups.hmb\"],\n",
    "                            \"diseaseSpecificUse\": format_list(input_entry[\"consentGroups.diseaseSpecificUse\"], 0),\n",
    "                            \"gs\": input_entry[\"consentGroups.gs\"],\n",
    "                            \"poa\": input_entry[\"consentGroups.poa\"],\n",
    "                            \"nmds\": input_entry[\"consentGroups.nmds\"],\n",
    "                            \"gso\": input_entry[\"consentGroups.gso\"],\n",
    "                            \"pub\": input_entry[\"consentGroups.pub\"],\n",
    "                            \"col\": input_entry[\"consentGroups.col\"],\n",
    "                            \"irb\": input_entry[\"consentGroups.irb\"],\n",
    "                            \"npu\": input_entry[\"consentGroups.npu\"],\n",
    "                            \"otherPrimary\": input_entry[\"consentGroups.otherPrimary\"],\n",
    "                            #\"otherSecondary\": input_entry[\"consentGroups.otherSecondary\"], --> Excluding for now, per JL's request\n",
    "                            #\"mor\": input_entry[\"consentGroups.mor\"], --> Date formatting validation for morDate, exclude for now\n",
    "                            #\"morDate\": input_entry[\"consentGroups.morDate\"], --> Date formatting validation, exclude for now\n",
    "                            \"dataLocation\": input_entry[\"consentGroups.dataLocation\"],\n",
    "                            \"url\": input_entry[\"consentGroups.url\"],\n",
    "                            \"fileTypes\": []\n",
    "                            #\"fileTypes\": format_file_types(input_entry[\"consentGroups.fileTypes.fileType\"], input_entry[\"consentGroups.fileTypes.functionalEquivalence\"]) --> Enumeration, exclude for now\n",
    "                    }\n",
    "\n",
    "            # If the study associated with the record is not already in the upload dictionary, create a new study dict and append the consent group dict\n",
    "            study_dict = {}\n",
    "            consent_group_list = []\n",
    "            if study_name not in upload_dict.keys():\n",
    "                consent_group_list.append(consent_group_dict)\n",
    "                study_dict = {\n",
    "                    \"studyName\": study_name,\n",
    "                    #\"studyType\": input_entry[\"studyType\"], --> Enumeration, exclude for now\n",
    "                    \"studyDescription\": input_entry[\"studyDescription\"].replace(\"\\\\n\", \"\\n\"),\n",
    "                    \"dataTypes\": format_list(input_entry[\"dataTypes\"], 1),\n",
    "                    \"phenotypeIndication\": input_entry[\"phenotypeIndication\"],\n",
    "                    \"species\": input_entry[\"species\"],\n",
    "                    \"piName\": input_entry[\"piName\"] if input_entry[\"piName\"] else \"NA\",\n",
    "                    \"dataSubmitterUserId\": data_submitter_id,\n",
    "                    \"dataCustodianEmail\": format_list(input_entry[\"dataCustodianEmail\"], 0),\n",
    "                    \"publicVisibility\": input_entry[\"publicVisibility\"],\n",
    "                    \"nihAnvilUse\": input_entry[\"nihAnvilUse\"],\n",
    "                    \"submittingToAnvil\": input_entry[\"submittingToAnvil\"],\n",
    "                    \"dbGaPPhsID\": input_entry[\"dbGaPPhsID\"],\n",
    "                    \"dbGaPStudyRegistrationName\": input_entry[\"studyName\"],\n",
    "                    #\"embargoReleaseDate\": input_entry[\"embargoReleaseDate\"], --> Date formatting validation, exclude for now\n",
    "                    \"sequencingCenter\": input_entry[\"sequencingCenter\"],\n",
    "                    \"piEmail\": input_entry[\"piEmail\"],\n",
    "                    #\"piInstitution\": input_entry[\"piInstitution\"], --> Integer ID for registered institutions, exclude for now\n",
    "                    \"piInstitution\": 0,\n",
    "                    \"nihGrantContractNumber\": \"Unknown\", # Required currently\n",
    "                    \"nihICsSupportingStudy\": format_list(input_entry[\"nihICsSupportingStudy\"], 0),\n",
    "                    \"nihProgramOfficerName\": input_entry[\"nihProgramOfficerName\"],\n",
    "                    \"nihInstitutionCenterSubmission\": input_entry[\"nihInstitutionCenterSubmission\"],\n",
    "                    \"nihInstitutionalCertificationFileName\": input_entry[\"nihInstitutionalCertificationFileName\"],\n",
    "                    \"nihGenomicProgramAdministratorName\": input_entry[\"nihGenomicProgramAdministratorName\"],\n",
    "                    \"collaboratingSites\": format_list(input_entry[\"collaboratingSites\"], 0),\n",
    "                    \"alternativeDataSharingPlan\": input_entry[\"alternativeDataSharingPlan\"],\n",
    "                    \"alternativeDataSharingPlanExplanation\": input_entry[\"alternativeDataSharingPlanExplanation\"],\n",
    "                    \"alternativeDataSharingPlanReasons\": [\"Other\"] if input_entry[\"alternativeDataSharingPlan\"] == True and input_entry[\"alternativeDataSharingPlanReasons\"] == \"[]\" else format_list(input_entry[\"alternativeDataSharingPlanReasons\"], 0), \n",
    "                    \"consentGroups\": consent_group_list\n",
    "                }\n",
    "                upload_dict[study_name] = study_dict\n",
    "            # If the study is already in the upload dictionary, create an updated study dict and extend its list of consent groups\n",
    "            else:\n",
    "                study_dict = upload_dict[study_name].copy()\n",
    "                for consent_group in study_dict[\"consentGroups\"]:\n",
    "                    if consent_group[\"consentGroupName\"] != consent_group_dict[\"consentGroupName\"]:\n",
    "                        consent_group_list.append(consent_group)\n",
    "                consent_group_list.append(consent_group_dict)\n",
    "                study_dict[\"consentGroups\"] = consent_group_list\n",
    "                upload_dict[study_name] = study_dict\n",
    "        msg = f\"Input file formatting complete. Existing Datasets: {existing_dataset_cnt} New Datasets: {new_dataset_cnt}\"\n",
    "        print(msg)\n",
    "        results_log.append([\"Input File Parsing and Formatting\", \"Succeeded\", msg])\n",
    "    except Exception as e:\n",
    "        msg = f\"Error parsing and formatting input file: {str(e)}\"\n",
    "        results_log.append([\"Input File Parsing and Formatting\", \"Failed\", msg])\n",
    "        print(msg)\n",
    "        #return results_log\n",
    "\n",
    "    # Loop through studies to upload and augment with an missing existing datasets\n",
    "    print(\"Augmenting upload set with missing existing datasets...\")\n",
    "    dataset_upload_aug_list = []\n",
    "    for study in upload_dict.keys():\n",
    "        if study in study_upload_list or len(study_upload_list) == 0:\n",
    "            study_id = study_lookup.get(study)\n",
    "            if study_id:\n",
    "                try:\n",
    "                    study_datasets_in_duos = set()\n",
    "                    study_datasets_in_input = set()\n",
    "                    study_datasets_diff = set()\n",
    "                    study_details = requests.get(\n",
    "                            url=f\"{url}/api/dataset/study/registration/{study_id}\",\n",
    "                            headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "                        ).json()\n",
    "                    for dataset in study_details[\"consentGroups\"]:\n",
    "                        if dataset.get(\"datasetId\"):\n",
    "                            study_datasets_in_duos.add(dataset.get(\"datasetId\"))\n",
    "                    for dataset in upload_dict[study][\"consentGroups\"]:\n",
    "                        if dataset.get(\"datasetId\"):\n",
    "                            study_datasets_in_input.add(dataset.get(\"datasetId\"))\n",
    "                    for dataset_in_duos in study_datasets_in_duos:\n",
    "                        if str(dataset_in_duos) not in study_datasets_in_input:\n",
    "                            study_datasets_diff.add(dataset_in_duos)\n",
    "                    # Add missing datasets to the upload dict\n",
    "                    temp_cg = upload_dict[study][\"consentGroups\"].copy()\n",
    "                    for missing_dataset_id in study_datasets_diff:\n",
    "                        dataset_upload_aug_list.append(missing_dataset_id)\n",
    "                        dataset_details = requests.get(\n",
    "                            url=f\"{url}/api/dataset/v2/{missing_dataset_id}\",\n",
    "                            headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "                        ).json()\n",
    "                        name = dataset_details[\"name\"]\n",
    "                        data_loc = \"\"\n",
    "                        data_loc_url = \"\"\n",
    "                        num_participants = 0\n",
    "                        for prop_entry in dataset_details[\"properties\"]:\n",
    "                            if prop_entry[\"propertyName\"] == \"Data Location\":\n",
    "                                data_loc = prop_entry[\"propertyValue\"]\n",
    "                            elif prop_entry[\"propertyName\"] == \"# of participants\":\n",
    "                                num_participants = prop_entry[\"propertyValue\"]\n",
    "                            elif prop_entry[\"propertyName\"] == \"URL\":\n",
    "                                data_loc_url = prop_entry[\"propertyValue\"] \n",
    "                        consent_group_dict = {\n",
    "                            \"consentGroupName\": dataset_details[\"name\"],\n",
    "                            \"datasetId\": missing_dataset_id,\n",
    "                            \"numberOfParticipants\": num_participants,\n",
    "                            \"dataLocation\": data_loc,\n",
    "                            \"url\": data_loc_url,\n",
    "                            \"fileTypes\": []\n",
    "                        }\n",
    "                        temp_cg.append(consent_group_dict)\n",
    "                    upload_dict[study][\"consentGroups\"] = temp_cg\n",
    "                except:\n",
    "                    print(f\"WARNING: Issue retrieving study details for study_id {study_id}. May cause issues with upload downstream.\")\n",
    "\n",
    "    # Preview of upload input dictionary\n",
    "    if preview_only:\n",
    "        # Build a preview of the upload dictionary data\n",
    "        print(\"Building upload set preview...\")\n",
    "        output_preview = []\n",
    "        study_id_set = set()\n",
    "        for study_name, study_dict in upload_dict.items():\n",
    "            if study_name in study_upload_list or len(study_upload_list) == 0:\n",
    "                study_id = study_lookup.get(study_name) if study_lookup.get(study_name) else f\"ID_TBD ({study_name})\"\n",
    "                study_id_set.add(study_id)\n",
    "                study_phs = study_dict[\"dbGaPPhsID\"]\n",
    "                for consent_group in study_dict[\"consentGroups\"]:\n",
    "                    dataset_id = consent_group.get(\"datasetId\")\n",
    "                    dataset_name = consent_group.get(\"consentGroupName\")\n",
    "                    snapshot_url = consent_group.get(\"url\")\n",
    "                    if snapshot_url and \"https://data.terra.bio/snapshots/\" in snapshot_url and dataset_id in dataset_upload_aug_list:\n",
    "                        snapshot_id = snapshot_url.replace(\"https://data.terra.bio/snapshots/\", \"\")\n",
    "                        record_src = \"upload_aug\"\n",
    "                    elif snapshot_url and \"https://data.terra.bio/snapshots/\" in snapshot_url:\n",
    "                        snapshot_id = snapshot_url.replace(\"https://data.terra.bio/snapshots/\", \"\")\n",
    "                        record_src = \"upload\"\n",
    "                    else:\n",
    "                        snapshot_id = \"\"\n",
    "                        record_src = \"upload_aug\"\n",
    "                    if dataset_id:\n",
    "                        dataset_details = requests.get(\n",
    "                            url=f\"{url}/api/dataset/v2/{dataset_id}\",\n",
    "                            headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "                        ).json()\n",
    "                        dataset_identifier = dataset_details.get(\"datasetIdentifier\")\n",
    "                        dac_id = dataset_details.get(\"dacId\") if dataset_details.get(\"dacId\") else \"\"\n",
    "                        duos_data_use_dict = dataset_details.get(\"dataUse\")\n",
    "                        du_gru = duos_data_use_dict.get(\"generalUse\") if duos_data_use_dict.get(\"generalUse\") else False\n",
    "                        du_hmb = duos_data_use_dict.get(\"hmbResearch\") if duos_data_use_dict.get(\"hmbResearch\") else False\n",
    "                        du_disease = duos_data_use_dict.get(\"diseaseRestrictions\") if duos_data_use_dict.get(\"diseaseRestrictions\") else []\n",
    "                        du_poa = duos_data_use_dict.get(\"populationOriginsAncestry\") if duos_data_use_dict.get(\"populationOriginsAncestry\") else False\n",
    "                        du_ethics = duos_data_use_dict.get(\"ethicsApprovalRequired\") if duos_data_use_dict.get(\"ethicsApprovalRequired\") else False\n",
    "                        du_collab = duos_data_use_dict.get(\"collaboratorRequired\") if duos_data_use_dict.get(\"collaboratorRequired\") else False\n",
    "                        du_geog = duos_data_use_dict.get(\"geographicalRestrictions\") if duos_data_use_dict.get(\"geographicalRestrictions\") else \"\"\n",
    "                        du_genetic = duos_data_use_dict.get(\"geneticStudiesOnly\") if duos_data_use_dict.get(\"geneticStudiesOnly\") else False\n",
    "                        du_pub = duos_data_use_dict.get(\"publicationResults\") if duos_data_use_dict.get(\"publicationResults\") else False\n",
    "                        du_nmds = duos_data_use_dict.get(\"methodsResearch\") if duos_data_use_dict.get(\"methodsResearch\") else False\n",
    "                        du_npu = duos_data_use_dict.get(\"nonProfitUse\") if duos_data_use_dict.get(\"nonProfitUse\") else False\n",
    "                        du_other = duos_data_use_dict.get(\"other\") if duos_data_use_dict.get(\"other\") else \"\"\n",
    "                        access_management = \"\"\n",
    "                        for prop_entry in dataset_details[\"properties\"]:\n",
    "                            if prop_entry[\"propertyName\"] == \"Access Management\":\n",
    "                                access_management = prop_entry[\"propertyValue\"]\n",
    "                                break\n",
    "                    else:\n",
    "                        dataset_id = f\"ID_TBD ({dataset_name})\"\n",
    "                        dataset_identifier = \"ID_TBD\"\n",
    "                        dac_id = consent_group.get(\"dataAccessCommitteeId\") if consent_group.get(\"dataAccessCommitteeId\") else \"\"\n",
    "                        du_gru = consent_group.get(\"generalResearchUse\") if consent_group.get(\"generalResearchUse\") else False\n",
    "                        du_hmb = consent_group.get(\"hmb\") if consent_group.get(\"hmb\") else False\n",
    "                        du_disease = consent_group.get(\"diseaseSpecificUse\") if consent_group.get(\"diseaseSpecificUse\") else []\n",
    "                        du_poa = consent_group.get(\"poa\") if consent_group.get(\"poa\") else False\n",
    "                        du_ethics = consent_group.get(\"irb\") if consent_group.get(\"irb\") else False\n",
    "                        du_collab = consent_group.get(\"col\") if consent_group.get(\"col\") else False\n",
    "                        du_geog = consent_group.get(\"gs\") if consent_group.get(\"gs\") else \"\"\n",
    "                        du_genetic = consent_group.get(\"gso\") if consent_group.get(\"gso\") else False\n",
    "                        du_pub = consent_group.get(\"pub\") if consent_group.get(\"pub\") else False\n",
    "                        du_nmds = consent_group.get(\"nmds\") if consent_group.get(\"nmds\") else False\n",
    "                        du_npu = consent_group.get(\"npu\") if consent_group.get(\"npu\") else False\n",
    "                        du_other = consent_group.get(\"otherPrimary\") if consent_group.get(\"otherPrimary\") else \"\"\n",
    "                        access_management = consent_group.get(\"accessManagement\") if consent_group.get(\"accessManagement\") else \"\" \n",
    "                    output_preview.append([study_id, study_name, study_phs, dataset_id, dataset_identifier, dataset_name, dac_id, access_management, du_gru, du_hmb, du_disease, du_poa, du_ethics, du_collab, du_geog, du_genetic, du_pub, du_nmds, du_npu, du_other, snapshot_id, record_src])\n",
    "\n",
    "        # Add in AnVIL datasets not in the upload dictionary \n",
    "        if len(study_upload_list) == 0 and include_anvil_in_preview:\n",
    "            anvil_datasets_in_duos = get_anvil_datasets_from_duos(token, env)\n",
    "            for dataset in anvil_datasets_in_duos:\n",
    "                dataset_exists = False\n",
    "                for output_dataset in output_preview:\n",
    "                    if str(dataset[3]) == str(output_dataset[3]):\n",
    "                        dataset_exists = True\n",
    "                        break\n",
    "                if not dataset_exists:\n",
    "                    rec_to_add = dataset.copy()\n",
    "                    rec_to_add.append(\"prod_add\")\n",
    "                    output_preview.append(rec_to_add)\n",
    "\n",
    "        # Display output preview\n",
    "        df_results = pd.DataFrame(output_preview, columns = [\"Study ID\", \"Study Name\", \"Study PHS\", \"Dataset ID\", \"Dataset Identifier\", \"Dataset Name\", \"DAC ID\", \"Access\", \"GRU\", \"HMB\", \"DS\", \"POA\", \"IRB\", \"COL\", \"GS\", \"GSO\", \"PUB\", \"NMDS\", \"NPU\", \"OTHER\", \"Snapshot ID\", \"Record Source\"])\n",
    "        print(\"\\nOutput Preview:\")\n",
    "        display(df_results)\n",
    "    \n",
    "    else:\n",
    "        print(\"Uploading studies to DUOS...\")\n",
    "        for study in upload_dict.keys():\n",
    "            if study in study_upload_list or len(study_upload_list) == 0:\n",
    "                study_id = study_lookup.get(study)\n",
    "                # For studies that don't exist in DUOS, create a new study\n",
    "                if not study_id:\n",
    "                    print(\"Study does NOT currently exist in DUOS. Registering new study...\")\n",
    "                    try:\n",
    "                        new_study_response = requests.post(\n",
    "                            url=f\"{url}/api/dataset/v3\",\n",
    "                            headers={\"Authorization\": f\"Bearer {token}\"},\n",
    "                            files = {\n",
    "                                \"dataset\": json.dumps(upload_dict[study]),\n",
    "                                \"alternativeDataSharingPlan\": \"\",\n",
    "                                \"consentGroups[0].nihInstitutionalCertificationFile\": \"\"  \n",
    "                            }\n",
    "                        ).json()\n",
    "                        if new_study_response.get(\"studyId\"):\n",
    "                            study_id = new_study_response[\"studyId\"]\n",
    "                            msg = f\"Study registration succeeded! Study Id: {study_id}\"\n",
    "                            results_log.append([f\"New Study Registration - {study}\", \"Succeeded\", msg])\n",
    "                            print(msg)\n",
    "                        else:\n",
    "                            err_msg = new_study_response[\"message\"]\n",
    "                            msg = f\"Study registration failed: {err_msg}\"\n",
    "                            results_log.append([f\"New Study Registration - {study}\", \"Failed\", msg])\n",
    "                            print(msg)\n",
    "                    except Exception as e:\n",
    "                        msg = f\"Study registration failed: {str(e)}\"\n",
    "                        results_log.append([f\"New Study Registration - {study}\", \"Failed\", msg])\n",
    "                        print(msg)\n",
    "                # For studies that already exist in DUOS, update the existing study\n",
    "                else:\n",
    "                    print(\"Study DOES currently exist in DUOS. Updating study...\")\n",
    "                    try:\n",
    "                        # Update study in DUOS\n",
    "#                         print(study_id)\n",
    "#                         print(json.dumps(upload_dict[study]))\n",
    "                        update_study_response = requests.put(\n",
    "                            url=f\"{url}/api/dataset/study/{study_id}\",\n",
    "                            headers={\"Authorization\": f\"Bearer {token}\"},\n",
    "                            files = {\n",
    "                                \"dataset\": json.dumps(upload_dict[study]),\n",
    "                                \"alternativeDataSharingPlan\": \"\",\n",
    "                                \"consentGroups[0].nihInstitutionalCertificationFile\": \"\"  \n",
    "                            }\n",
    "                        ).json()   \n",
    "                        if update_study_response.get(\"studyId\"):\n",
    "                            study_id = update_study_response[\"studyId\"]\n",
    "                            msg = f\"Study registration succeeded! Study Id: {study_id}\"\n",
    "                            results_log.append([f\"Study Registration Update - {study}\", \"Succeeded\", msg])\n",
    "                            print(msg)\n",
    "                        else:\n",
    "                            err_msg = update_study_response[\"message\"]\n",
    "                            msg = f\"Study registration failed: {err_msg}\"\n",
    "                            results_log.append([f\"Study Registration Update - {study}\", \"Failed\", msg])\n",
    "                            print(msg)\n",
    "                    except Exception as e:\n",
    "                        msg = f\"Study registration failed: {str(e)}\"\n",
    "                        results_log.append([f\"Study Registration Update - {study}\", \"Failed\", msg])\n",
    "                        print(msg)\n",
    "    \n",
    "    # Return results\n",
    "    return results_log\n",
    "\n",
    "\n",
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# Cloud path to file to process\n",
    "input_file_gcs_path = \"gs://fc-2a9eefc3-0302-427f-9ac3-82f078741c03/dataset_metadata/input/firecloud_target_tcga_metadata_20250227.tsv\"\n",
    "\n",
    "# User token (use gcloud auth print-access-token to get this)\n",
    "duos_token = \"\"\n",
    "\n",
    "# Environment\n",
    "duos_env = \"dev\"\n",
    "\n",
    "# Study Upload List (to limit the studies upload, leave empty for all)\n",
    "study_upload_list = [\n",
    "#     \"Center for Common Disease Genomics [CCDG] - Autoimmune: Inflammatory Bowel Disease (IBD) Exomes and Genomes (phs001642)\",\n",
    "#     \"Center for Common Disease Genomics [CCDG] - Neuropsychiatric: Epilepsy: Epi25 Consortium (phs001489)\",\n",
    "#     \"Center for Common Disease Genomics [CCDG] Neuropsychiatric: Autism Spectrum Disorder (ASD) - Whole Exomes (phs002502)\",\n",
    "]\n",
    "\n",
    "# Specifies whether the upload should run (False) or if only a preview of the upload should be displayed\n",
    "preview_only = True\n",
    "\n",
    "# For preview_only = True cases, specifies whether AnVIL datasets not included in the upload should also be displayed\n",
    "include_anvil_in_preview = False\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "\n",
    "upload_results = upload_to_duos(input_file_gcs_path, duos_token, duos_env, study_upload_list, preview_only, include_anvil_in_preview)\n",
    "df_results = pd.DataFrame(upload_results, columns = [\"Item\", \"Status\", \"Message\"])\n",
    "print(\"\\nUpload Results:\")\n",
    "display(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Sync DUOS Datasets with TDR Snapshots\n",
    "Based on the provided pairs of Snapshots and DUOS IDs:\n",
    "- If no DUOS ID is specified, the existing DUOS ID will be removed from the snapshot. The DUOS group will NOT be automatically removed from the snapshot's auth domain group, given that auth domain group may be shared with multiple snapshots. \n",
    "- If a DUOS ID is specified and the snapshot doesn't currently have one, the DUOS ID will be linked to the snapshot, the DUOS group will be added to the snapshot auth domain group, and the DUOS dataset registration will be updated with to point to the snapshot. \n",
    "- If a DUOS ID is specified and the snapshot currently has a different one, the new DUOS ID will be linked to the snapshot, the new DUOS group will be added to the snapshot auth domain group, the old DUOS group will be removed from the snapshot auth domain group, and the DUOS dataset registration will be updated to point to the snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Functions\n",
    "#############################################\n",
    "\n",
    "def sync_duos_ids_and_snapshots(duos_token, duos_env, snapshot_duos_list):\n",
    "    results_log = []\n",
    "\n",
    "    # Determine the target URL from the env variable\n",
    "    if duos_env == \"prod\":\n",
    "        duos_url = \"https://consent.dsde-prod.broadinstitute.org\"\n",
    "    else:\n",
    "        duos_url = \"https://consent.dsde-dev.broadinstitute.org\"\n",
    "    \n",
    "    # Loop through input snapshots and link DUOS IDs to them\n",
    "    print(\"Syncing DUOS IDs to Snapshots...\")\n",
    "    for ss_duos_entry in snapshot_duos_list:\n",
    "        creds, project = google.auth.default()\n",
    "        auth_req = google.auth.transport.requests.Request()\n",
    "        creds.refresh(auth_req)\n",
    "        api_client = refresh_tdr_api_client()\n",
    "        snapshots_api = data_repo_client.SnapshotsApi(api_client=api_client)\n",
    "        duos_api = data_repo_client.DuosApi(api_client=api_client)\n",
    "        snapshot_id = ss_duos_entry[0]\n",
    "        new_duos_id = ss_duos_entry[1]\n",
    "        print(f\"\\tProcessing snapshot ID = {snapshot_id}\")\n",
    "        if new_duos_id:\n",
    "            duos_action = \"LINK\"\n",
    "        else:\n",
    "            duos_action = \"UNLINK\"\n",
    "            \n",
    "        # Get current DUOS ID on the snapshot\n",
    "        print(f\"\\t\\t- Retrieving original DUOS ID from snapshot {snapshot_id} (if any).\")\n",
    "        current_duos_id = \"\"\n",
    "        attempt_counter = 0\n",
    "        while attempt_counter <= 2:\n",
    "            try:\n",
    "                response = snapshots_api.retrieve_snapshot(id=snapshot_id, include=[\"DUOS\"]).to_dict()\n",
    "                duos_firecloud_group = response[\"duos_firecloud_group\"]\n",
    "                if duos_firecloud_group:\n",
    "                    current_duos_id = response[\"duos_firecloud_group\"].get(\"duos_id\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                msg = f\"Error retrieving original DUOS ID from Snapshot: {str(e)}\"\n",
    "                if attempt_counter >= 2:\n",
    "                    results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id} - {duos_id})\", \"Failed\", msg])\n",
    "                    current_duos_id = \"Unknown\"\n",
    "                    break\n",
    "                sleep(5)\n",
    "                attempt_counter += 1\n",
    "        if current_duos_id == \"Unknown\":\n",
    "            continue\n",
    "        \n",
    "        # Get DUOS user group associated with new and current duos id\n",
    "        new_duos_group = \"\"\n",
    "        current_duos_group = \"\"\n",
    "        if new_duos_id:\n",
    "            print(f\"\\t\\t- Fetching DUOS user group from new DUOS ID {new_duos_id}.\")\n",
    "            attempt_counter = 0\n",
    "            while attempt_counter <= 2:\n",
    "                try:  \n",
    "                    response = duos_api.retrieve_duos_firecloud_group(duos_id=new_duos_id).to_dict()\n",
    "                    new_duos_group = response[\"firecloud_group_email\"]\n",
    "                    results_log.append([f\"DUOS User Group Fetching ({new_duos_id})\", \"Success\", \"\"])\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    msg = f\"Error fetching DUOS user group for DUOS ID {new_duos_id}: {str(e)}\"\n",
    "                    if attempt_counter >= 2:\n",
    "                        results_log.append([f\"DUOS User Group Fetching ({new_duos_id})\", \"Failed\", msg])\n",
    "                    sleep(5)\n",
    "                    attempt_counter += 1 \n",
    "        if current_duos_id:\n",
    "            if new_duos_id == current_duos_id:\n",
    "                print(f\"\\t\\t- New DUOS ID matches original DUOS ID on snapshot, so no additinoal DUOS user group to fetch.\")\n",
    "                current_duos_group = new_duos_group\n",
    "            else:\n",
    "                print(f\"\\t\\t- Fetching DUOS user group from original DUOS ID {current_duos_id}.\")\n",
    "                attempt_counter = 0\n",
    "                while attempt_counter <= 2:\n",
    "                    try:  \n",
    "                        response = duos_api.retrieve_duos_firecloud_group(duos_id=current_duos_id).to_dict()\n",
    "                        current_duos_group = response[\"firecloud_group_email\"]\n",
    "                        results_log.append([f\"DUOS User Group Fetching ({current_duos_id})\", \"Success\", \"\"])\n",
    "                        break\n",
    "                    except Exception as e:\n",
    "                        msg = f\"Error fetching DUOS user group for DUOS ID {current_duos_id}: {str(e)}\"\n",
    "                        if attempt_counter >= 2:\n",
    "                            results_log.append([f\"DUOS User Group Fetching ({current_duos_id})\", \"Failed\", msg])\n",
    "                        sleep(5)\n",
    "                        attempt_counter += 1 \n",
    "            \n",
    "        # Processing DUOS_ID-Snapshot sync\n",
    "        if duos_action == \"LINK\":\n",
    "            # Link the DUOS ID to the snapshot\n",
    "            print(f\"\\t\\t- Linking DUOS ID {new_duos_id} to snapshot.\")\n",
    "            attempt_counter = 0\n",
    "            while attempt_counter <= 2:\n",
    "                try:\n",
    "                    response = snapshots_api.link_duos_dataset_to_snapshot(id=snapshot_id, duos_id=new_duos_id).to_dict()\n",
    "                    if response.get(\"linked\"):\n",
    "                        results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id} - {new_duos_id})\", \"Success\", \"\"])\n",
    "                        break\n",
    "                    elif response.get(\"message\"):\n",
    "                        response_message = response.get(\"message\")\n",
    "                        msg = f\"Error linking DUOS ID to Snapshot: {response_message}\"\n",
    "                        if attempt_counter >= 2:\n",
    "                            results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id} - {new_duos_id})\", \"Failed\", msg])\n",
    "                            break\n",
    "                except Exception as e:\n",
    "                    msg = f\"Error linking DUOS ID to Snapshot: {str(e)}\"\n",
    "                    if attempt_counter >= 2:\n",
    "                        results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id} - {new_duos_id})\", \"Failed\", msg])\n",
    "                    sleep(5)\n",
    "                    attempt_counter += 1  \n",
    "\n",
    "            # Add the DUOS user group to any DAC groups on the snapshot\n",
    "            print(f\"\\t\\t- Adding DUOS user group {new_duos_group} to snapshot DAC user group(s).\")\n",
    "            dac_groups = []\n",
    "            try:\n",
    "                response = snapshots_api.retrieve_snapshot_policies(id=snapshot_id).to_dict()\n",
    "                if response.get(\"auth_domain\"):\n",
    "                    dac_groups = response[\"auth_domain\"]\n",
    "                if dac_groups:\n",
    "                    print(f\"\\t\\t\\t- DAC user group(s) found on snapshot: {dac_groups}.\")\n",
    "                    for dac_group in dac_groups:\n",
    "                        response = requests.put(\n",
    "                            url=f\"https://api.firecloud.org/api/groups/{dac_group}/member/{new_duos_group}\",\n",
    "                            headers={\"Authorization\": f\"Bearer {creds.token}\"}\n",
    "                        )\n",
    "                        if response.status_code != 204:\n",
    "                            results_log.append([f\"DUOS Group to DAC Group Addition ({new_duos_group} - {dac_group})\", \"Failed\", \"Error adding DUOS group to DAC group.\"])\n",
    "                        else:\n",
    "                            results_log.append([f\"DUOS Group to DAC Group Addition ({new_duos_group} - {dac_group})\", \"Success\", \"\"])\n",
    "                else:\n",
    "                    msg = f\"No DAC user group(s) found on snapshot.\"\n",
    "                    print(f\"\\t\\t\\t- {msg}\")\n",
    "                    results_log.append([f\"DUOS Group to DAC Group Addition ({snapshot_id} - {new_duos_id})\", \"Warning\", msg])   \n",
    "            except Exception as e:\n",
    "                msg = f\"Error adding DUOS Group to DAC Group: {str(e)}\"\n",
    "                results_log.append([f\"DUOS Group to DAC Group Addition ({snapshot_id} - {new_duos_id})\", \"Failed\", msg])\n",
    "                \n",
    "            # Retrieve DUOS registration\n",
    "            print(f\"\\t\\t- Retrieving DUOS dataset registration for DUOS ID {new_duos_id}.\")\n",
    "            duos_dataset_id = \"\"\n",
    "            try:\n",
    "                dataset_details = requests.get(\n",
    "                    url=f\"{duos_url}/api/tdr/{new_duos_id}\",\n",
    "                    headers={\"Authorization\": f\"Bearer {duos_token}\"}\n",
    "                ).json()\n",
    "                duos_dataset_id = dataset_details[\"datasetId\"]\n",
    "                duos_dataset_name = dataset_details[\"name\"]\n",
    "                results_log.append([f\"DUOS Dataset Retrieval ({snapshot_id} - {new_duos_id})\", \"Success\", f\"Dataset_id = {duos_dataset_id}\"])\n",
    "            except Exception as e:\n",
    "                msg = f\"Error retrieving DUOS dataset registration: {str(e)}\"\n",
    "                results_log.append([f\"DUOS Dataset Retrieval ({snapshot_id} - {new_duos_id})\", \"Failed\", msg])\n",
    "            \n",
    "            # Update snapshot on the DUOS registration\n",
    "            if duos_dataset_id and duos_dataset_name:\n",
    "                payload = {\n",
    "                    \"name\": duos_dataset_name,\n",
    "                    \"properties\": [{\n",
    "                        \"propertyName\": \"URL\",\n",
    "                        \"propertyValue\": f\"https://data.terra.bio/snapshots/{snapshot_id}\",\n",
    "                        \"schemaProperty\": \"url\",\n",
    "                        \"propertyType\": \"String\"\n",
    "                    }, {\n",
    "                        \"propertyName\": \"Data Location\",\n",
    "                        \"propertyValue\": \"TDR Location\",\n",
    "                        \"schemaProperty\": \"dataLocation\",\n",
    "                        \"propertyType\": \"String\"\n",
    "                    }]\n",
    "                }\n",
    "                try:\n",
    "                    dataset_patch_response = requests.patch(\n",
    "                        url=f\"{duos_url}/api/dataset/{duos_dataset_id}\",\n",
    "                        headers={\"Authorization\": f\"Bearer {duos_token}\"},\n",
    "                        json=payload\n",
    "                    )\n",
    "                    if dataset_patch_response.status_code == 200:\n",
    "                        results_log.append([f\"DUOS Dataset Patch ({snapshot_id} - {new_duos_id})\", \"Success\", \"\"])\n",
    "                    elif dataset_patch_response.status_code == 304:\n",
    "                        results_log.append([f\"DUOS Dataset Patch ({snapshot_id} - {new_duos_id})\", \"Success\", \"Dataset not modified. No patch required.\"])\n",
    "                    else:\n",
    "                        err = dataset_patch_response.text\n",
    "                        msg = f\"Error patching DUOS Dataset: {err}\"\n",
    "                        results_log.append([f\"DUOS Dataset Patch ({snapshot_id} - {new_duos_id})\", \"Failed\", msg])\n",
    "                except Exception as e:\n",
    "                    msg = f\"Error patching DUOS Dataset: {str(e)}\"\n",
    "                    results_log.append([f\"DUOS Dataset Patch ({snapshot_id} - {new_duos_id})\", \"Failed\", msg])\n",
    "            else:\n",
    "                results_log.append([f\"DUOS Dataset Patch ({snapshot_id} - {new_duos_id})\", \"Failed\", \"Missing DUOS dataset ID or name\"])     \n",
    "        \n",
    "        elif duos_action == \"UNLINK\" and current_duos_id:\n",
    "            # Unlink the current DUOS ID from the snapshot (if any)\n",
    "            print(f\"\\t\\t- No DUOS ID specified. Removing current DUOS ID {current_duos_id} from the snapshot.\")\n",
    "            attempt_counter = 0\n",
    "            while attempt_counter <= 2:\n",
    "                try:\n",
    "                    response = snapshots_api.unlink_duos_dataset_from_snapshot(id=snapshot_id).to_dict()\n",
    "                    if response.get(\"message\"):\n",
    "                        response_message = response.get(\"message\")\n",
    "                        msg = f\"Error removing DUOS ID from Snapshot: {response_message}\"\n",
    "                        if attempt_counter >= 2:\n",
    "                            results_log.append([f\"Remove existing DUOS ID from Snapshot ({snapshot_id})\", \"Failed\", msg])\n",
    "                            break\n",
    "                    else:\n",
    "                        results_log.append([f\"Remove existing DUOS ID from Snapshot ({snapshot_id})\", \"Success\", \"\"])\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    msg = f\"Error removing DUOS ID from Snapshot: {str(e)}\"\n",
    "                    if attempt_counter >= 2:\n",
    "                        results_log.append([f\"Remove existing DUOS ID from Snapshot ({snapshot_id})\", \"Failed\", msg])\n",
    "                    sleep(5)\n",
    "                    attempt_counter += 1\n",
    "        else:\n",
    "            print(f\"\\t\\t- No DUOS ID specified and no current DUOS ID to remove from the snapshot.\")\n",
    "            results_log.append([f\"Remove existing DUOS ID from Snapshot ({snapshot_id})\", \"Success\", \"\"])\n",
    "            \n",
    "        # If a new duos ID is replacing an existing duos ID, remove the current DUOS user group from any DAC groups on the snapshot\n",
    "        if new_duos_group and current_duos_group and new_duos_group != current_duos_group:\n",
    "            print(f\"\\t\\t- Removing DUOS user group {current_duos_group} from snapshot DAC user group(s).\")\n",
    "            dac_groups = []\n",
    "            try:\n",
    "                response = snapshots_api.retrieve_snapshot_policies(id=snapshot_id).to_dict()\n",
    "                if response.get(\"auth_domain\"):\n",
    "                    dac_groups = response[\"auth_domain\"]\n",
    "                if dac_groups:\n",
    "                    print(f\"\\t\\t\\t- DAC user group(s) found on snapshot: {dac_groups}.\")\n",
    "                    for dac_group in dac_groups:\n",
    "                        response = requests.delete(\n",
    "                            url=f\"https://api.firecloud.org/api/groups/{dac_group}/member/{current_duos_group}\",\n",
    "                            headers={\"Authorization\": f\"Bearer {creds.token}\"}\n",
    "                        )\n",
    "                        if response.status_code != 204:\n",
    "                            results_log.append([f\"DUOS Group Removal from DAC Group ({current_duos_group} - {dac_group})\", \"Failed\", \"Error removing DUOS group from DAC group.\"])\n",
    "                        else:\n",
    "                            results_log.append([f\"DUOS Group Removal from DAC Group ({current_duos_group} - {dac_group})\", \"Success\", \"\"])\n",
    "                else:\n",
    "                    msg = f\"No DAC user group(s) found on snapshot.\"\n",
    "                    print(f\"\\t\\t\\t- {msg}\")\n",
    "                    results_log.append([f\"DUOS Group Removal from DAC Group ({current_duos_group} - N/A)\", \"Warning\", msg])   \n",
    "            except Exception as e:\n",
    "                msg = f\"Error removing DUOS Group from DAC Group: {str(e)}\"\n",
    "                results_log.append([f\"DUOS Group Removal from DAC Group ({current_duos_group})\", \"Failed\", msg])\n",
    "                \n",
    "    return results_log\n",
    "\n",
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# Token for use in DUOS (use gcloud auth print-access-token to get this)\n",
    "duos_token = \"\"\n",
    "\n",
    "# DUOS Environment\n",
    "duos_env = \"prod\"\n",
    "\n",
    "# Snapshot list\n",
    "snapshot_duos_list = [\n",
    "    #['snapshot_id', 'duos_id (or empty string to remove existing duos_id from snapshot)']\n",
    "    ['34526f3b-945e-4f81-a25c-150f342b46c0', 'DUOS-000474'],\n",
    "    ['22f3c573-ea7a-4ba3-ad0a-1680dc44c4bb', 'DUOS-000485'],\n",
    "]\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "\n",
    "results = sync_duos_ids_and_snapshots(duos_token, duos_env, snapshot_duos_list)\n",
    "df_results = pd.DataFrame(results, columns = [\"Item\", \"Status\", \"Message\"])\n",
    "print(\"\\nLinking Results:\")\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Script Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Fetch parameters from snapshot/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "snapshot_id = \"099d2585-1379-4333-b3b1-ffc0d26d95c5\"\n",
    "\n",
    "# Retrieve snapshot details\n",
    "api_client = refresh_tdr_api_client()\n",
    "datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "snapshots_api = data_repo_client.SnapshotsApi(api_client=api_client)\n",
    "snapshot_details = snapshots_api.retrieve_snapshot(id=snapshot_id).to_dict()\n",
    "dataset_id = snapshot_details[\"source\"][0][\"dataset\"][\"id\"]\n",
    "phs_id = snapshot_details[\"source\"][0][\"dataset\"][\"phs_id\"]\n",
    "\n",
    "# Retrieve dataset details\n",
    "dataset_details = datasets_api.retrieve_dataset(id=dataset_id, include=[\"PROPERTIES\"]).to_dict()\n",
    "if dataset_details[\"properties\"].get(\"auth_domains\"):\n",
    "    auth_domain = dataset_details[\"properties\"][\"auth_domains\"][0]\n",
    "if dataset_details[\"properties\"].get(\"source_workspaces\"):\n",
    "    source_workspace = dataset_details[\"properties\"][\"source_workspaces\"][0]\n",
    "\n",
    "# Print output\n",
    "print(phs_id)\n",
    "print(source_workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Pulling Workspace Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "ws_project = \"anvil-datastorage\"\n",
    "ws_name = \"AnVIL_DepMap_HMB\"\n",
    "\n",
    "# Establish credentials\n",
    "creds, project = google.auth.default()\n",
    "auth_req = google.auth.transport.requests.Request()\n",
    "creds.refresh(auth_req)\n",
    "\n",
    "# Pull workspace attributes\n",
    "ws_attributes = requests.get(\n",
    "    url=f\"https://api.firecloud.org/api/workspaces/{ws_project}/{ws_name}?fields=workspace.attributes,workspace.authorizationDomain,workspace.googleProject,workspace.bucketName\",\n",
    "    headers={\"Authorization\": f\"Bearer {creds.token}\"}\n",
    ").json()\n",
    "\n",
    "# Map to schema\n",
    "terra_dict = {}\n",
    "terra_dict[\"studyName\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:projectName\")\n",
    "terra_dict[\"studyType\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:studyDesign\")\n",
    "#terra_dict[\"studyDescription\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"description\")\n",
    "terra_dict[\"dataTypes\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:dataCategory\")[\"items\"]\n",
    "terra_dict[\"phenotypeIndication\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:indication\")\n",
    "terra_dict[\"species\"] = \"Homo sapiens\"\n",
    "terra_dict[\"piName\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:datasetOwner\")\n",
    "terra_dict[\"dataCustodianEmail\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:contactEmail\")\n",
    "if ws_attributes[\"workspace\"][\"attributes\"].get(\"tag:tags\"):\n",
    "    for tag in ws_attributes[\"workspace\"][\"attributes\"].get(\"tag:tags\")[\"items\"]:\n",
    "        if \"Consortium:\" in tag:\n",
    "            terra_dict[\"consortium\"] = tag.split(\":\")[1].strip()\n",
    "        elif \"dbGaP:\" in tag:\n",
    "            terra_dict[\"dbGaPPhsID\"] = tag.split(\":\")[1].strip()\n",
    "terra_dict[\"consentGroups.consentCode\"] = ws_attributes[\"workspace\"][\"attributes\"][\"library:dataUseRestriction\"] \n",
    "terra_dict[\"consentGroups.fileTypes.fileType\"] = ws_attributes[\"workspace\"][\"attributes\"][\"library:datatype\"][\"items\"]\n",
    "\n",
    "# View schema\n",
    "print(terra_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ws_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ws_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## dbGaP XML Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "#phs_id = \"phs003047\"\n",
    "phs_id = \"phs003444\"\n",
    "\n",
    "# Pull and parse XML\n",
    "phs_short = phs_id.replace(\"phs\", \"\")\n",
    "dbgap_url = \"https://dbgap.ncbi.nlm.nih.gov/ss/dbgapssws.cgi?request=Study&phs=\" + phs_short\n",
    "response = requests.get(url=dbgap_url)\n",
    "xml_data = xmltodict.parse(response.text)\n",
    "\n",
    "# Map to schema\n",
    "dac_names = \"\"\n",
    "dbgap_xml_dict = {}\n",
    "if isinstance(xml_data[\"dbgapss\"][\"Study\"], list):\n",
    "    study_data = xml_data[\"dbgapss\"][\"Study\"][0]\n",
    "else:\n",
    "    study_data = xml_data[\"dbgapss\"][\"Study\"] \n",
    "dbgap_xml_dict[\"studyName\"] = study_data[\"StudyInfo\"].get(\"StudyNameEntrez\")\n",
    "dbgap_xml_dict[\"studyDescription\"] = study_data[\"StudyInfo\"].get(\"Description\")\n",
    "dbgap_xml_dict[\"dbGaPPhsID\"] = phs_id\n",
    "dbgap_xml_dict[\"dbGaPStudyRegistrationName\"] = study_data[\"StudyInfo\"].get(\"StudyNameEntrez\")\n",
    "for ap_entry in study_data[\"Authority\"][\"Persons\"][\"Person\"]:\n",
    "    if ap_entry[\"Role\"] == \"PI\":\n",
    "        dbgap_xml_dict[\"piName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "        dbgap_xml_dict[\"piEmail\"] = ap_entry[\"@email\"]\n",
    "        dbgap_xml_dict[\"piInstitution\"] = ap_entry[\"Organization\"]\n",
    "    elif ap_entry[\"Role\"] == \"PO\" and ap_entry[\"Organization\"] == \"NIH\":\n",
    "        dbgap_xml_dict[\"nihProgramOfficerName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "    elif ap_entry[\"Role\"] == \"GPA\" and ap_entry[\"Organization\"] == \"NIH\":\n",
    "        dbgap_xml_dict[\"nihGenomicProgramAdministratorName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "ic_list = []\n",
    "if isinstance(study_data[\"Authority\"][\"ICs\"][\"IC\"], list):\n",
    "    for ic_entry in study_data[\"Authority\"][\"ICs\"][\"IC\"]:\n",
    "        ic_list.append(ic_entry[\"@name\"])\n",
    "else:\n",
    "    ic_list.append(study_data[\"Authority\"][\"ICs\"][\"IC\"][\"@name\"])\n",
    "dbgap_xml_dict[\"nihICsSupportingStudy\"] = ic_list\n",
    "dbgap_xml_dict[\"numberOfParticipants\"] = study_data.get(\"@num_participants\")\n",
    "dbgap_xml_dict[\"embargoReleaseDate\"] = study_data[\"Policy\"].get(\"@pub-embargo\")\n",
    "if isinstance(study_data[\"Policy\"][\"ConsentGroup\"], list):\n",
    "    dac_name_set = set()\n",
    "    for idx, consent in enumerate(study_data[\"Policy\"][\"ConsentGroup\"]):\n",
    "        tmp_dac = consent[\"@dac_name\"]\n",
    "        dac_name_set.add(tmp_dac)\n",
    "    dac_name_list = list(dac_name_set)\n",
    "    dac_names = \", \".join(dac_name_list)\n",
    "else:\n",
    "    dac_names = study_data[\"Policy\"][\"ConsentGroup\"][\"@dac_name\"]\n",
    "\n",
    "# View schema\n",
    "print(dbgap_xml_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dac_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "type(study_data[\"Policy\"][\"ConsentGroup\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## dbGaP Study API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "study_uid = 483191234\n",
    "\n",
    "# Pull and parse JSON\n",
    "dbgap_study_url = \"https://submit.ncbi.nlm.nih.gov/dbgap/api/v1/study_config/\" + str(study_uid)\n",
    "response = requests.get(url=dbgap_study_url)\n",
    "study_api_data = json.loads(response.text)\n",
    "\n",
    "# Map to schema\n",
    "dbgap_study_api_dict = {}\n",
    "if study_api_data.get(\"error\") == None:\n",
    "    dbgap_study_api_dict[\"studyName\"] = study_api_data[\"data\"].get(\"report_name\")\n",
    "    dbgap_study_api_dict[\"studyDescription\"] = study_api_data[\"data\"].get(\"description\")\n",
    "    dbgap_study_api_dict[\"phenotypeIndication\"] = study_api_data[\"data\"].get(\"primary_disease\")\n",
    "    dbgap_study_api_dict[\"studyType\"] = study_api_data[\"data\"].get(\"study_design\")\n",
    "    for attr_entry in study_api_data[\"data\"].get(\"attribution\"):\n",
    "        if attr_entry.get(\"title\") == \"Principal Investigator\":\n",
    "            dbgap_study_api_dict[\"piName\"] = attr_entry.get(\"name\")\n",
    "            dbgap_study_api_dict[\"piInstitution\"] = attr_entry.get(\"institute\")\n",
    "            break\n",
    "\n",
    "# View schema\n",
    "print(dbgap_study_api_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "study_api_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## dbGaP FHIR API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "#phs_id = \"phs003047\"\n",
    "phs_id = \"phs000693\"\n",
    "\n",
    "# Pull and parse JSON\n",
    "dbgap_fhir_url = \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/ResearchStudy?_format=json&_id=\" + phs_id\n",
    "response = requests.get(url=dbgap_fhir_url)\n",
    "fhir_data = json.loads(response.text)\n",
    "\n",
    "# Map to schema\n",
    "dbgap_fhir_dict = {}\n",
    "dbgap_fhir_dict[\"studyName\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"title\")\n",
    "dbgap_fhir_dict[\"studyDescription\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"description\")\n",
    "dbgap_fhir_dict[\"dbGaPPhsID\"] = phs_id\n",
    "dbgap_fhir_dict[\"dbGaPStudyRegistrationName\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"title\")\n",
    "dbgap_fhir_dict[\"nihICsSupportingStudy\"] = fhir_data[\"entry\"][0][\"resource\"][\"sponsor\"].get(\"display\")\n",
    "# studyType\n",
    "for cat_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"category\"):\n",
    "    for coding_entry in cat_entry.get(\"coding\"):\n",
    "        if coding_entry.get(\"system\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/CodeSystem/ResearchStudy-StudyDesign\":\n",
    "            value = coding_entry.get(\"display\") if coding_entry.get(\"display\") else coding_entry.get(\"code\")\n",
    "            if dbgap_fhir_dict.get(\"studyType\") and value:\n",
    "                dbgap_fhir_dict[\"studyType\"] += f\", {value}\"\n",
    "            elif value:\n",
    "                dbgap_fhir_dict[\"studyType\"] = value\n",
    "# dataTypes\n",
    "dt_list = []\n",
    "for ext_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "    if ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-MolecularDataTypes\":\n",
    "        for inner_ext_entry in ext_entry.get(\"extension\"):\n",
    "            if inner_ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-MolecularDataTypes-MolecularDataType\":\n",
    "                for coding_entry in inner_ext_entry[\"valueCodeableConcept\"].get(\"coding\"):\n",
    "                    dt_list.append(coding_entry.get(\"code\"))\n",
    "dbgap_fhir_dict[\"dataTypes\"] = dt_list\n",
    "# phenotypeIndication\n",
    "for focus_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"focus\"):\n",
    "    for coding_entry in focus_entry.get(\"coding\"):\n",
    "        value = coding_entry.get(\"display\") if coding_entry.get(\"display\") else coding_entry.get(\"code\")\n",
    "        if dbgap_fhir_dict.get(\"phenotypeIndication\") and value:\n",
    "            dbgap_fhir_dict[\"phenotypeIndication\"] += f\", {value}\"\n",
    "        elif value:\n",
    "            dbgap_fhir_dict[\"phenotypeIndication\"] = value\n",
    "# numberOfParticipants\n",
    "for ext_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "    if ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-Content\":\n",
    "        for inner_ext_entry in ext_entry.get(\"extension\"):\n",
    "            if inner_ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-Content-NumSubjects\":\n",
    "                dbgap_fhir_dict[\"numberOfParticipants\"] = inner_ext_entry[\"valueCount\"].get(\"code\")\n",
    "\n",
    "# View schema\n",
    "print(dbgap_fhir_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fhir_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create Study Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# User token (use gcloud auth print-access-token to get this)\n",
    "duos_token = \"\"\n",
    "\n",
    "# Environment\n",
    "duos_env = \"prod\"\n",
    "\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "\n",
    "if duos_env == \"prod\":\n",
    "    url = \"https://consent.dsde-prod.broadinstitute.org\"\n",
    "else:\n",
    "    url = \"https://consent.dsde-dev.broadinstitute.org\"\n",
    "    \n",
    "# Iterate through studies sequentially\n",
    "results = []\n",
    "study_id = 1\n",
    "missing_count = 0\n",
    "print(\"Pulling study registrations...\")\n",
    "while missing_count < 50:\n",
    "    try:\n",
    "        print(f\"Attempting to pull registration for study_id = {study_id}...\")\n",
    "        study_registration = requests.get(\n",
    "            url=f\"{url}/api/dataset/study/registration/{study_id}\",\n",
    "            headers={\"Authorization\": f\"Bearer {duos_token}\"}\n",
    "        ).json()\n",
    "        study_name = study_registration[\"studyName\"]\n",
    "        consent_groups = study_registration[\"consentGroups\"]\n",
    "        cg_length = 0\n",
    "        if consent_groups:\n",
    "            cg_length = len(consent_groups)\n",
    "        results.append([study_id, study_name, cg_length])\n",
    "        missing_count = 0\n",
    "    except:\n",
    "        missing_count += 1\n",
    "    study_id += 1\n",
    "\n",
    "# Display study lookup\n",
    "print(\"\\nDUOS Studies: \")\n",
    "results_df = pd.DataFrame(results, columns=[\"study_id\", \"study_name\", \"consent_group_count\"])  \n",
    "display(results_df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "study_registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Delete Studies from DUOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# User token (use gcloud auth print-access-token to get this)\n",
    "duos_token = \"\"\n",
    "\n",
    "# Environment\n",
    "duos_env = \"dev\"\n",
    "\n",
    "# Studies to delete\n",
    "study_id_list = [\n",
    "]\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "\n",
    "if duos_env == \"prod\":\n",
    "    url = \"https://consent.dsde-prod.broadinstitute.org\"\n",
    "else:\n",
    "    url = \"https://consent.dsde-dev.broadinstitute.org\"\n",
    "\n",
    "# Delete studies\n",
    "for study_id in study_id_list:\n",
    "    print(f\"Deleting study ID {study_id}\")\n",
    "    response = requests.delete(\n",
    "        url=f\"{url}/api/dataset/study/{study_id}\",\n",
    "        headers={\"Authorization\": f\"Bearer {duos_token}\"} \n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        print(\"Study deleted successfully.\")\n",
    "    else:\n",
    "        msg = response.json()[\"message\"]\n",
    "        print(f\"Error deleting study: {msg}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Delete Datasets from DUOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# User token (use gcloud auth print-access-token to get this)\n",
    "duos_token = \"\"\n",
    "\n",
    "# Environment\n",
    "duos_env = \"dev\"\n",
    "\n",
    "# Datasets to delete\n",
    "dataset_id_list = [ \n",
    "]\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "\n",
    "if duos_env == \"prod\":\n",
    "    url = \"https://consent.dsde-prod.broadinstitute.org\"\n",
    "else:\n",
    "    url = \"https://consent.dsde-dev.broadinstitute.org\"\n",
    "\n",
    "# Delete datasets\n",
    "for dataset_id in dataset_id_list:\n",
    "    print(f\"Deleting dataset ID {dataset_id}\")\n",
    "    response = requests.delete(\n",
    "        url=f\"{url}/api/dataset/index/{dataset_id}\",\n",
    "        headers={\"Authorization\": f\"Bearer {duos_token}\"} \n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        print(\"Dataset deleted successfully.\")\n",
    "    else:\n",
    "        msg = response.json()[\"message\"]\n",
    "        print(f\"Error deleting dataset: {msg}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Export Datasets from DUOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def coalesce(*arg): \n",
    "    remove_list = [\"\", \"NA\", \"N/A\", \"NONE\", \"TBD\", \"UNKNOWN\", \"UNSPECIFIED\"]\n",
    "    # update to remove N/A, None, Null, TBD\n",
    "    for input_item in arg:\n",
    "        if input_item is False or input_item == []:\n",
    "            return input_item\n",
    "        elif input_item:\n",
    "            if isinstance(input_item, list):\n",
    "                temp_list = [ele for ele in input_item if ele is not None and ele.upper() not in remove_list]\n",
    "                if temp_list:\n",
    "                    return temp_list\n",
    "                else:\n",
    "                    return []\n",
    "            else:\n",
    "                if str(input_item).upper() not in remove_list:\n",
    "                    return input_item\n",
    "    return None\n",
    "\n",
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# User token (use gcloud auth print-access-token to get this)\n",
    "duos_token = \"\"\n",
    "\n",
    "# Environment\n",
    "duos_env = \"prod\"\n",
    "\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "\n",
    "if duos_env == \"prod\":\n",
    "    url = \"https://consent.dsde-prod.broadinstitute.org\"\n",
    "else:\n",
    "    url = \"https://consent.dsde-dev.broadinstitute.org\"\n",
    "datasets = requests.get(\n",
    "        url=f\"{url}/api/dataset/v3\",\n",
    "        headers={\"Authorization\": f\"Bearer {duos_token}\"}\n",
    "    ).json()\n",
    "# Loop through datasets and capture information from dataset schema\n",
    "dataset_details_records = []\n",
    "for dataset in datasets:\n",
    "    duos_identifier = dataset[\"identifier\"]\n",
    "    \n",
    "    # Fetch dataset details\n",
    "    duos_dict = {}\n",
    "    duos_dict = requests.get(\n",
    "        url=f\"{url}/api/dataset/registration/{duos_identifier}\",\n",
    "        headers={\"Authorization\": f\"Bearer {duos_token}\"}\n",
    "    ).json()\n",
    "   \n",
    "    # Pull additional dataset details from DUOS if needed (to get data use info) \n",
    "    if not duos_dict.get(\"consentGroups\"):\n",
    "        duos_dict[\"consentGroups\"] = [{\"datasetId\": None}]\n",
    "    duos_dataset_id = duos_dict[\"consentGroups\"][0].get(\"datasetId\")\n",
    "    duos_data_use_dict = {}\n",
    "    dac_id = \"\"\n",
    "    if duos_dataset_id:\n",
    "        dataset_details = requests.get(\n",
    "            url=f\"{url}/api/dataset/v2/{duos_dataset_id}\",\n",
    "            headers={\"Authorization\": f\"Bearer {duos_token}\"}\n",
    "        ).json()\n",
    "        duos_data_use_dict = dataset_details.get(\"dataUse\")\n",
    "        dac_id = dataset_details.get(\"dacId\") if dataset_details.get(\"dacId\") else \"\"\n",
    "    \n",
    "    # Format output\n",
    "    final_results_dict = {}\n",
    "    final_results_dict[\"dacId\"] = dac_id\n",
    "    final_results_dict[\"studyName\"] = duos_dict.get(\"studyName\")\n",
    "    final_results_dict[\"studyType\"] = duos_dict.get(\"studyType\")\n",
    "    final_results_dict[\"studyDescription\"] = duos_dict.get(\"studyDescription\")\n",
    "    final_results_dict[\"dataTypes\"] = duos_dict.get(\"dataTypes\")\n",
    "    final_results_dict[\"phenotypeIndication\"] = duos_dict.get(\"phenotypeIndication\")\n",
    "    final_results_dict[\"species\"] = duos_dict.get(\"species\")\n",
    "    final_results_dict[\"piName\"] = duos_dict.get(\"piName\")\n",
    "    final_results_dict[\"dataCustodianEmail\"] = duos_dict.get(\"dataCustodianEmail\")\n",
    "    final_results_dict[\"publicVisibility\"] = duos_dict.get(\"publicVisibility\")\n",
    "    final_results_dict[\"nihAnvilUse\"] = \"I am NHGRI funded and I have a dbGaP PHS ID already\" if duos_dict.get(\"nihAnvilUse\") and 'already' in duos_dict.get(\"nihAnvilUse\").lower() else \"I am NHGRI funded and I do not have a dbGaP PHS ID\"\n",
    "    final_results_dict[\"submittingToAnvil\"] = duos_dict.get(\"submittingToAnvil\")\n",
    "    final_results_dict[\"dbGaPPhsID\"] = duos_dict.get(\"dbGaPPhsID\")\n",
    "    final_results_dict[\"dbGaPStudyRegistrationName\"] = duos_dict.get(\"dbGaPStudyRegistrationName\")\n",
    "    final_results_dict[\"embargoReleaseDate\"] = duos_dict.get(\"embargoReleaseDate\")\n",
    "    final_results_dict[\"sequencingCenter\"] = duos_dict.get(\"sequencingCenter\")\n",
    "    final_results_dict[\"piEmail\"] = duos_dict.get(\"piEmail\")\n",
    "    final_results_dict[\"piInstitution\"] = duos_dict.get(\"piInstitution\")\n",
    "    final_results_dict[\"nihGrantContractNumber\"] = duos_dict.get(\"nihGrantContractNumber\")\n",
    "    final_results_dict[\"nihICsSupportingStudy\"] = duos_dict.get(\"nihICsSupportingStudy\")\n",
    "    final_results_dict[\"nihProgramOfficerName\"] = duos_dict.get(\"nihProgramOfficerName\")\n",
    "    final_results_dict[\"nihInstitutionCenterSubmission\"] = duos_dict.get(\"nihInstitutionCenterSubmission\")\n",
    "    final_results_dict[\"nihInstitutionalCertificationFileName\"] = duos_dict.get(\"nihInstitutionalCertificationFileName\")\n",
    "    final_results_dict[\"nihGenomicProgramAdministratorName\"] = duos_dict.get(\"nihGenomicProgramAdministratorName\")\n",
    "    final_results_dict[\"multiCenterStudy\"] = duos_dict.get(\"multiCenterStudy\")\n",
    "    final_results_dict[\"collaboratingSites\"] = duos_dict.get(\"collaboratingSites\")\n",
    "    final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSR\"] = duos_dict.get(\"controlledAccessRequiredForGenomicSummaryResultsGSR\")\n",
    "    final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation\"] = duos_dict.get(\"controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation\")\n",
    "    final_results_dict[\"alternativeDataSharingPlan\"] = duos_dict.get(\"alternativeDataSharingPlan\")\n",
    "    final_results_dict[\"alternativeDataSharingPlanReasons\"] = duos_dict.get(\"alternativeDataSharingPlanReasons\")\n",
    "    final_results_dict[\"alternativeDataSharingPlanExplanation\"] = duos_dict.get(\"alternativeDataSharingPlanExplanation\")\n",
    "    final_results_dict[\"alternativeDataSharingPlanFileName\"] = duos_dict.get(\"alternativeDataSharingPlanFileName\")\n",
    "    final_results_dict[\"alternativeDataSharingPlanDataSubmitted\"] = duos_dict.get(\"alternativeDataSharingPlanDataSubmitted\")\n",
    "    final_results_dict[\"alternativeDataSharingPlanDataReleased\"] = duos_dict.get(\"alternativeDataSharingPlanDataReleased\")\n",
    "    final_results_dict[\"alternativeDataSharingPlanTargetDeliveryDate\"] = duos_dict.get(\"alternativeDataSharingPlanTargetDeliveryDate\")\n",
    "    final_results_dict[\"alternativeDataSharingPlanTargetPublicReleaseDate\"] = duos_dict.get(\"alternativeDataSharingPlanTargetPublicReleaseDate\")\n",
    "    final_results_dict[\"alternativeDataSharingPlanAccessManagement\"] = duos_dict.get(\"alternativeDataSharingPlanAccessManagement\")\n",
    "    final_results_dict[\"consentGroups.consentGroupName\"] = duos_dict[\"consentGroups\"][0].get(\"consentGroupName\")\n",
    "    final_results_dict[\"consentGroups.accessManagement\"] = duos_dict[\"consentGroups\"][0].get(\"accessManagement\")\n",
    "    final_results_dict[\"consentGroups.numberOfParticipants\"] = duos_dict[\"consentGroups\"][0].get(\"numberOfParticipants\")\n",
    "    final_results_dict[\"consentGroups.generalResearchUse\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"generalResearchUse\"), duos_data_use_dict.get(\"generalUse\"), False)\n",
    "    final_results_dict[\"consentGroups.hmb\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"hmb\"), duos_data_use_dict.get(\"hmbResearch\"), False)\n",
    "    final_results_dict[\"consentGroups.diseaseSpecificUse\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"diseaseSpecificUse\"), duos_data_use_dict.get(\"diseaseRestrictions\"), [])\n",
    "    final_results_dict[\"consentGroups.gs\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"gs\"), duos_data_use_dict.get(\"geographicalRestrictions\"))\n",
    "    final_results_dict[\"consentGroups.poa\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"poa\"), duos_data_use_dict.get(\"populationOriginsAncestry\"), False)\n",
    "    final_results_dict[\"consentGroups.nmds\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"nmds\"), False)\n",
    "    final_results_dict[\"consentGroups.gso\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"gso\"), duos_data_use_dict.get(\"geneticStudiesOnly\"), False)\n",
    "    final_results_dict[\"consentGroups.pub\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"pub\"), duos_data_use_dict.get(\"publicationResults\"), False)\n",
    "    final_results_dict[\"consentGroups.col\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"col\"), duos_data_use_dict.get(\"collaboratorRequired\"), False)\n",
    "    final_results_dict[\"consentGroups.irb\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"irb\"), duos_data_use_dict.get(\"ethicsApprovalRequired\"), False)\n",
    "    final_results_dict[\"consentGroups.npu\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"npu\"), False)\n",
    "    final_results_dict[\"consentGroups.otherPrimary\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"otherPrimary\"), duos_data_use_dict.get(\"other\"))\n",
    "    final_results_dict[\"consentGroups.otherSecondary\"] = duos_dict[\"consentGroups\"][0].get(\"otherSecondary\")\n",
    "    final_results_dict[\"consentGroups.mor\"] = duos_dict[\"consentGroups\"][0].get(\"mor\")\n",
    "    final_results_dict[\"consentGroups.morDate\"] = duos_dict[\"consentGroups\"][0].get(\"morDate\")\n",
    "    final_results_dict[\"consentGroups.dataLocation\"] = duos_dict[\"consentGroups\"][0].get(\"dataLocation\")\n",
    "    final_results_dict[\"consentGroups.url\"] = duos_dict[\"consentGroups\"][0].get(\"url\")\n",
    "    final_results_dict[\"consentGroups.fileTypes\"] = str(duos_dict[\"consentGroups\"][0].get(\"fileTypes\"))\n",
    "    dataset_details_records.append(final_results_dict)\n",
    "    \n",
    "# Display results\n",
    "print(\"\\nDUOS Datasets: \")\n",
    "results_df = pd.DataFrame(dataset_details_records)  \n",
    "display(results_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## TSV File Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_file = \"gs://fc-2a9eefc3-0302-427f-9ac3-82f078741c03/dataset_metadata/input/firecloud_target_tcga_metadata_20250227.tsv\" \n",
    "\n",
    "# Pull down specified file from the cloud\n",
    "results_log = []\n",
    "print(f\"Downloading input file {input_file}...\")\n",
    "try:\n",
    "    input_df = pd.read_csv(input_file, delimiter = \"\\t\", encoding='unicode_escape')\n",
    "    input_df = input_df.astype(object).where(pd.notnull(input_df),None)\n",
    "    input_df.fillna(\"\",inplace=True)\n",
    "    input_dict = input_df.to_dict(orient=\"records\")\n",
    "    results_log.append([\"Input File Download\", \"Succeeded\", \"\"])\n",
    "except Exception as e:\n",
    "    msg = f\"Error downloading input file ({input_file}): {str(e)}\"\n",
    "    results_log.append([\"Input File Download\", \"Failed\", msg])\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file_types_dict = json.loads(input_dict[0][\"consentGroups.fileTypes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file_types_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
