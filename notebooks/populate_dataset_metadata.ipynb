{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade data_repo_client\n",
    "#!pip install --upgrade xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "import json\n",
    "import google.auth\n",
    "import xmltodict\n",
    "import data_repo_client\n",
    "import pandas as pd\n",
    "import re\n",
    "from time import sleep\n",
    "import ast\n",
    "\n",
    "# Function to refresh TDR API client\n",
    "def refresh_tdr_api_client():\n",
    "    creds, project = google.auth.default()\n",
    "    auth_req = google.auth.transport.requests.Request()\n",
    "    creds.refresh(auth_req)\n",
    "    config = data_repo_client.Configuration()\n",
    "    config.host = \"https://data.terra.bio\"\n",
    "    config.access_token = creds.token\n",
    "    api_client = data_repo_client.ApiClient(configuration=config)\n",
    "    api_client.client_side_validation = False\n",
    "    return api_client\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Collect Metadata for Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4,
     22,
     29,
     40,
     46,
     49,
     52,
     55,
     58,
     61,
     67,
     70,
     587,
     847,
     865
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Functions\n",
    "#############################################\n",
    "\n",
    "def coalesce(*arg): \n",
    "    remove_list = [\"\", \"NA\", \"N/A\", \"NONE\", \"TBD\", \"UNKNOWN\", \"UNSPECIFIED\"]\n",
    "    # update to remove N/A, None, Null, TBD\n",
    "    for input_item in arg:\n",
    "        if input_item is False or input_item == []:\n",
    "            return input_item\n",
    "        elif input_item:\n",
    "            if isinstance(input_item, list):\n",
    "                temp_list = [ele for ele in input_item if ele is not None and ele.upper() not in remove_list]\n",
    "                if temp_list:\n",
    "                    return temp_list\n",
    "                else:\n",
    "                    return []\n",
    "            else:\n",
    "                if str(input_item).upper() not in remove_list:\n",
    "                    return input_item\n",
    "    return None\n",
    "\n",
    "def format_description(input_string):\n",
    "    output_string = input_string if input_string else \"\"\n",
    "    output_string = re.sub(\"\\n\\n\\t\", \" \", output_string)\n",
    "    output_string = re.sub(\"\\t\", \" \", output_string)\n",
    "    output_string = re.sub(\"study.cgi\\?study_id=|.\\/study.cgi\\?study_id=\", \"https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=\", output_string)\n",
    "    return output_string\n",
    "\n",
    "def format_phs_id(input_str):\n",
    "    try:\n",
    "        num = re.search(\"phs0*([0-9]+)\", input_str, re.IGNORECASE).group(1)\n",
    "    except:\n",
    "        num = \"\"\n",
    "    if num:\n",
    "        output_str = \"phs\" + str(num).zfill(6)\n",
    "    else:\n",
    "        output_str = \"\"\n",
    "    return output_str\n",
    "\n",
    "def try_join(l):\n",
    "    try:\n",
    "        if isinstance(l, list):\n",
    "            return ', '.join(map(str, l))\n",
    "        else:\n",
    "            return l\n",
    "    except TypeError:\n",
    "        return l\n",
    "    \n",
    "def val_study_type_enum(l):\n",
    "    if l and l not in [\"Observational\", \"Interventional\", \"Descriptive\", \"Analytical\", \"Prospective\", \"Retrospective\", \"Case report\", \"Case series\", \"Cross-sectional\", \"Cohort study\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def val_nih_inst_center_sub_enum(l):\n",
    "    if l and l not in [\"NCI\", \"NEI\", \"NHLBI\", \"NHGRI\", \"NIA\", \"NIAAA\", \"NIAID\", \"NIAMS\", \"NIBIB\", \"NICHD\", \"NIDCD\", \"NIDCR\", \"NIDDK\", \"NIDA\", \"NIEHS\", \"NIGMS\", \"NIMH\", \"NIMHD\", \"NINDS\", \"NINR\", \"NLM\", \"CC\", \"CIT\", \"CSR\", \"FIC\", \"NCATS\", \"NCCIH\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def val_nih_ic_supp_study_enum(l):\n",
    "    if l and isinstance(l, list):\n",
    "        for item in l:\n",
    "            if item not in [\"NCI\", \"NEI\", \"NHLBI\", \"NHGRI\", \"NIA\", \"NIAAA\", \"NIAID\", \"NIAMS\", \"NIBIB\", \"NICHD\", \"NIDCD\", \"NIDCR\", \"NIDDK\", \"NIDA\", \"NIEHS\", \"NIGMS\", \"NIMH\", \"NIMHD\", \"NINDS\", \"NINR\", \"NLM\", \"CC\", \"CIT\", \"CSR\", \"FIC\", \"NCATS\", \"NCCIH\"]:\n",
    "                return 1\n",
    "        return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def val_file_type_enum(l):\n",
    "    if l and isinstance(l, list):\n",
    "        for item in l:\n",
    "            if item not in [\"Arrays\", \"Genome\", \"Exome\", \"Survey\", \"Phenotype\"]:\n",
    "                return 1\n",
    "        return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def fetch_dataset_details(snapshot_id, ds_consent_map, duos_token):\n",
    "    \n",
    "    # Initialize variables\n",
    "    terra_dict = {}\n",
    "    dbgap_xml_dict = {}\n",
    "    dbgap_study_api_dict = {}\n",
    "    dbgap_fhir_dict = {}\n",
    "    final_results_dict = {}\n",
    "    \n",
    "    # Retrieve snapshot details\n",
    "    api_client = refresh_tdr_api_client()\n",
    "    datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "    snapshots_api = data_repo_client.SnapshotsApi(api_client=api_client)\n",
    "    attempt_counter = 0\n",
    "    while attempt_counter <= 2:\n",
    "        try:\n",
    "            snapshot_details = snapshots_api.retrieve_snapshot(id=snapshot_id).to_dict()\n",
    "            break\n",
    "        except:\n",
    "            sleep(5)\n",
    "            attempt_counter += 1  \n",
    "    snapshot_name = snapshot_details[\"name\"]\n",
    "    dataset_id = snapshot_details[\"source\"][0][\"dataset\"][\"id\"]\n",
    "    phs_id = format_phs_id(snapshot_details[\"source\"][0][\"dataset\"][\"phs_id\"])\n",
    "    if snapshot_details[\"source\"][0][\"dataset\"][\"secure_monitoring_enabled\"] == True:\n",
    "        access_management = \"controlled\"\n",
    "    else:\n",
    "        access_management = \"open\"\n",
    "    if snapshot_details[\"source\"][0][\"dataset_properties\"].get(\"source_workspaces\"):  \n",
    "        source_workspace = snapshot_details[\"source\"][0][\"dataset_properties\"][\"source_workspaces\"][0]\n",
    "    else:\n",
    "        source_workspace = None\n",
    "    if snapshot_details[\"source\"][0][\"dataset_properties\"].get(\"consent_name\"):\n",
    "        snapshot_consent_code = snapshot_details[\"source\"][0][\"dataset_properties\"][\"consent_name\"]\n",
    "    else:\n",
    "        snapshot_consent_code = None\n",
    "    if snapshot_details[\"duos_firecloud_group\"] != None:\n",
    "        duos_id = snapshot_details[\"duos_firecloud_group\"][\"duos_id\"]\n",
    "    else:\n",
    "        duos_id = None\n",
    "    print(\"\\tSnapshot PHS_ID: \" + str(phs_id))\n",
    "    print(\"\\tSource Workspace: \" + str(source_workspace))\n",
    "    print(\"\\tCurrent DUOS ID: \" + str(duos_id))\n",
    "    \n",
    "    # Build lookups\n",
    "    datasets = requests.get(\n",
    "        url=f\"{url}/api/dataset/v3\",\n",
    "        headers={\"Authorization\": f\"Bearer {duos_token}\"}\n",
    "            ).json()\n",
    "    #PSEUDOCODE - For each snapshot, we want to assign a recorded DUOS ID, target DUOS ID, target Study ID\n",
    "    try:\n",
    "        consent_group_name = re.search(r'(.*)_[0-9]{8}_ANV[0-9]+_[0-9]{12}$', snapshot_name).group(1)\n",
    "    except:\n",
    "        consent_group_name = snapshot_name\n",
    "    # Loop through new datasets API\n",
    "        # Create base consent_group_name from dataset_name to use for comparison (see above regex)\n",
    "        # Attempt to match the dataset based on the consent group name\n",
    "            # If match found, stop looking, assign the \"identifer\" as the target DUOS ID and \"study_id\" as the target study id\n",
    "    # Loop through study lookup\n",
    "        # Attempt to match snapshot PHS ID to a PHS ID for a study\n",
    "            # If match found, stop looking, and assign this as another target study ID\n",
    "#     If DUO on Snapshot, use that for both Study and Dataset information\n",
    "#     If dataset match, use that for both Study and Dataset information\n",
    "#     If no dataset match, try study match. If study match, use that for Study information\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    # Pull a list of existing AnVIL studies and datasets from DUOS\n",
    "studies_processed = set()\n",
    "results = []\n",
    "datasets = requests.get(\n",
    "    url=f\"{url}/api/dataset/v2?asCustodian=true\",\n",
    "    headers={\"Authorization\": f\"Bearer {token}\"}\n",
    ").json()\n",
    "for dataset_entry in datasets:\n",
    "    if dataset_entry.get(\"study\") and dataset_entry[\"study\"][\"studyId\"] not in studies_processed:\n",
    "        study_id = dataset_entry[\"study\"][\"studyId\"]\n",
    "        if dataset_entry[\"study\"].get(\"description\") and \"Platform: AnVIL\" in dataset_entry[\"study\"][\"description\"]: \n",
    "            study_name = dataset_entry[\"study\"][\"name\"]\n",
    "            study_phs = \"\"\n",
    "            for prop_entry in dataset_entry[\"study\"][\"properties\"]:\n",
    "                if prop_entry[\"key\"] == \"dbGaPPhsID\":\n",
    "                    study_phs = prop_entry[\"value\"]\n",
    "                    break\n",
    "            for dataset_id in dataset_entry[\"study\"][\"datasetIds\"]:\n",
    "                dataset_details = requests.get(\n",
    "                    url=f\"{url}/api/dataset/v2/{dataset_id}\",\n",
    "                    headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "                ).json()\n",
    "                dataset_name = dataset_details[\"name\"]\n",
    "                dataset_identifier = dataset_details[\"datasetIdentifier\"]\n",
    "                snapshot_id = \"\"\n",
    "                for prop_entry in dataset_entry[\"properties\"]:\n",
    "                    if prop_entry[\"propertyName\"] == \"URL\":\n",
    "                        snapshot_url = prop_entry[\"propertyValue\"]\n",
    "                        if snapshot_url:\n",
    "                            if \"https://data.terra.bio/snapshots/\" in snapshot_url:\n",
    "                                snapshot_id = snapshot_url.replace(\"https://data.terra.bio/snapshots/\", \"\")\n",
    "                        \n",
    "                results.append([study_id, study_name, study_phs, dataset_id, dataset_identifier, dataset_name, snapshot_id])\n",
    "        studies_processed.add(study_id)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Pull information from existing DUOS registration (if listed)\n",
    "    if duos_id:\n",
    "        # Establish credentials\n",
    "        creds, project = google.auth.default()\n",
    "        auth_req = google.auth.transport.requests.Request()\n",
    "        creds.refresh(auth_req)\n",
    "        \n",
    "        # Pull existing DUOS study registration\n",
    "        duos_dict = requests.get(\n",
    "            url=f\"https://consent.dsde-prod.broadinstitute.org/api/dataset/registration/{duos_id}\",\n",
    "            headers={\"Authorization\": f\"Bearer {creds.token}\"}\n",
    "        ).json()\n",
    "#         print(duos_dict)\n",
    "        \n",
    "        # Pull dataset details from DUOS (to get data use info) \n",
    "        duos_dataset_id = duos_dict[\"consentGroups\"][0].get(\"datasetId\")\n",
    "        duos_data_use_dict = {}\n",
    "        if duos_dataset_id:\n",
    "            dataset_details = requests.get(\n",
    "                url=f\"https://consent.dsde-prod.broadinstitute.org/api/dataset/v2/{duos_dataset_id}\",\n",
    "                headers={\"Authorization\": f\"Bearer {creds.token}\"}\n",
    "            ).json()\n",
    "            duos_data_use_dict = dataset_details.get(\"dataUse\")\n",
    "#         print(duos_data_use_dict)\n",
    "    \n",
    "    # Pull information from DUOS\n",
    "    \n",
    "    # Pull information from original workspace (if listed)\n",
    "    if source_workspace:\n",
    "        # Establish credentials\n",
    "        creds, project = google.auth.default()\n",
    "        auth_req = google.auth.transport.requests.Request()\n",
    "        creds.refresh(auth_req)\n",
    "\n",
    "        # Pull workspace attributes\n",
    "        attempt_counter = 0\n",
    "        while attempt_counter <= 2:\n",
    "            try:\n",
    "                ws_attributes = requests.get(\n",
    "                    url=f\"https://api.firecloud.org/api/workspaces/anvil-datastorage/{source_workspace}?fields=workspace.attributes,workspace.authorizationDomain,workspace.googleProject,workspace.bucketName\",\n",
    "                    headers={\"Authorization\": f\"Bearer {creds.token}\"}\n",
    "                ).json()\n",
    "                break\n",
    "            except:\n",
    "                sleep(5)\n",
    "                attempt_counter += 1\n",
    "        \n",
    "        # Map to schema\n",
    "        if ws_attributes.get(\"workspace\"):\n",
    "            terra_dict[\"studyName\"] = coalesce(ws_attributes[\"workspace\"][\"attributes\"].get(\"library:projectName\"), source_workspace) \n",
    "            terra_dict[\"studyType\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:studyDesign\")\n",
    "            terra_dict[\"studyDescription\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"description\")\n",
    "            if ws_attributes[\"workspace\"][\"attributes\"].get(\"library:dataCategory\"):\n",
    "                terra_dict[\"dataTypes\"] = []\n",
    "                for item in ws_attributes[\"workspace\"][\"attributes\"][\"library:dataCategory\"][\"items\"]:\n",
    "                    inner_list = item.split(\",\")\n",
    "                    for inner_item in inner_list:\n",
    "                        inner_item = inner_item.replace(\"'\", \"\").strip()\n",
    "                        terra_dict[\"dataTypes\"].append(inner_item)\n",
    "            terra_dict[\"phenotypeIndication\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:indication\")\n",
    "            terra_dict[\"species\"] = \"Homo sapiens\"\n",
    "            terra_dict[\"piName\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:datasetOwner\")\n",
    "            terra_dict[\"dataCustodianEmail\"] = [ws_attributes[\"workspace\"][\"attributes\"].get(\"library:contactEmail\")]\n",
    "            if ws_attributes[\"workspace\"][\"attributes\"].get(\"tag:tags\"):\n",
    "                for tag in ws_attributes[\"workspace\"][\"attributes\"].get(\"tag:tags\")[\"items\"]:\n",
    "                    if \"Consortium:\" in tag:\n",
    "                        terra_dict[\"consortium\"] = tag.split(\":\")[1].strip()\n",
    "                    elif \"dbGaP:\" in tag:\n",
    "                        terra_dict[\"dbGaPPhsID\"] = format_phs_id(tag.split(\":\")[1].strip())\n",
    "                        if not phs_id:\n",
    "                            phs_id = format_phs_id(tag.split(\":\")[1].strip()) \n",
    "            terra_dict[\"consentGroups.consentCode\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:dataUseRestriction\")\n",
    "            if ws_attributes[\"workspace\"][\"attributes\"].get(\"library:datatype\"):\n",
    "                terra_dict[\"consentGroups.fileTypes.fileType\"] = ws_attributes[\"workspace\"][\"attributes\"][\"library:datatype\"][\"items\"]\n",
    "            if ws_attributes[\"workspace\"][\"attributes\"].get(\"library:numSubjects\"):\n",
    "                terra_dict[\"consentGroups.numberOfParticipants\"] = ws_attributes[\"workspace\"][\"attributes\"][\"library:numSubjects\"]\n",
    "#         print(\"------------------------------------------------------\")\n",
    "#         print(\"terra_dict\")\n",
    "#         print(terra_dict)\n",
    "        \n",
    "    # Pull information from dbGaP (if phs_id listed)\n",
    "#     print(\"PHS ID for dbGaP: \" + phs_id)\n",
    "    if phs_id:\n",
    "        # Pull and parse XML\n",
    "        phs_short = phs_id.replace(\"phs\", \"\")\n",
    "        dbgap_url = \"https://dbgap.ncbi.nlm.nih.gov/ss/dbgapssws.cgi?request=Study&phs=\" + phs_short\n",
    "        attempt_counter = 0\n",
    "        while attempt_counter <= 2:\n",
    "            try:\n",
    "                response = requests.get(url=dbgap_url)\n",
    "                xml_data = xmltodict.parse(response.text)\n",
    "                break\n",
    "            except:\n",
    "                sleep(5)\n",
    "                attempt_counter += 1\n",
    "        study_uid = \"\"\n",
    "\n",
    "        # Map to schema\n",
    "        if xml_data[\"dbgapss\"].get(\"Study\"):\n",
    "            if isinstance(xml_data[\"dbgapss\"][\"Study\"], list):\n",
    "                study_data = xml_data[\"dbgapss\"][\"Study\"][0]\n",
    "            else:\n",
    "                study_data = xml_data[\"dbgapss\"][\"Study\"] \n",
    "            study_uid = study_data.get(\"@uid\")\n",
    "            dbgap_xml_dict[\"studyName\"] = study_data[\"StudyInfo\"].get(\"StudyNameEntrez\")\n",
    "            dbgap_xml_dict[\"studyDescription\"] = study_data[\"StudyInfo\"].get(\"Description\")\n",
    "            dbgap_xml_dict[\"dbGaPPhsID\"] = phs_id\n",
    "            dbgap_xml_dict[\"dbGaPStudyRegistrationName\"] = study_data[\"StudyInfo\"].get(\"StudyNameEntrez\")\n",
    "            if study_data[\"Authority\"][\"Persons\"].get(\"Person\"):\n",
    "                for ap_entry in study_data[\"Authority\"][\"Persons\"][\"Person\"]:\n",
    "                    if ap_entry[\"Role\"] == \"PI\":\n",
    "                        dbgap_xml_dict[\"piName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "                        dbgap_xml_dict[\"piEmail\"] = ap_entry[\"@email\"]\n",
    "                        dbgap_xml_dict[\"piInstitution\"] = ap_entry[\"Organization\"]\n",
    "                    elif ap_entry[\"Role\"] == \"PO\" and ap_entry[\"Organization\"] == \"NIH\":\n",
    "                        dbgap_xml_dict[\"nihProgramOfficerName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "                    elif ap_entry[\"Role\"] == \"GPA\" and ap_entry[\"Organization\"] == \"NIH\":\n",
    "                        dbgap_xml_dict[\"nihGenomicProgramAdministratorName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "            ic_list = []\n",
    "            if isinstance(study_data[\"Authority\"][\"ICs\"][\"IC\"], list):\n",
    "                for ic_entry in study_data[\"Authority\"][\"ICs\"][\"IC\"]:\n",
    "                    ic_list.append(ic_entry[\"@name\"])\n",
    "            else:\n",
    "                ic_list.append(study_data[\"Authority\"][\"ICs\"][\"IC\"][\"@name\"])\n",
    "            dbgap_xml_dict[\"nihICsSupportingStudy\"] = ic_list\n",
    "            dbgap_xml_dict[\"consentGroups.numberOfParticipants\"] = study_data.get(\"@num_participants\")\n",
    "            dbgap_xml_dict[\"embargoReleaseDate\"] = study_data[\"Policy\"].get(\"@pub-embargo\")\n",
    "#             print(\"------------------------------------------------------\")\n",
    "#             print(\"dbgap_xml_dict\")\n",
    "#             print(dbgap_xml_dict)\n",
    "        \n",
    "        # Pull and parse Study API JSON\n",
    "        if study_uid:\n",
    "            dbgap_study_url = \"https://submit.ncbi.nlm.nih.gov/dbgap/api/v1/study_config/\" + str(study_uid)\n",
    "            attempt_counter = 0\n",
    "            while attempt_counter <= 2:\n",
    "                try:\n",
    "                    response = requests.get(url=dbgap_study_url)\n",
    "                    study_api_data = json.loads(response.text)\n",
    "                    break\n",
    "                except:\n",
    "                    sleep(5)\n",
    "                    attempt_counter += 1\n",
    "            \n",
    "            # Map to schema\n",
    "            if study_api_data.get(\"error\") == None:\n",
    "                dbgap_study_api_dict[\"studyName\"] = study_api_data[\"data\"].get(\"report_name\")\n",
    "                dbgap_study_api_dict[\"studyDescription\"] = study_api_data[\"data\"].get(\"description\")\n",
    "                dbgap_study_api_dict[\"phenotypeIndication\"] = study_api_data[\"data\"].get(\"primary_disease\")\n",
    "                dbgap_study_api_dict[\"studyType\"] = study_api_data[\"data\"].get(\"study_design\")\n",
    "                dbgap_study_api_dict[\"dbGaPPhsID\"] = phs_id\n",
    "                dbgap_study_api_dict[\"dbGaPStudyRegistrationName\"] = study_api_data[\"data\"].get(\"report_name\")\n",
    "                for attr_entry in study_api_data[\"data\"].get(\"attribution\"):\n",
    "                    if attr_entry.get(\"title\") == \"Principal Investigator\":\n",
    "                        dbgap_study_api_dict[\"piName\"] = attr_entry.get(\"name\")\n",
    "                        dbgap_study_api_dict[\"piInstitution\"] = attr_entry.get(\"institute\")\n",
    "                        break\n",
    "#             print(\"------------------------------------------------------\")\n",
    "#             print(\"dbgap_study_api_dict\")\n",
    "#             print(dbgap_study_api_dict)\n",
    "        \n",
    "        # Pull and parse FHIR API JSON\n",
    "        dbgap_fhir_url = \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/ResearchStudy?_format=json&_id=\" + phs_id\n",
    "        attempt_counter = 0\n",
    "        while attempt_counter <= 2:\n",
    "            try:\n",
    "                response = requests.get(url=dbgap_fhir_url)\n",
    "                fhir_data = json.loads(response.text)\n",
    "                break\n",
    "            except:\n",
    "                sleep(5)\n",
    "                attempt_counter += 1\n",
    "\n",
    "        # Map to schema\n",
    "        if fhir_data.get(\"entry\"):\n",
    "            dbgap_fhir_dict[\"studyName\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"title\")\n",
    "            dbgap_fhir_dict[\"studyDescription\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"description\")\n",
    "            dbgap_fhir_dict[\"dbGaPPhsID\"] = phs_id\n",
    "            dbgap_fhir_dict[\"dbGaPStudyRegistrationName\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"title\")\n",
    "            # NIH ICs\n",
    "            if \"Organization/\" in fhir_data[\"entry\"][0][\"resource\"][\"sponsor\"].get(\"reference\"):\n",
    "                dbgap_fhir_dict[\"nihICsSupportingStudy\"] = [fhir_data[\"entry\"][0][\"resource\"][\"sponsor\"].get(\"reference\")[13:]]\n",
    "            else:\n",
    "                ic_display = fhir_data[\"entry\"][0][\"resource\"][\"sponsor\"].get(\"display\")\n",
    "                if ic_display == \"National Human Genome Research Institute\":\n",
    "                    dbgap_fhir_dict[\"nihICsSupportingStudy\"] = [\"NHGRI\"]\n",
    "                else:\n",
    "                    dbgap_fhir_dict[\"nihICsSupportingStudy\"] = [ic_display]\n",
    "            # studyType\n",
    "            if fhir_data[\"entry\"][0][\"resource\"].get(\"category\"):\n",
    "                for cat_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"category\"):\n",
    "                    if cat_entry.get(\"coding\"):\n",
    "                        for coding_entry in cat_entry.get(\"coding\"):\n",
    "                            if coding_entry.get(\"system\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/CodeSystem/ResearchStudy-StudyDesign\":\n",
    "                                value = coding_entry.get(\"display\") if coding_entry.get(\"display\") else coding_entry.get(\"code\")\n",
    "                                if dbgap_fhir_dict.get(\"studyType\") and value:\n",
    "                                    dbgap_fhir_dict[\"studyType\"] += f\", {value}\"\n",
    "                                elif value:\n",
    "                                    dbgap_fhir_dict[\"studyType\"] = value\n",
    "            # dataTypes\n",
    "            dt_list = []\n",
    "            if fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"): \n",
    "                for ext_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "                    if ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-MolecularDataTypes\":\n",
    "                        for inner_ext_entry in ext_entry.get(\"extension\"):\n",
    "                            if inner_ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-MolecularDataTypes-MolecularDataType\":\n",
    "                                for coding_entry in inner_ext_entry[\"valueCodeableConcept\"].get(\"coding\"):\n",
    "                                    dt_list.append(coding_entry.get(\"code\"))\n",
    "            dbgap_fhir_dict[\"dataTypes\"] = dt_list\n",
    "            # phenotypeIndication\n",
    "            if fhir_data[\"entry\"][0][\"resource\"].get(\"focus\"):\n",
    "                for focus_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"focus\"):\n",
    "                    if focus_entry.get(\"coding\"):\n",
    "                        for coding_entry in focus_entry.get(\"coding\"):\n",
    "                            value = coding_entry.get(\"display\") if coding_entry.get(\"display\") else coding_entry.get(\"code\")\n",
    "                            if dbgap_fhir_dict.get(\"phenotypeIndication\") and value:\n",
    "                                dbgap_fhir_dict[\"phenotypeIndication\"] += f\", {value}\"\n",
    "                            elif value:\n",
    "                                dbgap_fhir_dict[\"phenotypeIndication\"] = value\n",
    "            # numberOfParticipants\n",
    "            if fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "                for ext_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "                    if ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-Content\":\n",
    "                        for inner_ext_entry in ext_entry.get(\"extension\"):\n",
    "                            if inner_ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-Content-NumSubjects\":\n",
    "                                dbgap_fhir_dict[\"consentGroups.numberOfParticipants\"] = inner_ext_entry[\"valueCount\"].get(\"code\")\n",
    "#         print(\"------------------------------------------------------\")\n",
    "#         print(\"dbgap_fhir_dict\")\n",
    "#         print(dbgap_fhir_dict)\n",
    "    \n",
    "    # Reconcile information and create final results\n",
    "    consent_code = coalesce(snapshot_consent_code, terra_dict.get(\"consentGroups.consentCode\"), dbgap_fhir_dict.get(\"consentGroups.consentCode\"), dbgap_xml_dict.get(\"consentGroups.consentCode\"), dbgap_study_api_dict.get(\"consentGroups.consentCode\"))\n",
    "    if consent_code:\n",
    "        consent_code = consent_code.upper().replace(\"_\", \"-\")\n",
    "    else:\n",
    "        consent_code = \"\"\n",
    "    consortium = coalesce(terra_dict.get(\"consortium\"), dbgap_fhir_dict.get(\"consortium\"), dbgap_xml_dict.get(\"consortium\"), dbgap_study_api_dict.get(\"consortium\"))\n",
    "    dbGaPPhsID = coalesce(dbgap_fhir_dict.get(\"dbGaPPhsID\"), dbgap_xml_dict.get(\"dbGaPPhsID\"), dbgap_study_api_dict.get(\"dbGaPPhsID\"), terra_dict.get(\"dbGaPPhsID\"))\n",
    "    studyName = coalesce(dbgap_fhir_dict.get(\"studyName\"), dbgap_xml_dict.get(\"studyName\"), dbgap_study_api_dict.get(\"studyName\"), terra_dict.get(\"studyName\"))\n",
    "    if dbGaPPhsID and consent_code:\n",
    "        study_consent = dbGaPPhsID + \":\" + consent_code\n",
    "        purl_doid = ds_consent_map.get(study_consent)\n",
    "        if purl_doid:\n",
    "            if not isinstance(purl_doid, list):\n",
    "                purl_doid = [purl_doid]\n",
    "        else:\n",
    "            purl_doid = []\n",
    "    else:\n",
    "        purl_doid = []\n",
    "    final_results_dict[\"snapshot_id\"] = snapshot_id\n",
    "    final_results_dict[\"duos_id\"] = duos_id\n",
    "    try:\n",
    "        consent_group_name = re.search(r'(.*)_[0-9]{8}_ANV[0-9]+_[0-9]{12}$', snapshot_name).group(1)\n",
    "    except:\n",
    "        consent_group_name = snapshot_name\n",
    "    if duos_id:\n",
    "        final_results_dict[\"studyName\"] = duos_dict.get(\"studyName\")\n",
    "        final_results_dict[\"studyType\"] = duos_dict.get(\"studyType\")\n",
    "        final_results_dict[\"studyDescription\"] = duos_dict.get(\"studyDescription\")\n",
    "        final_results_dict[\"dataTypes\"] = duos_dict.get(\"dataTypes\")\n",
    "        final_results_dict[\"phenotypeIndication\"] = duos_dict.get(\"phenotypeIndication\")\n",
    "        final_results_dict[\"species\"] = duos_dict.get(\"species\")\n",
    "        final_results_dict[\"piName\"] = duos_dict.get(\"piName\")\n",
    "        final_results_dict[\"dataCustodianEmail\"] = duos_dict.get(\"dataCustodianEmail\")\n",
    "        final_results_dict[\"publicVisibility\"] = duos_dict.get(\"publicVisibility\")\n",
    "        final_results_dict[\"nihAnvilUse\"] = \"I am NHGRI funded and I have a dbGaP PHS ID already\" if 'already' in duos_dict.get(\"nihAnvilUse\").lower() else \"I am NHGRI funded and I do not have a dbGaP PHS ID\"\n",
    "        final_results_dict[\"submittingToAnvil\"] = duos_dict.get(\"submittingToAnvil\")\n",
    "        final_results_dict[\"dbGaPPhsID\"] = duos_dict.get(\"dbGaPPhsID\")\n",
    "        final_results_dict[\"dbGaPStudyRegistrationName\"] = duos_dict.get(\"dbGaPStudyRegistrationName\")\n",
    "        final_results_dict[\"embargoReleaseDate\"] = duos_dict.get(\"embargoReleaseDate\")\n",
    "        final_results_dict[\"sequencingCenter\"] = duos_dict.get(\"sequencingCenter\")\n",
    "        final_results_dict[\"piEmail\"] = duos_dict.get(\"piEmail\")\n",
    "        final_results_dict[\"piInstitution\"] = duos_dict.get(\"piInstitution\")\n",
    "        final_results_dict[\"nihGrantContractNumber\"] = duos_dict.get(\"nihGrantContractNumber\")\n",
    "        final_results_dict[\"nihICsSupportingStudy\"] = duos_dict.get(\"nihICsSupportingStudy\")\n",
    "        final_results_dict[\"nihProgramOfficerName\"] = duos_dict.get(\"nihProgramOfficerName\")\n",
    "        final_results_dict[\"nihInstitutionCenterSubmission\"] = duos_dict.get(\"nihInstitutionCenterSubmission\")\n",
    "        final_results_dict[\"nihInstitutionalCertificationFileName\"] = duos_dict.get(\"nihInstitutionalCertificationFileName\")\n",
    "        final_results_dict[\"nihGenomicProgramAdministratorName\"] = duos_dict.get(\"nihGenomicProgramAdministratorName\")\n",
    "        final_results_dict[\"multiCenterStudy\"] = duos_dict.get(\"multiCenterStudy\")\n",
    "        final_results_dict[\"collaboratingSites\"] = duos_dict.get(\"collaboratingSites\")\n",
    "        final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSR\"] = duos_dict.get(\"controlledAccessRequiredForGenomicSummaryResultsGSR\")\n",
    "        final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation\"] = duos_dict.get(\"controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation\")\n",
    "        final_results_dict[\"alternativeDataSharingPlan\"] = duos_dict.get(\"alternativeDataSharingPlan\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanReasons\"] = duos_dict.get(\"alternativeDataSharingPlanReasons\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanExplanation\"] = duos_dict.get(\"alternativeDataSharingPlanExplanation\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanFileName\"] = duos_dict.get(\"alternativeDataSharingPlanFileName\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanDataSubmitted\"] = duos_dict.get(\"alternativeDataSharingPlanDataSubmitted\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanDataReleased\"] = duos_dict.get(\"alternativeDataSharingPlanDataReleased\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanTargetDeliveryDate\"] = duos_dict.get(\"alternativeDataSharingPlanTargetDeliveryDate\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanTargetPublicReleaseDate\"] = duos_dict.get(\"alternativeDataSharingPlanTargetPublicReleaseDate\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanAccessManagement\"] = duos_dict.get(\"alternativeDataSharingPlanAccessManagement\")\n",
    "        final_results_dict[\"consentGroups.consentGroupName\"] = consent_group_name\n",
    "        final_results_dict[\"consentGroups.accessManagement\"] = access_management\n",
    "        final_results_dict[\"consentGroups.numberOfParticipants\"] = duos_dict[\"consentGroups\"][0].get(\"numberOfParticipants\")\n",
    "        final_results_dict[\"consentCode\"] = consent_code\n",
    "        final_results_dict[\"consentGroups.generalResearchUse\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"generalResearchUse\"), duos_data_use_dict.get(\"generalUse\"), False)\n",
    "        final_results_dict[\"consentGroups.hmb\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"hmb\"), duos_data_use_dict.get(\"hmbResearch\"), False)\n",
    "        final_results_dict[\"consentGroups.diseaseSpecificUse\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"diseaseSpecificUse\"), duos_data_use_dict.get(\"diseaseRestrictions\"), [])\n",
    "        final_results_dict[\"consentGroups.gs\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"gs\"), duos_data_use_dict.get(\"geographicalRestrictions\"))\n",
    "        final_results_dict[\"consentGroups.poa\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"poa\"), duos_data_use_dict.get(\"populationOriginsAncestry\"), False)\n",
    "        final_results_dict[\"consentGroups.nmds\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"nmds\"), False)\n",
    "        final_results_dict[\"consentGroups.gso\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"gso\"), duos_data_use_dict.get(\"geneticStudiesOnly\"), False)\n",
    "        final_results_dict[\"consentGroups.pub\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"pub\"), duos_data_use_dict.get(\"publicationResults\"), False)\n",
    "        final_results_dict[\"consentGroups.col\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"col\"), duos_data_use_dict.get(\"collaboratorRequired\"), False)\n",
    "        final_results_dict[\"consentGroups.irb\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"irb\"), duos_data_use_dict.get(\"ethicsApprovalRequired\"), False)\n",
    "        final_results_dict[\"consentGroups.npu\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"npu\"), False)\n",
    "        final_results_dict[\"consentGroups.otherPrimary\"] = duos_dict[\"consentGroups\"][0].get(\"otherPrimary\")\n",
    "        final_results_dict[\"consentGroups.otherSecondary\"] = duos_dict[\"consentGroups\"][0].get(\"otherSecondary\")\n",
    "        final_results_dict[\"consentGroups.mor\"] = duos_dict[\"consentGroups\"][0].get(\"mor\")\n",
    "        final_results_dict[\"consentGroups.morDate\"] = duos_dict[\"consentGroups\"][0].get(\"morDate\")\n",
    "        final_results_dict[\"consentGroups.dataLocation\"] = \"TDR Location\"\n",
    "        final_results_dict[\"consentGroups.url\"] = \"https://data.terra.bio/snapshots/\" + snapshot_id\n",
    "        if duos_dict[\"consentGroups\"][0][\"fileTypes\"] and duos_dict[\"consentGroups\"][0][\"fileTypes\"].get(\"fileType\"):\n",
    "            final_results_dict[\"consentGroups.fileTypes.fileType\"] = duos_dict[\"consentGroups\"][0][\"fileTypes\"][0].get(\"fileType\")\n",
    "        else:\n",
    "            final_results_dict[\"consentGroups.fileTypes.fileType\"] = None\n",
    "        if duos_dict[\"consentGroups\"][0][\"fileTypes\"] and duos_dict[\"consentGroups\"][0][\"fileTypes\"].get(\"functionalEquivalence\"):\n",
    "            final_results_dict[\"consentGroups.fileTypes.functionalEquivalence\"] = duos_dict[\"consentGroups\"][0][\"fileTypes\"][0].get(\"functionalEquivalence\")\n",
    "        else:\n",
    "            final_results_dict[\"consentGroups.fileTypes.functionalEquivalence\"] = None\n",
    "        final_results_dict[\"consortium\"] = consortium\n",
    "    else:\n",
    "        if dbGaPPhsID:\n",
    "            final_results_dict[\"studyName\"] = studyName + f\" ({dbGaPPhsID})\"\n",
    "        else:\n",
    "            final_results_dict[\"studyName\"] = studyName\n",
    "        final_results_dict[\"studyType\"] = coalesce(dbgap_fhir_dict.get(\"studyType\"), dbgap_xml_dict.get(\"studyType\"), dbgap_study_api_dict.get(\"studyType\"), terra_dict.get(\"studyType\"))\n",
    "        final_results_dict[\"studyDescription\"] = format_description(coalesce(dbgap_fhir_dict.get(\"studyDescription\"), dbgap_xml_dict.get(\"studyDescription\"), dbgap_study_api_dict.get(\"studyDescription\"), terra_dict.get(\"studyDescription\")))\n",
    "        if final_results_dict[\"studyDescription\"]:\n",
    "            final_results_dict[\"studyDescription\"] = final_results_dict[\"studyDescription\"] + \"\\nPlatform: AnVIL\"\n",
    "        else:\n",
    "            final_results_dict[\"studyDescription\"] = \"Platform: AnVIL\"\n",
    "        final_results_dict[\"dataTypes\"] = coalesce(terra_dict.get(\"dataTypes\"), dbgap_fhir_dict.get(\"dataTypes\"), dbgap_xml_dict.get(\"dataTypes\"), dbgap_study_api_dict.get(\"dataTypes\"))\n",
    "        final_results_dict[\"phenotypeIndication\"] = coalesce(terra_dict.get(\"phenotypeIndication\"), dbgap_fhir_dict.get(\"phenotypeIndication\"), dbgap_xml_dict.get(\"phenotypeIndication\"), dbgap_study_api_dict.get(\"phenotypeIndication\"))\n",
    "        final_results_dict[\"species\"] = \"Human\"\n",
    "        final_results_dict[\"piName\"] = coalesce(dbgap_fhir_dict.get(\"piName\"), dbgap_xml_dict.get(\"piName\"), dbgap_study_api_dict.get(\"piName\"), terra_dict.get(\"piName\"), \"None\")\n",
    "        final_results_dict[\"dataCustodianEmail\"] = [\"help@lists.anvilproject.org\"]\n",
    "        final_results_dict[\"publicVisibility\"] = True\n",
    "        final_results_dict[\"nihAnvilUse\"] = \"I am NHGRI funded and I have a dbGaP PHS ID already\" if dbGaPPhsID else \"I am NHGRI funded and I do not have a dbGaP PHS ID\"\n",
    "        final_results_dict[\"submittingToAnvil\"] = True\n",
    "        final_results_dict[\"dbGaPPhsID\"] = dbGaPPhsID\n",
    "        final_results_dict[\"dbGaPStudyRegistrationName\"] = coalesce(dbgap_fhir_dict.get(\"dbGaPStudyRegistrationName\"), dbgap_xml_dict.get(\"dbGaPStudyRegistrationName\"), dbgap_study_api_dict.get(\"dbGaPStudyRegistrationName\"), terra_dict.get(\"dbGaPStudyRegistrationName\"))\n",
    "        final_results_dict[\"embargoReleaseDate\"] = coalesce(dbgap_fhir_dict.get(\"embargoReleaseDate\"), dbgap_xml_dict.get(\"embargoReleaseDate\"), dbgap_study_api_dict.get(\"embargoReleaseDate\"), terra_dict.get(\"embargoReleaseDate\"))\n",
    "        final_results_dict[\"sequencingCenter\"] = None\n",
    "        final_results_dict[\"piEmail\"] = coalesce(dbgap_fhir_dict.get(\"piEmail\"), dbgap_xml_dict.get(\"piEmail\"), dbgap_study_api_dict.get(\"piEmail\"), terra_dict.get(\"piEmail\"))\n",
    "        final_results_dict[\"piInstitution\"] = coalesce(dbgap_fhir_dict.get(\"piInstitution\"), dbgap_xml_dict.get(\"piInstitution\"), dbgap_study_api_dict.get(\"piInstitution\"), terra_dict.get(\"piInstitution\"))\n",
    "        final_results_dict[\"nihGrantContractNumber\"] = None\n",
    "        final_results_dict[\"nihICsSupportingStudy\"] = coalesce(dbgap_fhir_dict.get(\"nihICsSupportingStudy\"), dbgap_xml_dict.get(\"nihICsSupportingStudy\"), dbgap_study_api_dict.get(\"nihICsSupportingStudy\"), terra_dict.get(\"nihICsSupportingStudy\"))\n",
    "        final_results_dict[\"nihProgramOfficerName\"] = coalesce(dbgap_fhir_dict.get(\"nihProgramOfficerName\"), dbgap_xml_dict.get(\"nihProgramOfficerName\"), dbgap_study_api_dict.get(\"nihProgramOfficerName\"), terra_dict.get(\"nihProgramOfficerName\"))\n",
    "        final_results_dict[\"nihInstitutionCenterSubmission\"] = \"NHGRI\"\n",
    "        final_results_dict[\"nihInstitutionalCertificationFileName\"] = None\n",
    "        final_results_dict[\"nihGenomicProgramAdministratorName\"] = coalesce(dbgap_fhir_dict.get(\"nihGenomicProgramAdministratorName\"), dbgap_xml_dict.get(\"nihGenomicProgramAdministratorName\"), dbgap_study_api_dict.get(\"nihGenomicProgramAdministratorName\"), terra_dict.get(\"nihGenomicProgramAdministratorName\"))\n",
    "        final_results_dict[\"multiCenterStudy\"] = None\n",
    "        final_results_dict[\"collaboratingSites\"] = [consortium] if consortium else []\n",
    "        final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSR\"] = None\n",
    "        final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlan\"] = False\n",
    "        final_results_dict[\"alternativeDataSharingPlanReasons\"] = []\n",
    "        final_results_dict[\"alternativeDataSharingPlanExplanation\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlanFileName\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlanDataSubmitted\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlanDataReleased\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlanTargetDeliveryDate\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlanTargetPublicReleaseDate\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlanAccessManagement\"] = None\n",
    "        final_results_dict[\"consentGroups.consentGroupName\"] = consent_group_name\n",
    "        final_results_dict[\"consentGroups.accessManagement\"] = access_management\n",
    "        final_results_dict[\"consentGroups.numberOfParticipants\"] = coalesce(terra_dict.get(\"consentGroups.numberOfParticipants\"), dbgap_fhir_dict.get(\"consentGroups.numberOfParticipants\"), dbgap_xml_dict.get(\"consentGroups.numberOfParticipants\"), dbgap_study_api_dict.get(\"consentGroups.numberOfParticipants\"), \"0\")\n",
    "        final_results_dict[\"consentCode\"] = consent_code\n",
    "        final_results_dict[\"consentGroups.generalResearchUse\"] = True if access_management == \"controlled\" and \"GRU\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.hmb\"] = True if access_management == \"controlled\" and \"HMB\" in consent_code else False\n",
    "        if purl_doid:\n",
    "            final_results_dict[\"consentGroups.diseaseSpecificUse\"] = purl_doid\n",
    "        else:\n",
    "            final_results_dict[\"consentGroups.diseaseSpecificUse\"] = []\n",
    "        final_results_dict[\"consentGroups.gs\"] = consent_code if access_management == \"controlled\" and \"GS-\" in consent_code else None\n",
    "        final_results_dict[\"consentGroups.poa\"] = True if access_management == \"controlled\" and \"POA\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.nmds\"] = True if access_management == \"controlled\" and \"NMDS\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.gso\"] = True if access_management == \"controlled\" and \"GSO\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.pub\"] = True if access_management == \"controlled\" and \"PUB\" in consent_code else False \n",
    "        final_results_dict[\"consentGroups.col\"] = True if access_management == \"controlled\" and \"COL-\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.irb\"] = True if access_management == \"controlled\" and \"IRB\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.npu\"] = True if access_management == \"controlled\" and \"NPU\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.otherPrimary\"] = consent_code if (consent_code and access_management == \"controlled\" and not (final_results_dict[\"consentGroups.generalResearchUse\"] or final_results_dict[\"consentGroups.hmb\"] or final_results_dict[\"consentGroups.diseaseSpecificUse\"] or final_results_dict[\"consentGroups.gs\"] or final_results_dict[\"consentGroups.poa\"] or final_results_dict[\"consentGroups.nmds\"] or final_results_dict[\"consentGroups.gso\"] or final_results_dict[\"consentGroups.pub\"] or final_results_dict[\"consentGroups.col\"] or final_results_dict[\"consentGroups.irb\"] or final_results_dict[\"consentGroups.npu\"])) else None\n",
    "        final_results_dict[\"consentGroups.otherSecondary\"] = None\n",
    "        final_results_dict[\"consentGroups.mor\"] = None\n",
    "        final_results_dict[\"consentGroups.morDate\"] = None\n",
    "        final_results_dict[\"consentGroups.dataLocation\"] = \"TDR Location\"\n",
    "        final_results_dict[\"consentGroups.url\"] = \"https://data.terra.bio/snapshots/\" + snapshot_id\n",
    "        final_results_dict[\"consentGroups.fileTypes.fileType\"] = coalesce(terra_dict.get(\"consentGroups.fileTypes.fileType\"), dbgap_fhir_dict.get(\"consentGroups.fileTypes.fileType\"), dbgap_xml_dict.get(\"consentGroups.fileTypes.fileType\"), dbgap_study_api_dict.get(\"consentGroups.fileTypes.fileType\"))\n",
    "        final_results_dict[\"consentGroups.fileTypes.functionalEquivalence\"] = None\n",
    "        final_results_dict[\"consortium\"] = consortium\n",
    "    \n",
    "    # Return results\n",
    "    return final_results_dict\n",
    "\n",
    "\n",
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# Specify the snapshots to pull data for:\n",
    "snapshot_id_list = [\n",
    "    'dd2b61fb-d420-4a38-9cd2-8464f51d7617',\n",
    "    '253e2b36-1674-482b-bfbd-4e0b05cdfe63',\n",
    "    '3f53e841-ca9d-4b55-b390-590718533561',\n",
    "    '01cf2450-604b-43e5-9f4e-9ec4e0bf0a61',\n",
    "    '85b0b351-cd0a-4efe-95a4-e39273c42831',\n",
    "    '0b31081f-1bce-490a-bd0a-b1aa0fd0daf6',\n",
    "    '76ec3691-30f3-43cd-af8b-e73c80da90b9',\n",
    "    '62a4b183-9157-4320-96e6-32f79c561399',\n",
    "    '553ba443-b8cc-4d8e-9743-e384116a1236',\n",
    "    '3fc2937c-dc08-400f-9458-3779de623bd0',\n",
    "    'bfab39d1-1a38-4884-a139-be2809378e7b',\n",
    "    '99a1ace0-aa83-4d9d-9e9c-e9b6b0111ba2',\n",
    "    '2fdba9a4-6593-439a-a7fc-c3a5825c26cd',\n",
    "    '18a28450-31ec-4e4a-a305-dbbdd226ae3c',\n",
    "    'f7d225d9-1675-483d-a1eb-9ef750301cd4',\n",
    "    'b13297c4-bb9a-4222-b069-9efcdc9d7ac3',\n",
    "    'c753046a-cf9b-4813-be68-cb3b9dd9866e',\n",
    "    '37374406-0c9c-4b94-bdb5-d4f9daf3b335',\n",
    "    'ad4ed62b-bf63-4dff-ab94-70a6432c161c',\n",
    "    'c195ed64-842d-4525-8a1c-9083eccaafa7',\n",
    "    '84103748-39eb-45f9-b4ca-e23a9e52d0cc',\n",
    "    '96cfd9ec-5eb4-48f5-9284-84f349701033',\n",
    "    '8f104c7f-8b5a-489e-95b4-616130405e7c',\n",
    "    'b300b5ae-6ca3-4350-bc46-345173f6faba',\n",
    "    'a2bb366f-029d-4bef-8da7-dce818743881',\n",
    "    '7bc891a2-a634-4cf2-b41e-0b1e98fce599',\n",
    "    'f2f0d8a3-6e18-436a-bc51-ff742d30d6a4',\n",
    "    '2b2a1f74-9c2e-4c6c-840b-80f466d1e209',\n",
    "    '9dbac1be-a33c-419c-be92-d1a5452c1292',\n",
    "    '3442e75a-7452-4680-9ce5-70fa21363083',\n",
    "    '79509151-b96a-483f-a6b3-eeede54467d1',\n",
    "    '40d6feec-e6f7-42f1-8e74-a3404e1f9208',\n",
    "    '887dd90c-6742-4283-92b2-bc9ed6bc2ae1',\n",
    "    '95b4c57b-8e88-45f5-9dbb-e2575f4b2a68',\n",
    "    'ec292668-bc78-45f7-b601-8d452b038e6c',\n",
    "    '432c6422-ceaf-4c6c-bd8d-7c90771a284f',\n",
    "    '8d055301-47e0-4384-9746-8bc1b93d9a96',\n",
    "    '6f1d6a31-1997-4b59-a311-f84631ebdcbf',\n",
    "    '79502d0c-bc1c-4d51-a6de-eb0334b3b660',\n",
    "    '0565b2e4-ade1-46e7-80bf-ca647a89a8b8',\n",
    "    '0af0d35e-1f9a-464d-80fe-474b5dbbd914',\n",
    "    '2aee2dfa-a819-4beb-b8a0-c07d5d577470',\n",
    "    '514bbe9f-0ffc-47a6-b25e-fe01fe26b720',\n",
    "    '79c20af6-5788-47ce-9651-f6a6ae084cbc',\n",
    "    'ea08adf0-2383-41ae-a91a-88c7b8f6f42b',\n",
    "    'f5626dd5-b0f3-4c59-b7e1-e7fce6488419',\n",
    "    'f90f565e-0ade-4750-a308-5c8e1677b43d',\n",
    "    'a51570ab-b0f7-4f30-bdad-ef25e5a6e9a9',\n",
    "    '194c4b14-cb6a-469c-83db-d37f7ec65f29',\n",
    "    '72f7d3a3-8c70-46cb-93eb-f258a5577fd8',\n",
    "    '33c73ae8-f829-438d-bdb1-da0be8f3773f',\n",
    "    '3d6afb8e-dbcd-4972-8281-ae546b23356c',\n",
    "    '88b16321-7f0a-44b1-8131-d4b2188d9839',\n",
    "    '08f28ada-3fa1-41f3-a7eb-5b4ff8325145',\n",
    "    '12d5b6d6-0942-4759-978f-768c92b9f2dd',\n",
    "    '9345adce-2f83-4c02-8859-72ddccb22069',\n",
    "    '75f5452d-ceca-402e-bfc4-759c8352f4da',\n",
    "    'cdcfc6ac-6c9f-4d99-a8c3-4d1e5d171261',\n",
    "    '245805dc-d7ab-4a78-bb35-18e1635e6ba5',\n",
    "    'ecef49e8-2fa4-4507-ada8-2c8d9ad39417',\n",
    "    '218f6eb5-a71f-4e2f-bc6d-ed6df248422a',\n",
    "    'd3047f14-4202-4986-9daa-673a578eebcc',\n",
    "    '57457a3b-ed1e-4d48-8585-ef8a4b053c64',\n",
    "    '651049a2-2950-4be3-b755-6d133233a010',\n",
    "    '16f19aec-a9df-4ca8-84fb-b892e9a40ea8',\n",
    "    '6441b9e0-ca7b-4ab4-b7e7-9c7c7041ebaa',\n",
    "    'ab9e5f9a-a829-4a63-bb72-d3cdb2d02ecf',\n",
    "    'ae0c27d6-c8e3-4dd5-abf5-06e5f39fc4a0',\n",
    "    '49e0dc54-7254-43c5-849e-7b1434638f73',\n",
    "    'cb5a6268-c0c8-433d-b62c-7beeeb0a6a92',\n",
    "    'c4ed93d6-b3f0-4f3f-844f-07d90366b64d',\n",
    "    'ad18153b-870c-491a-9d4e-df30d902a03f',\n",
    "    '76ee61e9-ca73-4f0b-8c7d-26f7d0a0a383',\n",
    "    '0f6db24a-05d6-46fc-9ff6-795e29d10ca5',\n",
    "    'a8d89992-838e-474e-86b7-b3384ce6d6a6',\n",
    "    '19c8ccd5-fc2e-4c45-984e-453994dab156',\n",
    "    '127fcfd9-565f-4d05-a91a-5a508ece85bd',\n",
    "    'b5b89490-cc7a-44fe-8de2-f0934819c22f',\n",
    "    '10d94161-9a9a-419f-8f80-b6f6b1f03f66',\n",
    "    'ca17fec7-109d-4534-b969-5e0246249196',\n",
    "    'e18cd59b-cb26-426b-ade1-e4342b082a6c',\n",
    "    '66544f8c-034f-487e-a923-8418eb6c4f94',\n",
    "    '5fe081df-aede-4283-9ee9-5858ad8d4d85',\n",
    "    'e2736891-a569-449e-8cbf-b7d0274b64d0',\n",
    "    '92e0bbb7-3bde-4382-984c-55324e415685',\n",
    "    'bf6c8799-c680-4dc3-abd0-03589d98cf26',\n",
    "    'ae61a5ab-7a98-446e-8520-e9198b6a039c',\n",
    "    '6f1efaa0-0b77-4719-8d15-0d9afc01d91a',\n",
    "    '602f3f08-3067-4fda-b586-1e114a03151e',\n",
    "    'f14783da-5251-4800-abbd-0dbd18b2d306',\n",
    "    '3a599138-282a-4dec-9a29-40bc0885321e',\n",
    "    'b32c07bc-d899-4194-ba1d-a29ec70ae0b5',\n",
    "    '5b4c1063-a1de-46af-a844-ce56800548d8',\n",
    "    'f105f715-7bd0-4103-9c12-e097f902fc35',\n",
    "    'ac852b54-1578-4812-bd62-8544617b1c00',\n",
    "    '495329a6-fc6f-4088-a7d8-afd5d3148bfd',\n",
    "    '30c2f5b3-80d2-4b96-846e-3774160c0417',\n",
    "    '16c066f7-d2c1-4920-966c-c545e9d1d114',\n",
    "    'f68344f4-4aee-4ce5-aa8f-44cd24e934e2',\n",
    "    '4e711c00-75bb-4b1f-a4ee-ec8e47e2b9af',\n",
    "    '0dfe1df2-8139-4fba-9afb-bd47d1a2fbf6',\n",
    "    '7300865c-2f5f-412d-a40c-0eef523a1738',\n",
    "    '6287a9aa-0556-4ef3-89b4-e9a16da6f71c',\n",
    "    'f8e05104-0369-49f8-8469-0b49d3de1ebd',\n",
    "    '9ebfd2a3-aeba-4aa4-a38f-6fbbf794c7af',\n",
    "    '6babae16-eb39-4fcf-8bcb-5d4896fc2cd3',\n",
    "    '269300d9-c82c-4fbc-be11-f27cc7a010bf',\n",
    "    'e1560527-6e20-447c-835c-44b10fa20b79',\n",
    "    '19ba7e89-3d13-4f19-a7a7-04ad93185b44',\n",
    "    '02b4a9fc-4e4d-4977-be04-977ea8f88176',\n",
    "    '492d02fd-2194-4c1d-a888-e665a068b35f',\n",
    "    '273be8c5-6303-47a6-8b33-57f65cc88840',\n",
    "    'bea23c53-b3c0-488a-a997-52ab2fe38f01',\n",
    "    '74bb77d8-e245-4305-8c3f-65385d331fb9',\n",
    "    '2b2d0eb2-6d1f-4072-ab28-082ec1b054e6',\n",
    "    'e0d46f3a-5872-4190-ae94-8eddca9d65d0',\n",
    "    '07d82c74-91a0-4eaa-87e0-a6f055d9a5c6',\n",
    "    '341f76ba-c06c-4e58-a9d5-7e9f740d621d',\n",
    "    '80969539-637f-4a71-bdfa-fdaf414cf8b4',\n",
    "    '9a747c42-9058-4fcf-9fda-7b355e42d7b3',\n",
    "    'cd3d7010-c63c-467f-b585-abe1b3da4e48',\n",
    "    'd761e8f3-45e7-4d2d-99b9-462ace937e68',\n",
    "    'bfadebce-def1-4e3e-97e1-0b768188db02',\n",
    "    'c138efe7-9400-4ad6-b23d-287d06ab2179',\n",
    "    '95dc1d22-9bff-4363-bddb-b29c266b4e28',\n",
    "    '67211908-3193-4d4f-9966-a5de8548b4d0',\n",
    "    'ff1d59ff-dc35-482a-933a-e9d9a1eb6a20',\n",
    "    '6c6b260b-0a17-4cfa-ad5a-8cc5a75c2188',\n",
    "    '363888df-5cb4-4c07-9218-06938d219c2e',\n",
    "    '835c7254-7b6d-4db2-9f91-c3a5261304af',\n",
    "    '461d7216-0d2c-4349-90eb-9a8e5db4d3c3',\n",
    "    '4e682923-5e29-48e4-a3ff-76d86c08cf8d',\n",
    "    'f8404885-5a20-4c14-a75c-5711262868fb',\n",
    "    'dbd5c82f-0e81-4d4d-9f29-a34a2404fbbe',\n",
    "    '6d95d827-c9b5-4296-9b90-15dc646bb00d',\n",
    "    '3e4ebe7c-b5d4-4239-95da-03da7d8dedd3',\n",
    "    '3cce8ea2-297c-4097-9c13-c3f1cadad921',\n",
    "    '9986e29b-1b35-439d-83c9-2120679e1860',\n",
    "    '12add555-dbc1-45a5-a5c4-d3d9a172759e',\n",
    "    'd197888e-7be6-4bf0-b33a-0919236481b2',\n",
    "    '3633eeb2-b317-4d17-9daa-4a5ca479c05b',\n",
    "    'e28d0ba2-5523-4b40-b34e-0dd80653dd0a',\n",
    "    'b378d487-7de4-41b1-aca9-050c6e5deef9',\n",
    "    '57b52802-5caf-4611-aa0a-7371dd11d221',\n",
    "    '455c8618-fe26-4424-87ae-42b1fbaeb9d9',\n",
    "    '7a8e14f1-ffec-47d1-ae87-fdbb8267d427',\n",
    "    '82b5cf36-94e7-408a-a4d3-db797a0ffbe9',\n",
    "    'b6d3176b-525a-417a-bda0-def9611bf08a',\n",
    "    '1d676097-4e9e-4c5a-8ee1-63d865054897',\n",
    "    'a1df0d3b-4871-4371-8418-58a302719e6e',\n",
    "    'ee5ca91d-01d8-43a9-a571-16b1390109b1',\n",
    "    'ea14aac8-3c44-4f09-acdd-34d22a0169a2',\n",
    "    '9c3e6a87-ac6b-4f3a-bd86-c2e0ce9051e9',\n",
    "    'dc9ed67a-62da-48a4-89eb-61d86474659b',\n",
    "    '441b79d9-6142-44d9-9aa9-05d4d03bc118',\n",
    "    '30387b65-4b3c-4f9a-9f15-f57f30ff76ef',\n",
    "    '83cfe90a-6c9e-44ca-aae4-16ed7f78554a',\n",
    "    '3877f3c9-bd2f-4f86-b97b-a5bec85f9f3c',\n",
    "    'f183e8af-8728-4ad0-bac0-fb68a7eb9bef',\n",
    "    '83a1eee3-0395-4916-a62b-a37b24d9ca78',\n",
    "    'cbc80926-dd3e-4ff8-8d8f-77078f260c7e',\n",
    "    'c2f86bff-92c2-4c35-a5ec-f284bfc934b9',\n",
    "    'c5da9730-1af8-4944-9dc8-273f6c845731',\n",
    "    '80b8af9b-d54e-447a-9a53-e1b1c12b7e55',\n",
    "    'c53cc8ed-7b5f-4c7d-ba7f-c3520856c082',\n",
    "    '991b8415-06bf-4527-9753-0345b32cc4b0',\n",
    "    'f033bb12-7aef-4b7e-86bb-448b8e9f1c58',\n",
    "    '138c04b9-bf59-45c9-89d9-630fe606074e',\n",
    "    '23dbf4be-b4c1-492a-b754-941626d03c53',\n",
    "    '47cf45d3-8054-4e53-b569-ecb7d47d72b7',\n",
    "    '4574e2f2-832b-430d-9558-f9ea6088cbe6',\n",
    "    'a504feea-036f-4627-83c8-4cbb0e42da65',\n",
    "    'ed24c069-fde1-443a-8bf2-77ec8b4e86dd',\n",
    "    '58226893-e7d5-4ea3-9195-d512c70dacf9',\n",
    "    '1623f347-3bb0-40cd-a9c6-207d0278025f',\n",
    "    'b9992098-e09c-44f4-b091-b290b12dfc10',\n",
    "    '5dcb42e6-3702-4764-a3be-2829f704f176',\n",
    "    '30092c80-3b91-4433-ae6b-8085b0a19a5b',\n",
    "    'e1e5a2c3-e046-4483-ad39-909980026783',\n",
    "    '5a8aef0b-e101-4b9e-8cc5-da005295e42a',\n",
    "    '22331a2a-42d9-47e8-a6a9-ff6fb3e71ee5',\n",
    "    '15d118c9-4954-41ef-920a-bbce759e5ed0',\n",
    "    'cb787d4a-8f56-4e79-a0da-2e4281e30362',\n",
    "    '461c1b26-7306-4feb-b141-f83c209baf27',\n",
    "    '36e807b4-3e10-41fe-a92b-21fa352648e6',\n",
    "    '9e2f0ab6-f964-4aa8-a83c-894d716d55ce',\n",
    "    '6b129887-63b8-41a9-aa5e-0ed83755c58f',\n",
    "    'd7b2b2c6-72fd-4084-af34-a86edfe3ac47',\n",
    "    'd63a63ce-24c8-413a-89c0-4bd4c82370c0',\n",
    "    '6a242848-a716-4de9-ab38-3c82983810a8',\n",
    "    'c48c956a-1ede-4c6e-805d-46754dc58126',\n",
    "    'b116216f-8ee1-4058-b40e-0b33b0928107',\n",
    "    'aeee7408-eb4e-42a9-956f-bb61759f2f55',\n",
    "    'f3e644af-d04a-4bf1-8dc2-f2932e98ac89',\n",
    "    '775b8b5f-9e9c-477f-a97d-a4307343b28a',\n",
    "    '1b66db3a-1ef6-4f05-b8a3-b0765fa9407d',\n",
    "    '7fffbc86-4ac1-4fb4-8e47-13b83706a6bd',\n",
    "    'b24fe2ae-a0a2-4ac7-ad2a-f810a0b88a9b',\n",
    "    'bb70de9b-a893-476b-b698-b1ee228831ee',\n",
    "    '1bccd783-15a8-4191-b08f-b8a5556bfd52',\n",
    "    '45cdfb71-f149-4910-89cb-446111ba741f',\n",
    "    '4ca93f73-cf6c-47b9-854c-8465e79c7fc8',\n",
    "    '8efb7fd2-1395-40f6-83fa-4ed459a3370e',\n",
    "    'efaea9d6-0c9c-41aa-b739-600a431e8f58',\n",
    "    '73f0ac44-748b-4b94-9e53-5b5eb3507ffa',\n",
    "    'b8a6edf5-3636-47ab-94f6-d948f2d14571',\n",
    "    '7b00e1cf-e811-40af-9f01-2b6682b1c44d',\n",
    "    'f73959f2-8d1c-4998-bae4-85551e2ca445',\n",
    "    'e66e025f-e07c-4f0d-93ed-3ac609b570d5',\n",
    "    '6a477149-a7f0-4758-8570-b288a8314fbd',\n",
    "    '07b0243c-48fc-4eee-a338-c7571cc2df1a',\n",
    "    '94f79040-68f5-4801-bf41-6f29bc0be8c6',\n",
    "    'c9e51094-9991-4946-b6a8-6cd19c399173',\n",
    "    'ac0cdd08-47f4-4776-bd70-8bb512c6563e',\n",
    "    'b9134038-96b5-434b-8456-963caac4c6db',\n",
    "    '0b3dd699-d4d3-4295-8ec2-502e6c41d8d7',\n",
    "    '2b781259-3ff4-44fa-bba1-e2b674548e6c',\n",
    "    '8fda9c6e-3e5d-474a-99d2-07eeae12f768',\n",
    "    'ca358d94-47cb-4aa1-8565-9d4280f286fb',\n",
    "    '6c69e870-8def-432d-8fbe-dc0da610635e',\n",
    "    '53fd76c8-6745-414e-adbe-62ff72011fc5',\n",
    "    'f6db6471-03c5-44b6-a463-4976d8fc6350',\n",
    "    'a6c392e5-cbef-469d-a151-4f54c73b5fb3',\n",
    "    '1985e363-b6da-47ec-8c92-dabcd587e6b6',\n",
    "    '389f685b-f727-41ad-adf5-c72365223ab6',\n",
    "    '031a89ca-ed61-407b-91f6-a07092b48214',\n",
    "    '79a135da-2f10-4dc7-8424-f49dad0cf24c',\n",
    "    '1c4ff086-8435-4572-a6af-898b73852711',\n",
    "    '09027102-ca0f-44d1-94cd-3ebd6af379ec',\n",
    "    '808e4748-b080-4989-89ba-003a2b8b76bf',\n",
    "    'f7867764-967a-4c61-a680-3c5741340bf3',\n",
    "    'c48b26c3-a7aa-45ad-829c-1967ddd41be2',\n",
    "    'ceb17697-5bd1-4ada-8201-cf875be1b8dd',\n",
    "    '09eb47e8-1683-485b-84ae-9cef53ca6981',\n",
    "    '0c742f04-7723-49b4-8b5b-290856e508c3',\n",
    "    'dfbe2ba6-7f48-4309-989b-0c65e5cb2788',\n",
    "    '8902fe1d-a7a9-4046-9a35-244475e113fd',\n",
    "    '00d1d1e0-4b46-4af1-ba91-4f15f23d55cb',\n",
    "    '66945b11-520c-4a1e-b76c-e09e36cb7a02',\n",
    "    '66b2f4d2-ecea-4eee-9868-8e8c41d76efa',\n",
    "    '4019997c-8d8e-4e21-8caa-26458c743b24',\n",
    "    '8d157b6b-8f13-4bbf-9b88-e1fbf6844749',\n",
    "    'c24bf8dd-fa9c-4e4e-98ed-83a1713f3276',\n",
    "    '6b21e796-e4bd-410c-990f-31698edd7275',\n",
    "    '18651608-70f6-4725-8084-aa51833367a9',\n",
    "    'ad73394e-f797-4a85-aaff-b69a9a1700e0',\n",
    "    '8d68226a-47c7-4c25-a1a3-95dca2b6cc1a',\n",
    "    'ca3fb362-a24e-4c79-a84c-b61f60542a38',\n",
    "    '7cd8067f-67b2-4934-9d07-4da82109f9e4',\n",
    "    'c2bbc543-f2de-442a-9fc0-13d2e6332aba',\n",
    "    '996bcad4-fa2c-4ccd-bb2a-918ddb323d0c',\n",
    "    'c05817ac-8e5f-406d-995f-3826e117207c',\n",
    "    'c212be24-0858-4c8e-9da9-6730f6352617',\n",
    "    '6cae032f-4be2-4d2f-a136-42d096a659d8',\n",
    "    '12791f33-5f01-4cf5-bf99-3f9fde75077a',\n",
    "    '57bde55e-64bb-404d-b3c1-60e3ec50f46a',\n",
    "    'd5606eac-b0d3-48d8-9c59-1e18d8ecc032',\n",
    "    '51c965df-d267-4e26-95f0-878ca2dede2c',\n",
    "]\n",
    "snapshot_id_list = [\n",
    "    'c195ed64-842d-4525-8a1c-9083eccaafa7',\n",
    "    '84103748-39eb-45f9-b4ca-e23a9e52d0cc',\n",
    "    '96cfd9ec-5eb4-48f5-9284-84f349701033',\n",
    "    '8f104c7f-8b5a-489e-95b4-616130405e7c',\n",
    "    'a2bb366f-029d-4bef-8da7-dce818743881',\n",
    "    'f2f0d8a3-6e18-436a-bc51-ff742d30d6a4',\n",
    "    '2b2a1f74-9c2e-4c6c-840b-80f466d1e209',\n",
    "    '3442e75a-7452-4680-9ce5-70fa21363083',\n",
    "    '79509151-b96a-483f-a6b3-eeede54467d1',\n",
    "    '887dd90c-6742-4283-92b2-bc9ed6bc2ae1',\n",
    "    'ec292668-bc78-45f7-b601-8d452b038e6c',\n",
    "    '432c6422-ceaf-4c6c-bd8d-7c90771a284f',\n",
    "    '8d055301-47e0-4384-9746-8bc1b93d9a96',\n",
    "    '79502d0c-bc1c-4d51-a6de-eb0334b3b660',\n",
    "]\n",
    "\n",
    "# Specify a mapping from phs-consent to DOID for DS consent codes (replace \"_\" with \"-\" in consent first)\n",
    "ds_consent_map = {\n",
    "    'phs000298:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs000693:DS-BDIS': 'http://purl.obolibrary.org/obo/DOID_936',\n",
    "    'phs000693:DS-EP': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs000744:DS-RD': 'http://purl.obolibrary.org/obo/DOID_15',\n",
    "    'phs000744:DS-THAL-IRB': 'http://purl.obolibrary.org/obo/DOID_10241',\n",
    "    'phs001222:DS-DRC-IRB-NPU': 'http://purl.obolibrary.org/obo/DOID_9351',\n",
    "    'phs001227:DS-ATHSCL-IRB-MDS': 'http://purl.obolibrary.org/obo/DOID_1936',\n",
    "    'phs001259:DS-CARD-MDS-GSO': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001487:DS-MULTIPLE-DISEASES-IRB-COL-NPU-RD': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001489:DS-EAED-IRB-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EAED-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EARET-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EP': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EP-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPASM-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPI-ADULT-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPI-MULTI-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPASM-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EP-NPU': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPCOM-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBA-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBACID-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBACID-NPU-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBAID-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-MBND-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'phs001489:DS-NSD-ADULTS-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_863',\n",
    "    'phs001489:DS-NSD-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_863',\n",
    "    'phs001506:DS-CVD-IRB': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001592:DS-CVD': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001642:DS-GR-IRB-MDS': 'http://purl.obolibrary.org/obo/DOID_77',\n",
    "    'phs001642:DS-DSDI-MDS': 'http://purl.obolibrary.org/obo/DOID_77',\n",
    "    'phs001642:DS-GID': 'http://purl.obolibrary.org/obo/DOID_77',\n",
    "    'phs001642:DS-IBD': 'http://purl.obolibrary.org/obo/DOID_0050589',\n",
    "    'phs001642:DS-IBD-MDS': 'http://purl.obolibrary.org/obo/DOID_0050589',\n",
    "    'phs001676:DS-AONDD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001740:DS-ASD-RD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001741:DS-ASD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001766:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001766:DS-ASD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001871:DS-CAD-IRB': 'http://purl.obolibrary.org/obo/DOID_3393',\n",
    "    'phs001894:DS-EAC-PUB-GSO': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001901:DS-CVD-MDS': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs002004:DS-AUT': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002032:DS-SMA-MDS': 'http://purl.obolibrary.org/obo/DOID_12377',\n",
    "    'phs002032:DS-MBND-MDS': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'phs002041:DS-MLHLTH-MDS': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'phs002041:DS-SZ-MDS': 'http://purl.obolibrary.org/obo/DOID_5419',\n",
    "    'phs002041:DS-SZRD-MDS': 'http://purl.obolibrary.org/obo/DOID_5419',\n",
    "    'phs002042:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002043:DS-AASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002044:DS-ASD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002206:DS-PEDD-IRB': 'http://purl.obolibrary.org/obo/DOID_4',\n",
    "    'phs002282:DS-CVDRF': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs002502:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002502:DS-ASD-MDS': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002502:DS-ASD-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002502:DS-ASD-NPU': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'ph2002502:DS-MLHLTH-IRB-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'ph2002502:DS-MH': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'phs002502:DS-MBND-MDS': 'http://purl.obolibrary.org/obo/DOID_1289',\n",
    "    'phs003200:DS-MSC-MDS': ['http://purl.obolibrary.org/obo/DOID_1909', 'http://purl.obolibrary.org/obo/DOID_4159']\n",
    "}\n",
    "\n",
    "# Token for use in DUOS (use gcloud auth print-access-token to get this)\n",
    "duos_token = \"\"\n",
    "\n",
    "# DUOS Environment\n",
    "env = \"dev\"\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "dataset_details_records = []\n",
    "for snapshot_id in snapshot_id_list:\n",
    "    print(f\"Processing snapshot_id: {snapshot_id}...\")\n",
    "    dataset_details = fetch_dataset_details(snapshot_id, ds_consent_map)\n",
    "    dataset_details_records.append(dataset_details)\n",
    "output = pd.DataFrame(dataset_details_records)\n",
    "output_sorted = output.sort_values(by=[\"studyName\", \"consentGroups.consentGroupName\"], ascending=[True, True], ignore_index=True)\n",
    "\n",
    "#############################################\n",
    "## Validation and Output\n",
    "#############################################\n",
    "# Create copy of dataframe for unique value validation\n",
    "output_unique_val = output_sorted.copy()\n",
    "\n",
    "# Convert study list fields to strings\n",
    "list_fields = [\"dataTypes\", \"dataCustodianEmail\", \"nihICsSupportingStudy\", \"collaboratingSites\", \"alternativeDataSharingPlanReasons\"]\n",
    "for field in list_fields:\n",
    "    output_unique_val[field] = [try_join(l) for l in output_unique_val[field]]\n",
    "\n",
    "# Get unique values per study-level field, by study\n",
    "study_level_col_list = []\n",
    "for col in output_unique_val.columns:\n",
    "    if \"consentGroups.\" not in col and col not in [\"studyName\", \"snapshot_id\", \"consortium\", \"consentCode\"]:\n",
    "        study_level_col_list.append(col)\n",
    "df_unique = output_unique_val.groupby(\"studyName\")[study_level_col_list].nunique()\n",
    "df_unique[\"unique_value_validation\"] = df_unique.max(axis=1)\n",
    "df_unique[\"unique_value_validation\"] = [\"Pass\" if l <= 1 else \"Fail\" for l in df_unique[\"unique_value_validation\"]]\n",
    "\n",
    "# Create copy of dataframe for enum validation\n",
    "output_enum_val = output_sorted.copy()\n",
    "\n",
    "# Validate enum fields\n",
    "output_enum_val[\"studyType\"] = [val_study_type_enum(l) for l in output_enum_val[\"studyType\"]]\n",
    "output_enum_val[\"nihInstitutionCenterSubmission\"] = [val_nih_inst_center_sub_enum(l) for l in output_enum_val[\"nihInstitutionCenterSubmission\"]]\n",
    "output_enum_val[\"nihICsSupportingStudy\"] = [val_nih_ic_supp_study_enum(l) for l in output_enum_val[\"nihICsSupportingStudy\"]]\n",
    "output_enum_val[\"consentGroups.fileTypes.fileType\"] = [val_file_type_enum(l) for l in output_enum_val[\"consentGroups.fileTypes.fileType\"]]\n",
    "study_enum_cols = [\"studyType\", \"nihInstitutionCenterSubmission\", \"nihICsSupportingStudy\"]\n",
    "df_study_enum = output_enum_val.groupby(\"studyName\")[study_enum_cols].sum()\n",
    "df_study_enum[\"study_enum_value_validation\"] = df_study_enum.max(axis=1)\n",
    "df_study_enum[\"study_enum_value_validation\"] = [\"Pass\" if l < 1 else \"Fail\" for l in df_study_enum[\"study_enum_value_validation\"]]\n",
    "consent_group_enum_cols = [\"consentGroups.fileTypes.fileType\"]\n",
    "df_consent_group_enum = output_enum_val.groupby(\"consentGroups.consentGroupName\")[consent_group_enum_cols].sum()\n",
    "df_consent_group_enum[\"consent_group_enum_value_validation\"] = df_consent_group_enum.max(axis=1)\n",
    "df_consent_group_enum[\"consent_group_enum_value_validation\"] = [\"Pass\" if l < 1 else \"Fail\" for l in df_consent_group_enum[\"consent_group_enum_value_validation\"]]\n",
    "\n",
    "# Join validation dataframes to original dataframe\n",
    "output_sorted_validated = output_sorted.join(df_unique[\"unique_value_validation\"], on=\"studyName\", how=\"left\")\n",
    "output_sorted_validated = output_sorted_validated.join(df_study_enum[\"study_enum_value_validation\"], on=\"studyName\", how=\"left\")\n",
    "output_sorted_validated = output_sorted_validated.join(df_consent_group_enum[\"consent_group_enum_value_validation\"], on=\"consentGroups.consentGroupName\", how=\"left\")\n",
    "\n",
    "# Display outputs\n",
    "print(\"----------------------------------------------------------------------------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------------\")\n",
    "print(\"Validated Metadata Output:\")\n",
    "display(output_sorted_validated.style.hide(axis=\"index\"))\n",
    "print(\"\\n\")\n",
    "print(\"Unique Study Value Validation Results:\")\n",
    "df_unique.reset_index(inplace=True)\n",
    "display(df_unique.style.hide(axis=\"index\"))\n",
    "print(\"\\n\")\n",
    "print(\"Study Enum Value Validation Results:\")\n",
    "df_study_enum.reset_index(inplace=True)\n",
    "display(df_study_enum.style.hide(axis=\"index\"))\n",
    "print(\"\\n\")\n",
    "print(\"Consent Group Enum Value Validation Results:\")\n",
    "df_consent_group_enum.reset_index(inplace=True)\n",
    "display(df_consent_group_enum.style.hide(axis=\"index\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "ds_consent_map = {\n",
    "    'phs000298:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs000693:DS-BDIS': 'http://purl.obolibrary.org/obo/DOID_936',\n",
    "    'phs000693:DS-EP': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs000744:DS-RD': 'http://purl.obolibrary.org/obo/DOID_15',\n",
    "    'phs000744:DS-THAL-IRB': 'http://purl.obolibrary.org/obo/DOID_10241',\n",
    "    'phs001222:DS-DRC-IRB-NPU': 'http://purl.obolibrary.org/obo/DOID_9351',\n",
    "    'phs001227:DS-ATHSCL-IRB-MDS': 'http://purl.obolibrary.org/obo/DOID_1936',\n",
    "    'phs001259:DS-CARD-MDS-GSO': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001487:DS-MULTIPLE-DISEASES-IRB-COL-NPU-RD': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001489:DS-EAED-IRB-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EAED-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EARET-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EP': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EP-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPASM-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPI-ADULT-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPI-MULTI-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPASM-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EP-NPU': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPCOM-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBA-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBACID-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBACID-NPU-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBAID-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-MBND-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'phs001489:DS-NSD-ADULTS-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_863',\n",
    "    'phs001489:DS-NSD-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_863',\n",
    "    'phs001506:DS-CVD-IRB': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001592:DS-CVD': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001642:DS-GR-IRB-MDS': 'http://purl.obolibrary.org/obo/DOID_77',\n",
    "    'phs001642:DS-DSDI-MDS': 'http://purl.obolibrary.org/obo/DOID_77',\n",
    "    'phs001642:DS-GID': 'http://purl.obolibrary.org/obo/DOID_77',\n",
    "    'phs001642:DS-IBD': 'http://purl.obolibrary.org/obo/DOID_0050589',\n",
    "    'phs001642:DS-IBD-MDS': 'http://purl.obolibrary.org/obo/DOID_0050589',\n",
    "    'phs001676:DS-AONDD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001740:DS-ASD-RD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001741:DS-ASD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001766:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001766:DS-ASD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001871:DS-CAD-IRB': 'http://purl.obolibrary.org/obo/DOID_3393',\n",
    "    'phs001894:DS-EAC-PUB-GSO': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001901:DS-CVD-MDS': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs002004:DS-AUT': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002032:DS-SMA-MDS': 'http://purl.obolibrary.org/obo/DOID_12377',\n",
    "    'phs002032:DS-MBND-MDS': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'phs002041:DS-MLHLTH-MDS': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'phs002041:DS-SZ-MDS': 'http://purl.obolibrary.org/obo/DOID_5419',\n",
    "    'phs002041:DS-SZRD-MDS': 'http://purl.obolibrary.org/obo/DOID_5419',\n",
    "    'phs002042:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002043:DS-AASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002044:DS-ASD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002206:DS-PEDD-IRB': 'http://purl.obolibrary.org/obo/DOID_4',\n",
    "    'phs002282:DS-CVDRF': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs002502:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002502:DS-ASD-MDS': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002502:DS-ASD-NPU': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'ph2002502:DS-MLHLTH-IRB-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'ph2002502:DS-MH': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'phs002502:DS-MBND-MDS': 'http://purl.obolibrary.org/obo/DOID_1289',\n",
    "    'phs003200:DS-MSC-MDS': ['http://purl.obolibrary.org/obo/DOID_1909', 'http://purl.obolibrary.org/obo/DOID_4159']\n",
    "}\n",
    "\n",
    "for key, val in ds_consent_map.items():\n",
    "    print(key+\"|\"+val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     18,
     25,
     36,
     45,
     51,
     57,
     66
    ]
   },
   "outputs": [],
   "source": [
    "def coalesce(*arg): \n",
    "    remove_list = [\"\", \"NA\", \"N/A\", \"NONE\", \"TBD\", \"UNKNOWN\", \"UNSPECIFIED\"]\n",
    "    # update to remove N/A, None, Null, TBD\n",
    "    for input_item in arg:\n",
    "        if input_item is False or input_item == []:\n",
    "            return input_item\n",
    "        elif input_item:\n",
    "            if isinstance(input_item, list):\n",
    "                temp_list = [ele for ele in input_item if ele is not None and ele.upper() not in remove_list]\n",
    "                if temp_list:\n",
    "                    return temp_list\n",
    "                else:\n",
    "                    return []\n",
    "            else:\n",
    "                if str(input_item).upper() not in remove_list:\n",
    "                    return input_item\n",
    "    return None\n",
    "\n",
    "def format_description(input_string):\n",
    "    output_string = input_string if input_string else \"\"\n",
    "    output_string = re.sub(\"\\n\\n\\t\", \" \", output_string)\n",
    "    output_string = re.sub(\"\\t\", \" \", output_string)\n",
    "    output_string = re.sub(\"study.cgi\\?study_id=|.\\/study.cgi\\?study_id=\", \"https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=\", output_string)\n",
    "    return output_string\n",
    "\n",
    "def format_phs_id(input_str):\n",
    "    try:\n",
    "        num = re.search(\"phs0*([0-9]+)\", input_str, re.IGNORECASE).group(1)\n",
    "    except:\n",
    "        num = \"\"\n",
    "    if num:\n",
    "        output_str = \"phs\" + str(num).zfill(6)\n",
    "    else:\n",
    "        output_str = \"\"\n",
    "    return output_str\n",
    "\n",
    "def try_join(l):\n",
    "    try:\n",
    "        if isinstance(l, list):\n",
    "            return ', '.join(map(str, l))\n",
    "        else:\n",
    "            return l\n",
    "    except TypeError:\n",
    "        return l\n",
    "    \n",
    "def val_study_type_enum(l):\n",
    "    if l and l not in [\"Observational\", \"Interventional\", \"Descriptive\", \"Analytical\", \"Prospective\", \"Retrospective\", \"Case report\", \"Case series\", \"Cross-sectional\", \"Cohort study\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def val_nih_inst_center_sub_enum(l):\n",
    "    if l and l not in [\"NCI\", \"NEI\", \"NHLBI\", \"NHGRI\", \"NIA\", \"NIAAA\", \"NIAID\", \"NIAMS\", \"NIBIB\", \"NICHD\", \"NIDCD\", \"NIDCR\", \"NIDDK\", \"NIDA\", \"NIEHS\", \"NIGMS\", \"NIMH\", \"NIMHD\", \"NINDS\", \"NINR\", \"NLM\", \"CC\", \"CIT\", \"CSR\", \"FIC\", \"NCATS\", \"NCCIH\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def val_nih_ic_supp_study_enum(l):\n",
    "    if l and isinstance(l, list):\n",
    "        for item in l:\n",
    "            if item not in [\"NCI\", \"NEI\", \"NHLBI\", \"NHGRI\", \"NIA\", \"NIAAA\", \"NIAID\", \"NIAMS\", \"NIBIB\", \"NICHD\", \"NIDCD\", \"NIDCR\", \"NIDDK\", \"NIDA\", \"NIEHS\", \"NIGMS\", \"NIMH\", \"NIMHD\", \"NINDS\", \"NINR\", \"NLM\", \"CC\", \"CIT\", \"CSR\", \"FIC\", \"NCATS\", \"NCCIH\"]:\n",
    "                return 1\n",
    "        return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def val_file_type_enum(l):\n",
    "    if l and isinstance(l, list):\n",
    "        for item in l:\n",
    "            if item not in [\"Arrays\", \"Genome\", \"Exome\", \"Survey\", \"Phenotype\"]:\n",
    "                return 1\n",
    "        return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     19
    ]
   },
   "outputs": [],
   "source": [
    "# Snapshot list\n",
    "snapshot_id_list = [\n",
    "    'e2736891-a569-449e-8cbf-b7d0274b64d0',\n",
    "#     'a2bb366f-029d-4bef-8da7-dce818743881',\n",
    "#     'f2f0d8a3-6e18-436a-bc51-ff742d30d6a4',\n",
    "#     '2b2a1f74-9c2e-4c6c-840b-80f466d1e209',\n",
    "#     '3442e75a-7452-4680-9ce5-70fa21363083',\n",
    "#     '79509151-b96a-483f-a6b3-eeede54467d1',\n",
    "#     '887dd90c-6742-4283-92b2-bc9ed6bc2ae1',\n",
    "#     'ec292668-bc78-45f7-b601-8d452b038e6c',\n",
    "#     '432c6422-ceaf-4c6c-bd8d-7c90771a284f',\n",
    "#     '8d055301-47e0-4384-9746-8bc1b93d9a96',\n",
    "#     '79502d0c-bc1c-4d51-a6de-eb0334b3b660',\n",
    "]\n",
    "\n",
    "# Specify a mapping from phs-consent to DOID for DS consent codes (replace \"_\" with \"-\" in consent first)\n",
    "ds_consent_map = {\n",
    "    'phs000298:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs000693:DS-BDIS': 'http://purl.obolibrary.org/obo/DOID_936',\n",
    "    'phs000693:DS-EP': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs000744:DS-RD': 'http://purl.obolibrary.org/obo/DOID_15',\n",
    "    'phs000744:DS-THAL-IRB': 'http://purl.obolibrary.org/obo/DOID_10241',\n",
    "    'phs001222:DS-DRC-IRB-NPU': 'http://purl.obolibrary.org/obo/DOID_9351',\n",
    "    'phs001227:DS-ATHSCL-IRB-MDS': 'http://purl.obolibrary.org/obo/DOID_1936',\n",
    "    'phs001259:DS-CARD-MDS-GSO': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001487:DS-MULTIPLE-DISEASES-IRB-COL-NPU-RD': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001489:DS-EAED-IRB-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EAED-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EARET-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EP': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EP-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPASM-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPI-ADULT-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPI-MULTI-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPASM-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EP-NPU': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPCOM-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBA-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBACID-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBACID-NPU-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBAID-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-MBND-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'phs001489:DS-NSD-ADULTS-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_863',\n",
    "    'phs001489:DS-NSD-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_863',\n",
    "    'phs001506:DS-CVD-IRB': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001592:DS-CVD': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001642:DS-GR-IRB-MDS': 'http://purl.obolibrary.org/obo/DOID_77',\n",
    "    'phs001642:DS-DSDI-MDS': 'http://purl.obolibrary.org/obo/DOID_77',\n",
    "    'phs001642:DS-GID': 'http://purl.obolibrary.org/obo/DOID_77',\n",
    "    'phs001642:DS-IBD': 'http://purl.obolibrary.org/obo/DOID_0050589',\n",
    "    'phs001642:DS-IBD-MDS': 'http://purl.obolibrary.org/obo/DOID_0050589',\n",
    "    'phs001676:DS-AONDD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001740:DS-ASD-RD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001741:DS-ASD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001766:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001766:DS-ASD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001871:DS-CAD-IRB': 'http://purl.obolibrary.org/obo/DOID_3393',\n",
    "    'phs001894:DS-EAC-PUB-GSO': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001901:DS-CVD-MDS': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs002004:DS-AUT': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002032:DS-SMA-MDS': 'http://purl.obolibrary.org/obo/DOID_12377',\n",
    "    'phs002032:DS-MBND-MDS': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'phs002041:DS-MLHLTH-MDS': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'phs002041:DS-SZ-MDS': 'http://purl.obolibrary.org/obo/DOID_5419',\n",
    "    'phs002041:DS-SZRD-MDS': 'http://purl.obolibrary.org/obo/DOID_5419',\n",
    "    'phs002042:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002043:DS-AASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002044:DS-ASD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002206:DS-PEDD-IRB': 'http://purl.obolibrary.org/obo/DOID_4',\n",
    "    'phs002282:DS-CVDRF': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs002502:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002502:DS-ASD-MDS': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002502:DS-ASD-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002502:DS-ASD-NPU': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'ph2002502:DS-MLHLTH-IRB-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'ph2002502:DS-MH': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'phs002502:DS-MBND-MDS': 'http://purl.obolibrary.org/obo/DOID_1289',\n",
    "    'phs003200:DS-MSC-MDS': ['http://purl.obolibrary.org/obo/DOID_1909', 'http://purl.obolibrary.org/obo/DOID_4159']\n",
    "}\n",
    "\n",
    "# Token for use in DUOS (use gcloud auth print-access-token to get this)\n",
    "duos_token = \"\"\n",
    "\n",
    "# DUOS Environment\n",
    "duos_env = \"dev\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "dataset_details_records = []\n",
    "terra_dict = {}\n",
    "dbgap_xml_dict = {}\n",
    "dbgap_study_api_dict = {}\n",
    "dbgap_fhir_dict = {}\n",
    "final_results_dict = {}\n",
    "\n",
    "# Determine the DUOS URL from the duos_env variable\n",
    "if duos_env == \"prod\":\n",
    "    url = \"https://consent.dsde-prod.broadinstitute.org\"\n",
    "else:\n",
    "    url = \"https://consent.dsde-dev.broadinstitute.org\"\n",
    "\n",
    "# Build DUOS lookups\n",
    "print(f\"Building DUOS dataset and study lookups...\")\n",
    "study_lookup = {}\n",
    "dataset_lookup = []\n",
    "datasets = requests.get(\n",
    "    url=f\"{url}/api/dataset/v3\",\n",
    "    headers={\"Authorization\": f\"Bearer {duos_token}\"}\n",
    ").json()\n",
    "study_ids_processed = set()\n",
    "for dataset_entry in datasets:\n",
    "    datasets_parsed += 1\n",
    "    dataset_id = dataset_entry.get(\"dataset_id\")\n",
    "    dataset_name = dataset_entry.get(\"dataset_name\")\n",
    "    identifier = dataset_entry.get(\"identifier\")\n",
    "    study_id = dataset_entry.get(\"study_id\")\n",
    "    try:\n",
    "        consent_group_name = re.search(r'(.*)_[0-9]{8}_ANV[0-9]+_[0-9]{12}$', dataset_name).group(1)\n",
    "    except:\n",
    "        consent_group_name = dataset_name\n",
    "    if study_id:\n",
    "        # Build dataset lookup\n",
    "        dataset_lookup.append({\n",
    "            \"dataset_id\": dataset_id,\n",
    "            \"current_consent_group_name\": dataset_name, \n",
    "            \"consent_group_name\": consent_group_name,\n",
    "            \"identifier\": identifier,\n",
    "            \"study_id\": study_id\n",
    "        })\n",
    "        # Build study lookup\n",
    "        if study_id not in study_ids_processed:\n",
    "            study_ids_processed.add(study_id)\n",
    "            study_details = requests.get(\n",
    "                url=f\"{url}/api/dataset/registration/{identifier}\",\n",
    "                headers={\"Authorization\": f\"Bearer {duos_token}\"}\n",
    "            ).json()\n",
    "            study_desc = study_details.get(\"studyDescription\")\n",
    "            if study_desc and \"Platform: AnVIL\" in study_desc:\n",
    "                study_phs = study_details.get(\"dbGaPPhsID\")\n",
    "                if study_phs:\n",
    "                    id_in_lookup = study_lookup.get(study_phs)\n",
    "                    if id_in_lookup and id_in_lookup != study_id:\n",
    "                        print(f\"Warning: PHS ID {study_phs} tied to multiple studies in DUOS: {id_in_lookup}, {study_id}. Please review.\")\n",
    "                    else:\n",
    "                        study_lookup[study_phs] = study_id\n",
    "\n",
    "# Loop through and process snapshots\n",
    "for snapshot_id in snapshot_id_list:\n",
    "\n",
    "    # Retrieve snapshot details\n",
    "    print(f\"Processing snapshot_id: {snapshot_id}...\")\n",
    "    final_results_dict = {}\n",
    "    api_client = refresh_tdr_api_client()\n",
    "    datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "    snapshots_api = data_repo_client.SnapshotsApi(api_client=api_client)\n",
    "    attempt_counter = 0\n",
    "    snapshot_details = {}\n",
    "    while attempt_counter <= 2:\n",
    "        try:\n",
    "            snapshot_details = snapshots_api.retrieve_snapshot(id=snapshot_id).to_dict()\n",
    "            break\n",
    "        except:\n",
    "            sleep(5)\n",
    "            attempt_counter += 1  \n",
    "    snapshot_name = snapshot_details[\"name\"]\n",
    "    try:\n",
    "        consent_group_name = re.search(r'(.*)_[0-9]{8}_ANV[0-9]+_[0-9]{12}$', snapshot_name).group(1)\n",
    "    except:\n",
    "        consent_group_name = snapshot_name\n",
    "    dataset_id = snapshot_details[\"source\"][0][\"dataset\"][\"id\"]\n",
    "    phs_id = format_phs_id(snapshot_details[\"source\"][0][\"dataset\"][\"phs_id\"])\n",
    "    if snapshot_details[\"source\"][0][\"dataset\"][\"secure_monitoring_enabled\"] == True:\n",
    "        access_management = \"controlled\"\n",
    "    else:\n",
    "        access_management = \"open\"\n",
    "    if snapshot_details[\"source\"][0][\"dataset_properties\"].get(\"source_workspaces\"):  \n",
    "        source_workspace = snapshot_details[\"source\"][0][\"dataset_properties\"][\"source_workspaces\"][0]\n",
    "    else:\n",
    "        source_workspace = None\n",
    "    if snapshot_details[\"source\"][0][\"dataset_properties\"].get(\"consent_name\"):\n",
    "        snapshot_consent_code = snapshot_details[\"source\"][0][\"dataset_properties\"][\"consent_name\"]\n",
    "    else:\n",
    "        snapshot_consent_code = None\n",
    "    if snapshot_details[\"duos_firecloud_group\"] != None:\n",
    "        duos_id = snapshot_details[\"duos_firecloud_group\"][\"duos_id\"]\n",
    "    else:\n",
    "        duos_id = None\n",
    "    duos_id = \"DUOS-000774\" # REMOVE THIS\n",
    "    print(\"\\tSnapshot PHS_ID: \" + str(phs_id))\n",
    "    print(\"\\tSnapshot Consent Code: \" + str(snapshot_consent_code))\n",
    "    print(\"\\tSource Workspace: \" + str(source_workspace))\n",
    "    print(\"\\tDUOS ID: \" + str(duos_id))\n",
    "    \n",
    "    # Attempt to match to a DUOS ID based on consent group name and DUOS Study based on PHS ID\n",
    "    match_duos_id = \"\"\n",
    "    for dataset in dataset_lookup:\n",
    "        if dataset[\"consent_group_name\"] == consent_group_name:\n",
    "            match_duos_id = dataset[\"identifier\"]\n",
    "            break\n",
    "    match_study_id = \"\"\n",
    "    if phs_id:\n",
    "        match_study_id = study_lookup.get(phs_id)\n",
    "    \n",
    "    # If a snapshot or match DUOS ID is present, use this to build the final result dictionary\n",
    "    if duos_id or match_duos_id:\n",
    "        \n",
    "        duos_id_to_use = coalesce(duos_id, match_duos_id)\n",
    "        \n",
    "        # Pull existing DUOS study registration\n",
    "        duos_dict = requests.get(\n",
    "            url=f\"{url}/api/dataset/registration/{duos_id_to_use}\",\n",
    "            headers={\"Authorization\": f\"Bearer {duos_token}\"}\n",
    "        ).json()\n",
    "        #print(duos_dict)\n",
    "\n",
    "        # Pull dataset details from DUOS (to get data use info) \n",
    "        duos_dataset_id = duos_dict[\"consentGroups\"][0].get(\"datasetId\")\n",
    "        duos_data_use_dict = {}\n",
    "        if duos_dataset_id:\n",
    "            dataset_details = requests.get(\n",
    "                url=f\"{url}/api/dataset/v2/{duos_dataset_id}\",\n",
    "                headers={\"Authorization\": f\"Bearer {duos_token}\"}\n",
    "            ).json()\n",
    "            duos_data_use_dict = dataset_details.get(\"dataUse\")\n",
    "        duos_data_use_dict = {} # REMOVE THIS\n",
    "        \n",
    "        # Build final results dictionary\n",
    "        if snapshot_consent_code:\n",
    "            consent_code = snapshot_consent_code.upper().replace(\"_\", \"-\")\n",
    "        else:\n",
    "            consent_code = \"\"\n",
    "        final_results_dict[\"snapshot_id\"] = snapshot_id\n",
    "        final_results_dict[\"snapshot_duos_id\"] = duos_id\n",
    "        final_results_dict[\"match_duos_id\"] = match_duos_id\n",
    "        final_results_dict[\"match_study_id\"] = match_study_id\n",
    "        final_results_dict[\"studyName\"] = duos_dict.get(\"studyName\")\n",
    "        final_results_dict[\"studyType\"] = duos_dict.get(\"studyType\")\n",
    "        final_results_dict[\"studyDescription\"] = duos_dict.get(\"studyDescription\")\n",
    "        final_results_dict[\"dataTypes\"] = duos_dict.get(\"dataTypes\")\n",
    "        final_results_dict[\"phenotypeIndication\"] = duos_dict.get(\"phenotypeIndication\")\n",
    "        final_results_dict[\"species\"] = duos_dict.get(\"species\")\n",
    "        final_results_dict[\"piName\"] = duos_dict.get(\"piName\")\n",
    "        final_results_dict[\"dataCustodianEmail\"] = duos_dict.get(\"dataCustodianEmail\")\n",
    "        final_results_dict[\"publicVisibility\"] = duos_dict.get(\"publicVisibility\")\n",
    "        final_results_dict[\"nihAnvilUse\"] = \"I am NHGRI funded and I have a dbGaP PHS ID already\" if 'already' in duos_dict.get(\"nihAnvilUse\").lower() else \"I am NHGRI funded and I do not have a dbGaP PHS ID\"\n",
    "        final_results_dict[\"submittingToAnvil\"] = duos_dict.get(\"submittingToAnvil\")\n",
    "        final_results_dict[\"dbGaPPhsID\"] = duos_dict.get(\"dbGaPPhsID\")\n",
    "        final_results_dict[\"dbGaPStudyRegistrationName\"] = duos_dict.get(\"dbGaPStudyRegistrationName\")\n",
    "        final_results_dict[\"embargoReleaseDate\"] = duos_dict.get(\"embargoReleaseDate\")\n",
    "        final_results_dict[\"sequencingCenter\"] = duos_dict.get(\"sequencingCenter\")\n",
    "        final_results_dict[\"piEmail\"] = duos_dict.get(\"piEmail\")\n",
    "        final_results_dict[\"piInstitution\"] = duos_dict.get(\"piInstitution\")\n",
    "        final_results_dict[\"nihGrantContractNumber\"] = duos_dict.get(\"nihGrantContractNumber\")\n",
    "        final_results_dict[\"nihICsSupportingStudy\"] = duos_dict.get(\"nihICsSupportingStudy\")\n",
    "        final_results_dict[\"nihProgramOfficerName\"] = duos_dict.get(\"nihProgramOfficerName\")\n",
    "        final_results_dict[\"nihInstitutionCenterSubmission\"] = duos_dict.get(\"nihInstitutionCenterSubmission\")\n",
    "        final_results_dict[\"nihInstitutionalCertificationFileName\"] = duos_dict.get(\"nihInstitutionalCertificationFileName\")\n",
    "        final_results_dict[\"nihGenomicProgramAdministratorName\"] = duos_dict.get(\"nihGenomicProgramAdministratorName\")\n",
    "        final_results_dict[\"multiCenterStudy\"] = duos_dict.get(\"multiCenterStudy\")\n",
    "        final_results_dict[\"collaboratingSites\"] = duos_dict.get(\"collaboratingSites\")\n",
    "        final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSR\"] = duos_dict.get(\"controlledAccessRequiredForGenomicSummaryResultsGSR\")\n",
    "        final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation\"] = duos_dict.get(\"controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation\")\n",
    "        final_results_dict[\"alternativeDataSharingPlan\"] = duos_dict.get(\"alternativeDataSharingPlan\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanReasons\"] = duos_dict.get(\"alternativeDataSharingPlanReasons\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanExplanation\"] = duos_dict.get(\"alternativeDataSharingPlanExplanation\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanFileName\"] = duos_dict.get(\"alternativeDataSharingPlanFileName\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanDataSubmitted\"] = duos_dict.get(\"alternativeDataSharingPlanDataSubmitted\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanDataReleased\"] = duos_dict.get(\"alternativeDataSharingPlanDataReleased\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanTargetDeliveryDate\"] = duos_dict.get(\"alternativeDataSharingPlanTargetDeliveryDate\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanTargetPublicReleaseDate\"] = duos_dict.get(\"alternativeDataSharingPlanTargetPublicReleaseDate\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanAccessManagement\"] = duos_dict.get(\"alternativeDataSharingPlanAccessManagement\")\n",
    "        final_results_dict[\"consentGroups.consentGroupName\"] = consent_group_name\n",
    "        final_results_dict[\"consentGroups.accessManagement\"] = access_management\n",
    "        final_results_dict[\"consentGroups.numberOfParticipants\"] = duos_dict[\"consentGroups\"][0].get(\"numberOfParticipants\")\n",
    "        final_results_dict[\"consentCode\"] = consent_code\n",
    "        final_results_dict[\"consentGroups.generalResearchUse\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"generalResearchUse\"), duos_data_use_dict.get(\"generalUse\"), False)\n",
    "        final_results_dict[\"consentGroups.hmb\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"hmb\"), duos_data_use_dict.get(\"hmbResearch\"), False)\n",
    "        final_results_dict[\"consentGroups.diseaseSpecificUse\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"diseaseSpecificUse\"), duos_data_use_dict.get(\"diseaseRestrictions\"), [])\n",
    "        final_results_dict[\"consentGroups.gs\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"gs\"), duos_data_use_dict.get(\"geographicalRestrictions\"))\n",
    "        final_results_dict[\"consentGroups.poa\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"poa\"), duos_data_use_dict.get(\"populationOriginsAncestry\"), False)\n",
    "        final_results_dict[\"consentGroups.nmds\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"nmds\"), False)\n",
    "        final_results_dict[\"consentGroups.gso\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"gso\"), duos_data_use_dict.get(\"geneticStudiesOnly\"), False)\n",
    "        final_results_dict[\"consentGroups.pub\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"pub\"), duos_data_use_dict.get(\"publicationResults\"), False)\n",
    "        final_results_dict[\"consentGroups.col\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"col\"), duos_data_use_dict.get(\"collaboratorRequired\"), False)\n",
    "        final_results_dict[\"consentGroups.irb\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"irb\"), duos_data_use_dict.get(\"ethicsApprovalRequired\"), False)\n",
    "        final_results_dict[\"consentGroups.npu\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"npu\"), False)\n",
    "        final_results_dict[\"consentGroups.otherPrimary\"] = duos_dict[\"consentGroups\"][0].get(\"otherPrimary\")\n",
    "        final_results_dict[\"consentGroups.otherSecondary\"] = duos_dict[\"consentGroups\"][0].get(\"otherSecondary\")\n",
    "        final_results_dict[\"consentGroups.mor\"] = duos_dict[\"consentGroups\"][0].get(\"mor\")\n",
    "        final_results_dict[\"consentGroups.morDate\"] = duos_dict[\"consentGroups\"][0].get(\"morDate\")\n",
    "        final_results_dict[\"consentGroups.dataLocation\"] = \"TDR Location\"\n",
    "        final_results_dict[\"consentGroups.url\"] = \"https://data.terra.bio/snapshots/\" + snapshot_id\n",
    "        if duos_dict[\"consentGroups\"][0][\"fileTypes\"] and duos_dict[\"consentGroups\"][0][\"fileTypes\"].get(\"fileType\"):\n",
    "            final_results_dict[\"consentGroups.fileTypes.fileType\"] = duos_dict[\"consentGroups\"][0][\"fileTypes\"][0].get(\"fileType\")\n",
    "        else:\n",
    "            final_results_dict[\"consentGroups.fileTypes.fileType\"] = None\n",
    "        if duos_dict[\"consentGroups\"][0][\"fileTypes\"] and duos_dict[\"consentGroups\"][0][\"fileTypes\"].get(\"functionalEquivalence\"):\n",
    "            final_results_dict[\"consentGroups.fileTypes.functionalEquivalence\"] = duos_dict[\"consentGroups\"][0][\"fileTypes\"][0].get(\"functionalEquivalence\")\n",
    "        else:\n",
    "            final_results_dict[\"consentGroups.fileTypes.functionalEquivalence\"] = None\n",
    "        collab_site = duos_dict.get(\"collaboratingSites\")\n",
    "        if collab_site:\n",
    "            final_results_dict[\"consortium\"] = collab_site[0]\n",
    "        else:\n",
    "            final_results_dict[\"consortium\"] = None\n",
    "        dataset_details_records.append(final_results_dict)\n",
    "        continue\n",
    "        \n",
    "    # Pull study information from DUOS (if matched to existing study)\n",
    "    duos_study_dict = {}\n",
    "    if match_study_id:\n",
    "        duos_study_dict = requests.get(\n",
    "                url=f\"{url}/api/dataset/study/registration/{match_study_id}\",\n",
    "                headers={\"Authorization\": f\"Bearer {duos_token}\"}\n",
    "            ).json()\n",
    "        collab_site = duos_study_dict.get(\"collaboratingSites\")\n",
    "        if collab_site:\n",
    "            duos_study_dict[\"consortium\"] = collab_site[0]\n",
    "    \n",
    "    # Pull information from original workspace (if listed)\n",
    "    if source_workspace:\n",
    "        # Establish credentials\n",
    "        creds, project = google.auth.default()\n",
    "        auth_req = google.auth.transport.requests.Request()\n",
    "        creds.refresh(auth_req)\n",
    "\n",
    "        # Pull workspace attributes\n",
    "        attempt_counter = 0\n",
    "        while attempt_counter <= 2:\n",
    "            try:\n",
    "                ws_attributes = requests.get(\n",
    "                    url=f\"https://api.firecloud.org/api/workspaces/anvil-datastorage/{source_workspace}?fields=workspace.attributes,workspace.authorizationDomain,workspace.googleProject,workspace.bucketName\",\n",
    "                    headers={\"Authorization\": f\"Bearer {creds.token}\"}\n",
    "                ).json()\n",
    "                break\n",
    "            except:\n",
    "                sleep(5)\n",
    "                attempt_counter += 1\n",
    "\n",
    "        # Map to schema\n",
    "        if ws_attributes.get(\"workspace\"):\n",
    "            terra_dict[\"studyName\"] = coalesce(ws_attributes[\"workspace\"][\"attributes\"].get(\"library:projectName\"), source_workspace) \n",
    "            terra_dict[\"studyType\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:studyDesign\")\n",
    "            terra_dict[\"studyDescription\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"description\")\n",
    "            if ws_attributes[\"workspace\"][\"attributes\"].get(\"library:dataCategory\"):\n",
    "                terra_dict[\"dataTypes\"] = []\n",
    "                for item in ws_attributes[\"workspace\"][\"attributes\"][\"library:dataCategory\"][\"items\"]:\n",
    "                    inner_list = item.split(\",\")\n",
    "                    for inner_item in inner_list:\n",
    "                        inner_item = inner_item.replace(\"'\", \"\").strip()\n",
    "                        terra_dict[\"dataTypes\"].append(inner_item)\n",
    "            terra_dict[\"phenotypeIndication\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:indication\")\n",
    "            terra_dict[\"species\"] = \"Homo sapiens\"\n",
    "            terra_dict[\"piName\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:datasetOwner\")\n",
    "            terra_dict[\"dataCustodianEmail\"] = [ws_attributes[\"workspace\"][\"attributes\"].get(\"library:contactEmail\")]\n",
    "            if ws_attributes[\"workspace\"][\"attributes\"].get(\"tag:tags\"):\n",
    "                for tag in ws_attributes[\"workspace\"][\"attributes\"].get(\"tag:tags\")[\"items\"]:\n",
    "                    if \"Consortium:\" in tag:\n",
    "                        terra_dict[\"consortium\"] = tag.split(\":\")[1].strip()\n",
    "                    elif \"dbGaP:\" in tag:\n",
    "                        terra_dict[\"dbGaPPhsID\"] = format_phs_id(tag.split(\":\")[1].strip())\n",
    "                        if not phs_id:\n",
    "                            phs_id = format_phs_id(tag.split(\":\")[1].strip()) \n",
    "            terra_dict[\"consentGroups.consentCode\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:dataUseRestriction\")\n",
    "            if ws_attributes[\"workspace\"][\"attributes\"].get(\"library:datatype\"):\n",
    "                terra_dict[\"consentGroups.fileTypes.fileType\"] = ws_attributes[\"workspace\"][\"attributes\"][\"library:datatype\"][\"items\"]\n",
    "            if ws_attributes[\"workspace\"][\"attributes\"].get(\"library:numSubjects\"):\n",
    "                terra_dict[\"consentGroups.numberOfParticipants\"] = ws_attributes[\"workspace\"][\"attributes\"][\"library:numSubjects\"]\n",
    "    #         print(\"------------------------------------------------------\")\n",
    "    #         print(\"terra_dict\")\n",
    "    #         print(terra_dict)\n",
    "\n",
    "    # Pull information from dbGaP (if phs_id listed)\n",
    "    #     print(\"PHS ID for dbGaP: \" + phs_id)\n",
    "    if phs_id:\n",
    "        # Pull and parse XML\n",
    "        phs_short = phs_id.replace(\"phs\", \"\")\n",
    "        dbgap_url = \"https://dbgap.ncbi.nlm.nih.gov/ss/dbgapssws.cgi?request=Study&phs=\" + phs_short\n",
    "        attempt_counter = 0\n",
    "        while attempt_counter <= 2:\n",
    "            try:\n",
    "                response = requests.get(url=dbgap_url)\n",
    "                xml_data = xmltodict.parse(response.text)\n",
    "                break\n",
    "            except:\n",
    "                sleep(5)\n",
    "                attempt_counter += 1\n",
    "        study_uid = \"\"\n",
    "\n",
    "        # Map to schema\n",
    "        if xml_data[\"dbgapss\"].get(\"Study\"):\n",
    "            if isinstance(xml_data[\"dbgapss\"][\"Study\"], list):\n",
    "                study_data = xml_data[\"dbgapss\"][\"Study\"][0]\n",
    "            else:\n",
    "                study_data = xml_data[\"dbgapss\"][\"Study\"] \n",
    "            study_uid = study_data.get(\"@uid\")\n",
    "            dbgap_xml_dict[\"studyName\"] = study_data[\"StudyInfo\"].get(\"StudyNameEntrez\")\n",
    "            dbgap_xml_dict[\"studyDescription\"] = study_data[\"StudyInfo\"].get(\"Description\")\n",
    "            dbgap_xml_dict[\"dbGaPPhsID\"] = phs_id\n",
    "            dbgap_xml_dict[\"dbGaPStudyRegistrationName\"] = study_data[\"StudyInfo\"].get(\"StudyNameEntrez\")\n",
    "            if study_data[\"Authority\"][\"Persons\"].get(\"Person\"):\n",
    "                for ap_entry in study_data[\"Authority\"][\"Persons\"][\"Person\"]:\n",
    "                    if ap_entry[\"Role\"] == \"PI\":\n",
    "                        dbgap_xml_dict[\"piName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "                        dbgap_xml_dict[\"piEmail\"] = ap_entry[\"@email\"]\n",
    "                        dbgap_xml_dict[\"piInstitution\"] = ap_entry[\"Organization\"]\n",
    "                    elif ap_entry[\"Role\"] == \"PO\" and ap_entry[\"Organization\"] == \"NIH\":\n",
    "                        dbgap_xml_dict[\"nihProgramOfficerName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "                    elif ap_entry[\"Role\"] == \"GPA\" and ap_entry[\"Organization\"] == \"NIH\":\n",
    "                        dbgap_xml_dict[\"nihGenomicProgramAdministratorName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "            ic_list = []\n",
    "            if isinstance(study_data[\"Authority\"][\"ICs\"][\"IC\"], list):\n",
    "                for ic_entry in study_data[\"Authority\"][\"ICs\"][\"IC\"]:\n",
    "                    ic_list.append(ic_entry[\"@name\"])\n",
    "            else:\n",
    "                ic_list.append(study_data[\"Authority\"][\"ICs\"][\"IC\"][\"@name\"])\n",
    "            dbgap_xml_dict[\"nihICsSupportingStudy\"] = ic_list\n",
    "            dbgap_xml_dict[\"consentGroups.numberOfParticipants\"] = study_data.get(\"@num_participants\")\n",
    "            dbgap_xml_dict[\"embargoReleaseDate\"] = study_data[\"Policy\"].get(\"@pub-embargo\")\n",
    "    #             print(\"------------------------------------------------------\")\n",
    "    #             print(\"dbgap_xml_dict\")\n",
    "    #             print(dbgap_xml_dict)\n",
    "\n",
    "        # Pull and parse Study API JSON\n",
    "        if study_uid:\n",
    "            dbgap_study_url = \"https://submit.ncbi.nlm.nih.gov/dbgap/api/v1/study_config/\" + str(study_uid)\n",
    "            attempt_counter = 0\n",
    "            while attempt_counter <= 2:\n",
    "                try:\n",
    "                    response = requests.get(url=dbgap_study_url)\n",
    "                    study_api_data = json.loads(response.text)\n",
    "                    break\n",
    "                except:\n",
    "                    sleep(5)\n",
    "                    attempt_counter += 1\n",
    "\n",
    "            # Map to schema\n",
    "            if study_api_data.get(\"error\") == None:\n",
    "                dbgap_study_api_dict[\"studyName\"] = study_api_data[\"data\"].get(\"report_name\")\n",
    "                dbgap_study_api_dict[\"studyDescription\"] = study_api_data[\"data\"].get(\"description\")\n",
    "                dbgap_study_api_dict[\"phenotypeIndication\"] = study_api_data[\"data\"].get(\"primary_disease\")\n",
    "                dbgap_study_api_dict[\"studyType\"] = study_api_data[\"data\"].get(\"study_design\")\n",
    "                dbgap_study_api_dict[\"dbGaPPhsID\"] = phs_id\n",
    "                dbgap_study_api_dict[\"dbGaPStudyRegistrationName\"] = study_api_data[\"data\"].get(\"report_name\")\n",
    "                for attr_entry in study_api_data[\"data\"].get(\"attribution\"):\n",
    "                    if attr_entry.get(\"title\") == \"Principal Investigator\":\n",
    "                        dbgap_study_api_dict[\"piName\"] = attr_entry.get(\"name\")\n",
    "                        dbgap_study_api_dict[\"piInstitution\"] = attr_entry.get(\"institute\")\n",
    "                        break\n",
    "    #             print(\"------------------------------------------------------\")\n",
    "    #             print(\"dbgap_study_api_dict\")\n",
    "    #             print(dbgap_study_api_dict)\n",
    "\n",
    "        # Pull and parse FHIR API JSON\n",
    "        dbgap_fhir_url = \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/ResearchStudy?_format=json&_id=\" + phs_id\n",
    "        attempt_counter = 0\n",
    "        while attempt_counter <= 2:\n",
    "            try:\n",
    "                response = requests.get(url=dbgap_fhir_url)\n",
    "                fhir_data = json.loads(response.text)\n",
    "                break\n",
    "            except:\n",
    "                sleep(5)\n",
    "                attempt_counter += 1\n",
    "\n",
    "        # Map to schema\n",
    "        if fhir_data.get(\"entry\"):\n",
    "            dbgap_fhir_dict[\"studyName\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"title\")\n",
    "            dbgap_fhir_dict[\"studyDescription\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"description\")\n",
    "            dbgap_fhir_dict[\"dbGaPPhsID\"] = phs_id\n",
    "            dbgap_fhir_dict[\"dbGaPStudyRegistrationName\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"title\")\n",
    "            # NIH ICs\n",
    "            if \"Organization/\" in fhir_data[\"entry\"][0][\"resource\"][\"sponsor\"].get(\"reference\"):\n",
    "                dbgap_fhir_dict[\"nihICsSupportingStudy\"] = [fhir_data[\"entry\"][0][\"resource\"][\"sponsor\"].get(\"reference\")[13:]]\n",
    "            else:\n",
    "                ic_display = fhir_data[\"entry\"][0][\"resource\"][\"sponsor\"].get(\"display\")\n",
    "                if ic_display == \"National Human Genome Research Institute\":\n",
    "                    dbgap_fhir_dict[\"nihICsSupportingStudy\"] = [\"NHGRI\"]\n",
    "                else:\n",
    "                    dbgap_fhir_dict[\"nihICsSupportingStudy\"] = [ic_display]\n",
    "            # studyType\n",
    "            if fhir_data[\"entry\"][0][\"resource\"].get(\"category\"):\n",
    "                for cat_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"category\"):\n",
    "                    if cat_entry.get(\"coding\"):\n",
    "                        for coding_entry in cat_entry.get(\"coding\"):\n",
    "                            if coding_entry.get(\"system\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/CodeSystem/ResearchStudy-StudyDesign\":\n",
    "                                value = coding_entry.get(\"display\") if coding_entry.get(\"display\") else coding_entry.get(\"code\")\n",
    "                                if dbgap_fhir_dict.get(\"studyType\") and value:\n",
    "                                    dbgap_fhir_dict[\"studyType\"] += f\", {value}\"\n",
    "                                elif value:\n",
    "                                    dbgap_fhir_dict[\"studyType\"] = value\n",
    "            # dataTypes\n",
    "            dt_list = []\n",
    "            if fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"): \n",
    "                for ext_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "                    if ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-MolecularDataTypes\":\n",
    "                        for inner_ext_entry in ext_entry.get(\"extension\"):\n",
    "                            if inner_ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-MolecularDataTypes-MolecularDataType\":\n",
    "                                for coding_entry in inner_ext_entry[\"valueCodeableConcept\"].get(\"coding\"):\n",
    "                                    dt_list.append(coding_entry.get(\"code\"))\n",
    "            dbgap_fhir_dict[\"dataTypes\"] = dt_list\n",
    "            # phenotypeIndication\n",
    "            if fhir_data[\"entry\"][0][\"resource\"].get(\"focus\"):\n",
    "                for focus_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"focus\"):\n",
    "                    if focus_entry.get(\"coding\"):\n",
    "                        for coding_entry in focus_entry.get(\"coding\"):\n",
    "                            value = coding_entry.get(\"display\") if coding_entry.get(\"display\") else coding_entry.get(\"code\")\n",
    "                            if dbgap_fhir_dict.get(\"phenotypeIndication\") and value:\n",
    "                                dbgap_fhir_dict[\"phenotypeIndication\"] += f\", {value}\"\n",
    "                            elif value:\n",
    "                                dbgap_fhir_dict[\"phenotypeIndication\"] = value\n",
    "            # numberOfParticipants\n",
    "            if fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "                for ext_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "                    if ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-Content\":\n",
    "                        for inner_ext_entry in ext_entry.get(\"extension\"):\n",
    "                            if inner_ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-Content-NumSubjects\":\n",
    "                                dbgap_fhir_dict[\"consentGroups.numberOfParticipants\"] = inner_ext_entry[\"valueCount\"].get(\"code\")\n",
    "    #         print(\"------------------------------------------------------\")\n",
    "    #         print(\"dbgap_fhir_dict\")\n",
    "    #         print(dbgap_fhir_dict)\n",
    "\n",
    "    # Reconcile information and create final results\n",
    "    consent_code = coalesce(snapshot_consent_code, terra_dict.get(\"consentGroups.consentCode\"), dbgap_fhir_dict.get(\"consentGroups.consentCode\"), dbgap_xml_dict.get(\"consentGroups.consentCode\"), dbgap_study_api_dict.get(\"consentGroups.consentCode\"))\n",
    "    if consent_code:\n",
    "        consent_code = consent_code.upper().replace(\"_\", \"-\")\n",
    "    else:\n",
    "        consent_code = \"\"\n",
    "    consortium = coalesce(duos_study_dict.get(\"consortium\"), terra_dict.get(\"consortium\"), dbgap_fhir_dict.get(\"consortium\"), dbgap_xml_dict.get(\"consortium\"), dbgap_study_api_dict.get(\"consortium\"))\n",
    "    dbGaPPhsID = coalesce(duos_study_dict.get(\"dbGaPPhsID\"), dbgap_fhir_dict.get(\"dbGaPPhsID\"), dbgap_xml_dict.get(\"dbGaPPhsID\"), dbgap_study_api_dict.get(\"dbGaPPhsID\"), terra_dict.get(\"dbGaPPhsID\"))\n",
    "    studyName = coalesce(duos_study_dict.get(\"studyName\"), dbgap_fhir_dict.get(\"studyName\"), dbgap_xml_dict.get(\"studyName\"), dbgap_study_api_dict.get(\"studyName\"), terra_dict.get(\"studyName\"))\n",
    "    if dbGaPPhsID and consent_code:\n",
    "        study_consent = dbGaPPhsID + \":\" + consent_code\n",
    "        purl_doid = ds_consent_map.get(study_consent)\n",
    "        if purl_doid:\n",
    "            if not isinstance(purl_doid, list):\n",
    "                purl_doid = [purl_doid]\n",
    "        else:\n",
    "            purl_doid = []\n",
    "    else:\n",
    "        purl_doid = []\n",
    "    final_results_dict[\"snapshot_id\"] = snapshot_id\n",
    "    final_results_dict[\"snapshot_duos_id\"] = duos_id\n",
    "    final_results_dict[\"match_duos_id\"] = match_duos_id\n",
    "    final_results_dict[\"match_study_id\"] = match_study_id\n",
    "    if dbGaPPhsID and f\" ({dbGaPPhsID})\" not in final_results_dict[\"studyName\"]:\n",
    "        final_results_dict[\"studyName\"] = studyName + f\" ({dbGaPPhsID})\"\n",
    "    else:\n",
    "        final_results_dict[\"studyName\"] = studyName\n",
    "    final_results_dict[\"studyType\"] = coalesce(duos_study_dict.get(\"studyType\"), dbgap_fhir_dict.get(\"studyType\"), dbgap_xml_dict.get(\"studyType\"), dbgap_study_api_dict.get(\"studyType\"), terra_dict.get(\"studyType\"))\n",
    "    final_results_dict[\"studyDescription\"] = format_description(coalesce(duos_study_dict.get(\"studyDescription\"), dbgap_fhir_dict.get(\"studyDescription\"), dbgap_xml_dict.get(\"studyDescription\"), dbgap_study_api_dict.get(\"studyDescription\"), terra_dict.get(\"studyDescription\")))\n",
    "    if final_results_dict[\"studyDescription\"]:\n",
    "        if \"Platform: AnVIL\" not in final_results_dict[\"studyDescription\"]:\n",
    "            final_results_dict[\"studyDescription\"] = final_results_dict[\"studyDescription\"] + \"\\nPlatform: AnVIL\"\n",
    "    else:\n",
    "        final_results_dict[\"studyDescription\"] = \"Platform: AnVIL\"\n",
    "    final_results_dict[\"dataTypes\"] = coalesce(duos_study_dict.get(\"dataTypes\"), terra_dict.get(\"dataTypes\"), dbgap_fhir_dict.get(\"dataTypes\"), dbgap_xml_dict.get(\"dataTypes\"), dbgap_study_api_dict.get(\"dataTypes\"))\n",
    "    final_results_dict[\"phenotypeIndication\"] = coalesce(duos_study_dict.get(\"phenotypeIndication\"), terra_dict.get(\"phenotypeIndication\"), dbgap_fhir_dict.get(\"phenotypeIndication\"), dbgap_xml_dict.get(\"phenotypeIndication\"), dbgap_study_api_dict.get(\"phenotypeIndication\"))\n",
    "    final_results_dict[\"species\"] = \"Human\"\n",
    "    final_results_dict[\"piName\"] = coalesce(duos_study_dict.get(\"piName\"), dbgap_fhir_dict.get(\"piName\"), dbgap_xml_dict.get(\"piName\"), dbgap_study_api_dict.get(\"piName\"), terra_dict.get(\"piName\"), \"None\")\n",
    "    final_results_dict[\"dataCustodianEmail\"] = [\"help@lists.anvilproject.org\"]\n",
    "    final_results_dict[\"publicVisibility\"] = True\n",
    "    final_results_dict[\"nihAnvilUse\"] = \"I am NHGRI funded and I have a dbGaP PHS ID already\" if dbGaPPhsID else \"I am NHGRI funded and I do not have a dbGaP PHS ID\"\n",
    "    final_results_dict[\"submittingToAnvil\"] = True\n",
    "    final_results_dict[\"dbGaPPhsID\"] = dbGaPPhsID\n",
    "    final_results_dict[\"dbGaPStudyRegistrationName\"] = coalesce(duos_study_dict.get(\"dbGaPStudyRegistrationName\"), dbgap_fhir_dict.get(\"dbGaPStudyRegistrationName\"), dbgap_xml_dict.get(\"dbGaPStudyRegistrationName\"), dbgap_study_api_dict.get(\"dbGaPStudyRegistrationName\"), terra_dict.get(\"dbGaPStudyRegistrationName\"))\n",
    "    final_results_dict[\"embargoReleaseDate\"] = coalesce(duos_study_dict.get(\"embargoReleaseDate\"), dbgap_fhir_dict.get(\"embargoReleaseDate\"), dbgap_xml_dict.get(\"embargoReleaseDate\"), dbgap_study_api_dict.get(\"embargoReleaseDate\"), terra_dict.get(\"embargoReleaseDate\"))\n",
    "    final_results_dict[\"sequencingCenter\"] = None\n",
    "    final_results_dict[\"piEmail\"] = coalesce(duos_study_dict.get(\"piEmail\"), dbgap_fhir_dict.get(\"piEmail\"), dbgap_xml_dict.get(\"piEmail\"), dbgap_study_api_dict.get(\"piEmail\"), terra_dict.get(\"piEmail\"))\n",
    "    final_results_dict[\"piInstitution\"] = coalesce(duos_study_dict.get(\"piInstitution\"), dbgap_fhir_dict.get(\"piInstitution\"), dbgap_xml_dict.get(\"piInstitution\"), dbgap_study_api_dict.get(\"piInstitution\"), terra_dict.get(\"piInstitution\"))\n",
    "    final_results_dict[\"nihGrantContractNumber\"] = None\n",
    "    final_results_dict[\"nihICsSupportingStudy\"] = coalesce(duos_study_dict.get(\"nihICsSupportingStudy\"), dbgap_fhir_dict.get(\"nihICsSupportingStudy\"), dbgap_xml_dict.get(\"nihICsSupportingStudy\"), dbgap_study_api_dict.get(\"nihICsSupportingStudy\"), terra_dict.get(\"nihICsSupportingStudy\"))\n",
    "    final_results_dict[\"nihProgramOfficerName\"] = coalesce(duos_study_dict.get(\"nihProgramOfficerName\"), dbgap_fhir_dict.get(\"nihProgramOfficerName\"), dbgap_xml_dict.get(\"nihProgramOfficerName\"), dbgap_study_api_dict.get(\"nihProgramOfficerName\"), terra_dict.get(\"nihProgramOfficerName\"))\n",
    "    final_results_dict[\"nihInstitutionCenterSubmission\"] = \"NHGRI\"\n",
    "    final_results_dict[\"nihInstitutionalCertificationFileName\"] = None\n",
    "    final_results_dict[\"nihGenomicProgramAdministratorName\"] = coalesce(duos_study_dict.get(\"nihGenomicProgramAdministratorName\"), dbgap_fhir_dict.get(\"nihGenomicProgramAdministratorName\"), dbgap_xml_dict.get(\"nihGenomicProgramAdministratorName\"), dbgap_study_api_dict.get(\"nihGenomicProgramAdministratorName\"), terra_dict.get(\"nihGenomicProgramAdministratorName\"))\n",
    "    final_results_dict[\"multiCenterStudy\"] = None\n",
    "    final_results_dict[\"collaboratingSites\"] = [consortium] if consortium else []\n",
    "    final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSR\"] = None\n",
    "    final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation\"] = None\n",
    "    final_results_dict[\"alternativeDataSharingPlan\"] = False\n",
    "    final_results_dict[\"alternativeDataSharingPlanReasons\"] = []\n",
    "    final_results_dict[\"alternativeDataSharingPlanExplanation\"] = None\n",
    "    final_results_dict[\"alternativeDataSharingPlanFileName\"] = None\n",
    "    final_results_dict[\"alternativeDataSharingPlanDataSubmitted\"] = None\n",
    "    final_results_dict[\"alternativeDataSharingPlanDataReleased\"] = None\n",
    "    final_results_dict[\"alternativeDataSharingPlanTargetDeliveryDate\"] = None\n",
    "    final_results_dict[\"alternativeDataSharingPlanTargetPublicReleaseDate\"] = None\n",
    "    final_results_dict[\"alternativeDataSharingPlanAccessManagement\"] = None\n",
    "    final_results_dict[\"consentGroups.consentGroupName\"] = consent_group_name\n",
    "    final_results_dict[\"consentGroups.accessManagement\"] = access_management\n",
    "    final_results_dict[\"consentGroups.numberOfParticipants\"] = coalesce(terra_dict.get(\"consentGroups.numberOfParticipants\"), dbgap_fhir_dict.get(\"consentGroups.numberOfParticipants\"), dbgap_xml_dict.get(\"consentGroups.numberOfParticipants\"), dbgap_study_api_dict.get(\"consentGroups.numberOfParticipants\"), \"0\")\n",
    "    final_results_dict[\"consentCode\"] = consent_code\n",
    "    final_results_dict[\"consentGroups.generalResearchUse\"] = True if access_management == \"controlled\" and \"GRU\" in consent_code else False\n",
    "    final_results_dict[\"consentGroups.hmb\"] = True if access_management == \"controlled\" and \"HMB\" in consent_code else False\n",
    "    if purl_doid:\n",
    "        final_results_dict[\"consentGroups.diseaseSpecificUse\"] = purl_doid\n",
    "    else:\n",
    "        final_results_dict[\"consentGroups.diseaseSpecificUse\"] = []\n",
    "    final_results_dict[\"consentGroups.gs\"] = consent_code if access_management == \"controlled\" and \"GS-\" in consent_code else None\n",
    "    final_results_dict[\"consentGroups.poa\"] = True if access_management == \"controlled\" and \"POA\" in consent_code else False\n",
    "    final_results_dict[\"consentGroups.nmds\"] = True if access_management == \"controlled\" and \"NMDS\" in consent_code else False\n",
    "    final_results_dict[\"consentGroups.gso\"] = True if access_management == \"controlled\" and \"GSO\" in consent_code else False\n",
    "    final_results_dict[\"consentGroups.pub\"] = True if access_management == \"controlled\" and \"PUB\" in consent_code else False \n",
    "    final_results_dict[\"consentGroups.col\"] = True if access_management == \"controlled\" and \"COL-\" in consent_code else False\n",
    "    final_results_dict[\"consentGroups.irb\"] = True if access_management == \"controlled\" and \"IRB\" in consent_code else False\n",
    "    final_results_dict[\"consentGroups.npu\"] = True if access_management == \"controlled\" and \"NPU\" in consent_code else False\n",
    "    final_results_dict[\"consentGroups.otherPrimary\"] = consent_code if (consent_code and access_management == \"controlled\" and not (final_results_dict[\"consentGroups.generalResearchUse\"] or final_results_dict[\"consentGroups.hmb\"] or final_results_dict[\"consentGroups.diseaseSpecificUse\"] or final_results_dict[\"consentGroups.gs\"] or final_results_dict[\"consentGroups.poa\"] or final_results_dict[\"consentGroups.nmds\"] or final_results_dict[\"consentGroups.gso\"] or final_results_dict[\"consentGroups.pub\"] or final_results_dict[\"consentGroups.col\"] or final_results_dict[\"consentGroups.irb\"] or final_results_dict[\"consentGroups.npu\"])) else None\n",
    "    final_results_dict[\"consentGroups.otherSecondary\"] = None\n",
    "    final_results_dict[\"consentGroups.mor\"] = None\n",
    "    final_results_dict[\"consentGroups.morDate\"] = None\n",
    "    final_results_dict[\"consentGroups.dataLocation\"] = \"TDR Location\"\n",
    "    final_results_dict[\"consentGroups.url\"] = \"https://data.terra.bio/snapshots/\" + snapshot_id\n",
    "    final_results_dict[\"consentGroups.fileTypes.fileType\"] = coalesce(terra_dict.get(\"consentGroups.fileTypes.fileType\"), dbgap_fhir_dict.get(\"consentGroups.fileTypes.fileType\"), dbgap_xml_dict.get(\"consentGroups.fileTypes.fileType\"), dbgap_study_api_dict.get(\"consentGroups.fileTypes.fileType\"))\n",
    "    final_results_dict[\"consentGroups.fileTypes.functionalEquivalence\"] = None\n",
    "    final_results_dict[\"consortium\"] = consortium\n",
    "    dataset_details_records.append(final_results_dict)\n",
    "    \n",
    "# Return results\n",
    "#return dataset_details_records\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loop through new datasets API\n",
    "    # Create base consent_group_name from dataset_name to use for comparison (see above regex)\n",
    "    # Attempt to match the dataset based on the consent group name\n",
    "        # If match found, stop looking, assign the \"identifer\" as the target DUOS ID and \"study_id\" as the target study id\n",
    "# Loop through study lookup\n",
    "    # Attempt to match snapshot PHS ID to a PHS ID for a study\n",
    "        # If match found, stop looking, and assign this as another target study ID\n",
    "#     If DUO on Snapshot, use that for both Study and Dataset information\n",
    "#     If dataset match, use that for both Study and Dataset information\n",
    "#     If no dataset match, try study match. If study match, use that for Study information\n",
    "\n",
    "\n",
    "# Pull information from existing DUOS registration (if listed)\n",
    "if duos_id:\n",
    "    # Establish credentials\n",
    "    creds, project = google.auth.default()\n",
    "    auth_req = google.auth.transport.requests.Request()\n",
    "    creds.refresh(auth_req)\n",
    "\n",
    "    # Pull existing DUOS study registration\n",
    "    duos_dict = requests.get(\n",
    "        url=f\"https://consent.dsde-prod.broadinstitute.org/api/dataset/registration/{duos_id}\",\n",
    "        headers={\"Authorization\": f\"Bearer {creds.token}\"}\n",
    "    ).json()\n",
    "#         print(duos_dict)\n",
    "\n",
    "    # Pull dataset details from DUOS (to get data use info) \n",
    "    duos_dataset_id = duos_dict[\"consentGroups\"][0].get(\"datasetId\")\n",
    "    duos_data_use_dict = {}\n",
    "    if duos_dataset_id:\n",
    "        dataset_details = requests.get(\n",
    "            url=f\"https://consent.dsde-prod.broadinstitute.org/api/dataset/v2/{duos_dataset_id}\",\n",
    "            headers={\"Authorization\": f\"Bearer {creds.token}\"}\n",
    "        ).json()\n",
    "        duos_data_use_dict = dataset_details.get(\"dataUse\")\n",
    "#         print(duos_data_use_dict)\n",
    "\n",
    "# Pull information from DUOS\n",
    "\n",
    "# Pull information from original workspace (if listed)\n",
    "if source_workspace:\n",
    "    # Establish credentials\n",
    "    creds, project = google.auth.default()\n",
    "    auth_req = google.auth.transport.requests.Request()\n",
    "    creds.refresh(auth_req)\n",
    "\n",
    "    # Pull workspace attributes\n",
    "    attempt_counter = 0\n",
    "    while attempt_counter <= 2:\n",
    "        try:\n",
    "            ws_attributes = requests.get(\n",
    "                url=f\"https://api.firecloud.org/api/workspaces/anvil-datastorage/{source_workspace}?fields=workspace.attributes,workspace.authorizationDomain,workspace.googleProject,workspace.bucketName\",\n",
    "                headers={\"Authorization\": f\"Bearer {creds.token}\"}\n",
    "            ).json()\n",
    "            break\n",
    "        except:\n",
    "            sleep(5)\n",
    "            attempt_counter += 1\n",
    "\n",
    "    # Map to schema\n",
    "    if ws_attributes.get(\"workspace\"):\n",
    "        terra_dict[\"studyName\"] = coalesce(ws_attributes[\"workspace\"][\"attributes\"].get(\"library:projectName\"), source_workspace) \n",
    "        terra_dict[\"studyType\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:studyDesign\")\n",
    "        terra_dict[\"studyDescription\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"description\")\n",
    "        if ws_attributes[\"workspace\"][\"attributes\"].get(\"library:dataCategory\"):\n",
    "            terra_dict[\"dataTypes\"] = []\n",
    "            for item in ws_attributes[\"workspace\"][\"attributes\"][\"library:dataCategory\"][\"items\"]:\n",
    "                inner_list = item.split(\",\")\n",
    "                for inner_item in inner_list:\n",
    "                    inner_item = inner_item.replace(\"'\", \"\").strip()\n",
    "                    terra_dict[\"dataTypes\"].append(inner_item)\n",
    "        terra_dict[\"phenotypeIndication\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:indication\")\n",
    "        terra_dict[\"species\"] = \"Homo sapiens\"\n",
    "        terra_dict[\"piName\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:datasetOwner\")\n",
    "        terra_dict[\"dataCustodianEmail\"] = [ws_attributes[\"workspace\"][\"attributes\"].get(\"library:contactEmail\")]\n",
    "        if ws_attributes[\"workspace\"][\"attributes\"].get(\"tag:tags\"):\n",
    "            for tag in ws_attributes[\"workspace\"][\"attributes\"].get(\"tag:tags\")[\"items\"]:\n",
    "                if \"Consortium:\" in tag:\n",
    "                    terra_dict[\"consortium\"] = tag.split(\":\")[1].strip()\n",
    "                elif \"dbGaP:\" in tag:\n",
    "                    terra_dict[\"dbGaPPhsID\"] = format_phs_id(tag.split(\":\")[1].strip())\n",
    "                    if not phs_id:\n",
    "                        phs_id = format_phs_id(tag.split(\":\")[1].strip()) \n",
    "        terra_dict[\"consentGroups.consentCode\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:dataUseRestriction\")\n",
    "        if ws_attributes[\"workspace\"][\"attributes\"].get(\"library:datatype\"):\n",
    "            terra_dict[\"consentGroups.fileTypes.fileType\"] = ws_attributes[\"workspace\"][\"attributes\"][\"library:datatype\"][\"items\"]\n",
    "        if ws_attributes[\"workspace\"][\"attributes\"].get(\"library:numSubjects\"):\n",
    "            terra_dict[\"consentGroups.numberOfParticipants\"] = ws_attributes[\"workspace\"][\"attributes\"][\"library:numSubjects\"]\n",
    "#         print(\"------------------------------------------------------\")\n",
    "#         print(\"terra_dict\")\n",
    "#         print(terra_dict)\n",
    "\n",
    "# Pull information from dbGaP (if phs_id listed)\n",
    "#     print(\"PHS ID for dbGaP: \" + phs_id)\n",
    "if phs_id:\n",
    "    # Pull and parse XML\n",
    "    phs_short = phs_id.replace(\"phs\", \"\")\n",
    "    dbgap_url = \"https://dbgap.ncbi.nlm.nih.gov/ss/dbgapssws.cgi?request=Study&phs=\" + phs_short\n",
    "    attempt_counter = 0\n",
    "    while attempt_counter <= 2:\n",
    "        try:\n",
    "            response = requests.get(url=dbgap_url)\n",
    "            xml_data = xmltodict.parse(response.text)\n",
    "            break\n",
    "        except:\n",
    "            sleep(5)\n",
    "            attempt_counter += 1\n",
    "    study_uid = \"\"\n",
    "\n",
    "    # Map to schema\n",
    "    if xml_data[\"dbgapss\"].get(\"Study\"):\n",
    "        if isinstance(xml_data[\"dbgapss\"][\"Study\"], list):\n",
    "            study_data = xml_data[\"dbgapss\"][\"Study\"][0]\n",
    "        else:\n",
    "            study_data = xml_data[\"dbgapss\"][\"Study\"] \n",
    "        study_uid = study_data.get(\"@uid\")\n",
    "        dbgap_xml_dict[\"studyName\"] = study_data[\"StudyInfo\"].get(\"StudyNameEntrez\")\n",
    "        dbgap_xml_dict[\"studyDescription\"] = study_data[\"StudyInfo\"].get(\"Description\")\n",
    "        dbgap_xml_dict[\"dbGaPPhsID\"] = phs_id\n",
    "        dbgap_xml_dict[\"dbGaPStudyRegistrationName\"] = study_data[\"StudyInfo\"].get(\"StudyNameEntrez\")\n",
    "        if study_data[\"Authority\"][\"Persons\"].get(\"Person\"):\n",
    "            for ap_entry in study_data[\"Authority\"][\"Persons\"][\"Person\"]:\n",
    "                if ap_entry[\"Role\"] == \"PI\":\n",
    "                    dbgap_xml_dict[\"piName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "                    dbgap_xml_dict[\"piEmail\"] = ap_entry[\"@email\"]\n",
    "                    dbgap_xml_dict[\"piInstitution\"] = ap_entry[\"Organization\"]\n",
    "                elif ap_entry[\"Role\"] == \"PO\" and ap_entry[\"Organization\"] == \"NIH\":\n",
    "                    dbgap_xml_dict[\"nihProgramOfficerName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "                elif ap_entry[\"Role\"] == \"GPA\" and ap_entry[\"Organization\"] == \"NIH\":\n",
    "                    dbgap_xml_dict[\"nihGenomicProgramAdministratorName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "        ic_list = []\n",
    "        if isinstance(study_data[\"Authority\"][\"ICs\"][\"IC\"], list):\n",
    "            for ic_entry in study_data[\"Authority\"][\"ICs\"][\"IC\"]:\n",
    "                ic_list.append(ic_entry[\"@name\"])\n",
    "        else:\n",
    "            ic_list.append(study_data[\"Authority\"][\"ICs\"][\"IC\"][\"@name\"])\n",
    "        dbgap_xml_dict[\"nihICsSupportingStudy\"] = ic_list\n",
    "        dbgap_xml_dict[\"consentGroups.numberOfParticipants\"] = study_data.get(\"@num_participants\")\n",
    "        dbgap_xml_dict[\"embargoReleaseDate\"] = study_data[\"Policy\"].get(\"@pub-embargo\")\n",
    "#             print(\"------------------------------------------------------\")\n",
    "#             print(\"dbgap_xml_dict\")\n",
    "#             print(dbgap_xml_dict)\n",
    "\n",
    "    # Pull and parse Study API JSON\n",
    "    if study_uid:\n",
    "        dbgap_study_url = \"https://submit.ncbi.nlm.nih.gov/dbgap/api/v1/study_config/\" + str(study_uid)\n",
    "        attempt_counter = 0\n",
    "        while attempt_counter <= 2:\n",
    "            try:\n",
    "                response = requests.get(url=dbgap_study_url)\n",
    "                study_api_data = json.loads(response.text)\n",
    "                break\n",
    "            except:\n",
    "                sleep(5)\n",
    "                attempt_counter += 1\n",
    "\n",
    "        # Map to schema\n",
    "        if study_api_data.get(\"error\") == None:\n",
    "            dbgap_study_api_dict[\"studyName\"] = study_api_data[\"data\"].get(\"report_name\")\n",
    "            dbgap_study_api_dict[\"studyDescription\"] = study_api_data[\"data\"].get(\"description\")\n",
    "            dbgap_study_api_dict[\"phenotypeIndication\"] = study_api_data[\"data\"].get(\"primary_disease\")\n",
    "            dbgap_study_api_dict[\"studyType\"] = study_api_data[\"data\"].get(\"study_design\")\n",
    "            dbgap_study_api_dict[\"dbGaPPhsID\"] = phs_id\n",
    "            dbgap_study_api_dict[\"dbGaPStudyRegistrationName\"] = study_api_data[\"data\"].get(\"report_name\")\n",
    "            for attr_entry in study_api_data[\"data\"].get(\"attribution\"):\n",
    "                if attr_entry.get(\"title\") == \"Principal Investigator\":\n",
    "                    dbgap_study_api_dict[\"piName\"] = attr_entry.get(\"name\")\n",
    "                    dbgap_study_api_dict[\"piInstitution\"] = attr_entry.get(\"institute\")\n",
    "                    break\n",
    "#             print(\"------------------------------------------------------\")\n",
    "#             print(\"dbgap_study_api_dict\")\n",
    "#             print(dbgap_study_api_dict)\n",
    "\n",
    "    # Pull and parse FHIR API JSON\n",
    "    dbgap_fhir_url = \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/ResearchStudy?_format=json&_id=\" + phs_id\n",
    "    attempt_counter = 0\n",
    "    while attempt_counter <= 2:\n",
    "        try:\n",
    "            response = requests.get(url=dbgap_fhir_url)\n",
    "            fhir_data = json.loads(response.text)\n",
    "            break\n",
    "        except:\n",
    "            sleep(5)\n",
    "            attempt_counter += 1\n",
    "\n",
    "    # Map to schema\n",
    "    if fhir_data.get(\"entry\"):\n",
    "        dbgap_fhir_dict[\"studyName\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"title\")\n",
    "        dbgap_fhir_dict[\"studyDescription\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"description\")\n",
    "        dbgap_fhir_dict[\"dbGaPPhsID\"] = phs_id\n",
    "        dbgap_fhir_dict[\"dbGaPStudyRegistrationName\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"title\")\n",
    "        # NIH ICs\n",
    "        if \"Organization/\" in fhir_data[\"entry\"][0][\"resource\"][\"sponsor\"].get(\"reference\"):\n",
    "            dbgap_fhir_dict[\"nihICsSupportingStudy\"] = [fhir_data[\"entry\"][0][\"resource\"][\"sponsor\"].get(\"reference\")[13:]]\n",
    "        else:\n",
    "            ic_display = fhir_data[\"entry\"][0][\"resource\"][\"sponsor\"].get(\"display\")\n",
    "            if ic_display == \"National Human Genome Research Institute\":\n",
    "                dbgap_fhir_dict[\"nihICsSupportingStudy\"] = [\"NHGRI\"]\n",
    "            else:\n",
    "                dbgap_fhir_dict[\"nihICsSupportingStudy\"] = [ic_display]\n",
    "        # studyType\n",
    "        if fhir_data[\"entry\"][0][\"resource\"].get(\"category\"):\n",
    "            for cat_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"category\"):\n",
    "                if cat_entry.get(\"coding\"):\n",
    "                    for coding_entry in cat_entry.get(\"coding\"):\n",
    "                        if coding_entry.get(\"system\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/CodeSystem/ResearchStudy-StudyDesign\":\n",
    "                            value = coding_entry.get(\"display\") if coding_entry.get(\"display\") else coding_entry.get(\"code\")\n",
    "                            if dbgap_fhir_dict.get(\"studyType\") and value:\n",
    "                                dbgap_fhir_dict[\"studyType\"] += f\", {value}\"\n",
    "                            elif value:\n",
    "                                dbgap_fhir_dict[\"studyType\"] = value\n",
    "        # dataTypes\n",
    "        dt_list = []\n",
    "        if fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"): \n",
    "            for ext_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "                if ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-MolecularDataTypes\":\n",
    "                    for inner_ext_entry in ext_entry.get(\"extension\"):\n",
    "                        if inner_ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-MolecularDataTypes-MolecularDataType\":\n",
    "                            for coding_entry in inner_ext_entry[\"valueCodeableConcept\"].get(\"coding\"):\n",
    "                                dt_list.append(coding_entry.get(\"code\"))\n",
    "        dbgap_fhir_dict[\"dataTypes\"] = dt_list\n",
    "        # phenotypeIndication\n",
    "        if fhir_data[\"entry\"][0][\"resource\"].get(\"focus\"):\n",
    "            for focus_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"focus\"):\n",
    "                if focus_entry.get(\"coding\"):\n",
    "                    for coding_entry in focus_entry.get(\"coding\"):\n",
    "                        value = coding_entry.get(\"display\") if coding_entry.get(\"display\") else coding_entry.get(\"code\")\n",
    "                        if dbgap_fhir_dict.get(\"phenotypeIndication\") and value:\n",
    "                            dbgap_fhir_dict[\"phenotypeIndication\"] += f\", {value}\"\n",
    "                        elif value:\n",
    "                            dbgap_fhir_dict[\"phenotypeIndication\"] = value\n",
    "        # numberOfParticipants\n",
    "        if fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "            for ext_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "                if ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-Content\":\n",
    "                    for inner_ext_entry in ext_entry.get(\"extension\"):\n",
    "                        if inner_ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-Content-NumSubjects\":\n",
    "                            dbgap_fhir_dict[\"consentGroups.numberOfParticipants\"] = inner_ext_entry[\"valueCount\"].get(\"code\")\n",
    "#         print(\"------------------------------------------------------\")\n",
    "#         print(\"dbgap_fhir_dict\")\n",
    "#         print(dbgap_fhir_dict)\n",
    "\n",
    "# Reconcile information and create final results\n",
    "consent_code = coalesce(snapshot_consent_code, terra_dict.get(\"consentGroups.consentCode\"), dbgap_fhir_dict.get(\"consentGroups.consentCode\"), dbgap_xml_dict.get(\"consentGroups.consentCode\"), dbgap_study_api_dict.get(\"consentGroups.consentCode\"))\n",
    "if consent_code:\n",
    "    consent_code = consent_code.upper().replace(\"_\", \"-\")\n",
    "else:\n",
    "    consent_code = \"\"\n",
    "consortium = coalesce(terra_dict.get(\"consortium\"), dbgap_fhir_dict.get(\"consortium\"), dbgap_xml_dict.get(\"consortium\"), dbgap_study_api_dict.get(\"consortium\"))\n",
    "dbGaPPhsID = coalesce(dbgap_fhir_dict.get(\"dbGaPPhsID\"), dbgap_xml_dict.get(\"dbGaPPhsID\"), dbgap_study_api_dict.get(\"dbGaPPhsID\"), terra_dict.get(\"dbGaPPhsID\"))\n",
    "studyName = coalesce(dbgap_fhir_dict.get(\"studyName\"), dbgap_xml_dict.get(\"studyName\"), dbgap_study_api_dict.get(\"studyName\"), terra_dict.get(\"studyName\"))\n",
    "if dbGaPPhsID and consent_code:\n",
    "    study_consent = dbGaPPhsID + \":\" + consent_code\n",
    "    purl_doid = ds_consent_map.get(study_consent)\n",
    "    if purl_doid:\n",
    "        if not isinstance(purl_doid, list):\n",
    "            purl_doid = [purl_doid]\n",
    "    else:\n",
    "        purl_doid = []\n",
    "else:\n",
    "    purl_doid = []\n",
    "final_results_dict[\"snapshot_id\"] = snapshot_id\n",
    "final_results_dict[\"duos_id\"] = duos_id\n",
    "try:\n",
    "    consent_group_name = re.search(r'(.*)_[0-9]{8}_ANV[0-9]+_[0-9]{12}$', snapshot_name).group(1)\n",
    "except:\n",
    "    consent_group_name = snapshot_name\n",
    "if duos_id:\n",
    "    final_results_dict[\"studyName\"] = duos_dict.get(\"studyName\")\n",
    "    final_results_dict[\"studyType\"] = duos_dict.get(\"studyType\")\n",
    "    final_results_dict[\"studyDescription\"] = duos_dict.get(\"studyDescription\")\n",
    "    final_results_dict[\"dataTypes\"] = duos_dict.get(\"dataTypes\")\n",
    "    final_results_dict[\"phenotypeIndication\"] = duos_dict.get(\"phenotypeIndication\")\n",
    "    final_results_dict[\"species\"] = duos_dict.get(\"species\")\n",
    "    final_results_dict[\"piName\"] = duos_dict.get(\"piName\")\n",
    "    final_results_dict[\"dataCustodianEmail\"] = duos_dict.get(\"dataCustodianEmail\")\n",
    "    final_results_dict[\"publicVisibility\"] = duos_dict.get(\"publicVisibility\")\n",
    "    final_results_dict[\"nihAnvilUse\"] = \"I am NHGRI funded and I have a dbGaP PHS ID already\" if 'already' in duos_dict.get(\"nihAnvilUse\").lower() else \"I am NHGRI funded and I do not have a dbGaP PHS ID\"\n",
    "    final_results_dict[\"submittingToAnvil\"] = duos_dict.get(\"submittingToAnvil\")\n",
    "    final_results_dict[\"dbGaPPhsID\"] = duos_dict.get(\"dbGaPPhsID\")\n",
    "    final_results_dict[\"dbGaPStudyRegistrationName\"] = duos_dict.get(\"dbGaPStudyRegistrationName\")\n",
    "    final_results_dict[\"embargoReleaseDate\"] = duos_dict.get(\"embargoReleaseDate\")\n",
    "    final_results_dict[\"sequencingCenter\"] = duos_dict.get(\"sequencingCenter\")\n",
    "    final_results_dict[\"piEmail\"] = duos_dict.get(\"piEmail\")\n",
    "    final_results_dict[\"piInstitution\"] = duos_dict.get(\"piInstitution\")\n",
    "    final_results_dict[\"nihGrantContractNumber\"] = duos_dict.get(\"nihGrantContractNumber\")\n",
    "    final_results_dict[\"nihICsSupportingStudy\"] = duos_dict.get(\"nihICsSupportingStudy\")\n",
    "    final_results_dict[\"nihProgramOfficerName\"] = duos_dict.get(\"nihProgramOfficerName\")\n",
    "    final_results_dict[\"nihInstitutionCenterSubmission\"] = duos_dict.get(\"nihInstitutionCenterSubmission\")\n",
    "    final_results_dict[\"nihInstitutionalCertificationFileName\"] = duos_dict.get(\"nihInstitutionalCertificationFileName\")\n",
    "    final_results_dict[\"nihGenomicProgramAdministratorName\"] = duos_dict.get(\"nihGenomicProgramAdministratorName\")\n",
    "    final_results_dict[\"multiCenterStudy\"] = duos_dict.get(\"multiCenterStudy\")\n",
    "    final_results_dict[\"collaboratingSites\"] = duos_dict.get(\"collaboratingSites\")\n",
    "    final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSR\"] = duos_dict.get(\"controlledAccessRequiredForGenomicSummaryResultsGSR\")\n",
    "    final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation\"] = duos_dict.get(\"controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation\")\n",
    "    final_results_dict[\"alternativeDataSharingPlan\"] = duos_dict.get(\"alternativeDataSharingPlan\")\n",
    "    final_results_dict[\"alternativeDataSharingPlanReasons\"] = duos_dict.get(\"alternativeDataSharingPlanReasons\")\n",
    "    final_results_dict[\"alternativeDataSharingPlanExplanation\"] = duos_dict.get(\"alternativeDataSharingPlanExplanation\")\n",
    "    final_results_dict[\"alternativeDataSharingPlanFileName\"] = duos_dict.get(\"alternativeDataSharingPlanFileName\")\n",
    "    final_results_dict[\"alternativeDataSharingPlanDataSubmitted\"] = duos_dict.get(\"alternativeDataSharingPlanDataSubmitted\")\n",
    "    final_results_dict[\"alternativeDataSharingPlanDataReleased\"] = duos_dict.get(\"alternativeDataSharingPlanDataReleased\")\n",
    "    final_results_dict[\"alternativeDataSharingPlanTargetDeliveryDate\"] = duos_dict.get(\"alternativeDataSharingPlanTargetDeliveryDate\")\n",
    "    final_results_dict[\"alternativeDataSharingPlanTargetPublicReleaseDate\"] = duos_dict.get(\"alternativeDataSharingPlanTargetPublicReleaseDate\")\n",
    "    final_results_dict[\"alternativeDataSharingPlanAccessManagement\"] = duos_dict.get(\"alternativeDataSharingPlanAccessManagement\")\n",
    "    final_results_dict[\"consentGroups.consentGroupName\"] = consent_group_name\n",
    "    final_results_dict[\"consentGroups.accessManagement\"] = access_management\n",
    "    final_results_dict[\"consentGroups.numberOfParticipants\"] = duos_dict[\"consentGroups\"][0].get(\"numberOfParticipants\")\n",
    "    final_results_dict[\"consentCode\"] = consent_code\n",
    "    final_results_dict[\"consentGroups.generalResearchUse\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"generalResearchUse\"), duos_data_use_dict.get(\"generalUse\"), False)\n",
    "    final_results_dict[\"consentGroups.hmb\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"hmb\"), duos_data_use_dict.get(\"hmbResearch\"), False)\n",
    "    final_results_dict[\"consentGroups.diseaseSpecificUse\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"diseaseSpecificUse\"), duos_data_use_dict.get(\"diseaseRestrictions\"), [])\n",
    "    final_results_dict[\"consentGroups.gs\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"gs\"), duos_data_use_dict.get(\"geographicalRestrictions\"))\n",
    "    final_results_dict[\"consentGroups.poa\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"poa\"), duos_data_use_dict.get(\"populationOriginsAncestry\"), False)\n",
    "    final_results_dict[\"consentGroups.nmds\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"nmds\"), False)\n",
    "    final_results_dict[\"consentGroups.gso\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"gso\"), duos_data_use_dict.get(\"geneticStudiesOnly\"), False)\n",
    "    final_results_dict[\"consentGroups.pub\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"pub\"), duos_data_use_dict.get(\"publicationResults\"), False)\n",
    "    final_results_dict[\"consentGroups.col\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"col\"), duos_data_use_dict.get(\"collaboratorRequired\"), False)\n",
    "    final_results_dict[\"consentGroups.irb\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"irb\"), duos_data_use_dict.get(\"ethicsApprovalRequired\"), False)\n",
    "    final_results_dict[\"consentGroups.npu\"] = coalesce(duos_dict[\"consentGroups\"][0].get(\"npu\"), False)\n",
    "    final_results_dict[\"consentGroups.otherPrimary\"] = duos_dict[\"consentGroups\"][0].get(\"otherPrimary\")\n",
    "    final_results_dict[\"consentGroups.otherSecondary\"] = duos_dict[\"consentGroups\"][0].get(\"otherSecondary\")\n",
    "    final_results_dict[\"consentGroups.mor\"] = duos_dict[\"consentGroups\"][0].get(\"mor\")\n",
    "    final_results_dict[\"consentGroups.morDate\"] = duos_dict[\"consentGroups\"][0].get(\"morDate\")\n",
    "    final_results_dict[\"consentGroups.dataLocation\"] = \"TDR Location\"\n",
    "    final_results_dict[\"consentGroups.url\"] = \"https://data.terra.bio/snapshots/\" + snapshot_id\n",
    "    if duos_dict[\"consentGroups\"][0][\"fileTypes\"] and duos_dict[\"consentGroups\"][0][\"fileTypes\"].get(\"fileType\"):\n",
    "        final_results_dict[\"consentGroups.fileTypes.fileType\"] = duos_dict[\"consentGroups\"][0][\"fileTypes\"][0].get(\"fileType\")\n",
    "    else:\n",
    "        final_results_dict[\"consentGroups.fileTypes.fileType\"] = None\n",
    "    if duos_dict[\"consentGroups\"][0][\"fileTypes\"] and duos_dict[\"consentGroups\"][0][\"fileTypes\"].get(\"functionalEquivalence\"):\n",
    "        final_results_dict[\"consentGroups.fileTypes.functionalEquivalence\"] = duos_dict[\"consentGroups\"][0][\"fileTypes\"][0].get(\"functionalEquivalence\")\n",
    "    else:\n",
    "        final_results_dict[\"consentGroups.fileTypes.functionalEquivalence\"] = None\n",
    "    final_results_dict[\"consortium\"] = consortium\n",
    "else:\n",
    "    if dbGaPPhsID:\n",
    "        final_results_dict[\"studyName\"] = studyName + f\" ({dbGaPPhsID})\"\n",
    "    else:\n",
    "        final_results_dict[\"studyName\"] = studyName\n",
    "    final_results_dict[\"studyType\"] = coalesce(dbgap_fhir_dict.get(\"studyType\"), dbgap_xml_dict.get(\"studyType\"), dbgap_study_api_dict.get(\"studyType\"), terra_dict.get(\"studyType\"))\n",
    "    final_results_dict[\"studyDescription\"] = format_description(coalesce(dbgap_fhir_dict.get(\"studyDescription\"), dbgap_xml_dict.get(\"studyDescription\"), dbgap_study_api_dict.get(\"studyDescription\"), terra_dict.get(\"studyDescription\")))\n",
    "    if final_results_dict[\"studyDescription\"]:\n",
    "        final_results_dict[\"studyDescription\"] = final_results_dict[\"studyDescription\"] + \"\\nPlatform: AnVIL\"\n",
    "    else:\n",
    "        final_results_dict[\"studyDescription\"] = \"Platform: AnVIL\"\n",
    "    final_results_dict[\"dataTypes\"] = coalesce(terra_dict.get(\"dataTypes\"), dbgap_fhir_dict.get(\"dataTypes\"), dbgap_xml_dict.get(\"dataTypes\"), dbgap_study_api_dict.get(\"dataTypes\"))\n",
    "    final_results_dict[\"phenotypeIndication\"] = coalesce(terra_dict.get(\"phenotypeIndication\"), dbgap_fhir_dict.get(\"phenotypeIndication\"), dbgap_xml_dict.get(\"phenotypeIndication\"), dbgap_study_api_dict.get(\"phenotypeIndication\"))\n",
    "    final_results_dict[\"species\"] = \"Human\"\n",
    "    final_results_dict[\"piName\"] = coalesce(dbgap_fhir_dict.get(\"piName\"), dbgap_xml_dict.get(\"piName\"), dbgap_study_api_dict.get(\"piName\"), terra_dict.get(\"piName\"), \"None\")\n",
    "    final_results_dict[\"dataCustodianEmail\"] = [\"help@lists.anvilproject.org\"]\n",
    "    final_results_dict[\"publicVisibility\"] = True\n",
    "    final_results_dict[\"nihAnvilUse\"] = \"I am NHGRI funded and I have a dbGaP PHS ID already\" if dbGaPPhsID else \"I am NHGRI funded and I do not have a dbGaP PHS ID\"\n",
    "    final_results_dict[\"submittingToAnvil\"] = True\n",
    "    final_results_dict[\"dbGaPPhsID\"] = dbGaPPhsID\n",
    "    final_results_dict[\"dbGaPStudyRegistrationName\"] = coalesce(dbgap_fhir_dict.get(\"dbGaPStudyRegistrationName\"), dbgap_xml_dict.get(\"dbGaPStudyRegistrationName\"), dbgap_study_api_dict.get(\"dbGaPStudyRegistrationName\"), terra_dict.get(\"dbGaPStudyRegistrationName\"))\n",
    "    final_results_dict[\"embargoReleaseDate\"] = coalesce(dbgap_fhir_dict.get(\"embargoReleaseDate\"), dbgap_xml_dict.get(\"embargoReleaseDate\"), dbgap_study_api_dict.get(\"embargoReleaseDate\"), terra_dict.get(\"embargoReleaseDate\"))\n",
    "    final_results_dict[\"sequencingCenter\"] = None\n",
    "    final_results_dict[\"piEmail\"] = coalesce(dbgap_fhir_dict.get(\"piEmail\"), dbgap_xml_dict.get(\"piEmail\"), dbgap_study_api_dict.get(\"piEmail\"), terra_dict.get(\"piEmail\"))\n",
    "    final_results_dict[\"piInstitution\"] = coalesce(dbgap_fhir_dict.get(\"piInstitution\"), dbgap_xml_dict.get(\"piInstitution\"), dbgap_study_api_dict.get(\"piInstitution\"), terra_dict.get(\"piInstitution\"))\n",
    "    final_results_dict[\"nihGrantContractNumber\"] = None\n",
    "    final_results_dict[\"nihICsSupportingStudy\"] = coalesce(dbgap_fhir_dict.get(\"nihICsSupportingStudy\"), dbgap_xml_dict.get(\"nihICsSupportingStudy\"), dbgap_study_api_dict.get(\"nihICsSupportingStudy\"), terra_dict.get(\"nihICsSupportingStudy\"))\n",
    "    final_results_dict[\"nihProgramOfficerName\"] = coalesce(dbgap_fhir_dict.get(\"nihProgramOfficerName\"), dbgap_xml_dict.get(\"nihProgramOfficerName\"), dbgap_study_api_dict.get(\"nihProgramOfficerName\"), terra_dict.get(\"nihProgramOfficerName\"))\n",
    "    final_results_dict[\"nihInstitutionCenterSubmission\"] = \"NHGRI\"\n",
    "    final_results_dict[\"nihInstitutionalCertificationFileName\"] = None\n",
    "    final_results_dict[\"nihGenomicProgramAdministratorName\"] = coalesce(dbgap_fhir_dict.get(\"nihGenomicProgramAdministratorName\"), dbgap_xml_dict.get(\"nihGenomicProgramAdministratorName\"), dbgap_study_api_dict.get(\"nihGenomicProgramAdministratorName\"), terra_dict.get(\"nihGenomicProgramAdministratorName\"))\n",
    "    final_results_dict[\"multiCenterStudy\"] = None\n",
    "    final_results_dict[\"collaboratingSites\"] = [consortium] if consortium else []\n",
    "    final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSR\"] = None\n",
    "    final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation\"] = None\n",
    "    final_results_dict[\"alternativeDataSharingPlan\"] = False\n",
    "    final_results_dict[\"alternativeDataSharingPlanReasons\"] = []\n",
    "    final_results_dict[\"alternativeDataSharingPlanExplanation\"] = None\n",
    "    final_results_dict[\"alternativeDataSharingPlanFileName\"] = None\n",
    "    final_results_dict[\"alternativeDataSharingPlanDataSubmitted\"] = None\n",
    "    final_results_dict[\"alternativeDataSharingPlanDataReleased\"] = None\n",
    "    final_results_dict[\"alternativeDataSharingPlanTargetDeliveryDate\"] = None\n",
    "    final_results_dict[\"alternativeDataSharingPlanTargetPublicReleaseDate\"] = None\n",
    "    final_results_dict[\"alternativeDataSharingPlanAccessManagement\"] = None\n",
    "    final_results_dict[\"consentGroups.consentGroupName\"] = consent_group_name\n",
    "    final_results_dict[\"consentGroups.accessManagement\"] = access_management\n",
    "    final_results_dict[\"consentGroups.numberOfParticipants\"] = coalesce(terra_dict.get(\"consentGroups.numberOfParticipants\"), dbgap_fhir_dict.get(\"consentGroups.numberOfParticipants\"), dbgap_xml_dict.get(\"consentGroups.numberOfParticipants\"), dbgap_study_api_dict.get(\"consentGroups.numberOfParticipants\"), \"0\")\n",
    "    final_results_dict[\"consentCode\"] = consent_code\n",
    "    final_results_dict[\"consentGroups.generalResearchUse\"] = True if access_management == \"controlled\" and \"GRU\" in consent_code else False\n",
    "    final_results_dict[\"consentGroups.hmb\"] = True if access_management == \"controlled\" and \"HMB\" in consent_code else False\n",
    "    if purl_doid:\n",
    "        final_results_dict[\"consentGroups.diseaseSpecificUse\"] = purl_doid\n",
    "    else:\n",
    "        final_results_dict[\"consentGroups.diseaseSpecificUse\"] = []\n",
    "    final_results_dict[\"consentGroups.gs\"] = consent_code if access_management == \"controlled\" and \"GS-\" in consent_code else None\n",
    "    final_results_dict[\"consentGroups.poa\"] = True if access_management == \"controlled\" and \"POA\" in consent_code else False\n",
    "    final_results_dict[\"consentGroups.nmds\"] = True if access_management == \"controlled\" and \"NMDS\" in consent_code else False\n",
    "    final_results_dict[\"consentGroups.gso\"] = True if access_management == \"controlled\" and \"GSO\" in consent_code else False\n",
    "    final_results_dict[\"consentGroups.pub\"] = True if access_management == \"controlled\" and \"PUB\" in consent_code else False \n",
    "    final_results_dict[\"consentGroups.col\"] = True if access_management == \"controlled\" and \"COL-\" in consent_code else False\n",
    "    final_results_dict[\"consentGroups.irb\"] = True if access_management == \"controlled\" and \"IRB\" in consent_code else False\n",
    "    final_results_dict[\"consentGroups.npu\"] = True if access_management == \"controlled\" and \"NPU\" in consent_code else False\n",
    "    final_results_dict[\"consentGroups.otherPrimary\"] = consent_code if (consent_code and access_management == \"controlled\" and not (final_results_dict[\"consentGroups.generalResearchUse\"] or final_results_dict[\"consentGroups.hmb\"] or final_results_dict[\"consentGroups.diseaseSpecificUse\"] or final_results_dict[\"consentGroups.gs\"] or final_results_dict[\"consentGroups.poa\"] or final_results_dict[\"consentGroups.nmds\"] or final_results_dict[\"consentGroups.gso\"] or final_results_dict[\"consentGroups.pub\"] or final_results_dict[\"consentGroups.col\"] or final_results_dict[\"consentGroups.irb\"] or final_results_dict[\"consentGroups.npu\"])) else None\n",
    "    final_results_dict[\"consentGroups.otherSecondary\"] = None\n",
    "    final_results_dict[\"consentGroups.mor\"] = None\n",
    "    final_results_dict[\"consentGroups.morDate\"] = None\n",
    "    final_results_dict[\"consentGroups.dataLocation\"] = \"TDR Location\"\n",
    "    final_results_dict[\"consentGroups.url\"] = \"https://data.terra.bio/snapshots/\" + snapshot_id\n",
    "    final_results_dict[\"consentGroups.fileTypes.fileType\"] = coalesce(terra_dict.get(\"consentGroups.fileTypes.fileType\"), dbgap_fhir_dict.get(\"consentGroups.fileTypes.fileType\"), dbgap_xml_dict.get(\"consentGroups.fileTypes.fileType\"), dbgap_study_api_dict.get(\"consentGroups.fileTypes.fileType\"))\n",
    "    final_results_dict[\"consentGroups.fileTypes.functionalEquivalence\"] = None\n",
    "    final_results_dict[\"consortium\"] = consortium\n",
    "\n",
    "# Return results\n",
    "return final_results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load Reviewed Metadata into DUOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4,
     23,
     38
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Functions\n",
    "#############################################\n",
    "\n",
    "def format_list(input_list, min_items):\n",
    "    if input_list:\n",
    "        if isinstance(input_list, list):\n",
    "            return input_list\n",
    "        elif isinstance(input_list, str):\n",
    "            return format_list(ast.literal_eval(input_list), min_items)\n",
    "        else:\n",
    "            return []\n",
    "    else:\n",
    "        if min_items > 0:\n",
    "            i = 0\n",
    "            temp_list = []\n",
    "            while i < min_items:\n",
    "                temp_list.append(\"Unknown\")\n",
    "                i += 1\n",
    "            return temp_list\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "def format_file_types(ft_list, fe):\n",
    "    if ft_list:\n",
    "        output_list = []\n",
    "        formatted_ft_list = format_list(ft_list, 0)\n",
    "        for ft in formatted_ft_list:\n",
    "            ft_dict = {\"fileType\": ft}\n",
    "            if fe:\n",
    "                ft_dict[\"functionalEquivalence\"] = fe\n",
    "            else:\n",
    "                ft_dict[\"functionalEquivalence\"] = \"Unknown\"\n",
    "            output_list.append(ft_dict)\n",
    "        return output_list\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "def upload_to_duos(input_file, token, env, dac_id, study_upload_list):\n",
    "    \n",
    "    # Determine the target URL from the env variable\n",
    "    if env == \"prod\":\n",
    "        url = \"https://consent.dsde-prod.broadinstitute.org\"\n",
    "    else:\n",
    "        url = \"https://consent.dsde-dev.broadinstitute.org\"\n",
    "    \n",
    "    # Pull down specified file from the cloud\n",
    "    results_log = []\n",
    "    print(f\"Downloading input file {input_file}...\")\n",
    "    try:\n",
    "        input_df = pd.read_csv(input_file, delimiter = \"\\t\", encoding='unicode_escape')\n",
    "        input_df = input_df.astype(object).where(pd.notnull(input_df),None)\n",
    "        input_df.fillna(\"\",inplace=True)\n",
    "        input_dict = input_df.to_dict(orient=\"records\")\n",
    "        results_log.append([\"Input File Download\", \"Succeeded\", \"\"])\n",
    "    except Exception as e:\n",
    "        msg = f\"Error downloading input file ({input_file}): {str(e)}\"\n",
    "        results_log.append([\"Input File Download\", \"Failed\", msg])\n",
    "        print(msg)\n",
    "        return results_log\n",
    "\n",
    "    # Pull a list of existing datasets and studies from DUOS and build lookup dicts\n",
    "    print(\"Building study and dataset lookup dicts from DUOS...\")\n",
    "    try:\n",
    "        datasets = requests.get(\n",
    "            url=f\"{url}/api/dataset/v2?asCustodian=false\",\n",
    "            headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "        ).json()\n",
    "        study_lookup = {}\n",
    "        full_dataset_lookup = {}\n",
    "        dataset_lookup = {}\n",
    "        for dataset_entry in datasets:\n",
    "            base_name = \"\"\n",
    "            dataset_name = \"\"\n",
    "            dataset_id = dataset_entry.get(\"dataSetId\")\n",
    "            study_name = \"\"\n",
    "            study_id = None\n",
    "            if dataset_entry.get(\"name\"):\n",
    "                try:\n",
    "                    base_name =  dataset_entry.get(\"name\")\n",
    "                    dataset_name = re.search(r'(.*)_[0-9]{8}_ANV[0-9]+_[0-9]{12}$', base_name).group(1)\n",
    "                except:\n",
    "                    base_name =  dataset_entry.get(\"name\")\n",
    "                    dataset_name = dataset_entry.get(\"name\")\n",
    "            anvil_dataset = False\n",
    "            if dataset_entry.get(\"study\"):\n",
    "                if dataset_entry[\"study\"].get(\"name\"):\n",
    "                    study_name = dataset_entry[\"study\"].get(\"name\")\n",
    "                    study_id = dataset_entry[\"study\"].get(\"studyId\")\n",
    "                if dataset_entry[\"study\"].get(\"description\"):\n",
    "                    if \"Platform: AnVIL\" in dataset_entry[\"study\"].get(\"description\"):\n",
    "                        anvil_dataset = True\n",
    "            if study_name and study_name not in study_lookup.keys():\n",
    "                study_lookup[study_name] = study_id\n",
    "            if dataset_name:\n",
    "                full_dataset_lookup[dataset_name] = {\n",
    "                    \"id\": dataset_id,\n",
    "                    \"duos_identifier\": dataset_entry.get(\"datasetIdentifier\"),\n",
    "                    \"name\": base_name,\n",
    "                    \"create_date\": dataset_entry.get(\"createDate\"),\n",
    "                    \"study_name\": study_name,\n",
    "                    \"study_id\": study_id,\n",
    "                    \"anvil_dataset\": anvil_dataset,\n",
    "                    \"data_use\": dataset_entry.get(\"dataUse\")\n",
    "                }\n",
    "        for key, val in full_dataset_lookup.items():\n",
    "            if val[\"anvil_dataset\"] == True:\n",
    "                dataset_lookup[key] = val\n",
    "        results_log.append([\"DUOS Study and Dataset Lookup Dict Creation\", \"Succeeded\", \"\"])\n",
    "    except Exception as e:\n",
    "        msg = f\"Error building study and dataset lookups: {str(e)}\"\n",
    "        results_log.append([\"DUOS Study and Dataset Lookup Dict Creation\", \"Failed\", msg])\n",
    "        print(msg)\n",
    "        return results_log\n",
    "    \n",
    "    # Parse and build DUOS schema for inputted file\n",
    "    print(\"Parsing input file and formatting into DUOS schema...\")\n",
    "    try:\n",
    "        # Determine data submitter id\n",
    "        response = requests.get(\n",
    "            url=f\"{url}/api/user/me\",\n",
    "            headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "        ).json()\n",
    "        data_submitter_id = response[\"userId\"]\n",
    "        # Build dictionary for upload\n",
    "        upload_dict = {}\n",
    "        consent_mismatch_list = []\n",
    "        existing_dataset_cnt = 0\n",
    "        new_dataset_cnt = 0\n",
    "        for input_entry in input_dict:\n",
    "            snapshot_id = input_entry[\"snapshot_id\"]\n",
    "            study_name = input_entry[\"studyName\"]\n",
    "            try:\n",
    "                base_name = input_entry[\"consentGroups.consentGroupName\"]\n",
    "                consent_group_name = re.search(r'(.*)_[0-9]{8}_ANV[0-9]+_[0-9]{12}$', base_name).group(1)\n",
    "            except:\n",
    "                consent_group_name = input_entry[\"consentGroups.consentGroupName\"]\n",
    "            access_type = input_entry[\"consentGroups.accessManagement\"]\n",
    "            study_id = study_lookup.get(study_name)\n",
    "            dataset = dataset_lookup.get(consent_group_name)\n",
    "            dataset_id = \"\"\n",
    "            dataset_id_str = \"\"\n",
    "            if dataset:\n",
    "                dataset_id_from_dataset = dataset[\"id\"]\n",
    "                study_id_from_dataset = dataset[\"study_id\"]\n",
    "                gru_from_dataset = dataset[\"data_use\"].get(\"generalUse\")\n",
    "                gru_from_input = input_entry[\"consentGroups.generalResearchUse\"]\n",
    "                hmb_from_dataset = dataset[\"data_use\"].get(\"hmbResearch\")\n",
    "                hmb_from_input = input_entry[\"consentGroups.hmb\"]\n",
    "                ds_from_dataset = dataset[\"data_use\"].get(\"diseaseRestrictions\")\n",
    "                ds_from_input = format_list(input_entry[\"consentGroups.diseaseSpecificUse\"], 0)\n",
    "                if study_id_from_dataset == study_id:\n",
    "                    dataset_id = dataset_id_from_dataset\n",
    "                    dataset_id_str = f\" ({dataset_id})\"\n",
    "                else:\n",
    "                    dataset_id = None   \n",
    "                print(f\"Parsing and formatting metadata for snapshot {snapshot_id} from the input file. Target study is: {study_name}. Target consent group is: {consent_group_name}{dataset_id_str}\")\n",
    "                if input_entry[\"consentGroups.accessManagement\"] == \"controlled\" and (gru_from_dataset != gru_from_input or hmb_from_dataset != hmb_from_input or ds_from_dataset != ds_from_input):\n",
    "                    print(\"\\tERROR: Mismatching consent information in existing DUOS record vs. proposed new record. Update the consent in the new record to match OR update the consent group name in the new record to create a new DUOS record.\")\n",
    "                    consent_mismatch_list.append(snapshot_id)\n",
    "            else:\n",
    "                print(f\"Parsing and formatting metadata for snapshot {snapshot_id} from the input file. Target study is: {study_name}. Target consent group is: {consent_group_name}\")\n",
    "            # If this is an existing dataset in the specified existing study, provide limited consent group information (for updates only)\n",
    "            if study_id and dataset_id:\n",
    "                existing_dataset_cnt += 1\n",
    "                consent_group_dict = {\n",
    "                            \"consentGroupName\": consent_group_name,\n",
    "                            \"datasetId\": dataset_id,\n",
    "                            \"numberOfParticipants\": input_entry[\"consentGroups.numberOfParticipants\"],\n",
    "                            \"dataLocation\": input_entry[\"consentGroups.dataLocation\"],\n",
    "                            \"url\": input_entry[\"consentGroups.url\"],\n",
    "                            \"fileTypes\": []\n",
    "                            #\"fileTypes\": format_file_types(input_entry[\"consentGroups.fileTypes.fileType\"], input_entry[\"consentGroups.fileTypes.functionalEquivalence\"]) --> Enumeration, exclude for now\n",
    "                    }\n",
    "            # If this is a new dataset that is open access, provide limited consent group information\n",
    "            elif access_type == \"open\":\n",
    "                new_dataset_cnt += 1\n",
    "                consent_group_dict = {\n",
    "                            \"consentGroupName\": consent_group_name,\n",
    "                            \"accessManagement\": access_type,\n",
    "                            \"numberOfParticipants\": input_entry[\"consentGroups.numberOfParticipants\"],\n",
    "                            \"dataLocation\": input_entry[\"consentGroups.dataLocation\"],\n",
    "                            \"url\": input_entry[\"consentGroups.url\"],\n",
    "                            \"fileTypes\": []\n",
    "                            #\"fileTypes\": format_file_types(input_entry[\"consentGroups.fileTypes.fileType\"], input_entry[\"consentGroups.fileTypes.functionalEquivalence\"]) --> Enumeration, exclude for now\n",
    "                    }\n",
    "            # If this is a new dataset that is NOT open access, provide the full consent group information\n",
    "            else:\n",
    "                new_dataset_cnt += 1\n",
    "                consent_group_dict = {\n",
    "                            \"consentGroupName\": consent_group_name,\n",
    "                            \"dataAccessCommitteeId\": dac_id,\n",
    "                            \"accessManagement\": access_type,\n",
    "                            \"numberOfParticipants\": input_entry[\"consentGroups.numberOfParticipants\"],\n",
    "                            \"generalResearchUse\": input_entry[\"consentGroups.generalResearchUse\"],\n",
    "                            \"hmb\": input_entry[\"consentGroups.hmb\"],\n",
    "                            \"diseaseSpecificUse\": format_list(input_entry[\"consentGroups.diseaseSpecificUse\"], 0),\n",
    "                            \"gs\": input_entry[\"consentGroups.gs\"],\n",
    "                            \"poa\": input_entry[\"consentGroups.poa\"],\n",
    "                            \"nmds\": input_entry[\"consentGroups.nmds\"],\n",
    "                            \"gso\": input_entry[\"consentGroups.gso\"],\n",
    "                            \"pub\": input_entry[\"consentGroups.pub\"],\n",
    "                            \"col\": input_entry[\"consentGroups.col\"],\n",
    "                            \"irb\": input_entry[\"consentGroups.irb\"],\n",
    "                            \"npu\": input_entry[\"consentGroups.npu\"],\n",
    "                            \"otherPrimary\": input_entry[\"consentGroups.otherPrimary\"],\n",
    "                            #\"otherSecondary\": input_entry[\"consentGroups.otherSecondary\"], --> Excluding for now, per JL's request\n",
    "                            #\"mor\": input_entry[\"consentGroups.mor\"], --> Date formatting validation for morDate, exclude for now\n",
    "                            #\"morDate\": input_entry[\"consentGroups.morDate\"], --> Date formatting validation, exclude for now\n",
    "                            \"dataLocation\": input_entry[\"consentGroups.dataLocation\"],\n",
    "                            \"url\": input_entry[\"consentGroups.url\"],\n",
    "                            \"fileTypes\": []\n",
    "                            #\"fileTypes\": format_file_types(input_entry[\"consentGroups.fileTypes.fileType\"], input_entry[\"consentGroups.fileTypes.functionalEquivalence\"]) --> Enumeration, exclude for now\n",
    "                    }\n",
    "            study_dict = {}\n",
    "            consent_group_list = []\n",
    "            # If the study associated with the record is not already in the upload dictionary, create a new study dict and append the consent group dict\n",
    "            if study_name not in upload_dict.keys():\n",
    "                consent_group_list.append(consent_group_dict)\n",
    "                study_dict = {\n",
    "                    \"studyName\": study_name,\n",
    "                    #\"studyType\": input_entry[\"studyType\"], --> Enumeration, exclude for now\n",
    "                    \"studyDescription\": input_entry[\"studyDescription\"],\n",
    "                    \"dataTypes\": format_list(input_entry[\"dataTypes\"], 1),\n",
    "                    \"phenotypeIndication\": input_entry[\"phenotypeIndication\"],\n",
    "                    \"species\": input_entry[\"species\"],\n",
    "                    \"piName\": input_entry[\"piName\"] if input_entry[\"piName\"] else \"NA\",\n",
    "                    \"dataSubmitterUserId\": data_submitter_id,\n",
    "                    \"dataCustodianEmail\": format_list(input_entry[\"dataCustodianEmail\"], 0),\n",
    "                    \"publicVisibility\": input_entry[\"publicVisibility\"],\n",
    "                    \"nihAnvilUse\": input_entry[\"nihAnvilUse\"],\n",
    "                    \"submittingToAnvil\": input_entry[\"submittingToAnvil\"],\n",
    "                    \"dbGaPPhsID\": input_entry[\"dbGaPPhsID\"],\n",
    "                    \"dbGaPStudyRegistrationName\": input_entry[\"studyName\"],\n",
    "                    #\"embargoReleaseDate\": input_entry[\"embargoReleaseDate\"], --> Date formatting validation, exclude for now\n",
    "                    \"sequencingCenter\": input_entry[\"sequencingCenter\"],\n",
    "                    \"piEmail\": input_entry[\"piEmail\"],\n",
    "                    #\"piInstitution\": input_entry[\"piInstitution\"], --> Integer ID for registered institutions, exclude for now\n",
    "                    \"piInstitution\": 0,\n",
    "                    \"nihGrantContractNumber\": \"Unknown\", # Required currently\n",
    "                    \"nihICsSupportingStudy\": format_list(input_entry[\"nihICsSupportingStudy\"], 0),\n",
    "                    \"nihProgramOfficerName\": input_entry[\"nihProgramOfficerName\"],\n",
    "                    \"nihInstitutionCenterSubmission\": input_entry[\"nihInstitutionCenterSubmission\"],\n",
    "                    \"nihInstitutionalCertificationFileName\": input_entry[\"nihInstitutionalCertificationFileName\"],\n",
    "                    \"nihGenomicProgramAdministratorName\": input_entry[\"nihGenomicProgramAdministratorName\"],\n",
    "                    \"collaboratingSites\": format_list(input_entry[\"collaboratingSites\"], 0),\n",
    "                    \"alternativeDataSharingPlan\": input_entry[\"alternativeDataSharingPlan\"],\n",
    "                    \"alternativeDataSharingPlanExplanation\": input_entry[\"alternativeDataSharingPlanExplanation\"],\n",
    "                    \"alternativeDataSharingPlanReasons\": [\"Other\"] if input_entry[\"alternativeDataSharingPlan\"] == True and input_entry[\"alternativeDataSharingPlanReasons\"] == \"[]\" else format_list(input_entry[\"alternativeDataSharingPlanReasons\"], 0), \n",
    "                    \"consentGroups\": consent_group_list\n",
    "                }\n",
    "                upload_dict[study_name] = study_dict\n",
    "            # If the study is already in the upload dictionary, create an updated study dict and extend its list of consent groups\n",
    "            else:\n",
    "                for consent_group in upload_dict[study_name][\"consentGroups\"]:\n",
    "                    if consent_group[\"consentGroupName\"] != consent_group_dict[\"consentGroupName\"]:\n",
    "                        consent_group_list.append(consent_group)\n",
    "                consent_group_list.append(consent_group_dict)\n",
    "                study_dict = {\n",
    "                    \"studyName\": study_name,\n",
    "                    #\"studyType\": upload_dict[study_name][\"studyType\"], --> Enumeration, exclude for now\n",
    "                    \"studyDescription\": upload_dict[study_name][\"studyDescription\"],\n",
    "                    \"dataTypes\": upload_dict[study_name][\"dataTypes\"],\n",
    "                    \"phenotypeIndication\": upload_dict[study_name][\"phenotypeIndication\"],\n",
    "                    \"species\": upload_dict[study_name][\"species\"],\n",
    "                    \"piName\": upload_dict[study_name][\"piName\"] if upload_dict[study_name][\"piName\"] else \"NA\",\n",
    "                    \"dataSubmitterUserId\": upload_dict[study_name][\"dataSubmitterUserId\"],\n",
    "                    \"dataCustodianEmail\": upload_dict[study_name][\"dataCustodianEmail\"],\n",
    "                    \"publicVisibility\": upload_dict[study_name][\"publicVisibility\"],\n",
    "                    \"nihAnvilUse\": upload_dict[study_name][\"nihAnvilUse\"],\n",
    "                    \"submittingToAnvil\": upload_dict[study_name][\"submittingToAnvil\"],\n",
    "                    \"dbGaPPhsID\": upload_dict[study_name][\"dbGaPPhsID\"],\n",
    "                    \"dbGaPStudyRegistrationName\": upload_dict[study_name][\"studyName\"],\n",
    "                    #\"embargoReleaseDate\": upload_dict[study_name][\"embargoReleaseDate\"], --> Date formatting validation, exclude for now\n",
    "                    \"sequencingCenter\": upload_dict[study_name][\"sequencingCenter\"],\n",
    "                    \"piEmail\": upload_dict[study_name][\"piEmail\"],\n",
    "                    #\"piInstitution\": upload_dict[study_name][\"piInstitution\"], --> Integer ID for registered institutions, exclude for now\n",
    "                    \"piInstitution\": upload_dict[study_name][\"piInstitution\"],\n",
    "                    \"nihGrantContractNumber\": upload_dict[study_name][\"nihGrantContractNumber\"],\n",
    "                    \"nihICsSupportingStudy\": upload_dict[study_name][\"nihICsSupportingStudy\"],\n",
    "                    \"nihProgramOfficerName\": upload_dict[study_name][\"nihProgramOfficerName\"],\n",
    "                    \"nihInstitutionCenterSubmission\": upload_dict[study_name][\"nihInstitutionCenterSubmission\"],\n",
    "                    \"nihInstitutionalCertificationFileName\": upload_dict[study_name][\"nihInstitutionalCertificationFileName\"],\n",
    "                    \"nihGenomicProgramAdministratorName\": upload_dict[study_name][\"nihGenomicProgramAdministratorName\"],\n",
    "                    \"collaboratingSites\": upload_dict[study_name][\"collaboratingSites\"],\n",
    "                    \"alternativeDataSharingPlan\": upload_dict[study_name][\"alternativeDataSharingPlan\"],\n",
    "                    \"alternativeDataSharingPlanExplanation\": upload_dict[study_name][\"alternativeDataSharingPlanExplanation\"],\n",
    "                    \"alternativeDataSharingPlanReasons\": upload_dict[study_name][\"alternativeDataSharingPlanReasons\"],\n",
    "                    \"consentGroups\": consent_group_list\n",
    "                }\n",
    "                upload_dict[study_name] = study_dict\n",
    "        if consent_mismatch_list:\n",
    "            consent_mismatch_str = \", \".join(consent_mismatch_list)\n",
    "            results_log.append([\"Input File Formatting\", \"Failed\", f\"Snapshots with mismatched consent with existing DUOS datasets: {consent_mismatch_str}\"])\n",
    "        else:\n",
    "            msg = f\"Input file formatting complete. Existing Datasets: {existing_dataset_cnt} New Datasets: {new_dataset_cnt}\"\n",
    "            print(msg)\n",
    "            results_log.append([\"Input File Formatting\", \"Succeeded\", msg])\n",
    "    except Exception as e:\n",
    "        msg = f\"Error parsing and formatting input file: {str(e)}\"\n",
    "        results_log.append([\"Input File Formatting\", \"Failed\", msg])\n",
    "        print(msg)\n",
    "        return results_log\n",
    "    \n",
    "    # Loop through studies and dataset to upload\n",
    "    for study in upload_dict.keys():\n",
    "        if study in study_upload_list or len(study_upload_list) == 0:\n",
    "            print(f\"Uploading data for study {study} into DUOS\")\n",
    "            # For studies that don't exist in DUOS, create a new study\n",
    "            if not study_lookup.get(study):\n",
    "                print(\"Study does NOT currently exist in DUOS. Creating new study and dataset records...\")\n",
    "                try:\n",
    "                    new_study_response = requests.post(\n",
    "                        url=f\"{url}/api/dataset/v3\",\n",
    "                        headers={\"Authorization\": f\"Bearer {token}\"},\n",
    "                        files = {\n",
    "                            \"dataset\": json.dumps(upload_dict[study]),\n",
    "                            \"alternativeDataSharingPlan\": \"\",\n",
    "                            \"consentGroups[0].nihInstitutionalCertificationFile\": \"\"  \n",
    "                        }\n",
    "                    ).json()\n",
    "                    if new_study_response.get(\"studyId\"):\n",
    "                        study_id = new_study_response[\"studyId\"]\n",
    "                        msg = f\"Study registration succeeded! Study Id: {study_id}\"\n",
    "                        results_log.append([f\"New Study Registration - {study}\", \"Succeeded\", msg])\n",
    "                        print(msg)\n",
    "                    else:\n",
    "                        err_msg = new_study_response[\"message\"]\n",
    "                        msg = f\"Study registration failed: {err_msg}\"\n",
    "                        results_log.append([f\"New Study Registration - {study}\", \"Failed\", msg])\n",
    "                        print(msg)\n",
    "                except Exception as e:\n",
    "                    msg = f\"Study registration failed: {str(e)}\"\n",
    "                    results_log.append([f\"New Study Registration - {study}\", \"Failed\", msg])\n",
    "                    print(msg)\n",
    "\n",
    "            # For studies that already exist in DUOS, update the existing study\n",
    "            else:\n",
    "                print(\"Study currently exists in DUOS. Updating study and dataset records...\")\n",
    "                # Identify existing datasets for that are not present in the upload dict\n",
    "                study_id = study_lookup.get(study)\n",
    "                study_details = requests.get(\n",
    "                        url=f\"{url}/api/dataset/study/{study_id}\",\n",
    "                        headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "                    ).json()\n",
    "                study_datasets_in_duos = set(study_details.get(\"datasetIds\"))\n",
    "                study_datasets_in_input = set()\n",
    "                for datasets in upload_dict[study][\"consentGroups\"]:\n",
    "                    if datasets.get(\"datasetId\"):\n",
    "                        study_datasets_in_input.add(datasets.get(\"datasetId\"))\n",
    "                study_datasets_diff = study_datasets_in_duos.difference(study_datasets_in_input)\n",
    "                # Add missing datasets to the upload dict\n",
    "                temp_cg = upload_dict[study][\"consentGroups\"].copy()\n",
    "                for missing_dataset_id in study_datasets_diff:\n",
    "                    dataset_details = requests.get(\n",
    "                        url=f\"{url}/api/dataset/v2/{missing_dataset_id}\",\n",
    "                        headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "                    ).json()\n",
    "                    name = dataset_details[\"name\"]\n",
    "                    data_loc = \"\"\n",
    "                    data_loc_url = \"\"\n",
    "                    num_participants = 0\n",
    "                    for prop_entry in dataset_details[\"properties\"]:\n",
    "                        if prop_entry[\"propertyName\"] == \"Data Location\":\n",
    "                            data_loc = prop_entry[\"propertyValue\"]\n",
    "    #                     elif prop_entry[\"propertyName\"] == \"URL\":  # Nulling out URLs for snapshots not in the release set\n",
    "    #                         data_loc_url = prop_entry[\"propertyValue\"]\n",
    "                        elif prop_entry[\"propertyName\"] == \"# of participants\":\n",
    "                            num_participants = prop_entry[\"propertyValue\"]\n",
    "                    consent_group_dict = {\n",
    "                        \"consentGroupName\": dataset_details[\"name\"],\n",
    "                        \"datasetId\": missing_dataset_id,\n",
    "                        \"numberOfParticipants\": num_participants,\n",
    "                        \"dataLocation\": data_loc,\n",
    "                        \"url\": data_loc_url,\n",
    "                        \"fileTypes\": []\n",
    "                    }\n",
    "                    temp_cg.append(consent_group_dict)\n",
    "                upload_dict[study][\"consentGroups\"] = temp_cg\n",
    "                try:\n",
    "                    # Update study in DUOS\n",
    "                    update_study_response = requests.put(\n",
    "                        url=f\"{url}/api/dataset/study/{study_id}\",\n",
    "                        headers={\"Authorization\": f\"Bearer {token}\"},\n",
    "                        files = {\n",
    "                            \"dataset\": json.dumps(upload_dict[study]),\n",
    "                            \"alternativeDataSharingPlan\": \"\",\n",
    "                            \"consentGroups[0].nihInstitutionalCertificationFile\": \"\"  \n",
    "                        }\n",
    "                    ).json()   \n",
    "                    if update_study_response.get(\"studyId\"):\n",
    "                        study_id = update_study_response[\"studyId\"]\n",
    "                        msg = f\"Study registration succeeded! Study Id: {study_id}\"\n",
    "                        results_log.append([f\"New Study Registration - {study}\", \"Succeeded\", msg])\n",
    "                        print(msg)\n",
    "                    else:\n",
    "                        err_msg = update_study_response[\"message\"]\n",
    "                        msg = f\"Study registration failed: {err_msg}\"\n",
    "                        results_log.append([f\"New Study Registration - {study}\", \"Failed\", msg])\n",
    "                        print(msg)\n",
    "                except Exception as e:\n",
    "                    msg = f\"Study registration failed: {str(e)}\"\n",
    "                    results_log.append([f\"Study Registration Update - {study}\", \"Failed\", msg])\n",
    "                    print(msg)\n",
    "    \n",
    "    # Return results\n",
    "    return results_log\n",
    "\n",
    "\n",
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# Cloud path to file to process\n",
    "input_file_gcs_path = \"gs://fc-2a9eefc3-0302-427f-9ac3-82f078741c03/dataset_metadata/anvil_dataset_metadata_20240724.tsv\"\n",
    "\n",
    "# User token (use gcloud auth print-access-token to get this)\n",
    "token = \"\"\n",
    "\n",
    "# Environment\n",
    "env = \"dev\"\n",
    "\n",
    "# Target DAC identifier\n",
    "dac_id = 3\n",
    "\n",
    "# Study Upload List (to limit the studies upload, leave empty for all)\n",
    "study_upload_list = []\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "\n",
    "upload_results = upload_to_duos(input_file_gcs_path, token, env, dac_id, study_upload_list)\n",
    "df_results = pd.DataFrame(upload_results, columns = [\"Item\", \"Status\", \"Message\"])\n",
    "print(\"\\nUpload Results:\")\n",
    "display(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Through Code (Testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     15,
     34
    ]
   },
   "outputs": [],
   "source": [
    "# INPUTS\n",
    "#input_file_gcs_path = \"gs://fc-2a9eefc3-0302-427f-9ac3-82f078741c03/dataset_metadata/test/initial_metadata_ingest.txt\"\n",
    "#input_file_gcs_path = \"gs://fc-2a9eefc3-0302-427f-9ac3-82f078741c03/dataset_metadata/test/updated_metadata_ingest.txt\"\n",
    "#input_file_gcs_path = \"gs://fc-2a9eefc3-0302-427f-9ac3-82f078741c03/dataset_metadata/test/updated_metadata_ingest_2.txt\"\n",
    "#input_file_gcs_path = \"gs://fc-2a9eefc3-0302-427f-9ac3-82f078741c03/dataset_metadata/test/updated_metadata_ingest_3.txt\"\n",
    "input_file_gcs_path = \"gs://fc-2a9eefc3-0302-427f-9ac3-82f078741c03/dataset_metadata/anvil_dataset_metadata_20240724.tsv\"\n",
    "token = \"\"\n",
    "env = \"dev\"\n",
    "dac_id = 3\n",
    "\n",
    "# Determine the target URL from the env variable\n",
    "if env == \"prod\":\n",
    "    url = \"https://consent.dsde-prod.broadinstitute.org\"\n",
    "else:\n",
    "    url = \"https://consent.dsde-dev.broadinstitute.org\"\n",
    "    \n",
    "# Create results log\n",
    "results_log = []\n",
    "\n",
    "# FUNCTIONS\n",
    "def format_list(input_list, min_items):\n",
    "    if input_list:\n",
    "        if isinstance(input_list, list):\n",
    "            return input_list\n",
    "        elif isinstance(input_list, str):\n",
    "            return format_list(ast.literal_eval(input_list), min_items)\n",
    "        else:\n",
    "            return []\n",
    "    else:\n",
    "        if min_items > 0:\n",
    "            i = 0\n",
    "            temp_list = []\n",
    "            while i < min_items:\n",
    "                temp_list.append(\"Unknown\")\n",
    "                i += 1\n",
    "            return temp_list\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "def format_file_types(ft_list, fe):\n",
    "    if ft_list:\n",
    "        output_list = []\n",
    "        formatted_ft_list = format_list(ft_list, 0)\n",
    "        for ft in formatted_ft_list:\n",
    "            ft_dict = {\"fileType\": ft}\n",
    "            if fe:\n",
    "                ft_dict[\"functionalEquivalence\"] = fe\n",
    "            else:\n",
    "                ft_dict[\"functionalEquivalence\"] = \"Unknown\"\n",
    "            output_list.append(ft_dict)\n",
    "        return output_list\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Read in input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pull down specified file from the cloud\n",
    "print(f\"Downloading input file {input_file_gcs_path}...\")\n",
    "try:\n",
    "    input_df = pd.read_csv(input_file_gcs_path, delimiter = \"\\t\", encoding='unicode_escape')\n",
    "    input_df = input_df.astype(object).where(pd.notnull(input_df),None)\n",
    "    input_df.fillna(\"\",inplace=True)\n",
    "    input_dict = input_df.to_dict(orient=\"records\")\n",
    "    results_log.append([\"Input File Download\", \"Succeeded\", \"\"])\n",
    "except Exception as e:\n",
    "    msg = f\"Error downloading input file ({input_file_gcs_path}): {str(e)}\"\n",
    "    results_log.append([\"Input File Download\", \"Failed\", msg])\n",
    "    print(msg)\n",
    "    #return results_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "study_name_set = set()\n",
    "for entry in input_dict:\n",
    "    study_name_set.add(entry[\"studyName\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "study_name_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in existing DUOS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull a list of existing datasets and studies from DUOS and build lookup dicts\n",
    "print(\"Building study and dataset lookup dicts from DUOS...\")\n",
    "try:\n",
    "    datasets = requests.get(\n",
    "        url=f\"{url}/api/dataset/v2?asCustodian=false\",\n",
    "        headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "    ).json()\n",
    "    study_lookup = {}\n",
    "    full_dataset_lookup = {}\n",
    "    dataset_lookup = {}\n",
    "    for dataset_entry in datasets:\n",
    "        base_name = \"\"\n",
    "        dataset_name = \"\"\n",
    "        dataset_id = dataset_entry.get(\"dataSetId\")\n",
    "        study_name = \"\"\n",
    "        study_id = None\n",
    "        if dataset_entry.get(\"name\"):\n",
    "            try:\n",
    "                base_name =  dataset_entry.get(\"name\")\n",
    "                dataset_name = re.search(r'(.*)_[0-9]{8}_ANV[0-9]+_[0-9]{12}$', base_name).group(1)\n",
    "            except:\n",
    "                base_name =  dataset_entry.get(\"name\")\n",
    "                dataset_name = dataset_entry.get(\"name\")\n",
    "        anvil_dataset = False\n",
    "        if dataset_entry.get(\"study\"):\n",
    "            if dataset_entry[\"study\"].get(\"name\"):\n",
    "                study_name = dataset_entry[\"study\"].get(\"name\")\n",
    "                study_id = dataset_entry[\"study\"].get(\"studyId\")\n",
    "            if dataset_entry[\"study\"].get(\"description\"):\n",
    "                if \"Platform: AnVIL\" in dataset_entry[\"study\"].get(\"description\"):\n",
    "                    anvil_dataset = True\n",
    "        if study_name and study_name not in study_lookup.keys():\n",
    "            study_lookup[study_name] = study_id\n",
    "        if dataset_name:\n",
    "            full_dataset_lookup[dataset_name] = {\n",
    "                \"id\": dataset_id,\n",
    "                \"duos_identifier\": dataset_entry.get(\"datasetIdentifier\"),\n",
    "                \"name\": base_name,\n",
    "                \"create_date\": dataset_entry.get(\"createDate\"),\n",
    "                \"study_name\": study_name,\n",
    "                \"study_id\": study_id,\n",
    "                \"anvil_dataset\": anvil_dataset,\n",
    "                \"data_use\": dataset_entry.get(\"dataUse\")\n",
    "            }\n",
    "    for key, val in full_dataset_lookup.items():\n",
    "        if val[\"anvil_dataset\"] == True:\n",
    "            dataset_lookup[key] = val\n",
    "    results_log.append([\"DUOS Study and Dataset Lookup Dict Creation\", \"Succeeded\", \"\"])\n",
    "except Exception as e:\n",
    "    msg = f\"Error building study and dataset lookups: {str(e)}\"\n",
    "    results_log.append([\"DUOS Study and Dataset Lookup Dict Creation\", \"Failed\", msg])\n",
    "    print(msg)\n",
    "    #return results_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_lookup[\"ANVIL_GTEx_V8_hg38\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Build input data for DUOS from input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parse and build DUOS schema for inputted file\n",
    "print(\"Parsing input file and formatting into DUOS schema...\")\n",
    "try:\n",
    "    # Determine data submitter id\n",
    "    response = requests.get(\n",
    "        url=f\"{url}/api/user/me\",\n",
    "        headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "    ).json()\n",
    "    data_submitter_id = response[\"userId\"]\n",
    "    # Build dictionary for upload\n",
    "    upload_dict = {}\n",
    "    consent_mismatch_list = []\n",
    "    existing_dataset_cnt = 0\n",
    "    new_dataset_cnt = 0\n",
    "    for input_entry in input_dict:\n",
    "        snapshot_id = input_entry[\"snapshot_id\"]\n",
    "        study_name = input_entry[\"studyName\"]\n",
    "        try:\n",
    "            base_name = input_entry[\"consentGroups.consentGroupName\"]\n",
    "            consent_group_name = re.search(r'(.*)_[0-9]{8}_ANV[0-9]+_[0-9]{12}$', base_name).group(1)\n",
    "        except:\n",
    "            consent_group_name = input_entry[\"consentGroups.consentGroupName\"]\n",
    "        access_type = input_entry[\"consentGroups.accessManagement\"]\n",
    "        study_id = study_lookup.get(study_name)\n",
    "        dataset = dataset_lookup.get(consent_group_name)\n",
    "        dataset_id = \"\"\n",
    "        dataset_id_str = \"\"\n",
    "        if dataset:\n",
    "            dataset_id_from_dataset = dataset[\"id\"]\n",
    "            study_id_from_dataset = dataset[\"study_id\"]\n",
    "            gru_from_dataset = dataset[\"data_use\"].get(\"generalUse\")\n",
    "            gru_from_input = input_entry[\"consentGroups.generalResearchUse\"]\n",
    "            hmb_from_dataset = dataset[\"data_use\"].get(\"hmbResearch\")\n",
    "            hmb_from_input = input_entry[\"consentGroups.hmb\"]\n",
    "            ds_from_dataset = dataset[\"data_use\"].get(\"diseaseRestrictions\")\n",
    "            ds_from_input = format_list(input_entry[\"consentGroups.diseaseSpecificUse\"], 0)\n",
    "            if study_id_from_dataset == study_id:\n",
    "                dataset_id = dataset_id_from_dataset\n",
    "                dataset_id_str = f\" ({dataset_id})\"\n",
    "            else:\n",
    "                dataset_id = None   \n",
    "            print(f\"Parsing and formatting metadata for snapshot {snapshot_id} from the input file. Target study is: {study_name}. Target consent group is: {consent_group_name}{dataset_id_str}\")\n",
    "            if input_entry[\"consentGroups.accessManagement\"] == \"controlled\" and (gru_from_dataset != gru_from_input or hmb_from_dataset != hmb_from_input or ds_from_dataset != ds_from_input):\n",
    "                print(\"\\tERROR: Mismatching consent information in existing DUOS record vs. proposed new record. Update the consent in the new record to match OR update the consent group name in the new record to create a new DUOS record.\")\n",
    "                consent_mismatch_list.append(snapshot_id)\n",
    "        else:\n",
    "            print(f\"Parsing and formatting metadata for snapshot {snapshot_id} from the input file. Target study is: {study_name}. Target consent group is: {consent_group_name}\")\n",
    "        # If this is an existing dataset in the specified existing study, provide limited consent group information (for updates only)\n",
    "        if study_id and dataset_id:\n",
    "            existing_dataset_cnt += 1\n",
    "            consent_group_dict = {\n",
    "                        \"consentGroupName\": consent_group_name,\n",
    "                        \"datasetId\": dataset_id,\n",
    "                        \"numberOfParticipants\": input_entry[\"consentGroups.numberOfParticipants\"],\n",
    "                        \"dataLocation\": input_entry[\"consentGroups.dataLocation\"],\n",
    "                        \"url\": input_entry[\"consentGroups.url\"],\n",
    "                        \"fileTypes\": []\n",
    "                        #\"fileTypes\": format_file_types(input_entry[\"consentGroups.fileTypes.fileType\"], input_entry[\"consentGroups.fileTypes.functionalEquivalence\"]) --> Enumeration, exclude for now\n",
    "                }\n",
    "        # If this is a new dataset that is open access, provide limited consent group information\n",
    "        elif access_type == \"open\":\n",
    "            new_dataset_cnt += 1\n",
    "            consent_group_dict = {\n",
    "                        \"consentGroupName\": consent_group_name,\n",
    "                        \"accessManagement\": access_type,\n",
    "                        \"numberOfParticipants\": input_entry[\"consentGroups.numberOfParticipants\"],\n",
    "                        \"dataLocation\": input_entry[\"consentGroups.dataLocation\"],\n",
    "                        \"url\": input_entry[\"consentGroups.url\"],\n",
    "                        \"fileTypes\": []\n",
    "                        #\"fileTypes\": format_file_types(input_entry[\"consentGroups.fileTypes.fileType\"], input_entry[\"consentGroups.fileTypes.functionalEquivalence\"]) --> Enumeration, exclude for now\n",
    "                }\n",
    "        # If this is a new dataset that is NOT open access, provide the full consent group information\n",
    "        else:\n",
    "            new_dataset_cnt += 1\n",
    "            consent_group_dict = {\n",
    "                        \"consentGroupName\": consent_group_name,\n",
    "                        \"dataAccessCommitteeId\": dac_id,\n",
    "                        \"accessManagement\": access_type,\n",
    "                        \"numberOfParticipants\": input_entry[\"consentGroups.numberOfParticipants\"],\n",
    "                        \"generalResearchUse\": input_entry[\"consentGroups.generalResearchUse\"],\n",
    "                        \"hmb\": input_entry[\"consentGroups.hmb\"],\n",
    "                        \"diseaseSpecificUse\": format_list(input_entry[\"consentGroups.diseaseSpecificUse\"], 0),\n",
    "                        \"gs\": input_entry[\"consentGroups.gs\"],\n",
    "                        \"poa\": input_entry[\"consentGroups.poa\"],\n",
    "                        \"nmds\": input_entry[\"consentGroups.nmds\"],\n",
    "                        \"gso\": input_entry[\"consentGroups.gso\"],\n",
    "                        \"pub\": input_entry[\"consentGroups.pub\"],\n",
    "                        \"col\": input_entry[\"consentGroups.col\"],\n",
    "                        \"irb\": input_entry[\"consentGroups.irb\"],\n",
    "                        \"npu\": input_entry[\"consentGroups.npu\"],\n",
    "                        \"otherPrimary\": input_entry[\"consentGroups.otherPrimary\"],\n",
    "                        #\"otherSecondary\": input_entry[\"consentGroups.otherSecondary\"], --> Excluding for now, per JL's request\n",
    "                        #\"mor\": input_entry[\"consentGroups.mor\"], --> Date formatting validation for morDate, exclude for now\n",
    "                        #\"morDate\": input_entry[\"consentGroups.morDate\"], --> Date formatting validation, exclude for now\n",
    "                        \"dataLocation\": input_entry[\"consentGroups.dataLocation\"],\n",
    "                        \"url\": input_entry[\"consentGroups.url\"],\n",
    "                        \"fileTypes\": []\n",
    "                        #\"fileTypes\": format_file_types(input_entry[\"consentGroups.fileTypes.fileType\"], input_entry[\"consentGroups.fileTypes.functionalEquivalence\"]) --> Enumeration, exclude for now\n",
    "                }\n",
    "        study_dict = {}\n",
    "        consent_group_list = []\n",
    "        # If the study associated with the record is not already in the upload dictionary, create a new study dict and append the consent group dict\n",
    "        if study_name not in upload_dict.keys():\n",
    "            consent_group_list.append(consent_group_dict)\n",
    "            study_dict = {\n",
    "                \"studyName\": study_name,\n",
    "                #\"studyType\": input_entry[\"studyType\"], --> Enumeration, exclude for now\n",
    "                \"studyDescription\": input_entry[\"studyDescription\"],\n",
    "                \"dataTypes\": format_list(input_entry[\"dataTypes\"], 1),\n",
    "                \"phenotypeIndication\": input_entry[\"phenotypeIndication\"],\n",
    "                \"species\": input_entry[\"species\"],\n",
    "                \"piName\": input_entry[\"piName\"] if input_entry[\"piName\"] else \"NA\",\n",
    "                \"dataSubmitterUserId\": data_submitter_id,\n",
    "                \"dataCustodianEmail\": format_list(input_entry[\"dataCustodianEmail\"], 0),\n",
    "                \"publicVisibility\": input_entry[\"publicVisibility\"],\n",
    "                \"nihAnvilUse\": input_entry[\"nihAnvilUse\"],\n",
    "                \"submittingToAnvil\": input_entry[\"submittingToAnvil\"],\n",
    "                \"dbGaPPhsID\": input_entry[\"dbGaPPhsID\"],\n",
    "                \"dbGaPStudyRegistrationName\": input_entry[\"studyName\"],\n",
    "                #\"embargoReleaseDate\": input_entry[\"embargoReleaseDate\"], --> Date formatting validation, exclude for now\n",
    "                \"sequencingCenter\": input_entry[\"sequencingCenter\"],\n",
    "                \"piEmail\": input_entry[\"piEmail\"],\n",
    "                #\"piInstitution\": input_entry[\"piInstitution\"], --> Integer ID for registered institutions, exclude for now\n",
    "                \"piInstitution\": 0,\n",
    "                \"nihGrantContractNumber\": \"Unknown\", # Required currently\n",
    "                \"nihICsSupportingStudy\": format_list(input_entry[\"nihICsSupportingStudy\"], 0),\n",
    "                \"nihProgramOfficerName\": input_entry[\"nihProgramOfficerName\"],\n",
    "                \"nihInstitutionCenterSubmission\": input_entry[\"nihInstitutionCenterSubmission\"],\n",
    "                \"nihInstitutionalCertificationFileName\": input_entry[\"nihInstitutionalCertificationFileName\"],\n",
    "                \"nihGenomicProgramAdministratorName\": input_entry[\"nihGenomicProgramAdministratorName\"],\n",
    "                \"collaboratingSites\": format_list(input_entry[\"collaboratingSites\"], 0),\n",
    "                \"alternativeDataSharingPlan\": input_entry[\"alternativeDataSharingPlan\"],\n",
    "                \"alternativeDataSharingPlanExplanation\": input_entry[\"alternativeDataSharingPlanExplanation\"],\n",
    "                \"alternativeDataSharingPlanReasons\": [\"Other\"] if input_entry[\"alternativeDataSharingPlan\"] == True and input_entry[\"alternativeDataSharingPlanReasons\"] == \"[]\" else format_list(input_entry[\"alternativeDataSharingPlanReasons\"], 0), \n",
    "                \"consentGroups\": consent_group_list\n",
    "            }\n",
    "            upload_dict[study_name] = study_dict\n",
    "        # If the study is already in the upload dictionary, create an updated study dict and extend its list of consent groups\n",
    "        else:\n",
    "            for consent_group in upload_dict[study_name][\"consentGroups\"]:\n",
    "                if consent_group[\"consentGroupName\"] != consent_group_dict[\"consentGroupName\"]:\n",
    "                    consent_group_list.append(consent_group)\n",
    "            consent_group_list.append(consent_group_dict)\n",
    "            study_dict = {\n",
    "                \"studyName\": study_name,\n",
    "                #\"studyType\": upload_dict[study_name][\"studyType\"], --> Enumeration, exclude for now\n",
    "                \"studyDescription\": upload_dict[study_name][\"studyDescription\"],\n",
    "                \"dataTypes\": upload_dict[study_name][\"dataTypes\"],\n",
    "                \"phenotypeIndication\": upload_dict[study_name][\"phenotypeIndication\"],\n",
    "                \"species\": upload_dict[study_name][\"species\"],\n",
    "                \"piName\": upload_dict[study_name][\"piName\"] if upload_dict[study_name][\"piName\"] else \"NA\",\n",
    "                \"dataSubmitterUserId\": upload_dict[study_name][\"dataSubmitterUserId\"],\n",
    "                \"dataCustodianEmail\": upload_dict[study_name][\"dataCustodianEmail\"],\n",
    "                \"publicVisibility\": upload_dict[study_name][\"publicVisibility\"],\n",
    "                \"nihAnvilUse\": upload_dict[study_name][\"nihAnvilUse\"],\n",
    "                \"submittingToAnvil\": upload_dict[study_name][\"submittingToAnvil\"],\n",
    "                \"dbGaPPhsID\": upload_dict[study_name][\"dbGaPPhsID\"],\n",
    "                \"dbGaPStudyRegistrationName\": upload_dict[study_name][\"studyName\"],\n",
    "                #\"embargoReleaseDate\": upload_dict[study_name][\"embargoReleaseDate\"], --> Date formatting validation, exclude for now\n",
    "                \"sequencingCenter\": upload_dict[study_name][\"sequencingCenter\"],\n",
    "                \"piEmail\": upload_dict[study_name][\"piEmail\"],\n",
    "                #\"piInstitution\": upload_dict[study_name][\"piInstitution\"], --> Integer ID for registered institutions, exclude for now\n",
    "                \"piInstitution\": upload_dict[study_name][\"piInstitution\"],\n",
    "                \"nihGrantContractNumber\": upload_dict[study_name][\"nihGrantContractNumber\"],\n",
    "                \"nihICsSupportingStudy\": upload_dict[study_name][\"nihICsSupportingStudy\"],\n",
    "                \"nihProgramOfficerName\": upload_dict[study_name][\"nihProgramOfficerName\"],\n",
    "                \"nihInstitutionCenterSubmission\": upload_dict[study_name][\"nihInstitutionCenterSubmission\"],\n",
    "                \"nihInstitutionalCertificationFileName\": upload_dict[study_name][\"nihInstitutionalCertificationFileName\"],\n",
    "                \"nihGenomicProgramAdministratorName\": upload_dict[study_name][\"nihGenomicProgramAdministratorName\"],\n",
    "                \"collaboratingSites\": upload_dict[study_name][\"collaboratingSites\"],\n",
    "                \"alternativeDataSharingPlan\": upload_dict[study_name][\"alternativeDataSharingPlan\"],\n",
    "                \"alternativeDataSharingPlanExplanation\": upload_dict[study_name][\"alternativeDataSharingPlanExplanation\"],\n",
    "                \"alternativeDataSharingPlanReasons\": upload_dict[study_name][\"alternativeDataSharingPlanReasons\"],\n",
    "                \"consentGroups\": consent_group_list\n",
    "            }\n",
    "            upload_dict[study_name] = study_dict\n",
    "    if consent_mismatch_list:\n",
    "        consent_mismatch_str = \", \".join(consent_mismatch_list)\n",
    "        results_log.append([\"Input File Formatting\", \"Failed\", f\"Snapshots with mismatched consent with existing DUOS datasets: {consent_mismatch_str}\"])\n",
    "    else:\n",
    "        msg = f\"Input file formatting complete. Existing Datasets: {existing_dataset_cnt} New Datasets: {new_dataset_cnt}\"\n",
    "        print(msg)\n",
    "        results_log.append([\"Input File Formatting\", \"Succeeded\", msg])\n",
    "except Exception as e:\n",
    "    msg = f\"Error parsing and formatting input file: {str(e)}\"\n",
    "    results_log.append([\"Input File Formatting\", \"Failed\", msg])\n",
    "    print(msg)\n",
    "    #return results_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "upload_dict[\"Genotype-Tissue Expression (GTEx) (phs000424)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload to DUOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_upload_list = [\n",
    "]\n",
    "\n",
    "# Loop through studies and dataset to upload\n",
    "for study in upload_dict.keys():\n",
    "    if study in study_upload_list or len(study_upload_list) == 0:\n",
    "        print(f\"Uploading data for study {study} into DUOS\")\n",
    "        # For studies that don't exist in DUOS, create a new study\n",
    "        if not study_lookup.get(study):\n",
    "            print(\"Study does NOT currently exist in DUOS. Creating new study and dataset records...\")\n",
    "            try:\n",
    "                new_study_response = requests.post(\n",
    "                    url=f\"{url}/api/dataset/v3\",\n",
    "                    headers={\"Authorization\": f\"Bearer {token}\"},\n",
    "                    files = {\n",
    "                        \"dataset\": json.dumps(upload_dict[study]),\n",
    "                        \"alternativeDataSharingPlan\": \"\",\n",
    "                        \"consentGroups[0].nihInstitutionalCertificationFile\": \"\"  \n",
    "                    }\n",
    "                ).json()\n",
    "                if new_study_response.get(\"studyId\"):\n",
    "                    study_id = new_study_response[\"studyId\"]\n",
    "                    msg = f\"Study registration succeeded! Study Id: {study_id}\"\n",
    "                    results_log.append([f\"New Study Registration - {study}\", \"Succeeded\", msg])\n",
    "                    print(msg)\n",
    "                else:\n",
    "                    err_msg = new_study_response[\"message\"]\n",
    "                    msg = f\"Study registration failed: {err_msg}\"\n",
    "                    results_log.append([f\"New Study Registration - {study}\", \"Failed\", msg])\n",
    "                    print(msg)\n",
    "            except Exception as e:\n",
    "                msg = f\"Study registration failed: {str(e)}\"\n",
    "                results_log.append([f\"New Study Registration - {study}\", \"Failed\", msg])\n",
    "                print(msg)\n",
    "\n",
    "        # For studies that already exist in DUOS, update the existing study\n",
    "        else:\n",
    "            print(\"Study currently exists in DUOS. Updating study and dataset records...\")\n",
    "            # Identify existing datasets for that are not present in the upload dict\n",
    "            study_id = study_lookup.get(study)\n",
    "            study_details = requests.get(\n",
    "                    url=f\"{url}/api/dataset/study/{study_id}\",\n",
    "                    headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "                ).json()\n",
    "            study_datasets_in_duos = set(study_details.get(\"datasetIds\"))\n",
    "            study_datasets_in_input = set()\n",
    "            for datasets in upload_dict[study][\"consentGroups\"]:\n",
    "                if datasets.get(\"datasetId\"):\n",
    "                    study_datasets_in_input.add(datasets.get(\"datasetId\"))\n",
    "            study_datasets_diff = study_datasets_in_duos.difference(study_datasets_in_input)\n",
    "            # Add missing datasets to the upload dict\n",
    "            temp_cg = upload_dict[study][\"consentGroups\"].copy()\n",
    "            for missing_dataset_id in study_datasets_diff:\n",
    "                dataset_details = requests.get(\n",
    "                    url=f\"{url}/api/dataset/v2/{missing_dataset_id}\",\n",
    "                    headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "                ).json()\n",
    "                name = dataset_details[\"name\"]\n",
    "                data_loc = \"\"\n",
    "                data_loc_url = \"\"\n",
    "                num_participants = 0\n",
    "                for prop_entry in dataset_details[\"properties\"]:\n",
    "                    if prop_entry[\"propertyName\"] == \"Data Location\":\n",
    "                        data_loc = prop_entry[\"propertyValue\"]\n",
    "#                     elif prop_entry[\"propertyName\"] == \"URL\":  # Nulling out URLs for snapshots not in the release set\n",
    "#                         data_loc_url = prop_entry[\"propertyValue\"]\n",
    "                    elif prop_entry[\"propertyName\"] == \"# of participants\":\n",
    "                        num_participants = prop_entry[\"propertyValue\"]\n",
    "                consent_group_dict = {\n",
    "                    \"consentGroupName\": dataset_details[\"name\"],\n",
    "                    \"datasetId\": missing_dataset_id,\n",
    "                    \"numberOfParticipants\": num_participants,\n",
    "                    \"dataLocation\": data_loc,\n",
    "                    \"url\": data_loc_url,\n",
    "                    \"fileTypes\": []\n",
    "                }\n",
    "                temp_cg.append(consent_group_dict)\n",
    "            upload_dict[study][\"consentGroups\"] = temp_cg\n",
    "            try:\n",
    "                # Update study in DUOS\n",
    "                update_study_response = requests.put(\n",
    "                    url=f\"{url}/api/dataset/study/{study_id}\",\n",
    "                    headers={\"Authorization\": f\"Bearer {token}\"},\n",
    "                    files = {\n",
    "                        \"dataset\": json.dumps(upload_dict[study]),\n",
    "                        \"alternativeDataSharingPlan\": \"\",\n",
    "                        \"consentGroups[0].nihInstitutionalCertificationFile\": \"\"  \n",
    "                    }\n",
    "                ).json()   \n",
    "                if update_study_response.get(\"studyId\"):\n",
    "                    study_id = update_study_response[\"studyId\"]\n",
    "                    msg = f\"Study registration succeeded! Study Id: {study_id}\"\n",
    "                    results_log.append([f\"New Study Registration - {study}\", \"Succeeded\", msg])\n",
    "                    print(msg)\n",
    "                else:\n",
    "                    err_msg = update_study_response[\"message\"]\n",
    "                    msg = f\"Study registration failed: {err_msg}\"\n",
    "                    results_log.append([f\"New Study Registration - {study}\", \"Failed\", msg])\n",
    "                    print(msg)\n",
    "            except Exception as e:\n",
    "                msg = f\"Study registration failed: {str(e)}\"\n",
    "                results_log.append([f\"Study Registration Update - {study}\", \"Failed\", msg])\n",
    "                print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_study_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Verify the output in DUOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pull a existing dataset from DUOS and analyze\n",
    "datasets = requests.get(\n",
    "    url=f\"{url}/api/dataset/v2?asCustodian=false\",\n",
    "    headers={\"Authorization\": f\"Bearer {token}\"}\n",
    ").json()\n",
    "for dataset_entry in datasets:\n",
    "    dataset_name = dataset_entry.get(\"datasetName\")\n",
    "    study_name = \"\"\n",
    "    tdr_url = \"\"\n",
    "    if dataset_name and \"ANVIL_DSU\" in dataset_name and \"V2\" in dataset_name:\n",
    "        if dataset_entry.get(\"study\") and dataset_entry[\"study\"].get(\"name\"):\n",
    "            study_name = dataset_entry[\"study\"].get(\"name\") \n",
    "        properties = dataset_entry.get(\"properties\")\n",
    "        if properties:\n",
    "            for prop_entry in properties:\n",
    "                if prop_entry[\"propertyName\"] == \"URL\":\n",
    "                    tdr_url = prop_entry[\"propertyValue\"]\n",
    "        print(f\"Study Name: {study_name}\")\n",
    "        print(f\"Consent Group Name: {dataset_name}\")\n",
    "        print(f\"TDR URL: {tdr_url}\")\n",
    "        print(\"----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Step 3: Attach DUOS IDs to Snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Add DUOS IDs Based on Snapshot Listed in DUOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4,
     135
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Functions\n",
    "#############################################\n",
    "\n",
    "def link_duos_ids_to_snapshots(snapshot_id_list, env, token):\n",
    "    results_log = []\n",
    "\n",
    "    # Determine the target URL from the env variable\n",
    "    if env == \"prod\":\n",
    "        url = \"https://consent.dsde-prod.broadinstitute.org\"\n",
    "    else:\n",
    "        url = \"https://consent.dsde-dev.broadinstitute.org\"\n",
    "\n",
    "    # Pull a list of existing datasets and studies from DUOS and build lookup dicts\n",
    "    print(\"Building lookup between Snapshot and DUOS ID...\")\n",
    "    try:\n",
    "        datasets = requests.get(\n",
    "            url=f\"{url}/api/dataset/v2?asCustodian=false\",\n",
    "            headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "        ).json()\n",
    "        snapshot_lookup = {}\n",
    "        for dataset_entry in datasets:\n",
    "            try:\n",
    "                url = \"\"\n",
    "                snapshot = False\n",
    "                for prop_entry in dataset_entry[\"properties\"]:\n",
    "                    if prop_entry[\"propertyName\"] == \"URL\":\n",
    "                        url = prop_entry[\"propertyValue\"]\n",
    "                    elif prop_entry[\"propertyName\"] == \"Data Location\" and prop_entry[\"propertyValue\"] == \"TDR Location\":\n",
    "                        snapshot = True\n",
    "                if snapshot == True:\n",
    "                    snapshot_id = re.search(\"([a-z0-9]{8}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{12})\", url, re.IGNORECASE).group(1)\n",
    "                    duos_id = dataset_entry[\"datasetIdentifier\"]\n",
    "                    snapshot_lookup[snapshot_id] = duos_id\n",
    "            except:\n",
    "                pass\n",
    "        results_log.append([\"Snapshot Lookup Creation\", \"Success\", \"\"])\n",
    "    except Exception as e:\n",
    "        msg = f\"Error building lookup between Snapshot and DUOS ID: {str(e)}\"\n",
    "        results_log.append([\"Snapshot Lookup Creation\", \"Failed\", msg])\n",
    "        print(msg)\n",
    "        return results_log\n",
    "\n",
    "    # Loop through input snapshots and link DUOS IDs to them\n",
    "    print(\"Linking DUOS IDs to Snapshots...\")\n",
    "    creds, project = google.auth.default()\n",
    "    auth_req = google.auth.transport.requests.Request()\n",
    "    creds.refresh(auth_req)\n",
    "    api_client = refresh_tdr_api_client()\n",
    "    snapshots_api = data_repo_client.SnapshotsApi(api_client=api_client)\n",
    "    duos_api = data_repo_client.DuosApi(api_client=api_client)\n",
    "    for snapshot_id in snapshot_id_list:\n",
    "        print(f\"\\tProcessing snapshot ID = {snapshot_id}\")\n",
    "        duos_id = snapshot_lookup.get(snapshot_id)\n",
    "        if duos_id:\n",
    "            # Link the DUOS ID to the snapshot\n",
    "            print(f\"\\t\\t- Linking DUOS ID {duos_id} to snapshot.\")\n",
    "            attempt_counter = 0\n",
    "            while attempt_counter <= 2:\n",
    "                try:\n",
    "                    response = snapshots_api.link_duos_dataset_to_snapshot(id=snapshot_id, duos_id=duos_id).to_dict()\n",
    "                    if response.get(\"linked\"):\n",
    "                        results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id} - {duos_id})\", \"Success\", \"\"])\n",
    "                        break\n",
    "                    elif response.get(\"message\"):\n",
    "                        response_message = response.get(\"message\")\n",
    "                        msg = f\"Error linking DUOS ID to Snapshot: {response_message}\"\n",
    "                        if attempt_counter >= 2:\n",
    "                            results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id} - {duos_id})\", \"Failed\", msg])\n",
    "                            break\n",
    "                except Exception as e:\n",
    "                    msg = f\"Error linking DUOS ID to Snapshot: {str(e)}\"\n",
    "                    if attempt_counter >= 2:\n",
    "                        results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id} - {duos_id})\", \"Failed\", msg])\n",
    "                    sleep(5)\n",
    "                    attempt_counter += 1  \n",
    "            \n",
    "            # Fetch the DUOS user group associated with the DUOS ID\n",
    "            print(f\"\\t\\t- Fetching DUOS user group from DUOS ID {duos_id}.\")\n",
    "            duos_group = \"\"\n",
    "            attempt_counter = 0\n",
    "            while attempt_counter <= 2:\n",
    "                try:  \n",
    "                    response = duos_api.retrieve_duos_firecloud_group(duos_id=duos_id).to_dict()\n",
    "                    duos_group = response[\"firecloud_group_email\"]\n",
    "                    results_log.append([f\"DUOS User Group Fetching ({duos_id})\", \"Success\", \"\"])\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    msg = f\"Error fetching DUOS user group for DUOS ID {duos_id}: {str(e)}\"\n",
    "                    if attempt_counter >= 2:\n",
    "                        results_log.append([f\"DUOS User Group Fetching ({duos_id})\", \"Failed\", msg])\n",
    "                    sleep(5)\n",
    "                    attempt_counter += 1 \n",
    "            \n",
    "            # Add the DUOS user group to any DAC groups on the snapshot\n",
    "            print(f\"\\t\\t- Adding DUOS user group {duos_group} to snapshot DAC user group(s).\")\n",
    "            dac_groups = []\n",
    "            try:\n",
    "                response = snapshots_api.retrieve_snapshot_policies(id=snapshot_id).to_dict()\n",
    "                if response.get(\"auth_domain\"):\n",
    "                    dac_groups = response[\"auth_domain\"]\n",
    "                if dac_groups:\n",
    "                    print(f\"\\t\\t\\t- DAC user group(s) found on snapshot: {dac_groups}.\")\n",
    "                    for dac_group in dac_groups:\n",
    "                        response = requests.put(\n",
    "                            url=f\"https://api.firecloud.org/api/groups/{dac_group}/member/{duos_group}\",\n",
    "                            headers={\"Authorization\": f\"Bearer {creds.token}\"}\n",
    "                        )\n",
    "                        if response.status_code != 204:\n",
    "                            results_log.append([f\"DUOS Group to DAC Group Addition ({duos_group} - {dac_group})\", \"Failed\", \"Error adding DUOS group to DAC group.\"])\n",
    "                        else:\n",
    "                            results_log.append([f\"DUOS Group to DAC Group Addition ({duos_group} - {dac_group})\", \"Success\", \"\"])\n",
    "                else:\n",
    "                    msg = f\"No DAC user group(s) found on snapshot.\"\n",
    "                    print(f\"\\t\\t\\t- {msg}\")\n",
    "                    results_log.append([f\"DUOS Group to DAC Group Addition ({snapshot_id} - {duos_id})\", \"Warning\", msg])   \n",
    "            except Exception as e:\n",
    "                msg = f\"Error adding DUOS Group to DAC Group: {str(e)}\"\n",
    "                results_log.append([f\"DUOS Group to DAC Group Addition ({snapshot_id} - {duos_id})\", \"Failed\", msg])\n",
    "        \n",
    "        else:\n",
    "            results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id})\", \"Failed\", \"No DUOS ID found for the snapshot.\"])\n",
    "    return results_log\n",
    "\n",
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# User token (use gcloud auth print-access-token to get this)\n",
    "token = \"\"\n",
    "\n",
    "# Environment\n",
    "env = \"prod\"\n",
    "\n",
    "# Snapshot list\n",
    "snapshot_id_list = [\n",
    "    '737d454c-88be-477f-ae2c-ef473e2106ce',\n",
    "    '253e2b36-1674-482b-bfbd-4e0b05cdfe63',\n",
    "    '3f53e841-ca9d-4b55-b390-590718533561',\n",
    "    '01cf2450-604b-43e5-9f4e-9ec4e0bf0a61',\n",
    "    '85b0b351-cd0a-4efe-95a4-e39273c42831',\n",
    "    'c9037419-367e-439c-a247-b0dae7c24146',\n",
    "    'd7b2b2c6-72fd-4084-af34-a86edfe3ac47',\n",
    "    'd63a63ce-24c8-413a-89c0-4bd4c82370c0',\n",
    "    '1bb208f2-ecf3-4589-a9bd-b6e94178584d',\n",
    "    '5773565d-ad7c-4f51-8b4f-f1ee5dffc08a',\n",
    "    '2e5c5fe3-3af4-4c34-a85e-af6b4135f089',\n",
    "    '27068295-b3c0-4260-9447-9ca96814d46f',\n",
    "    '060c707a-2f0d-4730-bbd6-d25489abfcf6',\n",
    "    '7e59197f-b859-4279-add3-de24bbc7e52b',\n",
    "    '624fef99-e4ce-4c12-a3d9-90995b5da970',\n",
    "    'a68d3145-81c2-41f8-9944-5e4a5058934a',\n",
    "    'a3b18d45-96c2-4526-8fde-65ab3265868f',\n",
    "    '3ec72891-87d2-431f-850c-e52013330ea8',\n",
    "    '87d02347-d169-4ce0-9027-3c8e11e48c40',\n",
    "    '61b6ae23-ca19-4d31-bad3-2281a8528886',\n",
    "    '7c4edc65-bfe6-4ede-a68a-c0b9d2564f29',\n",
    "    'f330517e-46fd-4de3-8063-015b524a7324',\n",
    "    'f0d8bb27-1695-4faf-8b27-4b95260b8f17',\n",
    "    '17d14df1-cb64-4aae-8049-c1728a3c0c81',\n",
    "    '434f85e2-4435-483c-8099-b03c8ba794ed',\n",
    "    '5bba97dc-d6ab-4329-912f-148c8b807056',\n",
    "    '4c722626-c559-4f5a-84bd-8d7d46983e1e',\n",
    "    '6df525e1-b143-4e6f-b667-80c783ae1b66',\n",
    "    '079eb53c-e2b6-4da6-ab5f-fc2136a3ecc1',\n",
    "    '1a26532c-16e6-4f1c-81f9-8f07a8181421',\n",
    "    '3ac713b5-3645-4381-ac66-ecbc281a2ab8',\n",
    "    '4911bd18-5db9-418a-9dc0-0ea28ae937d6',\n",
    "    'bbd04481-0b9d-4c21-ba65-a43638116e0f',\n",
    "    '2b78a3ac-8bca-4938-bc7c-26a60f9c04ac',\n",
    "    '4bb891fc-fcae-40cc-bf59-73716de7e04e',\n",
    "    '574e0d42-e712-4a86-be7a-4b3a95187bcd',\n",
    "    '56078c29-a393-4c60-9e04-3674e02fe729',\n",
    "    '099d2585-1379-4333-b3b1-ffc0d26d95c5',\n",
    "    'ab71d294-4ba9-44d4-8051-913b3d5ccff3',\n",
    "    '90fe2016-e79c-456c-a5f9-3a31149fcd65',\n",
    "    'e43974fd-cee1-4d8c-a436-6846d7d24129',\n",
    "    '0d607d21-c9c7-4852-83e3-76825176ee0a',\n",
    "    '0a356156-961d-4829-b9b5-c07fbc73dacc',\n",
    "    '18a28450-31ec-4e4a-a305-dbbdd226ae3c',\n",
    "    'f7d225d9-1675-483d-a1eb-9ef750301cd4',\n",
    "    'd4b02f5f-7a62-4cad-8ffc-d3deb0fab445',\n",
    "    '4c8ce027-8094-4f5d-bf62-22b1d51b3c1e',\n",
    "    'c753046a-cf9b-4813-be68-cb3b9dd9866e',\n",
    "    'eb7948be-1007-4b0e-b9b6-a5c40bbb9596',\n",
    "    '7639a9e0-275c-49a8-80c1-cdb01ce23e1c',\n",
    "    'aa2bfacc-c28c-4192-960c-b1389cf68516',\n",
    "    'd7349942-f8ff-4ad6-b075-8f39652a7789',\n",
    "    'b9e0de2a-4085-4226-a073-1744914cbbd4',\n",
    "    '44b1f60b-e74c-4430-9378-d4a75e2de72f',\n",
    "    'a4c62d7f-34f0-4e2e-9e46-c762d3ab0ff2',\n",
    "    '6a5b3be6-d1de-4f23-a431-b08e7ab231b8',\n",
    "    '5208772d-21f9-46b0-8167-0b05b57296b8',\n",
    "    '36690013-e8bc-43a5-9ba9-83317537557c',\n",
    "    '172bada7-f1c5-41c4-836d-05381beaed9a',\n",
    "    '9a1e873b-b1db-4d3e-a83b-ed6c5b3f3ecc',\n",
    "    '2c6de04e-104d-42c8-8448-97d74985dacb',\n",
    "    '452bcafd-ab45-4e24-b5e0-13fcf22b0755',\n",
    "    'fbafdd31-21a0-44c5-ae4d-724839beff61',\n",
    "    '2a1882d9-88ca-4849-bcc1-f6914f593407',\n",
    "    '3838993f-59ba-4dec-8110-ac3ea387ab91',\n",
    "    'bf2f4106-cee9-419c-b4d1-d7b03a6293d5',\n",
    "    'a6c36f5e-b86c-4164-85ae-8bf0df2e4a90',\n",
    "    '11a7572f-02b9-4f88-8c2c-802dfb1f94b7',\n",
    "    '5e547934-c339-410e-a013-dfefed50f4b8',\n",
    "    'ffa84feb-ca0e-43d3-a04d-a402a8e24a3b',\n",
    "    '2be072bd-2153-4050-9358-e4b95297a9bf',\n",
    "    '7c19d852-e36a-4353-afea-10e501601d9a',\n",
    "    'fd3843fe-ee5d-4784-b0d2-6673f9886d30',\n",
    "    '84703c54-a9dd-400c-9701-2fc40922e3e3',\n",
    "    '00297802-e20a-413f-b389-a6f764b6600e',\n",
    "    'c853d4c0-d4be-433d-964e-e30bdc35480e',\n",
    "    '3e85b06a-a6ea-4ce8-a655-44b1fce12138',\n",
    "    '6e674477-522f-4adc-8c50-76910a6a282b',\n",
    "    '504089f1-c59d-48fe-84ef-858bd3eb3043',\n",
    "    '0565b2e4-ade1-46e7-80bf-ca647a89a8b8',\n",
    "    '1cf943bc-9ffe-4fd0-a92d-6fdcf68da743',\n",
    "    'bb11d621-e471-4ca9-b9ae-cf06c99db297',\n",
    "    '7b875b4b-a6c5-4c92-a252-cd5ff203089e',\n",
    "    '97b3d565-3c32-4fd5-be49-c16f0bae84e7',\n",
    "    'ea08adf0-2383-41ae-a91a-88c7b8f6f42b',\n",
    "    '5b8c745a-972b-455c-8021-ee24fdbce9a5',\n",
    "    'bebf0200-8458-4467-b001-ff436564e942',\n",
    "    '1c16f983-c090-457a-aca7-4181d16e225b',\n",
    "    'b259ac6c-3358-4faa-abfe-c9d614b76915',\n",
    "    '1a119cfe-3178-4f06-800b-b2aec50218b8',\n",
    "    '33c73ae8-f829-438d-bdb1-da0be8f3773f',\n",
    "    '3d6afb8e-dbcd-4972-8281-ae546b23356c',\n",
    "    '42fd7b4a-461d-4a4f-bb02-856e7124dce1',\n",
    "    '08f28ada-3fa1-41f3-a7eb-5b4ff8325145',\n",
    "    '189a0802-8538-41f8-ad51-8bb2a736783b',\n",
    "    'e0dc36c3-ff48-4ab5-881f-899578e08dd4',\n",
    "    '9052b5fc-8ac8-41ea-8a82-6860b8d2c33d',\n",
    "    'b8bc131f-68d6-4c56-bd37-55c1b0e27d2e',\n",
    "]\n",
    "snapshot_id_list = ['737d454c-88be-477f-ae2c-ef473e2106ce']\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "\n",
    "results = link_duos_ids_to_snapshots(snapshot_id_list, env, token)\n",
    "df_results = pd.DataFrame(results, columns = [\"Item\", \"Status\", \"Message\"])\n",
    "print(\"\\nLinking Results:\")\n",
    "display(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Add DUOS IDs Directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Functions\n",
    "#############################################\n",
    "\n",
    "def direct_link_duos_ids_to_snapshots(snapshot_duos_list):\n",
    "    results_log = []\n",
    "\n",
    "    # Loop through input snapshots and link DUOS IDs to them\n",
    "    print(\"Linking DUOS IDs to Snapshots...\")\n",
    "    creds, project = google.auth.default()\n",
    "    auth_req = google.auth.transport.requests.Request()\n",
    "    creds.refresh(auth_req)\n",
    "    api_client = refresh_tdr_api_client()\n",
    "    snapshots_api = data_repo_client.SnapshotsApi(api_client=api_client)\n",
    "    duos_api = data_repo_client.DuosApi(api_client=api_client)\n",
    "    for ss_duos_entry in snapshot_duos_list:\n",
    "        snapshot_id = ss_duos_entry[0]\n",
    "        duos_id = ss_duos_entry[1]\n",
    "        print(f\"\\tProcessing snapshot ID = {snapshot_id}\")\n",
    "        if duos_id:\n",
    "            # Link the DUOS ID to the snapshot\n",
    "            print(f\"\\t\\t- Linking DUOS ID {duos_id} to snapshot.\")\n",
    "            attempt_counter = 0\n",
    "            while attempt_counter <= 2:\n",
    "                try:\n",
    "                    response = snapshots_api.link_duos_dataset_to_snapshot(id=snapshot_id, duos_id=duos_id).to_dict()\n",
    "                    if response.get(\"linked\"):\n",
    "                        results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id} - {duos_id})\", \"Success\", \"\"])\n",
    "                        break\n",
    "                    elif response.get(\"message\"):\n",
    "                        response_message = response.get(\"message\")\n",
    "                        msg = f\"Error linking DUOS ID to Snapshot: {response_message}\"\n",
    "                        if attempt_counter >= 2:\n",
    "                            results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id} - {duos_id})\", \"Failed\", msg])\n",
    "                            break\n",
    "                except Exception as e:\n",
    "                    msg = f\"Error linking DUOS ID to Snapshot: {str(e)}\"\n",
    "                    if attempt_counter >= 2:\n",
    "                        results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id} - {duos_id})\", \"Failed\", msg])\n",
    "                    sleep(5)\n",
    "                    attempt_counter += 1  \n",
    "            \n",
    "            # Fetch the DUOS user group associated with the DUOS ID\n",
    "            print(f\"\\t\\t- Fetching DUOS user group from DUOS ID {duos_id}.\")\n",
    "            duos_group = \"\"\n",
    "            attempt_counter = 0\n",
    "            while attempt_counter <= 2:\n",
    "                try:  \n",
    "                    response = duos_api.retrieve_duos_firecloud_group(duos_id=duos_id).to_dict()\n",
    "                    duos_group = response[\"firecloud_group_email\"]\n",
    "                    results_log.append([f\"DUOS User Group Fetching ({duos_id})\", \"Success\", \"\"])\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    msg = f\"Error fetching DUOS user group for DUOS ID {duos_id}: {str(e)}\"\n",
    "                    if attempt_counter >= 2:\n",
    "                        results_log.append([f\"DUOS User Group Fetching ({duos_id})\", \"Failed\", msg])\n",
    "                    sleep(5)\n",
    "                    attempt_counter += 1 \n",
    "            \n",
    "            # Add the DUOS user group to any DAC groups on the snapshot\n",
    "            print(f\"\\t\\t- Adding DUOS user group {duos_group} to snapshot DAC user group(s).\")\n",
    "            dac_groups = []\n",
    "            try:\n",
    "                response = snapshots_api.retrieve_snapshot_policies(id=snapshot_id).to_dict()\n",
    "                if response.get(\"auth_domain\"):\n",
    "                    dac_groups = response[\"auth_domain\"]\n",
    "                if dac_groups:\n",
    "                    print(f\"\\t\\t\\t- DAC user group(s) found on snapshot: {dac_groups}.\")\n",
    "                    for dac_group in dac_groups:\n",
    "                        response = requests.put(\n",
    "                            url=f\"https://api.firecloud.org/api/groups/{dac_group}/member/{duos_group}\",\n",
    "                            headers={\"Authorization\": f\"Bearer {creds.token}\"}\n",
    "                        )\n",
    "                        if response.status_code != 204:\n",
    "                            results_log.append([f\"DUOS Group to DAC Group Addition ({duos_group} - {dac_group})\", \"Failed\", \"Error adding DUOS group to DAC group.\"])\n",
    "                        else:\n",
    "                            results_log.append([f\"DUOS Group to DAC Group Addition ({duos_group} - {dac_group})\", \"Success\", \"\"])\n",
    "                else:\n",
    "                    msg = f\"No DAC user group(s) found on snapshot.\"\n",
    "                    print(f\"\\t\\t\\t- {msg}\")\n",
    "                    results_log.append([f\"DUOS Group to DAC Group Addition ({snapshot_id} - {duos_id})\", \"Warning\", msg])   \n",
    "            except Exception as e:\n",
    "                msg = f\"Error adding DUOS Group to DAC Group: {str(e)}\"\n",
    "                results_log.append([f\"DUOS Group to DAC Group Addition ({snapshot_id} - {duos_id})\", \"Failed\", msg])\n",
    "        \n",
    "        else:\n",
    "            results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id})\", \"Failed\", \"No DUOS ID found for the snapshot.\"])\n",
    "    return results_log\n",
    "\n",
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# Snapshot list\n",
    "snapshot_duos_list = [\n",
    "    #['snapshot_id', 'duos_id']\n",
    "    ['737d454c-88be-477f-ae2c-ef473e2106ce', 'DUOS-000254'],\n",
    "]\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "\n",
    "results = direct_link_duos_ids_to_snapshots(snapshot_duos_list)\n",
    "df_results = pd.DataFrame(results, columns = [\"Item\", \"Status\", \"Message\"])\n",
    "print(\"\\nLinking Results:\")\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Script Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Fetch parameters from snapshot/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "snapshot_id = \"099d2585-1379-4333-b3b1-ffc0d26d95c5\"\n",
    "\n",
    "# Retrieve snapshot details\n",
    "api_client = refresh_tdr_api_client()\n",
    "datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "snapshots_api = data_repo_client.SnapshotsApi(api_client=api_client)\n",
    "snapshot_details = snapshots_api.retrieve_snapshot(id=snapshot_id).to_dict()\n",
    "dataset_id = snapshot_details[\"source\"][0][\"dataset\"][\"id\"]\n",
    "phs_id = snapshot_details[\"source\"][0][\"dataset\"][\"phs_id\"]\n",
    "\n",
    "# Retrieve dataset details\n",
    "dataset_details = datasets_api.retrieve_dataset(id=dataset_id, include=[\"PROPERTIES\"]).to_dict()\n",
    "if dataset_details[\"properties\"].get(\"auth_domains\"):\n",
    "    auth_domain = dataset_details[\"properties\"][\"auth_domains\"][0]\n",
    "if dataset_details[\"properties\"].get(\"source_workspaces\"):\n",
    "    source_workspace = dataset_details[\"properties\"][\"source_workspaces\"][0]\n",
    "\n",
    "# Print output\n",
    "print(phs_id)\n",
    "print(source_workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Pulling Workspace Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "ws_project = \"anvil-datastorage\"\n",
    "ws_name = \"AnVIL_GREGOR_RELEASE_01_HMB\"\n",
    "\n",
    "# Establish credentials\n",
    "creds, project = google.auth.default()\n",
    "auth_req = google.auth.transport.requests.Request()\n",
    "creds.refresh(auth_req)\n",
    "\n",
    "# Pull workspace attributes\n",
    "ws_attributes = requests.get(\n",
    "    url=f\"https://api.firecloud.org/api/workspaces/{ws_project}/{ws_name}?fields=workspace.attributes,workspace.authorizationDomain,workspace.googleProject,workspace.bucketName\",\n",
    "    headers={\"Authorization\": f\"Bearer {creds.token}\"}\n",
    ").json()\n",
    "\n",
    "# Map to schema\n",
    "terra_dict = {}\n",
    "terra_dict[\"studyName\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:projectName\")\n",
    "terra_dict[\"studyType\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:studyDesign\")\n",
    "#terra_dict[\"studyDescription\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"description\")\n",
    "terra_dict[\"dataTypes\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:dataCategory\")[\"items\"]\n",
    "terra_dict[\"phenotypeIndication\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:indication\")\n",
    "terra_dict[\"species\"] = \"Homo sapiens\"\n",
    "terra_dict[\"piName\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:datasetOwner\")\n",
    "terra_dict[\"dataCustodianEmail\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:contactEmail\")\n",
    "if ws_attributes[\"workspace\"][\"attributes\"].get(\"tag:tags\"):\n",
    "    for tag in ws_attributes[\"workspace\"][\"attributes\"].get(\"tag:tags\")[\"items\"]:\n",
    "        if \"Consortium:\" in tag:\n",
    "            terra_dict[\"consortium\"] = tag.split(\":\")[1].strip()\n",
    "        elif \"dbGaP:\" in tag:\n",
    "            terra_dict[\"dbGaPPhsID\"] = tag.split(\":\")[1].strip()\n",
    "terra_dict[\"consentGroups.consentCode\"] = ws_attributes[\"workspace\"][\"attributes\"][\"library:dataUseRestriction\"] \n",
    "terra_dict[\"consentGroups.fileTypes.fileType\"] = ws_attributes[\"workspace\"][\"attributes\"][\"library:datatype\"][\"items\"]\n",
    "\n",
    "# View schema\n",
    "print(terra_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ws_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ws_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## dbGaP XML Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "phs_id = \"phs003047\"\n",
    "#phs_id = \"phs000693\"\n",
    "\n",
    "# Pull and parse XML\n",
    "phs_short = phs_id.replace(\"phs\", \"\")\n",
    "dbgap_url = \"https://dbgap.ncbi.nlm.nih.gov/ss/dbgapssws.cgi?request=Study&phs=\" + phs_short\n",
    "response = requests.get(url=dbgap_url)\n",
    "xml_data = xmltodict.parse(response.text)\n",
    "\n",
    "# Map to schema\n",
    "dbgap_xml_dict = {}\n",
    "if isinstance(xml_data[\"dbgapss\"][\"Study\"], list):\n",
    "    study_data = xml_data[\"dbgapss\"][\"Study\"][0]\n",
    "else:\n",
    "    study_data = xml_data[\"dbgapss\"][\"Study\"] \n",
    "dbgap_xml_dict[\"studyName\"] = study_data[\"StudyInfo\"].get(\"StudyNameEntrez\")\n",
    "dbgap_xml_dict[\"studyDescription\"] = study_data[\"StudyInfo\"].get(\"Description\")\n",
    "dbgap_xml_dict[\"dbGaPPhsID\"] = phs_id\n",
    "dbgap_xml_dict[\"dbGaPStudyRegistrationName\"] = study_data[\"StudyInfo\"].get(\"StudyNameEntrez\")\n",
    "for ap_entry in study_data[\"Authority\"][\"Persons\"][\"Person\"]:\n",
    "    if ap_entry[\"Role\"] == \"PI\":\n",
    "        dbgap_xml_dict[\"piName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "        dbgap_xml_dict[\"piEmail\"] = ap_entry[\"@email\"]\n",
    "        dbgap_xml_dict[\"piInstitution\"] = ap_entry[\"Organization\"]\n",
    "    elif ap_entry[\"Role\"] == \"PO\" and ap_entry[\"Organization\"] == \"NIH\":\n",
    "        dbgap_xml_dict[\"nihProgramOfficerName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "    elif ap_entry[\"Role\"] == \"GPA\" and ap_entry[\"Organization\"] == \"NIH\":\n",
    "        dbgap_xml_dict[\"nihGenomicProgramAdministratorName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "ic_list = []\n",
    "if isinstance(study_data[\"Authority\"][\"ICs\"][\"IC\"], list):\n",
    "    for ic_entry in study_data[\"Authority\"][\"ICs\"][\"IC\"]:\n",
    "        ic_list.append(ic_entry[\"@name\"])\n",
    "else:\n",
    "    ic_list.append(study_data[\"Authority\"][\"ICs\"][\"IC\"][\"@name\"])\n",
    "dbgap_xml_dict[\"nihICsSupportingStudy\"] = ic_list\n",
    "dbgap_xml_dict[\"numberOfParticipants\"] = study_data.get(\"@num_participants\")\n",
    "dbgap_xml_dict[\"embargoReleaseDate\"] = study_data[\"Policy\"].get(\"@pub-embargo\")\n",
    "\n",
    "# View schema\n",
    "print(dbgap_xml_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "study_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "study_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## dbGaP Study API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "study_uid = 483191234\n",
    "\n",
    "# Pull and parse JSON\n",
    "dbgap_study_url = \"https://submit.ncbi.nlm.nih.gov/dbgap/api/v1/study_config/\" + str(study_uid)\n",
    "response = requests.get(url=dbgap_study_url)\n",
    "study_api_data = json.loads(response.text)\n",
    "\n",
    "# Map to schema\n",
    "dbgap_study_api_dict = {}\n",
    "if study_api_data.get(\"error\") == None:\n",
    "    dbgap_study_api_dict[\"studyName\"] = study_api_data[\"data\"].get(\"report_name\")\n",
    "    dbgap_study_api_dict[\"studyDescription\"] = study_api_data[\"data\"].get(\"description\")\n",
    "    dbgap_study_api_dict[\"phenotypeIndication\"] = study_api_data[\"data\"].get(\"primary_disease\")\n",
    "    dbgap_study_api_dict[\"studyType\"] = study_api_data[\"data\"].get(\"study_design\")\n",
    "    for attr_entry in study_api_data[\"data\"].get(\"attribution\"):\n",
    "        if attr_entry.get(\"title\") == \"Principal Investigator\":\n",
    "            dbgap_study_api_dict[\"piName\"] = attr_entry.get(\"name\")\n",
    "            dbgap_study_api_dict[\"piInstitution\"] = attr_entry.get(\"institute\")\n",
    "            break\n",
    "\n",
    "# View schema\n",
    "print(dbgap_study_api_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "study_api_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## dbGaP FHIR API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "#phs_id = \"phs003047\"\n",
    "phs_id = \"phs000693\"\n",
    "\n",
    "# Pull and parse JSON\n",
    "dbgap_fhir_url = \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/ResearchStudy?_format=json&_id=\" + phs_id\n",
    "response = requests.get(url=dbgap_fhir_url)\n",
    "fhir_data = json.loads(response.text)\n",
    "\n",
    "# Map to schema\n",
    "dbgap_fhir_dict = {}\n",
    "dbgap_fhir_dict[\"studyName\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"title\")\n",
    "dbgap_fhir_dict[\"studyDescription\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"description\")\n",
    "dbgap_fhir_dict[\"dbGaPPhsID\"] = phs_id\n",
    "dbgap_fhir_dict[\"dbGaPStudyRegistrationName\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"title\")\n",
    "dbgap_fhir_dict[\"nihICsSupportingStudy\"] = fhir_data[\"entry\"][0][\"resource\"][\"sponsor\"].get(\"display\")\n",
    "# studyType\n",
    "for cat_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"category\"):\n",
    "    for coding_entry in cat_entry.get(\"coding\"):\n",
    "        if coding_entry.get(\"system\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/CodeSystem/ResearchStudy-StudyDesign\":\n",
    "            value = coding_entry.get(\"display\") if coding_entry.get(\"display\") else coding_entry.get(\"code\")\n",
    "            if dbgap_fhir_dict.get(\"studyType\") and value:\n",
    "                dbgap_fhir_dict[\"studyType\"] += f\", {value}\"\n",
    "            elif value:\n",
    "                dbgap_fhir_dict[\"studyType\"] = value\n",
    "# dataTypes\n",
    "dt_list = []\n",
    "for ext_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "    if ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-MolecularDataTypes\":\n",
    "        for inner_ext_entry in ext_entry.get(\"extension\"):\n",
    "            if inner_ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-MolecularDataTypes-MolecularDataType\":\n",
    "                for coding_entry in inner_ext_entry[\"valueCodeableConcept\"].get(\"coding\"):\n",
    "                    dt_list.append(coding_entry.get(\"code\"))\n",
    "dbgap_fhir_dict[\"dataTypes\"] = dt_list\n",
    "# phenotypeIndication\n",
    "for focus_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"focus\"):\n",
    "    for coding_entry in focus_entry.get(\"coding\"):\n",
    "        value = coding_entry.get(\"display\") if coding_entry.get(\"display\") else coding_entry.get(\"code\")\n",
    "        if dbgap_fhir_dict.get(\"phenotypeIndication\") and value:\n",
    "            dbgap_fhir_dict[\"phenotypeIndication\"] += f\", {value}\"\n",
    "        elif value:\n",
    "            dbgap_fhir_dict[\"phenotypeIndication\"] = value\n",
    "# numberOfParticipants\n",
    "for ext_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "    if ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-Content\":\n",
    "        for inner_ext_entry in ext_entry.get(\"extension\"):\n",
    "            if inner_ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-Content-NumSubjects\":\n",
    "                dbgap_fhir_dict[\"numberOfParticipants\"] = inner_ext_entry[\"valueCount\"].get(\"code\")\n",
    "\n",
    "# View schema\n",
    "print(dbgap_fhir_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fhir_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Studies from DUOS (Dev Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "token = \"\"\n",
    "study_id_list = [\n",
    "    '5918',\n",
    "    '5919',\n",
    "    '5920',\n",
    "    '5921',\n",
    "    '5922',\n",
    "    '5923',\n",
    "    '5924',\n",
    "    '5925',\n",
    "    '5926',\n",
    "    '5927',\n",
    "    '5928',\n",
    "    '5929',\n",
    "    '5930',\n",
    "    '5931',\n",
    "    '5932',\n",
    "    '5933',\n",
    "    '5934',\n",
    "    '5935',\n",
    "    '5936',\n",
    "    '5937',\n",
    "    '5938',\n",
    "    '5939',\n",
    "    '5940',\n",
    "    '5941',\n",
    "    '5942',\n",
    "    '5943',\n",
    "    '5944',\n",
    "    '5945',\n",
    "    '5946',\n",
    "    '5947',\n",
    "    '5948',\n",
    "    '5949',\n",
    "    '5950',\n",
    "    '5951',\n",
    "    '5952',\n",
    "    '5953',\n",
    "    '5954',\n",
    "    '5955',\n",
    "    '5956',\n",
    "    '5957',\n",
    "    '5958',\n",
    "    '5959',\n",
    "    '5960',\n",
    "    '5961',\n",
    "    '5962',\n",
    "    '5963',\n",
    "    '5964',\n",
    "    '5965',\n",
    "    '5966',\n",
    "    '5967',\n",
    "    '5968',\n",
    "    '5969',\n",
    "    '6034',\n",
    "    '6035',\n",
    "    '6036',\n",
    "    '6037',\n",
    "    '6039',\n",
    "    '6040',\n",
    "    '6041',\n",
    "    '6042',\n",
    "    '6043',\n",
    "    '6044',\n",
    "    '6045',\n",
    "    '6046',\n",
    "    '6047',\n",
    "    '6048',\n",
    "    '6049',\n",
    "    '6050',\n",
    "    '6051',\n",
    "    '6052',\n",
    "    '6053',\n",
    "    '6054',\n",
    "    '6055',\n",
    "    '6056',\n",
    "    '6057',\n",
    "    '6058',\n",
    "    '6059',\n",
    "    '6060',\n",
    "    '6061',\n",
    "    '6062',\n",
    "    '6063',\n",
    "    '6064',\n",
    "    '6065',\n",
    "    '6066',\n",
    "    '6068',\n",
    "    '6069',\n",
    "    '6070',\n",
    "    '6071',\n",
    "    '6072',\n",
    "    '6073',\n",
    "    '6074',\n",
    "]\n",
    "\n",
    "# Delete studies\n",
    "for study_id in study_id_list:\n",
    "    print(f\"Deleting study ID {study_id}\")\n",
    "    response = requests.delete(\n",
    "        url=f\"https://consent.dsde-dev.broadinstitute.org/api/dataset/study/{study_id}\",\n",
    "        headers={\"Authorization\": f\"Bearer {token}\"} \n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        print(\"Study deleted successfully.\")\n",
    "    else:\n",
    "        msg = response.json()[\"message\"]\n",
    "        print(f\"Error deleting study: {msg}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Datasets from DUOS (Dev Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect datasets\n",
    "for key,val in dataset_lookup.items():\n",
    "    if val[\"create_date\"] == \"Jul 25, 2024\" or val[\"create_date\"] == \"Jul 24, 2024\":\n",
    "        print(val[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "token = \"\"\n",
    "dataset_id_list = [ \n",
    "    '2153',\n",
    "    '2154',\n",
    "    '2155',\n",
    "    '2156',\n",
    "    '2157',\n",
    "    '2158',\n",
    "    '2159',\n",
    "    '2160',\n",
    "    '2161',\n",
    "    '2162',\n",
    "    '2163',\n",
    "    '2164',\n",
    "    '2165',\n",
    "    '2166',\n",
    "    '2167',\n",
    "    '2168',\n",
    "    '2169',\n",
    "    '2170',\n",
    "    '2171',\n",
    "    '2172',\n",
    "    '2173',\n",
    "    '2174',\n",
    "    '2175',\n",
    "    '2176',\n",
    "    '2177',\n",
    "    '2178',\n",
    "    '2179',\n",
    "    '2180',\n",
    "    '2181',\n",
    "    '2182',\n",
    "    '2183',\n",
    "    '2184',\n",
    "    '2185',\n",
    "    '2186',\n",
    "    '2187',\n",
    "    '2188',\n",
    "    '2189',\n",
    "    '2190',\n",
    "    '2191',\n",
    "    '2192',\n",
    "    '2193',\n",
    "    '2194',\n",
    "    '2195',\n",
    "    '2196',\n",
    "    '2197',\n",
    "    '2198',\n",
    "    '2199',\n",
    "    '2200',\n",
    "    '2201',\n",
    "    '2202',\n",
    "    '2203',\n",
    "    '2204',\n",
    "    '2205',\n",
    "    '2206',\n",
    "    '2207',\n",
    "    '2208',\n",
    "    '2209',\n",
    "    '2210',\n",
    "    '2211',\n",
    "    '2212',\n",
    "    '2213',\n",
    "    '2214',\n",
    "    '2215',\n",
    "    '2216',\n",
    "    '2217',\n",
    "    '2218',\n",
    "    '2219',\n",
    "    '2220',\n",
    "    '2221',\n",
    "    '2222',\n",
    "    '2223',\n",
    "    '2224',\n",
    "    '2225',\n",
    "    '2226',\n",
    "    '2227',\n",
    "    '2228',\n",
    "    '2229',\n",
    "    '2230',\n",
    "    '2231',\n",
    "    '2232',\n",
    "    '2233',\n",
    "    '2234',\n",
    "    '2235',\n",
    "    '2236',\n",
    "    '2237',\n",
    "    '2238',\n",
    "    '2239',\n",
    "    '2240',\n",
    "    '2241',\n",
    "    '2242',\n",
    "    '2243',\n",
    "    '2244',\n",
    "    '2245',\n",
    "    '2246',\n",
    "    '2247',\n",
    "    '2248',\n",
    "    '2249',\n",
    "    '2250',\n",
    "    '2251',\n",
    "    '2252',\n",
    "    '2253',\n",
    "    '2254',\n",
    "    '2255',\n",
    "    '2256',\n",
    "    '2257',\n",
    "    '2258',\n",
    "    '2259',\n",
    "    '2260',\n",
    "    '2261',\n",
    "    '2262',\n",
    "    '2263',\n",
    "    '2264',\n",
    "    '2265',\n",
    "    '2266',\n",
    "    '2267',\n",
    "    '2268',\n",
    "    '2269',\n",
    "    '2270',\n",
    "    '2271',\n",
    "    '2272',\n",
    "    '2273',\n",
    "    '2274',\n",
    "    '2275',\n",
    "    '2276',\n",
    "    '2277',\n",
    "    '2278',\n",
    "    '2279',\n",
    "    '2280',\n",
    "    '2281',\n",
    "    '2282',\n",
    "    '2283',\n",
    "    '2284',\n",
    "    '2285',\n",
    "    '2286',\n",
    "    '2287',\n",
    "    '2288',\n",
    "    '2289',\n",
    "    '2290',\n",
    "    '2291',\n",
    "    '2292',\n",
    "    '2293',\n",
    "    '2294',\n",
    "    '2295',\n",
    "    '2296',\n",
    "    '2297',\n",
    "    '2298',\n",
    "    '2299',\n",
    "    '2300',\n",
    "    '2301',\n",
    "    '2302',\n",
    "    '2370',\n",
    "    '2371',\n",
    "    '2372',\n",
    "    '2373',\n",
    "    '2374',\n",
    "    '2375',\n",
    "    '2376',\n",
    "    '2377',\n",
    "    '2378',\n",
    "    '2379',\n",
    "    '2380',\n",
    "    '2381',\n",
    "    '2382',\n",
    "    '2383',\n",
    "    '2384',\n",
    "    '2385',\n",
    "    '2386',\n",
    "    '2387',\n",
    "    '2388',\n",
    "    '2389',\n",
    "    '2390',\n",
    "    '2391',\n",
    "    '2392',\n",
    "    '2393',\n",
    "    '2394',\n",
    "    '2395',\n",
    "    '2396',\n",
    "    '2397',\n",
    "    '2398',\n",
    "    '2399',\n",
    "    '2400',\n",
    "    '2401',\n",
    "    '2402',\n",
    "    '2403',\n",
    "    '2404',\n",
    "    '2405',\n",
    "    '2406',\n",
    "    '2407',\n",
    "    '2408',\n",
    "    '2409',\n",
    "    '2410',\n",
    "    '2411',\n",
    "    '2412',\n",
    "    '2413',\n",
    "    '2414',\n",
    "    '2415',\n",
    "    '2416',\n",
    "    '2417',\n",
    "    '2418',\n",
    "    '2419',\n",
    "    '2420',\n",
    "    '2421',\n",
    "    '2422',\n",
    "    '2423',\n",
    "    '2424',\n",
    "    '2425',\n",
    "    '2426',\n",
    "    '2427',\n",
    "    '2428',\n",
    "    '2429',\n",
    "    '2430',\n",
    "    '2431',\n",
    "    '2432',\n",
    "    '2433',\n",
    "    '2434',\n",
    "    '2435',\n",
    "    '2436',\n",
    "    '2437',\n",
    "    '2438',\n",
    "    '2439',\n",
    "    '2440',\n",
    "    '2441',\n",
    "    '2442',\n",
    "    '2443',\n",
    "    '2444',\n",
    "    '2445',\n",
    "    '2446',\n",
    "    '2447',\n",
    "    '2448',\n",
    "    '2449',\n",
    "    '2450',\n",
    "    '2451',\n",
    "    '2452',\n",
    "    '2453',\n",
    "    '2454',\n",
    "    '2455',\n",
    "    '2456',\n",
    "    '2457',\n",
    "    '2458',\n",
    "    '2459',\n",
    "    '2460',\n",
    "    '2461',\n",
    "    '2462',\n",
    "    '2463',\n",
    "    '2464',\n",
    "    '2465',\n",
    "    '2466',\n",
    "    '2467',\n",
    "    '2468',\n",
    "    '2469',\n",
    "    '2470',\n",
    "    '2471',\n",
    "    '2472',\n",
    "    '2473',\n",
    "    '2474',\n",
    "    '2475',\n",
    "    '2476',\n",
    "    '2477',\n",
    "    '2478',\n",
    "    '2479',\n",
    "    '2480',\n",
    "    '2481',\n",
    "    '2482',\n",
    "    '2483',\n",
    "    '2484',\n",
    "    '2485',\n",
    "    '2486',\n",
    "    '2487',\n",
    "    '2488',\n",
    "    '2489',\n",
    "    '2490',\n",
    "    '2491',\n",
    "    '2492',\n",
    "    '2493',\n",
    "    '2494',\n",
    "    '2495',\n",
    "    '2496',\n",
    "    '2497',\n",
    "    '2498',\n",
    "    '2499',\n",
    "    '2500',\n",
    "    '2501',\n",
    "    '2502',\n",
    "    '2503',\n",
    "    '2504',\n",
    "    '2505',\n",
    "    '2506',\n",
    "    '2507',\n",
    "    '2508',\n",
    "    '2509',\n",
    "    '2510',\n",
    "    '2511',\n",
    "    '2512',\n",
    "    '2513',\n",
    "    '2514',\n",
    "    '2515',\n",
    "    '2516',\n",
    "    '2517',\n",
    "    '2518',\n",
    "    '2519',\n",
    "    '2520',\n",
    "    '2521',\n",
    "    '2522',\n",
    "    '2523',\n",
    "    '2524',\n",
    "    '2525',\n",
    "    '2526',\n",
    "    '2527',\n",
    "    '2528',\n",
    "    '2529',\n",
    "    '2530',\n",
    "    '2531',\n",
    "    '2532',\n",
    "    '2533',\n",
    "    '2534',\n",
    "    '2535',\n",
    "    '2536',\n",
    "    '2537',\n",
    "    '2538',\n",
    "    '2539',\n",
    "    '2540',\n",
    "    '2541',\n",
    "    '2542',\n",
    "    '2543',\n",
    "    '2544',\n",
    "    '2545',\n",
    "    '2546',\n",
    "    '2547',\n",
    "    '2548',\n",
    "    '2549',\n",
    "    '2550',\n",
    "    '2551',\n",
    "    '2552',\n",
    "    '2553',\n",
    "    '2554',\n",
    "    '2555',\n",
    "    '2556',\n",
    "    '2557',\n",
    "    '2558',\n",
    "    '2559',\n",
    "    '2560',\n",
    "    '2561',\n",
    "    '2562',\n",
    "    '2563',\n",
    "    '2564',\n",
    "    '2568',\n",
    "    '2569',\n",
    "    '2570',\n",
    "    '2571',\n",
    "    '2572',\n",
    "    '2573',\n",
    "    '2574',\n",
    "    '2575',\n",
    "    '2576',\n",
    "    '2577',\n",
    "    '2578',\n",
    "    '2579',\n",
    "    '2580',\n",
    "]\n",
    "\n",
    "# Delete datasets\n",
    "for dataset_id in dataset_id_list:\n",
    "    print(f\"Deleting dataset ID {dataset_id}\")\n",
    "    response = requests.delete(\n",
    "        url=f\"https://consent.dsde-dev.broadinstitute.org/api/dataset/index/{dataset_id}\",\n",
    "        headers={\"Authorization\": f\"Bearer {token}\"} \n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        print(\"Dataset deleted successfully.\")\n",
    "    else:\n",
    "        msg = response.json()[\"message\"]\n",
    "        print(f\"Error deleting dataset: {msg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect AnVIL Studies and Datasets DUOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "token = \"\"\n",
    "env = \"prod\"\n",
    "\n",
    "# Determine the target URL from the env variable\n",
    "if env == \"prod\":\n",
    "    url = \"https://consent.dsde-prod.broadinstitute.org\"\n",
    "else:\n",
    "    url = \"https://consent.dsde-dev.broadinstitute.org\"\n",
    "\n",
    "# Pull a list of existing AnVIL studies and datasets from DUOS\n",
    "studies_processed = set()\n",
    "results = []\n",
    "datasets = requests.get(\n",
    "    url=f\"{url}/api/dataset/v2?asCustodian=true\",\n",
    "    headers={\"Authorization\": f\"Bearer {token}\"}\n",
    ").json()\n",
    "for dataset_entry in datasets:\n",
    "    if dataset_entry.get(\"study\") and dataset_entry[\"study\"][\"studyId\"] not in studies_processed:\n",
    "        study_id = dataset_entry[\"study\"][\"studyId\"]\n",
    "        if dataset_entry[\"study\"].get(\"description\") and \"Platform: AnVIL\" in dataset_entry[\"study\"][\"description\"]: \n",
    "            study_name = dataset_entry[\"study\"][\"name\"]\n",
    "            study_phs = \"\"\n",
    "            for prop_entry in dataset_entry[\"study\"][\"properties\"]:\n",
    "                if prop_entry[\"key\"] == \"dbGaPPhsID\":\n",
    "                    study_phs = prop_entry[\"value\"]\n",
    "                    break\n",
    "            for dataset_id in dataset_entry[\"study\"][\"datasetIds\"]:\n",
    "                dataset_details = requests.get(\n",
    "                    url=f\"{url}/api/dataset/v2/{dataset_id}\",\n",
    "                    headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "                ).json()\n",
    "                dataset_name = dataset_details[\"name\"]\n",
    "                dataset_identifier = dataset_details[\"datasetIdentifier\"]\n",
    "                snapshot_id = \"\"\n",
    "                for prop_entry in dataset_entry[\"properties\"]:\n",
    "                    if prop_entry[\"propertyName\"] == \"URL\":\n",
    "                        snapshot_url = prop_entry[\"propertyValue\"]\n",
    "                        if snapshot_url:\n",
    "                            if \"https://data.terra.bio/snapshots/\" in snapshot_url:\n",
    "                                snapshot_id = snapshot_url.replace(\"https://data.terra.bio/snapshots/\", \"\")\n",
    "                        \n",
    "                results.append([study_id, study_name, study_phs, dataset_id, dataset_identifier, dataset_name, snapshot_id])\n",
    "        studies_processed.add(study_id)\n",
    "\n",
    "# Display results\n",
    "df_results = pd.DataFrame(results, columns = [\"Study ID\", \"Study Name\", \"Study PHS\", \"Dataset ID\", \"Dataset Identifier\", \"Dataset Name\", \"Snapshot ID\"])\n",
    "print(\"\\nResults:\")\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = requests.get(\n",
    "    url=f\"{url}/api/dataset/v2?asCustodian=true\",\n",
    "    headers={\"Authorization\": f\"Bearer {token}\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "token = \"\"\n",
    "env = \"dev\"\n",
    "\n",
    "# Determine the target URL from the env variable\n",
    "if env == \"prod\":\n",
    "    url = \"https://consent.dsde-prod.broadinstitute.org\"\n",
    "else:\n",
    "    url = \"https://consent.dsde-dev.broadinstitute.org\"\n",
    "\n",
    "# Pull a list of existing AnVIL studies and datasets from DUOS\n",
    "results = []\n",
    "datasets = requests.get(\n",
    "    url=f\"{url}/api/dataset/v3\",\n",
    "    headers={\"Authorization\": f\"Bearer {token}\"}\n",
    ").json()\n",
    "datasets_to_process = len(datasets)\n",
    "datasets_processed = 0\n",
    "for dataset_entry in datasets:\n",
    "    datasets_processed += 1\n",
    "    print(f\"Processing dataset {datasets_processed} of {datasets_to_process}...\")\n",
    "    dataset_id = dataset_entry[\"dataset_id\"]\n",
    "    dataset_details = requests.get(\n",
    "        url=f\"{url}/api/dataset/v2/{dataset_id}\",\n",
    "        headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "    ).json() \n",
    "    if dataset_details.get(\"study\"):\n",
    "        study_id = dataset_details[\"study\"][\"studyId\"]\n",
    "        if dataset_details[\"study\"].get(\"description\") and \"Platform: AnVIL\" in dataset_details[\"study\"][\"description\"]: \n",
    "            study_name = dataset_details[\"study\"][\"name\"]\n",
    "            study_phs = \"\"\n",
    "            for prop_entry in dataset_details[\"study\"][\"properties\"]:\n",
    "                if prop_entry[\"key\"] == \"dbGaPPhsID\":\n",
    "                    study_phs = prop_entry[\"value\"]\n",
    "                    break\n",
    "            dataset_name = dataset_details[\"name\"]\n",
    "            dataset_identifier = dataset_details[\"datasetIdentifier\"]\n",
    "            snapshot_id = \"\"\n",
    "            for prop_entry in dataset_details[\"properties\"]:\n",
    "                if prop_entry[\"propertyName\"] == \"URL\":\n",
    "                    snapshot_url = prop_entry[\"propertyValue\"]\n",
    "                    if snapshot_url and \"https://data.terra.bio/snapshots/\" in snapshot_url:\n",
    "                            snapshot_id = snapshot_url.replace(\"https://data.terra.bio/snapshots/\", \"\")       \n",
    "            results.append([study_id, study_name, study_phs, dataset_id, dataset_identifier, dataset_name, snapshot_id])\n",
    "\n",
    "# Display results\n",
    "df_results = pd.DataFrame(results, columns = [\"Study ID\", \"Study Name\", \"Study PHS\", \"Dataset ID\", \"Dataset Identifier\", \"Dataset Name\", \"Snapshot ID\"])\n",
    "print(\"\\nResults:\")\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
