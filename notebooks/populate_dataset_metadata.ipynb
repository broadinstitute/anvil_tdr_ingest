{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade data_repo_client\n",
    "#!pip install --upgrade xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "import json\n",
    "import google.auth\n",
    "import xmltodict\n",
    "import data_repo_client\n",
    "import pandas as pd\n",
    "import re\n",
    "from time import sleep\n",
    "import ast\n",
    "\n",
    "# Function to refresh TDR API client\n",
    "def refresh_tdr_api_client():\n",
    "    creds, project = google.auth.default()\n",
    "    auth_req = google.auth.transport.requests.Request()\n",
    "    creds.refresh(auth_req)\n",
    "    config = data_repo_client.Configuration()\n",
    "    config.host = \"https://data.terra.bio\"\n",
    "    config.access_token = creds.token\n",
    "    api_client = data_repo_client.ApiClient(configuration=config)\n",
    "    api_client.client_side_validation = False\n",
    "    return api_client\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Collect Metadata for Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     4,
     20,
     27,
     38,
     44,
     47,
     50,
     53,
     56,
     59,
     65,
     68,
     424
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing snapshot_id: e2736891-a569-449e-8cbf-b7d0274b64d0...\n",
      "\tSnapshot PHS_ID: phs001642\n",
      "\tSource Workspace: AnVIL_CCDG_Broad_AI_IBD_Kugathasan_WGS\n",
      "\tCurrent DUOS ID: DUOS-000198\n",
      "{'studyId': 62, 'studyName': 'Center for Common Disease Genomics [CCDG] - Autoimmune: Inflammatory Bowel Disease (IBD) Exomes and Genomes (phs001642)', 'studyType': None, 'studyDescription': \"The National Human Genome Research Institute (NHGRI) has funded a collaborative large-scale genome sequencing effort to comprehensively identify rare risk and protective variants contributing to multiple common disease phenotypes. Called the Centers for Common Disease Genomics (CCDG), this initiative will explore a range of diseases with the ultimate goal of: undertaking variant discovery for enough different examples of disease architectures and study designs to better understand the general principles of the genomic architecture underlying common, complex inherited diseases; understanding how best to design rare variant studies for common disease; developing resources, informatics tools, and innovative approaches and technologies for multiple disease research communities and the wider biomedical research community. The initial focus of the CCDGs will be in cardiovascular disease (early-onset coronary artery disease, atrial fibrillation, hemorrhagic stroke), neuropsychiatric disease (epilepsy, autism), and autoimmune/inflammatory disease (type 1 diabetes, inflammatory bowel disease). The Broad Institute is one of four selected CCDG project centers. The overarching aim of the Inflammatory Bowel Disease (IBD) program is to define the full allelic spectrum of protein-altering variation in genes associated to IBD, and assess their role in both Crohn's Disease (CD) and Ulcerative Colitis (UC) risk. The whole genome sequencing data generated here is comprised of samples from US-based diverse populations including African American, Puerto-Rican, Caribean and Cuban origins. Platform: AnVIL\", 'dataTypes': ['Raw Sequencing data'], 'phenotypeIndication': 'inflammatory bowel disease', 'species': 'Human', 'piName': 'Mark Daly, PhD', 'dataSubmitterUserId': 6715, 'dataCustodianEmail': ['help@lists.anvilproject.org'], 'publicVisibility': True, 'nihAnvilUse': 'I_AM_NHGRI_FUNDED_AND_I_HAVE_A_DB_GA_P_PHS_ID_ALREADY', 'submittingToAnvil': True, 'dbGaPPhsID': 'phs001642', 'dbGaPStudyRegistrationName': 'Center for Common Disease Genomics [CCDG] - Autoimmune: Inflammatory Bowel Disease (IBD) Exomes and Genomes (phs001642)', 'embargoReleaseDate': None, 'sequencingCenter': '', 'piInstitution': 0, 'nihGrantContractNumber': 'Unknown', 'nihICsSupportingStudy': ['NHGRI'], 'nihProgramOfficerName': 'Felsenfeld, Adam', 'nihInstitutionCenterSubmission': 'NHGRI', 'nihGenomicProgramAdministratorName': 'Wetterstrand, Kris', 'multiCenterStudy': None, 'collaboratingSites': ['CCDG'], 'controlledAccessRequiredForGenomicSummaryResultsGSR': None, 'controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation': None, 'alternativeDataSharingPlan': True, 'alternativeDataSharingPlanReasons': [], 'alternativeDataSharingPlanExplanation': None, 'alternativeDataSharingPlanFileName': None, 'alternativeDataSharingPlanDataSubmitted': None, 'alternativeDataSharingPlanDataReleased': None, 'alternativeDataSharingPlanTargetDeliveryDate': None, 'alternativeDataSharingPlanTargetPublicReleaseDate': None, 'alternativeDataSharingPlanAccessManagement': None, 'consentGroups': [{'datasetId': 251, 'datasetIdentifier': 'DUOS-000198', 'consentGroupName': 'ANVIL_CCDG_Broad_AI_IBD_Kugathasan_WGS_20240113_ANV5_202401141350', 'accessManagement': 'CONTROLLED', 'generalResearchUse': None, 'hmb': None, 'diseaseSpecificUse': [], 'poa': None, 'otherPrimary': None, 'nmds': None, 'gso': None, 'pub': None, 'col': None, 'irb': None, 'gs': None, 'mor': None, 'morDate': None, 'npu': None, 'otherSecondary': None, 'dataAccessCommitteeId': None, 'dataLocation': 'TDR_LOCATION', 'url': 'https://data.terra.bio/snapshots/1bb208f2-ecf3-4589-a9bd-b6e94178584d', 'numberOfParticipants': 1348, 'fileTypes': []}]}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Validated Metadata Output:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_d3685\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_d3685_level0_col0\" class=\"col_heading level0 col0\" >snapshot_id</th>\n",
       "      <th id=\"T_d3685_level0_col1\" class=\"col_heading level0 col1\" >duos_id</th>\n",
       "      <th id=\"T_d3685_level0_col2\" class=\"col_heading level0 col2\" >studyName</th>\n",
       "      <th id=\"T_d3685_level0_col3\" class=\"col_heading level0 col3\" >studyType</th>\n",
       "      <th id=\"T_d3685_level0_col4\" class=\"col_heading level0 col4\" >studyDescription</th>\n",
       "      <th id=\"T_d3685_level0_col5\" class=\"col_heading level0 col5\" >dataTypes</th>\n",
       "      <th id=\"T_d3685_level0_col6\" class=\"col_heading level0 col6\" >phenotypeIndication</th>\n",
       "      <th id=\"T_d3685_level0_col7\" class=\"col_heading level0 col7\" >species</th>\n",
       "      <th id=\"T_d3685_level0_col8\" class=\"col_heading level0 col8\" >piName</th>\n",
       "      <th id=\"T_d3685_level0_col9\" class=\"col_heading level0 col9\" >dataCustodianEmail</th>\n",
       "      <th id=\"T_d3685_level0_col10\" class=\"col_heading level0 col10\" >publicVisibility</th>\n",
       "      <th id=\"T_d3685_level0_col11\" class=\"col_heading level0 col11\" >nihAnvilUse</th>\n",
       "      <th id=\"T_d3685_level0_col12\" class=\"col_heading level0 col12\" >submittingToAnvil</th>\n",
       "      <th id=\"T_d3685_level0_col13\" class=\"col_heading level0 col13\" >dbGaPPhsID</th>\n",
       "      <th id=\"T_d3685_level0_col14\" class=\"col_heading level0 col14\" >dbGaPStudyRegistrationName</th>\n",
       "      <th id=\"T_d3685_level0_col15\" class=\"col_heading level0 col15\" >embargoReleaseDate</th>\n",
       "      <th id=\"T_d3685_level0_col16\" class=\"col_heading level0 col16\" >sequencingCenter</th>\n",
       "      <th id=\"T_d3685_level0_col17\" class=\"col_heading level0 col17\" >piEmail</th>\n",
       "      <th id=\"T_d3685_level0_col18\" class=\"col_heading level0 col18\" >piInstitution</th>\n",
       "      <th id=\"T_d3685_level0_col19\" class=\"col_heading level0 col19\" >nihGrantContractNumber</th>\n",
       "      <th id=\"T_d3685_level0_col20\" class=\"col_heading level0 col20\" >nihICsSupportingStudy</th>\n",
       "      <th id=\"T_d3685_level0_col21\" class=\"col_heading level0 col21\" >nihProgramOfficerName</th>\n",
       "      <th id=\"T_d3685_level0_col22\" class=\"col_heading level0 col22\" >nihInstitutionCenterSubmission</th>\n",
       "      <th id=\"T_d3685_level0_col23\" class=\"col_heading level0 col23\" >nihInstitutionalCertificationFileName</th>\n",
       "      <th id=\"T_d3685_level0_col24\" class=\"col_heading level0 col24\" >nihGenomicProgramAdministratorName</th>\n",
       "      <th id=\"T_d3685_level0_col25\" class=\"col_heading level0 col25\" >multiCenterStudy</th>\n",
       "      <th id=\"T_d3685_level0_col26\" class=\"col_heading level0 col26\" >collaboratingSites</th>\n",
       "      <th id=\"T_d3685_level0_col27\" class=\"col_heading level0 col27\" >controlledAccessRequiredForGenomicSummaryResultsGSR</th>\n",
       "      <th id=\"T_d3685_level0_col28\" class=\"col_heading level0 col28\" >controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation</th>\n",
       "      <th id=\"T_d3685_level0_col29\" class=\"col_heading level0 col29\" >alternativeDataSharingPlan</th>\n",
       "      <th id=\"T_d3685_level0_col30\" class=\"col_heading level0 col30\" >alternativeDataSharingPlanReasons</th>\n",
       "      <th id=\"T_d3685_level0_col31\" class=\"col_heading level0 col31\" >alternativeDataSharingPlanExplanation</th>\n",
       "      <th id=\"T_d3685_level0_col32\" class=\"col_heading level0 col32\" >alternativeDataSharingPlanFileName</th>\n",
       "      <th id=\"T_d3685_level0_col33\" class=\"col_heading level0 col33\" >alternativeDataSharingPlanDataSubmitted</th>\n",
       "      <th id=\"T_d3685_level0_col34\" class=\"col_heading level0 col34\" >alternativeDataSharingPlanDataReleased</th>\n",
       "      <th id=\"T_d3685_level0_col35\" class=\"col_heading level0 col35\" >alternativeDataSharingPlanTargetDeliveryDate</th>\n",
       "      <th id=\"T_d3685_level0_col36\" class=\"col_heading level0 col36\" >alternativeDataSharingPlanTargetPublicReleaseDate</th>\n",
       "      <th id=\"T_d3685_level0_col37\" class=\"col_heading level0 col37\" >alternativeDataSharingPlanAccessManagement</th>\n",
       "      <th id=\"T_d3685_level0_col38\" class=\"col_heading level0 col38\" >consentGroups.consentGroupName</th>\n",
       "      <th id=\"T_d3685_level0_col39\" class=\"col_heading level0 col39\" >consentGroups.accessManagement</th>\n",
       "      <th id=\"T_d3685_level0_col40\" class=\"col_heading level0 col40\" >consentGroups.numberOfParticipants</th>\n",
       "      <th id=\"T_d3685_level0_col41\" class=\"col_heading level0 col41\" >consentCode</th>\n",
       "      <th id=\"T_d3685_level0_col42\" class=\"col_heading level0 col42\" >consentGroups.generalResearchUse</th>\n",
       "      <th id=\"T_d3685_level0_col43\" class=\"col_heading level0 col43\" >consentGroups.hmb</th>\n",
       "      <th id=\"T_d3685_level0_col44\" class=\"col_heading level0 col44\" >consentGroups.diseaseSpecificUse</th>\n",
       "      <th id=\"T_d3685_level0_col45\" class=\"col_heading level0 col45\" >consentGroups.gs</th>\n",
       "      <th id=\"T_d3685_level0_col46\" class=\"col_heading level0 col46\" >consentGroups.poa</th>\n",
       "      <th id=\"T_d3685_level0_col47\" class=\"col_heading level0 col47\" >consentGroups.nmds</th>\n",
       "      <th id=\"T_d3685_level0_col48\" class=\"col_heading level0 col48\" >consentGroups.gso</th>\n",
       "      <th id=\"T_d3685_level0_col49\" class=\"col_heading level0 col49\" >consentGroups.pub</th>\n",
       "      <th id=\"T_d3685_level0_col50\" class=\"col_heading level0 col50\" >consentGroups.col</th>\n",
       "      <th id=\"T_d3685_level0_col51\" class=\"col_heading level0 col51\" >consentGroups.irb</th>\n",
       "      <th id=\"T_d3685_level0_col52\" class=\"col_heading level0 col52\" >consentGroups.npu</th>\n",
       "      <th id=\"T_d3685_level0_col53\" class=\"col_heading level0 col53\" >consentGroups.otherPrimary</th>\n",
       "      <th id=\"T_d3685_level0_col54\" class=\"col_heading level0 col54\" >consentGroups.otherSecondary</th>\n",
       "      <th id=\"T_d3685_level0_col55\" class=\"col_heading level0 col55\" >consentGroups.mor</th>\n",
       "      <th id=\"T_d3685_level0_col56\" class=\"col_heading level0 col56\" >consentGroups.morDate</th>\n",
       "      <th id=\"T_d3685_level0_col57\" class=\"col_heading level0 col57\" >consentGroups.dataLocation</th>\n",
       "      <th id=\"T_d3685_level0_col58\" class=\"col_heading level0 col58\" >consentGroups.url</th>\n",
       "      <th id=\"T_d3685_level0_col59\" class=\"col_heading level0 col59\" >consentGroups.fileTypes.fileType</th>\n",
       "      <th id=\"T_d3685_level0_col60\" class=\"col_heading level0 col60\" >consentGroups.fileTypes.functionalEquivalence</th>\n",
       "      <th id=\"T_d3685_level0_col61\" class=\"col_heading level0 col61\" >consortium</th>\n",
       "      <th id=\"T_d3685_level0_col62\" class=\"col_heading level0 col62\" >unique_value_validation</th>\n",
       "      <th id=\"T_d3685_level0_col63\" class=\"col_heading level0 col63\" >study_enum_value_validation</th>\n",
       "      <th id=\"T_d3685_level0_col64\" class=\"col_heading level0 col64\" >consent_group_enum_value_validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_d3685_row0_col0\" class=\"data row0 col0\" >e2736891-a569-449e-8cbf-b7d0274b64d0</td>\n",
       "      <td id=\"T_d3685_row0_col1\" class=\"data row0 col1\" >DUOS-000198</td>\n",
       "      <td id=\"T_d3685_row0_col2\" class=\"data row0 col2\" >Center for Common Disease Genomics [CCDG] - Autoimmune: Inflammatory Bowel Disease (IBD) Exomes and Genomes (phs001642)</td>\n",
       "      <td id=\"T_d3685_row0_col3\" class=\"data row0 col3\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col4\" class=\"data row0 col4\" >The National Human Genome Research Institute (NHGRI) has funded a collaborative large-scale genome sequencing effort to comprehensively identify rare risk and protective variants contributing to multiple common disease phenotypes. Called the Centers for Common Disease Genomics (CCDG), this initiative will explore a range of diseases with the ultimate goal of: undertaking variant discovery for enough different examples of disease architectures and study designs to better understand the general principles of the genomic architecture underlying common, complex inherited diseases; understanding how best to design rare variant studies for common disease; developing resources, informatics tools, and innovative approaches and technologies for multiple disease research communities and the wider biomedical research community. The initial focus of the CCDGs will be in cardiovascular disease (early-onset coronary artery disease, atrial fibrillation, hemorrhagic stroke), neuropsychiatric disease (epilepsy, autism), and autoimmune/inflammatory disease (type 1 diabetes, inflammatory bowel disease). The Broad Institute is one of four selected CCDG project centers. The overarching aim of the Inflammatory Bowel Disease (IBD) program is to define the full allelic spectrum of protein-altering variation in genes associated to IBD, and assess their role in both Crohn's Disease (CD) and Ulcerative Colitis (UC) risk. The whole genome sequencing data generated here is comprised of samples from US-based diverse populations including African American, Puerto-Rican, Caribean and Cuban origins. Platform: AnVIL</td>\n",
       "      <td id=\"T_d3685_row0_col5\" class=\"data row0 col5\" >['Raw Sequencing data']</td>\n",
       "      <td id=\"T_d3685_row0_col6\" class=\"data row0 col6\" >inflammatory bowel disease</td>\n",
       "      <td id=\"T_d3685_row0_col7\" class=\"data row0 col7\" >Human</td>\n",
       "      <td id=\"T_d3685_row0_col8\" class=\"data row0 col8\" >Mark Daly, PhD</td>\n",
       "      <td id=\"T_d3685_row0_col9\" class=\"data row0 col9\" >['help@lists.anvilproject.org']</td>\n",
       "      <td id=\"T_d3685_row0_col10\" class=\"data row0 col10\" >True</td>\n",
       "      <td id=\"T_d3685_row0_col11\" class=\"data row0 col11\" >I am NHGRI funded and I have a dbGaP PHS ID already</td>\n",
       "      <td id=\"T_d3685_row0_col12\" class=\"data row0 col12\" >True</td>\n",
       "      <td id=\"T_d3685_row0_col13\" class=\"data row0 col13\" >phs001642</td>\n",
       "      <td id=\"T_d3685_row0_col14\" class=\"data row0 col14\" >Center for Common Disease Genomics [CCDG] - Autoimmune: Inflammatory Bowel Disease (IBD) Exomes and Genomes (phs001642)</td>\n",
       "      <td id=\"T_d3685_row0_col15\" class=\"data row0 col15\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col16\" class=\"data row0 col16\" ></td>\n",
       "      <td id=\"T_d3685_row0_col17\" class=\"data row0 col17\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col18\" class=\"data row0 col18\" >0</td>\n",
       "      <td id=\"T_d3685_row0_col19\" class=\"data row0 col19\" >Unknown</td>\n",
       "      <td id=\"T_d3685_row0_col20\" class=\"data row0 col20\" >['NHGRI']</td>\n",
       "      <td id=\"T_d3685_row0_col21\" class=\"data row0 col21\" >Felsenfeld, Adam</td>\n",
       "      <td id=\"T_d3685_row0_col22\" class=\"data row0 col22\" >NHGRI</td>\n",
       "      <td id=\"T_d3685_row0_col23\" class=\"data row0 col23\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col24\" class=\"data row0 col24\" >Wetterstrand, Kris</td>\n",
       "      <td id=\"T_d3685_row0_col25\" class=\"data row0 col25\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col26\" class=\"data row0 col26\" >['CCDG']</td>\n",
       "      <td id=\"T_d3685_row0_col27\" class=\"data row0 col27\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col28\" class=\"data row0 col28\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col29\" class=\"data row0 col29\" >True</td>\n",
       "      <td id=\"T_d3685_row0_col30\" class=\"data row0 col30\" >[]</td>\n",
       "      <td id=\"T_d3685_row0_col31\" class=\"data row0 col31\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col32\" class=\"data row0 col32\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col33\" class=\"data row0 col33\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col34\" class=\"data row0 col34\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col35\" class=\"data row0 col35\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col36\" class=\"data row0 col36\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col37\" class=\"data row0 col37\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col38\" class=\"data row0 col38\" >ANVIL_CCDG_Broad_AI_IBD_Kugathasan_WGS_20240113_ANV5_202401141350</td>\n",
       "      <td id=\"T_d3685_row0_col39\" class=\"data row0 col39\" >CONTROLLED</td>\n",
       "      <td id=\"T_d3685_row0_col40\" class=\"data row0 col40\" >1348</td>\n",
       "      <td id=\"T_d3685_row0_col41\" class=\"data row0 col41\" >GRU</td>\n",
       "      <td id=\"T_d3685_row0_col42\" class=\"data row0 col42\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col43\" class=\"data row0 col43\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col44\" class=\"data row0 col44\" >[]</td>\n",
       "      <td id=\"T_d3685_row0_col45\" class=\"data row0 col45\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col46\" class=\"data row0 col46\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col47\" class=\"data row0 col47\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col48\" class=\"data row0 col48\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col49\" class=\"data row0 col49\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col50\" class=\"data row0 col50\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col51\" class=\"data row0 col51\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col52\" class=\"data row0 col52\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col53\" class=\"data row0 col53\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col54\" class=\"data row0 col54\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col55\" class=\"data row0 col55\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col56\" class=\"data row0 col56\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col57\" class=\"data row0 col57\" >TDR_LOCATION</td>\n",
       "      <td id=\"T_d3685_row0_col58\" class=\"data row0 col58\" >https://data.terra.bio/snapshots/e2736891-a569-449e-8cbf-b7d0274b64d0</td>\n",
       "      <td id=\"T_d3685_row0_col59\" class=\"data row0 col59\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col60\" class=\"data row0 col60\" >None</td>\n",
       "      <td id=\"T_d3685_row0_col61\" class=\"data row0 col61\" >CCDG</td>\n",
       "      <td id=\"T_d3685_row0_col62\" class=\"data row0 col62\" >Pass</td>\n",
       "      <td id=\"T_d3685_row0_col63\" class=\"data row0 col63\" >Pass</td>\n",
       "      <td id=\"T_d3685_row0_col64\" class=\"data row0 col64\" >Pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2e2625cac0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Unique Study Value Validation Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_07a61\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_07a61_level0_col0\" class=\"col_heading level0 col0\" >studyName</th>\n",
       "      <th id=\"T_07a61_level0_col1\" class=\"col_heading level0 col1\" >duos_id</th>\n",
       "      <th id=\"T_07a61_level0_col2\" class=\"col_heading level0 col2\" >studyType</th>\n",
       "      <th id=\"T_07a61_level0_col3\" class=\"col_heading level0 col3\" >studyDescription</th>\n",
       "      <th id=\"T_07a61_level0_col4\" class=\"col_heading level0 col4\" >dataTypes</th>\n",
       "      <th id=\"T_07a61_level0_col5\" class=\"col_heading level0 col5\" >phenotypeIndication</th>\n",
       "      <th id=\"T_07a61_level0_col6\" class=\"col_heading level0 col6\" >species</th>\n",
       "      <th id=\"T_07a61_level0_col7\" class=\"col_heading level0 col7\" >piName</th>\n",
       "      <th id=\"T_07a61_level0_col8\" class=\"col_heading level0 col8\" >dataCustodianEmail</th>\n",
       "      <th id=\"T_07a61_level0_col9\" class=\"col_heading level0 col9\" >publicVisibility</th>\n",
       "      <th id=\"T_07a61_level0_col10\" class=\"col_heading level0 col10\" >nihAnvilUse</th>\n",
       "      <th id=\"T_07a61_level0_col11\" class=\"col_heading level0 col11\" >submittingToAnvil</th>\n",
       "      <th id=\"T_07a61_level0_col12\" class=\"col_heading level0 col12\" >dbGaPPhsID</th>\n",
       "      <th id=\"T_07a61_level0_col13\" class=\"col_heading level0 col13\" >dbGaPStudyRegistrationName</th>\n",
       "      <th id=\"T_07a61_level0_col14\" class=\"col_heading level0 col14\" >embargoReleaseDate</th>\n",
       "      <th id=\"T_07a61_level0_col15\" class=\"col_heading level0 col15\" >sequencingCenter</th>\n",
       "      <th id=\"T_07a61_level0_col16\" class=\"col_heading level0 col16\" >piEmail</th>\n",
       "      <th id=\"T_07a61_level0_col17\" class=\"col_heading level0 col17\" >piInstitution</th>\n",
       "      <th id=\"T_07a61_level0_col18\" class=\"col_heading level0 col18\" >nihGrantContractNumber</th>\n",
       "      <th id=\"T_07a61_level0_col19\" class=\"col_heading level0 col19\" >nihICsSupportingStudy</th>\n",
       "      <th id=\"T_07a61_level0_col20\" class=\"col_heading level0 col20\" >nihProgramOfficerName</th>\n",
       "      <th id=\"T_07a61_level0_col21\" class=\"col_heading level0 col21\" >nihInstitutionCenterSubmission</th>\n",
       "      <th id=\"T_07a61_level0_col22\" class=\"col_heading level0 col22\" >nihInstitutionalCertificationFileName</th>\n",
       "      <th id=\"T_07a61_level0_col23\" class=\"col_heading level0 col23\" >nihGenomicProgramAdministratorName</th>\n",
       "      <th id=\"T_07a61_level0_col24\" class=\"col_heading level0 col24\" >multiCenterStudy</th>\n",
       "      <th id=\"T_07a61_level0_col25\" class=\"col_heading level0 col25\" >collaboratingSites</th>\n",
       "      <th id=\"T_07a61_level0_col26\" class=\"col_heading level0 col26\" >controlledAccessRequiredForGenomicSummaryResultsGSR</th>\n",
       "      <th id=\"T_07a61_level0_col27\" class=\"col_heading level0 col27\" >controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation</th>\n",
       "      <th id=\"T_07a61_level0_col28\" class=\"col_heading level0 col28\" >alternativeDataSharingPlan</th>\n",
       "      <th id=\"T_07a61_level0_col29\" class=\"col_heading level0 col29\" >alternativeDataSharingPlanReasons</th>\n",
       "      <th id=\"T_07a61_level0_col30\" class=\"col_heading level0 col30\" >alternativeDataSharingPlanExplanation</th>\n",
       "      <th id=\"T_07a61_level0_col31\" class=\"col_heading level0 col31\" >alternativeDataSharingPlanFileName</th>\n",
       "      <th id=\"T_07a61_level0_col32\" class=\"col_heading level0 col32\" >alternativeDataSharingPlanDataSubmitted</th>\n",
       "      <th id=\"T_07a61_level0_col33\" class=\"col_heading level0 col33\" >alternativeDataSharingPlanDataReleased</th>\n",
       "      <th id=\"T_07a61_level0_col34\" class=\"col_heading level0 col34\" >alternativeDataSharingPlanTargetDeliveryDate</th>\n",
       "      <th id=\"T_07a61_level0_col35\" class=\"col_heading level0 col35\" >alternativeDataSharingPlanTargetPublicReleaseDate</th>\n",
       "      <th id=\"T_07a61_level0_col36\" class=\"col_heading level0 col36\" >alternativeDataSharingPlanAccessManagement</th>\n",
       "      <th id=\"T_07a61_level0_col37\" class=\"col_heading level0 col37\" >unique_value_validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_07a61_row0_col0\" class=\"data row0 col0\" >Center for Common Disease Genomics [CCDG] - Autoimmune: Inflammatory Bowel Disease (IBD) Exomes and Genomes (phs001642)</td>\n",
       "      <td id=\"T_07a61_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_07a61_row0_col3\" class=\"data row0 col3\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col4\" class=\"data row0 col4\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col5\" class=\"data row0 col5\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col6\" class=\"data row0 col6\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col7\" class=\"data row0 col7\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col8\" class=\"data row0 col8\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col9\" class=\"data row0 col9\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col10\" class=\"data row0 col10\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col11\" class=\"data row0 col11\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col12\" class=\"data row0 col12\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col13\" class=\"data row0 col13\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col14\" class=\"data row0 col14\" >0</td>\n",
       "      <td id=\"T_07a61_row0_col15\" class=\"data row0 col15\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col16\" class=\"data row0 col16\" >0</td>\n",
       "      <td id=\"T_07a61_row0_col17\" class=\"data row0 col17\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col18\" class=\"data row0 col18\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col19\" class=\"data row0 col19\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col20\" class=\"data row0 col20\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col21\" class=\"data row0 col21\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col22\" class=\"data row0 col22\" >0</td>\n",
       "      <td id=\"T_07a61_row0_col23\" class=\"data row0 col23\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col24\" class=\"data row0 col24\" >0</td>\n",
       "      <td id=\"T_07a61_row0_col25\" class=\"data row0 col25\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col26\" class=\"data row0 col26\" >0</td>\n",
       "      <td id=\"T_07a61_row0_col27\" class=\"data row0 col27\" >0</td>\n",
       "      <td id=\"T_07a61_row0_col28\" class=\"data row0 col28\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col29\" class=\"data row0 col29\" >1</td>\n",
       "      <td id=\"T_07a61_row0_col30\" class=\"data row0 col30\" >0</td>\n",
       "      <td id=\"T_07a61_row0_col31\" class=\"data row0 col31\" >0</td>\n",
       "      <td id=\"T_07a61_row0_col32\" class=\"data row0 col32\" >0</td>\n",
       "      <td id=\"T_07a61_row0_col33\" class=\"data row0 col33\" >0</td>\n",
       "      <td id=\"T_07a61_row0_col34\" class=\"data row0 col34\" >0</td>\n",
       "      <td id=\"T_07a61_row0_col35\" class=\"data row0 col35\" >0</td>\n",
       "      <td id=\"T_07a61_row0_col36\" class=\"data row0 col36\" >0</td>\n",
       "      <td id=\"T_07a61_row0_col37\" class=\"data row0 col37\" >Pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2e26c1f580>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Study Enum Value Validation Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_85d16\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_85d16_level0_col0\" class=\"col_heading level0 col0\" >studyName</th>\n",
       "      <th id=\"T_85d16_level0_col1\" class=\"col_heading level0 col1\" >studyType</th>\n",
       "      <th id=\"T_85d16_level0_col2\" class=\"col_heading level0 col2\" >nihInstitutionCenterSubmission</th>\n",
       "      <th id=\"T_85d16_level0_col3\" class=\"col_heading level0 col3\" >nihICsSupportingStudy</th>\n",
       "      <th id=\"T_85d16_level0_col4\" class=\"col_heading level0 col4\" >study_enum_value_validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_85d16_row0_col0\" class=\"data row0 col0\" >Center for Common Disease Genomics [CCDG] - Autoimmune: Inflammatory Bowel Disease (IBD) Exomes and Genomes (phs001642)</td>\n",
       "      <td id=\"T_85d16_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_85d16_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_85d16_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "      <td id=\"T_85d16_row0_col4\" class=\"data row0 col4\" >Pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2e26c1f580>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Consent Group Enum Value Validation Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ff0f4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_ff0f4_level0_col0\" class=\"col_heading level0 col0\" >consentGroups.consentGroupName</th>\n",
       "      <th id=\"T_ff0f4_level0_col1\" class=\"col_heading level0 col1\" >consentGroups.fileTypes.fileType</th>\n",
       "      <th id=\"T_ff0f4_level0_col2\" class=\"col_heading level0 col2\" >consent_group_enum_value_validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_ff0f4_row0_col0\" class=\"data row0 col0\" >ANVIL_CCDG_Broad_AI_IBD_Kugathasan_WGS_20240113_ANV5_202401141350</td>\n",
       "      <td id=\"T_ff0f4_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_ff0f4_row0_col2\" class=\"data row0 col2\" >Pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2e272eb820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################################\n",
    "## Functions\n",
    "#############################################\n",
    "\n",
    "def coalesce(*arg): \n",
    "    remove_list = [\"\", \"NA\", \"N/A\", \"NONE\", \"TBD\", \"UNKNOWN\", \"UNSPECIFIED\"]\n",
    "    # update to remove N/A, None, Null, TBD\n",
    "    for input_item in arg:\n",
    "        if input_item is not None:\n",
    "            if isinstance(input_item, list):\n",
    "                temp_list = [ele for ele in input_item if ele is not None and ele.upper() not in remove_list]\n",
    "                if temp_list:\n",
    "                    return temp_list\n",
    "                else:\n",
    "                    return []\n",
    "            else:\n",
    "                if str(input_item).upper() not in remove_list:\n",
    "                    return input_item\n",
    "    return None\n",
    "\n",
    "def format_description(input_string):\n",
    "    output_string = input_string if input_string else \"\"\n",
    "    output_string = re.sub(\"\\n\\n\\t\", \" \", output_string)\n",
    "    output_string = re.sub(\"\\t\", \" \", output_string)\n",
    "    output_string = re.sub(\"study.cgi\\?study_id=|.\\/study.cgi\\?study_id=\", \"https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=\", output_string)\n",
    "    return output_string\n",
    "\n",
    "def format_phs_id(input_str):\n",
    "    try:\n",
    "        num = re.search(\"phs0*([0-9]+)\", input_str, re.IGNORECASE).group(1)\n",
    "    except:\n",
    "        num = \"\"\n",
    "    if num:\n",
    "        output_str = \"phs\" + str(num).zfill(6)\n",
    "    else:\n",
    "        output_str = \"\"\n",
    "    return output_str\n",
    "\n",
    "def try_join(l):\n",
    "    try:\n",
    "        if isinstance(l, list):\n",
    "            return ', '.join(map(str, l))\n",
    "        else:\n",
    "            return l\n",
    "    except TypeError:\n",
    "        return l\n",
    "    \n",
    "def val_study_type_enum(l):\n",
    "    if l and l not in [\"Observational\", \"Interventional\", \"Descriptive\", \"Analytical\", \"Prospective\", \"Retrospective\", \"Case report\", \"Case series\", \"Cross-sectional\", \"Cohort study\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def val_nih_inst_center_sub_enum(l):\n",
    "    if l and l not in [\"NCI\", \"NEI\", \"NHLBI\", \"NHGRI\", \"NIA\", \"NIAAA\", \"NIAID\", \"NIAMS\", \"NIBIB\", \"NICHD\", \"NIDCD\", \"NIDCR\", \"NIDDK\", \"NIDA\", \"NIEHS\", \"NIGMS\", \"NIMH\", \"NIMHD\", \"NINDS\", \"NINR\", \"NLM\", \"CC\", \"CIT\", \"CSR\", \"FIC\", \"NCATS\", \"NCCIH\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def val_nih_ic_supp_study_enum(l):\n",
    "    if l and isinstance(l, list):\n",
    "        for item in l:\n",
    "            if item not in [\"NCI\", \"NEI\", \"NHLBI\", \"NHGRI\", \"NIA\", \"NIAAA\", \"NIAID\", \"NIAMS\", \"NIBIB\", \"NICHD\", \"NIDCD\", \"NIDCR\", \"NIDDK\", \"NIDA\", \"NIEHS\", \"NIGMS\", \"NIMH\", \"NIMHD\", \"NINDS\", \"NINR\", \"NLM\", \"CC\", \"CIT\", \"CSR\", \"FIC\", \"NCATS\", \"NCCIH\"]:\n",
    "                return 1\n",
    "        return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def val_file_type_enum(l):\n",
    "    if l and isinstance(l, list):\n",
    "        for item in l:\n",
    "            if item not in [\"Arrays\", \"Genome\", \"Exome\", \"Survey\", \"Phenotype\"]:\n",
    "                return 1\n",
    "        return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def fetch_dataset_details(snapshot_id, ds_consent_map):\n",
    "    \n",
    "    # Initialize variables\n",
    "    terra_dict = {}\n",
    "    dbgap_xml_dict = {}\n",
    "    dbgap_study_api_dict = {}\n",
    "    dbgap_fhir_dict = {}\n",
    "    final_results_dict = {}\n",
    "    \n",
    "    # Retrieve snapshot details\n",
    "    api_client = refresh_tdr_api_client()\n",
    "    datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "    snapshots_api = data_repo_client.SnapshotsApi(api_client=api_client)\n",
    "    attempt_counter = 0\n",
    "    while attempt_counter <= 2:\n",
    "        try:\n",
    "            snapshot_details = snapshots_api.retrieve_snapshot(id=snapshot_id).to_dict()\n",
    "            break\n",
    "        except:\n",
    "            sleep(5)\n",
    "            attempt_counter += 1  \n",
    "    snapshot_name = snapshot_details[\"name\"]\n",
    "    dataset_id = snapshot_details[\"source\"][0][\"dataset\"][\"id\"]\n",
    "    phs_id = format_phs_id(snapshot_details[\"source\"][0][\"dataset\"][\"phs_id\"])\n",
    "    if snapshot_details[\"source\"][0][\"dataset\"][\"secure_monitoring_enabled\"] == True:\n",
    "        access_management = \"controlled\"\n",
    "    else:\n",
    "        access_management = \"open\"\n",
    "    if snapshot_details[\"source\"][0][\"dataset_properties\"].get(\"source_workspaces\"):  \n",
    "        source_workspace = snapshot_details[\"source\"][0][\"dataset_properties\"][\"source_workspaces\"][0]\n",
    "    else:\n",
    "        source_workspace = None\n",
    "    if snapshot_details[\"duos_firecloud_group\"] != None:\n",
    "        duos_id = snapshot_details[\"duos_firecloud_group\"][\"duos_id\"]\n",
    "    else:\n",
    "        duos_id = None\n",
    "    print(\"\\tSnapshot PHS_ID: \" + str(phs_id))\n",
    "    print(\"\\tSource Workspace: \" + str(source_workspace))\n",
    "    print(\"\\tCurrent DUOS ID: \" + str(duos_id))\n",
    "    \n",
    "    # Pull information from existing DUOS registration (if listed)\n",
    "    if duos_id:\n",
    "        # Establish credentials\n",
    "        creds, project = google.auth.default()\n",
    "        auth_req = google.auth.transport.requests.Request()\n",
    "        creds.refresh(auth_req)\n",
    "        \n",
    "        # Pull existing DUOS registration\n",
    "        duos_dict = requests.get(\n",
    "            url=f\"https://consent.dsde-prod.broadinstitute.org/api/dataset/registration/{duos_id}\",\n",
    "            headers={\"Authorization\": f\"Bearer {creds.token}\"}\n",
    "        ).json()\n",
    "        print(duos_dict)\n",
    "    \n",
    "    # Pull information from original workspace (if listed)\n",
    "    if source_workspace:\n",
    "        # Establish credentials\n",
    "        creds, project = google.auth.default()\n",
    "        auth_req = google.auth.transport.requests.Request()\n",
    "        creds.refresh(auth_req)\n",
    "\n",
    "        # Pull workspace attributes\n",
    "        attempt_counter = 0\n",
    "        while attempt_counter <= 2:\n",
    "            try:\n",
    "                ws_attributes = requests.get(\n",
    "                    url=f\"https://api.firecloud.org/api/workspaces/anvil-datastorage/{source_workspace}?fields=workspace.attributes,workspace.authorizationDomain,workspace.googleProject,workspace.bucketName\",\n",
    "                    headers={\"Authorization\": f\"Bearer {creds.token}\"}\n",
    "                ).json()\n",
    "                break\n",
    "            except:\n",
    "                sleep(5)\n",
    "                attempt_counter += 1\n",
    "        \n",
    "        # Map to schema\n",
    "        if ws_attributes.get(\"workspace\"):\n",
    "            terra_dict[\"studyName\"] = coalesce(ws_attributes[\"workspace\"][\"attributes\"].get(\"library:projectName\"), source_workspace) \n",
    "            terra_dict[\"studyType\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:studyDesign\")\n",
    "            terra_dict[\"studyDescription\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"description\")\n",
    "            if ws_attributes[\"workspace\"][\"attributes\"].get(\"library:dataCategory\"):\n",
    "                terra_dict[\"dataTypes\"] = []\n",
    "                for item in ws_attributes[\"workspace\"][\"attributes\"][\"library:dataCategory\"][\"items\"]:\n",
    "                    inner_list = item.split(\",\")\n",
    "                    for inner_item in inner_list:\n",
    "                        inner_item = inner_item.replace(\"'\", \"\").strip()\n",
    "                        terra_dict[\"dataTypes\"].append(inner_item)\n",
    "            terra_dict[\"phenotypeIndication\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:indication\")\n",
    "            terra_dict[\"species\"] = \"Homo sapiens\"\n",
    "            terra_dict[\"piName\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:datasetOwner\")\n",
    "            terra_dict[\"dataCustodianEmail\"] = [ws_attributes[\"workspace\"][\"attributes\"].get(\"library:contactEmail\")]\n",
    "            if ws_attributes[\"workspace\"][\"attributes\"].get(\"tag:tags\"):\n",
    "                for tag in ws_attributes[\"workspace\"][\"attributes\"].get(\"tag:tags\")[\"items\"]:\n",
    "                    if \"Consortium:\" in tag:\n",
    "                        terra_dict[\"consortium\"] = tag.split(\":\")[1].strip()\n",
    "                    elif \"dbGaP:\" in tag:\n",
    "                        terra_dict[\"dbGaPPhsID\"] = format_phs_id(tag.split(\":\")[1].strip())\n",
    "                        if not phs_id:\n",
    "                            phs_id = format_phs_id(tag.split(\":\")[1].strip()) \n",
    "            terra_dict[\"consentGroups.consentCode\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:dataUseRestriction\")\n",
    "            if ws_attributes[\"workspace\"][\"attributes\"].get(\"library:datatype\"):\n",
    "                terra_dict[\"consentGroups.fileTypes.fileType\"] = ws_attributes[\"workspace\"][\"attributes\"][\"library:datatype\"][\"items\"]\n",
    "            if ws_attributes[\"workspace\"][\"attributes\"].get(\"library:numSubjects\"):\n",
    "                terra_dict[\"consentGroups.numberOfParticipants\"] = ws_attributes[\"workspace\"][\"attributes\"][\"library:numSubjects\"]\n",
    "#         print(\"------------------------------------------------------\")\n",
    "#         print(\"terra_dict\")\n",
    "#         print(terra_dict)\n",
    "        \n",
    "    # Pull information from dbGaP (if phs_id listed)\n",
    "#     print(\"PHS ID for dbGaP: \" + phs_id)\n",
    "    if phs_id:\n",
    "        # Pull and parse XML\n",
    "        phs_short = phs_id.replace(\"phs\", \"\")\n",
    "        dbgap_url = \"https://dbgap.ncbi.nlm.nih.gov/ss/dbgapssws.cgi?request=Study&phs=\" + phs_short\n",
    "        attempt_counter = 0\n",
    "        while attempt_counter <= 2:\n",
    "            try:\n",
    "                response = requests.get(url=dbgap_url)\n",
    "                xml_data = xmltodict.parse(response.text)\n",
    "                break\n",
    "            except:\n",
    "                sleep(5)\n",
    "                attempt_counter += 1\n",
    "        study_uid = \"\"\n",
    "\n",
    "        # Map to schema\n",
    "        if xml_data[\"dbgapss\"].get(\"Study\"):\n",
    "            if isinstance(xml_data[\"dbgapss\"][\"Study\"], list):\n",
    "                study_data = xml_data[\"dbgapss\"][\"Study\"][0]\n",
    "            else:\n",
    "                study_data = xml_data[\"dbgapss\"][\"Study\"] \n",
    "            study_uid = study_data.get(\"@uid\")\n",
    "            dbgap_xml_dict[\"studyName\"] = study_data[\"StudyInfo\"].get(\"StudyNameEntrez\")\n",
    "            dbgap_xml_dict[\"studyDescription\"] = study_data[\"StudyInfo\"].get(\"Description\")\n",
    "            dbgap_xml_dict[\"dbGaPPhsID\"] = phs_id\n",
    "            dbgap_xml_dict[\"dbGaPStudyRegistrationName\"] = study_data[\"StudyInfo\"].get(\"StudyNameEntrez\")\n",
    "            if study_data[\"Authority\"][\"Persons\"].get(\"Person\"):\n",
    "                for ap_entry in study_data[\"Authority\"][\"Persons\"][\"Person\"]:\n",
    "                    if ap_entry[\"Role\"] == \"PI\":\n",
    "                        dbgap_xml_dict[\"piName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "                        dbgap_xml_dict[\"piEmail\"] = ap_entry[\"@email\"]\n",
    "                        dbgap_xml_dict[\"piInstitution\"] = ap_entry[\"Organization\"]\n",
    "                    elif ap_entry[\"Role\"] == \"PO\" and ap_entry[\"Organization\"] == \"NIH\":\n",
    "                        dbgap_xml_dict[\"nihProgramOfficerName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "                    elif ap_entry[\"Role\"] == \"GPA\" and ap_entry[\"Organization\"] == \"NIH\":\n",
    "                        dbgap_xml_dict[\"nihGenomicProgramAdministratorName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "            ic_list = []\n",
    "            if isinstance(study_data[\"Authority\"][\"ICs\"][\"IC\"], list):\n",
    "                for ic_entry in study_data[\"Authority\"][\"ICs\"][\"IC\"]:\n",
    "                    ic_list.append(ic_entry[\"@name\"])\n",
    "            else:\n",
    "                ic_list.append(study_data[\"Authority\"][\"ICs\"][\"IC\"][\"@name\"])\n",
    "            dbgap_xml_dict[\"nihICsSupportingStudy\"] = ic_list\n",
    "            dbgap_xml_dict[\"consentGroups.numberOfParticipants\"] = study_data.get(\"@num_participants\")\n",
    "            dbgap_xml_dict[\"embargoReleaseDate\"] = study_data[\"Policy\"].get(\"@pub-embargo\")\n",
    "#             print(\"------------------------------------------------------\")\n",
    "#             print(\"dbgap_xml_dict\")\n",
    "#             print(dbgap_xml_dict)\n",
    "        \n",
    "        # Pull and parse Study API JSON\n",
    "        if study_uid:\n",
    "            dbgap_study_url = \"https://submit.ncbi.nlm.nih.gov/dbgap/api/v1/study_config/\" + str(study_uid)\n",
    "            attempt_counter = 0\n",
    "            while attempt_counter <= 2:\n",
    "                try:\n",
    "                    response = requests.get(url=dbgap_study_url)\n",
    "                    study_api_data = json.loads(response.text)\n",
    "                    break\n",
    "                except:\n",
    "                    sleep(5)\n",
    "                    attempt_counter += 1\n",
    "            \n",
    "            # Map to schema\n",
    "            if study_api_data.get(\"error\") == None:\n",
    "                dbgap_study_api_dict[\"studyName\"] = study_api_data[\"data\"].get(\"report_name\")\n",
    "                dbgap_study_api_dict[\"studyDescription\"] = study_api_data[\"data\"].get(\"description\")\n",
    "                dbgap_study_api_dict[\"phenotypeIndication\"] = study_api_data[\"data\"].get(\"primary_disease\")\n",
    "                dbgap_study_api_dict[\"studyType\"] = study_api_data[\"data\"].get(\"study_design\")\n",
    "                dbgap_study_api_dict[\"dbGaPPhsID\"] = phs_id\n",
    "                dbgap_study_api_dict[\"dbGaPStudyRegistrationName\"] = study_api_data[\"data\"].get(\"report_name\")\n",
    "                for attr_entry in study_api_data[\"data\"].get(\"attribution\"):\n",
    "                    if attr_entry.get(\"title\") == \"Principal Investigator\":\n",
    "                        dbgap_study_api_dict[\"piName\"] = attr_entry.get(\"name\")\n",
    "                        dbgap_study_api_dict[\"piInstitution\"] = attr_entry.get(\"institute\")\n",
    "                        break\n",
    "#             print(\"------------------------------------------------------\")\n",
    "#             print(\"dbgap_study_api_dict\")\n",
    "#             print(dbgap_study_api_dict)\n",
    "        \n",
    "        # Pull and parse FHIR API JSON\n",
    "        dbgap_fhir_url = \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/ResearchStudy?_format=json&_id=\" + phs_id\n",
    "        attempt_counter = 0\n",
    "        while attempt_counter <= 2:\n",
    "            try:\n",
    "                response = requests.get(url=dbgap_fhir_url)\n",
    "                fhir_data = json.loads(response.text)\n",
    "                break\n",
    "            except:\n",
    "                sleep(5)\n",
    "                attempt_counter += 1\n",
    "\n",
    "        # Map to schema\n",
    "        if fhir_data.get(\"entry\"):\n",
    "            dbgap_fhir_dict[\"studyName\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"title\")\n",
    "            dbgap_fhir_dict[\"studyDescription\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"description\")\n",
    "            dbgap_fhir_dict[\"dbGaPPhsID\"] = phs_id\n",
    "            dbgap_fhir_dict[\"dbGaPStudyRegistrationName\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"title\")\n",
    "            # NIH ICs\n",
    "            if \"Organization/\" in fhir_data[\"entry\"][0][\"resource\"][\"sponsor\"].get(\"reference\"):\n",
    "                dbgap_fhir_dict[\"nihICsSupportingStudy\"] = [fhir_data[\"entry\"][0][\"resource\"][\"sponsor\"].get(\"reference\")[13:]]\n",
    "            else:\n",
    "                ic_display = fhir_data[\"entry\"][0][\"resource\"][\"sponsor\"].get(\"display\")\n",
    "                if ic_display == \"National Human Genome Research Institute\":\n",
    "                    dbgap_fhir_dict[\"nihICsSupportingStudy\"] = [\"NHGRI\"]\n",
    "                else:\n",
    "                    dbgap_fhir_dict[\"nihICsSupportingStudy\"] = [ic_display]\n",
    "            # studyType\n",
    "            if fhir_data[\"entry\"][0][\"resource\"].get(\"category\"):\n",
    "                for cat_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"category\"):\n",
    "                    if cat_entry.get(\"coding\"):\n",
    "                        for coding_entry in cat_entry.get(\"coding\"):\n",
    "                            if coding_entry.get(\"system\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/CodeSystem/ResearchStudy-StudyDesign\":\n",
    "                                value = coding_entry.get(\"display\") if coding_entry.get(\"display\") else coding_entry.get(\"code\")\n",
    "                                if dbgap_fhir_dict.get(\"studyType\") and value:\n",
    "                                    dbgap_fhir_dict[\"studyType\"] += f\", {value}\"\n",
    "                                elif value:\n",
    "                                    dbgap_fhir_dict[\"studyType\"] = value\n",
    "            # dataTypes\n",
    "            dt_list = []\n",
    "            if fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"): \n",
    "                for ext_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "                    if ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-MolecularDataTypes\":\n",
    "                        for inner_ext_entry in ext_entry.get(\"extension\"):\n",
    "                            if inner_ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-MolecularDataTypes-MolecularDataType\":\n",
    "                                for coding_entry in inner_ext_entry[\"valueCodeableConcept\"].get(\"coding\"):\n",
    "                                    dt_list.append(coding_entry.get(\"code\"))\n",
    "            dbgap_fhir_dict[\"dataTypes\"] = dt_list\n",
    "            # phenotypeIndication\n",
    "            if fhir_data[\"entry\"][0][\"resource\"].get(\"focus\"):\n",
    "                for focus_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"focus\"):\n",
    "                    if focus_entry.get(\"coding\"):\n",
    "                        for coding_entry in focus_entry.get(\"coding\"):\n",
    "                            value = coding_entry.get(\"display\") if coding_entry.get(\"display\") else coding_entry.get(\"code\")\n",
    "                            if dbgap_fhir_dict.get(\"phenotypeIndication\") and value:\n",
    "                                dbgap_fhir_dict[\"phenotypeIndication\"] += f\", {value}\"\n",
    "                            elif value:\n",
    "                                dbgap_fhir_dict[\"phenotypeIndication\"] = value\n",
    "            # numberOfParticipants\n",
    "            if fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "                for ext_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "                    if ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-Content\":\n",
    "                        for inner_ext_entry in ext_entry.get(\"extension\"):\n",
    "                            if inner_ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-Content-NumSubjects\":\n",
    "                                dbgap_fhir_dict[\"consentGroups.numberOfParticipants\"] = inner_ext_entry[\"valueCount\"].get(\"code\")\n",
    "#         print(\"------------------------------------------------------\")\n",
    "#         print(\"dbgap_fhir_dict\")\n",
    "#         print(dbgap_fhir_dict)\n",
    "    \n",
    "    # Reconcile information and create final results\n",
    "    consent_code = coalesce(terra_dict.get(\"consentGroups.consentCode\"), dbgap_fhir_dict.get(\"consentGroups.consentCode\"), dbgap_xml_dict.get(\"consentGroups.consentCode\"), dbgap_study_api_dict.get(\"consentGroups.consentCode\"))\n",
    "    if consent_code:\n",
    "        consent_code = consent_code.upper().replace(\"_\", \"-\")\n",
    "    else:\n",
    "        consent_code = \"\"\n",
    "    consortium = coalesce(terra_dict.get(\"consortium\"), dbgap_fhir_dict.get(\"consortium\"), dbgap_xml_dict.get(\"consortium\"), dbgap_study_api_dict.get(\"consortium\"))\n",
    "    dbGaPPhsID = coalesce(dbgap_fhir_dict.get(\"dbGaPPhsID\"), dbgap_xml_dict.get(\"dbGaPPhsID\"), dbgap_study_api_dict.get(\"dbGaPPhsID\"), terra_dict.get(\"dbGaPPhsID\"))\n",
    "    studyName = coalesce(dbgap_fhir_dict.get(\"studyName\"), dbgap_xml_dict.get(\"studyName\"), dbgap_study_api_dict.get(\"studyName\"), terra_dict.get(\"studyName\"))\n",
    "    if dbGaPPhsID and consent_code:\n",
    "        study_consent = dbGaPPhsID + \":\" + consent_code\n",
    "        purl_doid = ds_consent_map.get(study_consent)\n",
    "    else:\n",
    "        purl_doid = None\n",
    "    final_results_dict[\"snapshot_id\"] = snapshot_id\n",
    "    final_results_dict[\"duos_id\"] = duos_id\n",
    "    if duos_id:\n",
    "        final_results_dict[\"studyName\"] = duos_dict.get(\"studyName\")\n",
    "        final_results_dict[\"studyType\"] = duos_dict.get(\"studyType\")\n",
    "        final_results_dict[\"studyDescription\"] = duos_dict.get(\"studyDescription\")\n",
    "        final_results_dict[\"dataTypes\"] = duos_dict.get(\"dataTypes\")\n",
    "        final_results_dict[\"phenotypeIndication\"] = duos_dict.get(\"phenotypeIndication\")\n",
    "        final_results_dict[\"species\"] = duos_dict.get(\"species\")\n",
    "        final_results_dict[\"piName\"] = duos_dict.get(\"piName\")\n",
    "        final_results_dict[\"dataCustodianEmail\"] = duos_dict.get(\"dataCustodianEmail\")\n",
    "        final_results_dict[\"publicVisibility\"] = duos_dict.get(\"publicVisibility\")\n",
    "        final_results_dict[\"nihAnvilUse\"] = \"I am NHGRI funded and I have a dbGaP PHS ID already\" if 'already' in duos_dict.get(\"nihAnvilUse\").lower() else \"I am NHGRI funded and I do not have a dbGaP PHS ID\"\n",
    "        final_results_dict[\"submittingToAnvil\"] = duos_dict.get(\"submittingToAnvil\")\n",
    "        final_results_dict[\"dbGaPPhsID\"] = duos_dict.get(\"dbGaPPhsID\")\n",
    "        final_results_dict[\"dbGaPStudyRegistrationName\"] = duos_dict.get(\"dbGaPStudyRegistrationName\")\n",
    "        final_results_dict[\"embargoReleaseDate\"] = duos_dict.get(\"embargoReleaseDate\")\n",
    "        final_results_dict[\"sequencingCenter\"] = duos_dict.get(\"sequencingCenter\")\n",
    "        final_results_dict[\"piEmail\"] = duos_dict.get(\"piEmail\")\n",
    "        final_results_dict[\"piInstitution\"] = duos_dict.get(\"piInstitution\")\n",
    "        final_results_dict[\"nihGrantContractNumber\"] = duos_dict.get(\"nihGrantContractNumber\")\n",
    "        final_results_dict[\"nihICsSupportingStudy\"] = duos_dict.get(\"nihICsSupportingStudy\")\n",
    "        final_results_dict[\"nihProgramOfficerName\"] = duos_dict.get(\"nihProgramOfficerName\")\n",
    "        final_results_dict[\"nihInstitutionCenterSubmission\"] = duos_dict.get(\"nihInstitutionCenterSubmission\")\n",
    "        final_results_dict[\"nihInstitutionalCertificationFileName\"] = duos_dict.get(\"nihInstitutionalCertificationFileName\")\n",
    "        final_results_dict[\"nihGenomicProgramAdministratorName\"] = duos_dict.get(\"nihGenomicProgramAdministratorName\")\n",
    "        final_results_dict[\"multiCenterStudy\"] = duos_dict.get(\"multiCenterStudy\")\n",
    "        final_results_dict[\"collaboratingSites\"] = duos_dict.get(\"collaboratingSites\")\n",
    "        final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSR\"] = duos_dict.get(\"controlledAccessRequiredForGenomicSummaryResultsGSR\")\n",
    "        final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation\"] = duos_dict.get(\"controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation\")\n",
    "        final_results_dict[\"alternativeDataSharingPlan\"] = duos_dict.get(\"alternativeDataSharingPlan\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanReasons\"] = duos_dict.get(\"alternativeDataSharingPlanReasons\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanExplanation\"] = duos_dict.get(\"alternativeDataSharingPlanExplanation\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanFileName\"] = duos_dict.get(\"alternativeDataSharingPlanFileName\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanDataSubmitted\"] = duos_dict.get(\"alternativeDataSharingPlanDataSubmitted\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanDataReleased\"] = duos_dict.get(\"alternativeDataSharingPlanDataReleased\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanTargetDeliveryDate\"] = duos_dict.get(\"alternativeDataSharingPlanTargetDeliveryDate\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanTargetPublicReleaseDate\"] = duos_dict.get(\"alternativeDataSharingPlanTargetPublicReleaseDate\")\n",
    "        final_results_dict[\"alternativeDataSharingPlanAccessManagement\"] = duos_dict.get(\"alternativeDataSharingPlanAccessManagement\")\n",
    "        final_results_dict[\"consentGroups.consentGroupName\"] = duos_dict[\"consentGroups\"][0].get(\"consentGroupName\")\n",
    "        final_results_dict[\"consentGroups.accessManagement\"] = duos_dict[\"consentGroups\"][0].get(\"accessManagement\")\n",
    "        final_results_dict[\"consentGroups.numberOfParticipants\"] = duos_dict[\"consentGroups\"][0].get(\"numberOfParticipants\")\n",
    "        final_results_dict[\"consentCode\"] = consent_code\n",
    "        final_results_dict[\"consentGroups.generalResearchUse\"] = duos_dict[\"consentGroups\"][0].get(\"generalResearchUse\")\n",
    "        final_results_dict[\"consentGroups.hmb\"] = duos_dict[\"consentGroups\"][0].get(\"hmb\")\n",
    "        final_results_dict[\"consentGroups.diseaseSpecificUse\"] = duos_dict[\"consentGroups\"][0].get(\"diseaseSpecificUse\")\n",
    "        final_results_dict[\"consentGroups.gs\"] = duos_dict[\"consentGroups\"][0].get(\"gs\")\n",
    "        final_results_dict[\"consentGroups.poa\"] = duos_dict[\"consentGroups\"][0].get(\"poa\")\n",
    "        final_results_dict[\"consentGroups.nmds\"] = duos_dict[\"consentGroups\"][0].get(\"nmds\")\n",
    "        final_results_dict[\"consentGroups.gso\"] = duos_dict[\"consentGroups\"][0].get(\"gso\")\n",
    "        final_results_dict[\"consentGroups.pub\"] = duos_dict[\"consentGroups\"][0].get(\"pub\")\n",
    "        final_results_dict[\"consentGroups.col\"] = duos_dict[\"consentGroups\"][0].get(\"col\")\n",
    "        final_results_dict[\"consentGroups.irb\"] = duos_dict[\"consentGroups\"][0].get(\"irb\")\n",
    "        final_results_dict[\"consentGroups.npu\"] = duos_dict[\"consentGroups\"][0].get(\"npu\")\n",
    "        final_results_dict[\"consentGroups.otherPrimary\"] = duos_dict[\"consentGroups\"][0].get(\"otherPrimary\")\n",
    "        final_results_dict[\"consentGroups.otherSecondary\"] = duos_dict[\"consentGroups\"][0].get(\"otherSecondary\")\n",
    "        final_results_dict[\"consentGroups.mor\"] = duos_dict[\"consentGroups\"][0].get(\"mor\")\n",
    "        final_results_dict[\"consentGroups.morDate\"] = duos_dict[\"consentGroups\"][0].get(\"morDate\")\n",
    "        final_results_dict[\"consentGroups.dataLocation\"] = duos_dict[\"consentGroups\"][0].get(\"dataLocation\")\n",
    "        final_results_dict[\"consentGroups.url\"] = \"https://data.terra.bio/snapshots/\" + snapshot_id\n",
    "        if duos_dict[\"consentGroups\"][0][\"fileTypes\"] and duos_dict[\"consentGroups\"][0][\"fileTypes\"].get(\"fileType\"):\n",
    "            final_results_dict[\"consentGroups.fileTypes.fileType\"] = duos_dict[\"consentGroups\"][0][\"fileTypes\"][0].get(\"fileType\")\n",
    "        else:\n",
    "            final_results_dict[\"consentGroups.fileTypes.fileType\"] = None\n",
    "        if duos_dict[\"consentGroups\"][0][\"fileTypes\"] and duos_dict[\"consentGroups\"][0][\"fileTypes\"].get(\"functionalEquivalence\"):\n",
    "            final_results_dict[\"consentGroups.fileTypes.functionalEquivalence\"] = duos_dict[\"consentGroups\"][0][\"fileTypes\"][0].get(\"functionalEquivalence\")\n",
    "        else:\n",
    "            final_results_dict[\"consentGroups.fileTypes.functionalEquivalence\"] = None\n",
    "        final_results_dict[\"consortium\"] = consortium\n",
    "    else:\n",
    "        if dbGaPPhsID:\n",
    "            final_results_dict[\"studyName\"] = studyName + f\" ({dbGaPPhsID})\"\n",
    "        else:\n",
    "            final_results_dict[\"studyName\"] = studyName\n",
    "        final_results_dict[\"studyType\"] = coalesce(dbgap_fhir_dict.get(\"studyType\"), dbgap_xml_dict.get(\"studyType\"), dbgap_study_api_dict.get(\"studyType\"), terra_dict.get(\"studyType\"))\n",
    "        final_results_dict[\"studyDescription\"] = format_description(coalesce(dbgap_fhir_dict.get(\"studyDescription\"), dbgap_xml_dict.get(\"studyDescription\"), dbgap_study_api_dict.get(\"studyDescription\"), terra_dict.get(\"studyDescription\")))\n",
    "        if final_results_dict[\"studyDescription\"]:\n",
    "            final_results_dict[\"studyDescription\"] = final_results_dict[\"studyDescription\"] + \"\\nPlatform: AnVIL\"\n",
    "        else:\n",
    "            final_results_dict[\"studyDescription\"] = \"Platform: AnVIL\"\n",
    "        final_results_dict[\"dataTypes\"] = coalesce(terra_dict.get(\"dataTypes\"), dbgap_fhir_dict.get(\"dataTypes\"), dbgap_xml_dict.get(\"dataTypes\"), dbgap_study_api_dict.get(\"dataTypes\"))\n",
    "        final_results_dict[\"phenotypeIndication\"] = coalesce(terra_dict.get(\"phenotypeIndication\"), dbgap_fhir_dict.get(\"phenotypeIndication\"), dbgap_xml_dict.get(\"phenotypeIndication\"), dbgap_study_api_dict.get(\"phenotypeIndication\"))\n",
    "        final_results_dict[\"species\"] = \"Human\"\n",
    "        final_results_dict[\"piName\"] = coalesce(dbgap_fhir_dict.get(\"piName\"), dbgap_xml_dict.get(\"piName\"), dbgap_study_api_dict.get(\"piName\"), terra_dict.get(\"piName\"), \"None\")\n",
    "        final_results_dict[\"dataCustodianEmail\"] = [\"help@lists.anvilproject.org\"]\n",
    "        final_results_dict[\"publicVisibility\"] = True\n",
    "        final_results_dict[\"nihAnvilUse\"] = \"I am NHGRI funded and I have a dbGaP PHS ID already\" if dbGaPPhsID else \"I am NHGRI funded and I do not have a dbGaP PHS ID\"\n",
    "        final_results_dict[\"submittingToAnvil\"] = True\n",
    "        final_results_dict[\"dbGaPPhsID\"] = dbGaPPhsID\n",
    "        final_results_dict[\"dbGaPStudyRegistrationName\"] = coalesce(dbgap_fhir_dict.get(\"dbGaPStudyRegistrationName\"), dbgap_xml_dict.get(\"dbGaPStudyRegistrationName\"), dbgap_study_api_dict.get(\"dbGaPStudyRegistrationName\"), terra_dict.get(\"dbGaPStudyRegistrationName\"))\n",
    "        final_results_dict[\"embargoReleaseDate\"] = coalesce(dbgap_fhir_dict.get(\"embargoReleaseDate\"), dbgap_xml_dict.get(\"embargoReleaseDate\"), dbgap_study_api_dict.get(\"embargoReleaseDate\"), terra_dict.get(\"embargoReleaseDate\"))\n",
    "        final_results_dict[\"sequencingCenter\"] = None\n",
    "        final_results_dict[\"piEmail\"] = coalesce(dbgap_fhir_dict.get(\"piEmail\"), dbgap_xml_dict.get(\"piEmail\"), dbgap_study_api_dict.get(\"piEmail\"), terra_dict.get(\"piEmail\"))\n",
    "        final_results_dict[\"piInstitution\"] = coalesce(dbgap_fhir_dict.get(\"piInstitution\"), dbgap_xml_dict.get(\"piInstitution\"), dbgap_study_api_dict.get(\"piInstitution\"), terra_dict.get(\"piInstitution\"))\n",
    "        final_results_dict[\"nihGrantContractNumber\"] = None\n",
    "        final_results_dict[\"nihICsSupportingStudy\"] = coalesce(dbgap_fhir_dict.get(\"nihICsSupportingStudy\"), dbgap_xml_dict.get(\"nihICsSupportingStudy\"), dbgap_study_api_dict.get(\"nihICsSupportingStudy\"), terra_dict.get(\"nihICsSupportingStudy\"))\n",
    "        final_results_dict[\"nihProgramOfficerName\"] = coalesce(dbgap_fhir_dict.get(\"nihProgramOfficerName\"), dbgap_xml_dict.get(\"nihProgramOfficerName\"), dbgap_study_api_dict.get(\"nihProgramOfficerName\"), terra_dict.get(\"nihProgramOfficerName\"))\n",
    "        final_results_dict[\"nihInstitutionCenterSubmission\"] = \"NHGRI\"\n",
    "        final_results_dict[\"nihInstitutionalCertificationFileName\"] = None\n",
    "        final_results_dict[\"nihGenomicProgramAdministratorName\"] = coalesce(dbgap_fhir_dict.get(\"nihGenomicProgramAdministratorName\"), dbgap_xml_dict.get(\"nihGenomicProgramAdministratorName\"), dbgap_study_api_dict.get(\"nihGenomicProgramAdministratorName\"), terra_dict.get(\"nihGenomicProgramAdministratorName\"))\n",
    "        final_results_dict[\"multiCenterStudy\"] = None\n",
    "        final_results_dict[\"collaboratingSites\"] = [consortium] if consortium else []\n",
    "        final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSR\"] = None\n",
    "        final_results_dict[\"controlledAccessRequiredForGenomicSummaryResultsGSRRequiredExplanation\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlan\"] = False\n",
    "        final_results_dict[\"alternativeDataSharingPlanReasons\"] = []\n",
    "        final_results_dict[\"alternativeDataSharingPlanExplanation\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlanFileName\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlanDataSubmitted\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlanDataReleased\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlanTargetDeliveryDate\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlanTargetPublicReleaseDate\"] = None\n",
    "        final_results_dict[\"alternativeDataSharingPlanAccessManagement\"] = None\n",
    "        final_results_dict[\"consentGroups.consentGroupName\"] = snapshot_name\n",
    "        final_results_dict[\"consentGroups.accessManagement\"] = access_management\n",
    "        final_results_dict[\"consentGroups.numberOfParticipants\"] = coalesce(terra_dict.get(\"consentGroups.numberOfParticipants\"), dbgap_fhir_dict.get(\"consentGroups.numberOfParticipants\"), dbgap_xml_dict.get(\"consentGroups.numberOfParticipants\"), dbgap_study_api_dict.get(\"consentGroups.numberOfParticipants\"), \"0\")\n",
    "        final_results_dict[\"consentCode\"] = consent_code\n",
    "        final_results_dict[\"consentGroups.generalResearchUse\"] = True if access_management == \"controlled\" and \"GRU\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.hmb\"] = True if access_management == \"controlled\" and \"HMB\" in consent_code else False\n",
    "        if purl_doid:\n",
    "            final_results_dict[\"consentGroups.diseaseSpecificUse\"] = [purl_doid]\n",
    "        else:\n",
    "            final_results_dict[\"consentGroups.diseaseSpecificUse\"] = [consent_code] if \"DS-\" in consent_code else []\n",
    "        final_results_dict[\"consentGroups.gs\"] = consent_code if access_management == \"controlled\" and \"GS-\" in consent_code else None\n",
    "        final_results_dict[\"consentGroups.poa\"] = True if access_management == \"controlled\" and \"POA\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.nmds\"] = True if access_management == \"controlled\" and \"NMDS\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.gso\"] = True if access_management == \"controlled\" and \"GSO\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.pub\"] = True if access_management == \"controlled\" and \"PUB\" in consent_code else False \n",
    "        final_results_dict[\"consentGroups.col\"] = True if access_management == \"controlled\" and \"COL\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.irb\"] = True if access_management == \"controlled\" and \"IRB\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.npu\"] = True if access_management == \"controlled\" and \"NPU\" in consent_code else False\n",
    "        final_results_dict[\"consentGroups.otherPrimary\"] = consent_code if (consent_code and access_management == \"controlled\" and not (final_results_dict[\"consentGroups.generalResearchUse\"] or final_results_dict[\"consentGroups.hmb\"] or final_results_dict[\"consentGroups.diseaseSpecificUse\"] or final_results_dict[\"consentGroups.gs\"] or final_results_dict[\"consentGroups.poa\"] or final_results_dict[\"consentGroups.nmds\"] or final_results_dict[\"consentGroups.gso\"] or final_results_dict[\"consentGroups.pub\"] or final_results_dict[\"consentGroups.col\"] or final_results_dict[\"consentGroups.irb\"] or final_results_dict[\"consentGroups.npu\"])) else None\n",
    "        final_results_dict[\"consentGroups.otherSecondary\"] = None\n",
    "        final_results_dict[\"consentGroups.mor\"] = None\n",
    "        final_results_dict[\"consentGroups.morDate\"] = None\n",
    "        final_results_dict[\"consentGroups.dataLocation\"] = \"TDR Location\"\n",
    "        final_results_dict[\"consentGroups.url\"] = \"https://data.terra.bio/snapshots/\" + snapshot_id\n",
    "        final_results_dict[\"consentGroups.fileTypes.fileType\"] = coalesce(terra_dict.get(\"consentGroups.fileTypes.fileType\"), dbgap_fhir_dict.get(\"consentGroups.fileTypes.fileType\"), dbgap_xml_dict.get(\"consentGroups.fileTypes.fileType\"), dbgap_study_api_dict.get(\"consentGroups.fileTypes.fileType\"))\n",
    "        final_results_dict[\"consentGroups.fileTypes.functionalEquivalence\"] = None\n",
    "        final_results_dict[\"consortium\"] = consortium\n",
    "    \n",
    "    # Return results\n",
    "    return final_results_dict\n",
    "\n",
    "\n",
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# Specify the snapshots to pull data for:\n",
    "snapshot_id_list = [\n",
    "    'e2736891-a569-449e-8cbf-b7d0274b64d0',\n",
    "]\n",
    "\n",
    "# Specify a mapping from phs-consent to DOID for DS consent codes (replace \"_\" with \"-\" in consent first)\n",
    "ds_consent_map = {\n",
    "    'phs000298:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs000693:DS-BDIS': 'http://purl.obolibrary.org/obo/DOID_936',\n",
    "    'phs000693:DS-EP': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs000744:DS-RD': 'http://purl.obolibrary.org/obo/DOID_15',\n",
    "    'phs000744:DS-THAL-IRB': 'http://purl.obolibrary.org/obo/DOID_10241',\n",
    "    'phs001222:DS-DRC-IRB-NPU': 'http://purl.obolibrary.org/obo/DOID_9351',\n",
    "    'phs001227:DS-ATHSCL-IRB-MDS': 'http://purl.obolibrary.org/obo/DOID_1936',\n",
    "    'phs001259:DS-CARD-MDS-GSO': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001487:DS-CVD-IRB-COL-MDS': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001489:DS-EAED-IRB-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EAED-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EARET-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EP': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EP-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EP-NPU': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPASM-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPASM-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPCOM-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPI-ADULT-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPI-MULTI-MDS': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBA-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBACID-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBACID-NPU-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-EPSBAID-MDS-RD': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs001489:DS-NSD-ADULTS-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_863',\n",
    "    'phs001489:DS-NSD-NPU-MDS': 'http://purl.obolibrary.org/obo/DOID_863',\n",
    "    'phs001506:DS-CVD-IRB': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001592:DS-CVD': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs001642:DS-GI': 'http://purl.obolibrary.org/obo/DOID_77',\n",
    "    'phs001642:DS-GI-18+-MDS': 'http://purl.obolibrary.org/obo/DOID_77',\n",
    "    'phs001642:DS-GI-IRB-MDS': 'http://purl.obolibrary.org/obo/DOID_77',\n",
    "    'phs001642:DS-GI,18+': 'http://purl.obolibrary.org/obo/DOID_77',\n",
    "    'phs001642:DS-GID': 'http://purl.obolibrary.org/obo/DOID_77',\n",
    "    'phs001642:DS-IBD': 'http://purl.obolibrary.org/obo/DOID_0050589',\n",
    "    'phs001642:DS-IBD-MDS': 'http://purl.obolibrary.org/obo/DOID_0050589',\n",
    "    'phs001676:DS-AONDD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001740:DS-ASD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001741:DS-ASD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001766:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001766:DS-ASD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs001871:DS-CAD-IRB-COL-NPU': 'http://purl.obolibrary.org/obo/DOID_3393',\n",
    "    'phs001894:DS-EAC-PUB-GSO': 'http://purl.obolibrary.org/obo/DOID_1826',\n",
    "    'phs002004:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002032:DS-SMA-MDS': 'http://purl.obolibrary.org/obo/DOID_12377',\n",
    "    'phs002041:DS-MLHLTH-MDS': 'http://purl.obolibrary.org/obo/DOID_150',\n",
    "    'phs002041:DS-SCZ-MDS': 'http://purl.obolibrary.org/obo/DOID_5419',\n",
    "    'phs002041:DS-SZRD-MDS': 'http://purl.obolibrary.org/obo/DOID_5419',\n",
    "    'phs002042:DS-ASD-MDS-PUB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002043:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002044:DS-ASD-IRB': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002206:DS-PEDD-IRB': 'http://purl.obolibrary.org/obo/DOID_4',\n",
    "    'phs002282:DS-CVDRF': 'http://purl.obolibrary.org/obo/DOID_1287',\n",
    "    'phs002502:DS-ASD': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002502:DS-ASD-MDS': 'http://purl.obolibrary.org/obo/DOID_0060041',\n",
    "    'phs002502:DS-ND': 'http://purl.obolibrary.org/obo/DOID_1289',\n",
    "}\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "dataset_details_records = []\n",
    "for snapshot_id in snapshot_id_list:\n",
    "    print(f\"Processing snapshot_id: {snapshot_id}...\")\n",
    "    dataset_details = fetch_dataset_details(snapshot_id, ds_consent_map)\n",
    "    dataset_details_records.append(dataset_details)\n",
    "output = pd.DataFrame(dataset_details_records)\n",
    "output_sorted = output.sort_values(by=[\"studyName\", \"consentGroups.consentGroupName\"], ascending=[True, True], ignore_index=True)\n",
    "\n",
    "#############################################\n",
    "## Validation and Output\n",
    "#############################################\n",
    "# Create copy of dataframe for unique value validation\n",
    "output_unique_val = output_sorted.copy()\n",
    "\n",
    "# Convert study list fields to strings\n",
    "list_fields = [\"dataTypes\", \"dataCustodianEmail\", \"nihICsSupportingStudy\", \"collaboratingSites\", \"alternativeDataSharingPlanReasons\"]\n",
    "for field in list_fields:\n",
    "    output_unique_val[field] = [try_join(l) for l in output_unique_val[field]]\n",
    "\n",
    "# Get unique values per study-level field, by study\n",
    "study_level_col_list = []\n",
    "for col in output_unique_val.columns:\n",
    "    if \"consentGroups.\" not in col and col not in [\"studyName\", \"snapshot_id\", \"consortium\", \"consentCode\"]:\n",
    "        study_level_col_list.append(col)\n",
    "df_unique = output_unique_val.groupby(\"studyName\")[study_level_col_list].nunique()\n",
    "df_unique[\"unique_value_validation\"] = df_unique.max(axis=1)\n",
    "df_unique[\"unique_value_validation\"] = [\"Pass\" if l <= 1 else \"Fail\" for l in df_unique[\"unique_value_validation\"]]\n",
    "\n",
    "# Create copy of dataframe for enum validation\n",
    "output_enum_val = output_sorted.copy()\n",
    "\n",
    "# Validate enum fields\n",
    "output_enum_val[\"studyType\"] = [val_study_type_enum(l) for l in output_enum_val[\"studyType\"]]\n",
    "output_enum_val[\"nihInstitutionCenterSubmission\"] = [val_nih_inst_center_sub_enum(l) for l in output_enum_val[\"nihInstitutionCenterSubmission\"]]\n",
    "output_enum_val[\"nihICsSupportingStudy\"] = [val_nih_ic_supp_study_enum(l) for l in output_enum_val[\"nihICsSupportingStudy\"]]\n",
    "output_enum_val[\"consentGroups.fileTypes.fileType\"] = [val_file_type_enum(l) for l in output_enum_val[\"consentGroups.fileTypes.fileType\"]]\n",
    "study_enum_cols = [\"studyType\", \"nihInstitutionCenterSubmission\", \"nihICsSupportingStudy\"]\n",
    "df_study_enum = output_enum_val.groupby(\"studyName\")[study_enum_cols].sum()\n",
    "df_study_enum[\"study_enum_value_validation\"] = df_study_enum.max(axis=1)\n",
    "df_study_enum[\"study_enum_value_validation\"] = [\"Pass\" if l < 1 else \"Fail\" for l in df_study_enum[\"study_enum_value_validation\"]]\n",
    "consent_group_enum_cols = [\"consentGroups.fileTypes.fileType\"]\n",
    "df_consent_group_enum = output_enum_val.groupby(\"consentGroups.consentGroupName\")[consent_group_enum_cols].sum()\n",
    "df_consent_group_enum[\"consent_group_enum_value_validation\"] = df_consent_group_enum.max(axis=1)\n",
    "df_consent_group_enum[\"consent_group_enum_value_validation\"] = [\"Pass\" if l < 1 else \"Fail\" for l in df_consent_group_enum[\"consent_group_enum_value_validation\"]]\n",
    "\n",
    "# Join validation dataframes to original dataframe\n",
    "output_sorted_validated = output_sorted.join(df_unique[\"unique_value_validation\"], on=\"studyName\", how=\"left\")\n",
    "output_sorted_validated = output_sorted_validated.join(df_study_enum[\"study_enum_value_validation\"], on=\"studyName\", how=\"left\")\n",
    "output_sorted_validated = output_sorted_validated.join(df_consent_group_enum[\"consent_group_enum_value_validation\"], on=\"consentGroups.consentGroupName\", how=\"left\")\n",
    "\n",
    "# Display outputs\n",
    "print(\"----------------------------------------------------------------------------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------------\")\n",
    "print(\"Validated Metadata Output:\")\n",
    "display(output_sorted_validated.style.hide(axis=\"index\"))\n",
    "print(\"\\n\")\n",
    "print(\"Unique Study Value Validation Results:\")\n",
    "df_unique.reset_index(inplace=True)\n",
    "display(df_unique.style.hide(axis=\"index\"))\n",
    "print(\"\\n\")\n",
    "print(\"Study Enum Value Validation Results:\")\n",
    "df_study_enum.reset_index(inplace=True)\n",
    "display(df_study_enum.style.hide(axis=\"index\"))\n",
    "print(\"\\n\")\n",
    "print(\"Consent Group Enum Value Validation Results:\")\n",
    "df_consent_group_enum.reset_index(inplace=True)\n",
    "display(df_consent_group_enum.style.hide(axis=\"index\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load Reviewed Metadata into DUOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4,
     23
    ]
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Functions\n",
    "#############################################\n",
    "\n",
    "def format_list(input_list, min_items):\n",
    "    if input_list:\n",
    "        if isinstance(input_list, list):\n",
    "            return input_list\n",
    "        elif isinstance(input_list, str):\n",
    "            return format_list(ast.literal_eval(input_list), min_items)\n",
    "        else:\n",
    "            return []\n",
    "    else:\n",
    "        if min_items > 0:\n",
    "            i = 0\n",
    "            temp_list = []\n",
    "            while i < min_items:\n",
    "                temp_list.append(\"Unknown\")\n",
    "                i += 1\n",
    "            return temp_list\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "def format_file_types(ft_list, fe):\n",
    "    if ft_list:\n",
    "        output_list = []\n",
    "        formatted_ft_list = format_list(ft_list, 0)\n",
    "        for ft in formatted_ft_list:\n",
    "            ft_dict = {\"fileType\": ft}\n",
    "            if fe:\n",
    "                ft_dict[\"functionalEquivalence\"] = fe\n",
    "            else:\n",
    "                ft_dict[\"functionalEquivalence\"] = \"Unknown\"\n",
    "            output_list.append(ft_dict)\n",
    "        return output_list\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "def upload_to_duos(input_file, token, env, dac_id):\n",
    "    \n",
    "    # Determine the target URL from the env variable\n",
    "    if env == \"prod\":\n",
    "        url = \"https://consent.dsde-prod.broadinstitute.org\"\n",
    "    else:\n",
    "        url = \"https://consent.dsde-dev.broadinstitute.org\"\n",
    "    \n",
    "    # Pull down specified file from the cloud\n",
    "    results_log = []\n",
    "    print(f\"Downloading input file {input_file}...\")\n",
    "    try:\n",
    "        input_df = pd.read_csv(input_file_gcs_path, delimiter = \"\\t\", encoding='unicode_escape')\n",
    "        input_df = input_df.astype(object).where(pd.notnull(input_df),None)\n",
    "        input_df.fillna(\"\",inplace=True)\n",
    "        input_dict = input_df.to_dict(orient=\"records\")\n",
    "        results_log.append([\"Input File Download\", \"Succeeded\", \"\"])\n",
    "    except Exception as e:\n",
    "        msg = f\"Error downloading input file ({input_file}): {str(e)}\"\n",
    "        results_log.append([\"Input File Download\", \"Failed\", msg])\n",
    "        print(msg)\n",
    "        return results_log\n",
    "\n",
    "    # Pull a list of existing datasets and studies from DUOS and build lookup dicts\n",
    "    print(\"Building study and dataset lookup dicts from DUOS...\")\n",
    "    try:\n",
    "        datasets = requests.get(\n",
    "            url=f\"{url}/api/dataset/v2?asCustodian=false\",\n",
    "            headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "        ).json()\n",
    "        study_lookup = {}\n",
    "        for dataset_entry in datasets:\n",
    "            if dataset_entry[\"study\"].get(\"name\"):\n",
    "                if not study_lookup.get(dataset_entry[\"study\"][\"name\"]):\n",
    "                    study_lookup[dataset_entry[\"study\"][\"name\"]] = dataset_entry[\"study\"][\"studyId\"]\n",
    "        dataset_lookup = {}\n",
    "        for dataset_entry in datasets:\n",
    "            if dataset_entry.get(\"name\"):\n",
    "                dataset_lookup[dataset_entry[\"name\"]] = dataset_entry[\"dataSetId\"]\n",
    "        results_log.append([\"DUOS Study and Dataset Lookup Dict Creation\", \"Succeeded\", \"\"])\n",
    "    except Exception as e:\n",
    "        msg = f\"Error building study and dataset lookups: {str(e)}\"\n",
    "        results_log.append([\"DUOS Study and Dataset Lookup Dict Creation\", \"Failed\", msg])\n",
    "        print(msg)\n",
    "        return results_log\n",
    "    \n",
    "    # Parse and build DUOS schema for inputted file\n",
    "    print(\"Parsing input file and formatting into DUOS schema...\")\n",
    "    try:\n",
    "        # Determine data submitter id\n",
    "        response = requests.get(\n",
    "            url=f\"{url}/api/user/me\",\n",
    "            headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "        ).json()\n",
    "        data_submitter_id = response[\"userId\"]\n",
    "        # Build dictionary for upload\n",
    "        upload_dict = {}\n",
    "        for input_entry in input_dict:\n",
    "            snapshot_id = input_entry[\"snapshot_id\"]\n",
    "            study_name = input_entry[\"studyName\"]\n",
    "            consent_group_name = input_entry[\"consentGroups.consentGroupName\"]\n",
    "            access_type = input_entry[\"consentGroups.accessManagement\"]\n",
    "            print(f\"Parsing and formatting metadata for snapshot {snapshot_id} from the input file. Target study is: {study_name}\")\n",
    "            study_id = study_lookup.get(study_name)\n",
    "            dataset_id = dataset_lookup.get(consent_group_name)\n",
    "            if study_id and dataset_id:\n",
    "                consent_group_dict = {\n",
    "                            \"consentGroupName\": consent_group_name,\n",
    "                            \"datasetId\": dataset_id,\n",
    "                            \"numberOfParticipants\": input_entry[\"consentGroups.numberOfParticipants\"],\n",
    "                            \"dataLocation\": input_entry[\"consentGroups.dataLocation\"],\n",
    "                            \"url\": input_entry[\"consentGroups.url\"],\n",
    "                            \"fileTypes\": []\n",
    "                            #\"fileTypes\": format_file_types(input_entry[\"consentGroups.fileTypes.fileType\"], input_entry[\"consentGroups.fileTypes.functionalEquivalence\"]) --> Enumeration, exclude for now\n",
    "                    }\n",
    "            elif access_type == \"open\":\n",
    "                consent_group_dict = {\n",
    "                            \"consentGroupName\": consent_group_name,\n",
    "                            \"accessManagement\": access_type,\n",
    "                            \"numberOfParticipants\": input_entry[\"consentGroups.numberOfParticipants\"],\n",
    "                            \"dataLocation\": input_entry[\"consentGroups.dataLocation\"],\n",
    "                            \"url\": input_entry[\"consentGroups.url\"],\n",
    "                            \"fileTypes\": []\n",
    "                            #\"fileTypes\": format_file_types(input_entry[\"consentGroups.fileTypes.fileType\"], input_entry[\"consentGroups.fileTypes.functionalEquivalence\"]) --> Enumeration, exclude for now\n",
    "                    }\n",
    "            else:\n",
    "                consent_group_dict = {\n",
    "                            \"consentGroupName\": consent_group_name,\n",
    "                            \"dataAccessCommitteeId\": dac_id,\n",
    "                            \"accessManagement\": access_type,\n",
    "                            \"numberOfParticipants\": input_entry[\"consentGroups.numberOfParticipants\"],\n",
    "                            \"generalResearchUse\": input_entry[\"consentGroups.generalResearchUse\"],\n",
    "                            \"hmb\": input_entry[\"consentGroups.hmb\"],\n",
    "                            \"diseaseSpecificUse\": format_list(input_entry[\"consentGroups.diseaseSpecificUse\"], 0),\n",
    "                            \"gs\": input_entry[\"consentGroups.gs\"],\n",
    "                            \"poa\": input_entry[\"consentGroups.poa\"],\n",
    "                            \"nmds\": input_entry[\"consentGroups.nmds\"],\n",
    "                            \"gso\": input_entry[\"consentGroups.gso\"],\n",
    "                            \"pub\": input_entry[\"consentGroups.pub\"],\n",
    "                            \"col\": input_entry[\"consentGroups.col\"],\n",
    "                            \"irb\": input_entry[\"consentGroups.irb\"],\n",
    "                            \"npu\": input_entry[\"consentGroups.npu\"],\n",
    "                            #\"otherPrimary\": input_entry[\"consentGroups.otherPrimary\"], --> Excluding for now, per JL's request\n",
    "                            #\"otherSecondary\": input_entry[\"consentGroups.otherSecondary\"], --> Excluding for now, per JL's request\n",
    "                            #\"mor\": input_entry[\"consentGroups.mor\"], --> Date formatting validation for morDate, exclude for now\n",
    "                            #\"morDate\": input_entry[\"consentGroups.morDate\"], --> Date formatting validation, exclude for now\n",
    "                            \"dataLocation\": input_entry[\"consentGroups.dataLocation\"],\n",
    "                            \"url\": input_entry[\"consentGroups.url\"],\n",
    "                            \"fileTypes\": []\n",
    "                            #\"fileTypes\": format_file_types(input_entry[\"consentGroups.fileTypes.fileType\"], input_entry[\"consentGroups.fileTypes.functionalEquivalence\"]) --> Enumeration, exclude for now\n",
    "                    }\n",
    "            study_dict = {}\n",
    "            consent_group_list = []\n",
    "            if study_name not in upload_dict.keys():\n",
    "                consent_group_list.append(consent_group_dict)\n",
    "                study_dict = {\n",
    "                    \"studyName\": study_name,\n",
    "                    #\"studyType\": input_entry[\"studyType\"], --> Enumeration, exclude for now\n",
    "                    \"studyDescription\": input_entry[\"studyDescription\"],\n",
    "                    \"dataTypes\": format_list(input_entry[\"dataTypes\"], 1),\n",
    "                    \"phenotypeIndication\": input_entry[\"phenotypeIndication\"],\n",
    "                    \"species\": input_entry[\"species\"],\n",
    "                    \"piName\": input_entry[\"piName\"] if input_entry[\"piName\"] else \"NA\",\n",
    "                    \"dataSubmitterUserId\": data_submitter_id,\n",
    "                    \"dataCustodianEmail\": format_list(input_entry[\"dataCustodianEmail\"], 0),\n",
    "                    \"publicVisibility\": input_entry[\"publicVisibility\"],\n",
    "                    \"nihAnvilUse\": input_entry[\"nihAnvilUse\"],\n",
    "                    \"submittingToAnvil\": input_entry[\"submittingToAnvil\"],\n",
    "                    \"dbGaPPhsID\": input_entry[\"dbGaPPhsID\"],\n",
    "                    \"dbGaPStudyRegistrationName\": input_entry[\"studyName\"],\n",
    "                    #\"embargoReleaseDate\": input_entry[\"embargoReleaseDate\"], --> Date formatting validation, exclude for now\n",
    "                    \"sequencingCenter\": input_entry[\"sequencingCenter\"],\n",
    "                    \"piEmail\": input_entry[\"piEmail\"],\n",
    "                    #\"piInstitution\": input_entry[\"piInstitution\"], --> Integer ID for registered institutions, exclude for now\n",
    "                    \"piInstitution\": 0,\n",
    "                    \"nihGrantContractNumber\": \"Unknown\", # Required currently\n",
    "                    \"nihICsSupportingStudy\": format_list(input_entry[\"nihICsSupportingStudy\"], 0),\n",
    "                    \"nihProgramOfficerName\": input_entry[\"nihProgramOfficerName\"],\n",
    "                    \"nihInstitutionCenterSubmission\": input_entry[\"nihInstitutionCenterSubmission\"],\n",
    "                    \"nihInstitutionalCertificationFileName\": input_entry[\"nihInstitutionalCertificationFileName\"],\n",
    "                    \"nihGenomicProgramAdministratorName\": input_entry[\"nihGenomicProgramAdministratorName\"],\n",
    "                    \"collaboratingSites\": format_list(input_entry[\"collaboratingSites\"], 0),\n",
    "                    \"alternativeDataSharingPlan\": input_entry[\"alternativeDataSharingPlan\"],\n",
    "                    \"consentGroups\": consent_group_list\n",
    "                }\n",
    "                upload_dict[study_name] = study_dict\n",
    "            else:\n",
    "                for consent_group in upload_dict[study_name][\"consentGroups\"]:\n",
    "                    if consent_group[\"consentGroupName\"] != consent_group_dict[\"consentGroupName\"]:\n",
    "                        consent_group_list.append(consent_group)\n",
    "                consent_group_list.append(consent_group_dict)\n",
    "                study_dict = {\n",
    "                    \"studyName\": study_name,\n",
    "                    #\"studyType\": upload_dict[study_name][\"studyType\"], --> Enumeration, exclude for now\n",
    "                    \"studyDescription\": upload_dict[study_name][\"studyDescription\"],\n",
    "                    \"dataTypes\": upload_dict[study_name][\"dataTypes\"],\n",
    "                    \"phenotypeIndication\": upload_dict[study_name][\"phenotypeIndication\"],\n",
    "                    \"species\": upload_dict[study_name][\"species\"],\n",
    "                    \"piName\": upload_dict[study_name][\"piName\"] if upload_dict[study_name][\"piName\"] else \"NA\",\n",
    "                    \"dataSubmitterUserId\": upload_dict[study_name][\"dataSubmitterUserId\"],\n",
    "                    \"dataCustodianEmail\": upload_dict[study_name][\"dataCustodianEmail\"],\n",
    "                    \"publicVisibility\": upload_dict[study_name][\"publicVisibility\"],\n",
    "                    \"nihAnvilUse\": upload_dict[study_name][\"nihAnvilUse\"],\n",
    "                    \"submittingToAnvil\": upload_dict[study_name][\"submittingToAnvil\"],\n",
    "                    \"dbGaPPhsID\": upload_dict[study_name][\"dbGaPPhsID\"],\n",
    "                    \"dbGaPStudyRegistrationName\": upload_dict[study_name][\"studyName\"],\n",
    "                    #\"embargoReleaseDate\": upload_dict[study_name][\"embargoReleaseDate\"], --> Date formatting validation, exclude for now\n",
    "                    \"sequencingCenter\": upload_dict[study_name][\"sequencingCenter\"],\n",
    "                    \"piEmail\": upload_dict[study_name][\"piEmail\"],\n",
    "                    #\"piInstitution\": upload_dict[study_name][\"piInstitution\"], --> Integer ID for registered institutions, exclude for now\n",
    "                    \"piInstitution\": upload_dict[study_name][\"piInstitution\"],\n",
    "                    \"nihGrantContractNumber\": upload_dict[study_name][\"nihGrantContractNumber\"],\n",
    "                    \"nihICsSupportingStudy\": upload_dict[study_name][\"nihICsSupportingStudy\"],\n",
    "                    \"nihProgramOfficerName\": upload_dict[study_name][\"nihProgramOfficerName\"],\n",
    "                    \"nihInstitutionCenterSubmission\": upload_dict[study_name][\"nihInstitutionCenterSubmission\"],\n",
    "                    \"nihInstitutionalCertificationFileName\": upload_dict[study_name][\"nihInstitutionalCertificationFileName\"],\n",
    "                    \"nihGenomicProgramAdministratorName\": upload_dict[study_name][\"nihGenomicProgramAdministratorName\"],\n",
    "                    \"collaboratingSites\": upload_dict[study_name][\"collaboratingSites\"],\n",
    "                    \"alternativeDataSharingPlan\": upload_dict[study_name][\"alternativeDataSharingPlan\"],\n",
    "                    \"consentGroups\": consent_group_list\n",
    "                }\n",
    "                upload_dict[study_name] = study_dict\n",
    "        results_log.append([\"Input File Formatting\", \"Succeeded\", \"\"])\n",
    "    except Exception as e:\n",
    "        msg = f\"Error parsing and formatting input file: {str(e)}\"\n",
    "        results_log.append([\"Input File Formatting\", \"Failed\", msg])\n",
    "        print(msg)\n",
    "        return results_log\n",
    "    \n",
    "    # Loop through studies and dataset to upload\n",
    "    for study in upload_dict.keys():\n",
    "        print(f\"Uploading data for study {study} into DUOS\")\n",
    "        # For studies that don't exist in DUOS, create a new study\n",
    "        if not study_lookup.get(study):\n",
    "            print(\"Study does NOT currently exist in DUOS. Creating new study and dataset records...\")\n",
    "            try:\n",
    "                new_study_response = requests.post(\n",
    "                    url=f\"{url}/api/dataset/v3\",\n",
    "                    headers={\"Authorization\": f\"Bearer {token}\"},\n",
    "                    files = {\n",
    "                        \"dataset\": json.dumps(upload_dict[study]),\n",
    "                        \"alternativeDataSharingPlan\": \"\",\n",
    "                        \"consentGroups[0].nihInstitutionalCertificationFile\": \"\"  \n",
    "                    }\n",
    "                ).json()\n",
    "                if new_study_response.get(\"studyId\"):\n",
    "                    study_id = new_study_response[\"studyId\"]\n",
    "                    msg = f\"Study registration succeeded! Study Id: {study_id}\"\n",
    "                    results_log.append([f\"New Study Registration - {study}\", \"Succeeded\", msg])\n",
    "                    print(msg)\n",
    "                else:\n",
    "                    err_msg = new_study_response[\"message\"]\n",
    "                    msg = f\"Study registration failed: {err_msg}\"\n",
    "                    results_log.append([f\"New Study Registration - {study}\", \"Failed\", msg])\n",
    "                    print(msg)\n",
    "            except Exception as e:\n",
    "                msg = f\"Study registration failed: {str(e)}\"\n",
    "                results_log.append([f\"New Study Registration - {study}\", \"Failed\", msg])\n",
    "                print(msg)\n",
    "                \n",
    "        # For studies that already exist in DUOS, lookup the study ID and update the existing study\n",
    "        else:\n",
    "            print(\"Study currently exists in DUOS. Updating study and dataset records...\")\n",
    "            pass\n",
    "            try:\n",
    "                # Update study in DUOS\n",
    "                study_id = study_lookup.get(study)\n",
    "                update_study_response = requests.put(\n",
    "                    url=f\"{url}/api/dataset/study/{study_id}\",\n",
    "                    headers={\"Authorization\": f\"Bearer {token}\"},\n",
    "                    files = {\n",
    "                        \"dataset\": json.dumps(upload_dict[study]),\n",
    "                        \"alternativeDataSharingPlan\": \"\",\n",
    "                        \"consentGroups[0].nihInstitutionalCertificationFile\": \"\"  \n",
    "                    }\n",
    "                ).json()   \n",
    "                if update_study_response.get(\"studyId\"):\n",
    "                    study_id = update_study_response[\"studyId\"]\n",
    "                    msg = f\"Study registration succeeded! Study Id: {study_id}\"\n",
    "                    results_log.append([f\"New Study Registration - {study}\", \"Succeeded\", msg])\n",
    "                    print(msg)\n",
    "                else:\n",
    "                    err_msg = update_study_response[\"message\"]\n",
    "                    msg = f\"Study registration failed: {err_msg}\"\n",
    "                    results_log.append([f\"New Study Registration - {study}\", \"Failed\", msg])\n",
    "                    print(msg)\n",
    "            except Exception as e:\n",
    "                msg = f\"Study registration failed: {str(e)}\"\n",
    "                results_log.append([f\"Study Registration Update - {study}\", \"Failed\", msg])\n",
    "                print(msg)\n",
    "    \n",
    "    # Return results\n",
    "    return results_log\n",
    "\n",
    "\n",
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# Cloud path to file to process\n",
    "input_file_gcs_path = \"gs://fc-2a9eefc3-0302-427f-9ac3-82f078741c03/dataset_metadata/anvil_dataset_metadata_20240118.txt\"\n",
    "\n",
    "# User token (use gcloud auth print-access-token to get this)\n",
    "token = \"ya29.a0AfB_byA59-WdVXqNoRcXwz5AO9WYA4uh7VUXxE7geMG0T8_LZmrAZ6CzuDt7vuu9eyt5WlfpNPN5W4tjTXlC5MWqiYz_7Akvm2VPJlAHlpZEtYFLZbS8RvJWCJJaaB6ZMDQJ3sHeBxE2Rm2wn1W5IitiZE93KHfXcb7B4uDnTwaCgYKAf8SARMSFQHGX2MiYGdreccHTRdJyEkINT7G_Q0177\"\n",
    "\n",
    "# Environment\n",
    "env = \"dev\"\n",
    "\n",
    "# Target DAC identifier\n",
    "dac_id = 2\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "\n",
    "upload_results = upload_to_duos(input_file_gcs_path, token, env, dac_id)\n",
    "df_results = pd.DataFrame(upload_results, columns = [\"Item\", \"Status\", \"Message\"])\n",
    "print(\"\\nUpload Results:\")\n",
    "display(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_file = \"gs://fc-2a9eefc3-0302-427f-9ac3-82f078741c03/dataset_metadata/dataset_metadata_1.txt\"\n",
    "token = \"ya29.a0AfB_byDTAjxdDOD3uehlSc89iGlnT3IvhteIM0J0XEn9xNE2tW75KXokeLNTpCzjE909nQuKy3eRgs-oQ4GM6UpwzkyzgdDEoA-a3N_2oFq4c1V_ER8z-QTwipH5Zz09w4k_H-t8vdUKotABaY0vJrfZeNBP3CRG2gFdSkWr7gaCgYKAR0SARMSFQHGX2Mifw3ecrSERdjCU16UthJy1g0177\"\n",
    "\n",
    "# Pull down specified file from the cloud\n",
    "results_log = []\n",
    "print(f\"Downloading input file {input_file}...\")\n",
    "try:\n",
    "    input_df = pd.read_csv(input_file_gcs_path, delimiter = \"\\t\", encoding='unicode_escape')\n",
    "    input_df = input_df.astype(object).where(pd.notnull(input_df),None)\n",
    "    input_df.fillna(\"\",inplace=True)\n",
    "    input_dict = input_df.to_dict(orient=\"records\")\n",
    "    results_log.append([\"Input File Download\", \"Succeeded\", \"\"])\n",
    "except Exception as e:\n",
    "    msg = f\"Error downloading input file ({input_file}): {str(e)}\"\n",
    "    results_log.append([\"Input File Download\", \"Failed\", msg])\n",
    "    print(msg)\n",
    "#     return results_log\n",
    "\n",
    "# Pull a list of existing datasets and studies from DUOS and build lookup dicts\n",
    "print(\"Building study and dataset lookup dicts from DUOS...\")\n",
    "try:\n",
    "    datasets = requests.get(\n",
    "        url=f\"https://consent.dsde-dev.broadinstitute.org/api/dataset/v2?asCustodian=false\",\n",
    "        headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "    ).json()\n",
    "    study_lookup = {}\n",
    "    dataset_lookup = {}\n",
    "    for dataset_entry in datasets:\n",
    "        if dataset_entry[\"study\"].get(\"name\"):\n",
    "            if not study_lookup.get(dataset_entry[\"study\"][\"name\"]):\n",
    "                study_lookup[dataset_entry[\"study\"][\"name\"]] = dataset_entry[\"study\"][\"studyId\"]\n",
    "        if dataset_entry.get(\"name\"):\n",
    "            dataset_lookup[dataset_entry[\"name\"]] = dataset_entry[\"dataSetId\"]\n",
    "    results_log.append([\"DUOS Study and Dataset Lookup Dict Creation\", \"Succeeded\", \"\"])\n",
    "except Exception as e:\n",
    "    msg = f\"Error building study and dataset lookups: {str(e)}\"\n",
    "    results_log.append([\"DUOS Study and Dataset Lookup Dict Creation\", \"Failed\", msg])\n",
    "    print(msg)\n",
    "#     return results_log\n",
    "\n",
    "# Parse and build DUOS schema for inputted file\n",
    "print(\"Parsing input file and formatting into DUOS schema...\")\n",
    "try:\n",
    "    # Determine data submitter id\n",
    "    response = requests.get(\n",
    "        url=f\"https://consent.dsde-dev.broadinstitute.org/api/user/me\",\n",
    "        headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "    ).json()\n",
    "    data_submitter_id = response[\"userId\"]\n",
    "    # Build dictionary for upload\n",
    "    upload_dict = {}\n",
    "    for input_entry in input_dict:\n",
    "        snapshot_id = input_entry[\"snapshot_id\"]\n",
    "        study_name = input_entry[\"studyName\"]\n",
    "        consent_group_name = input_entry[\"consentGroups.consentGroupName\"]\n",
    "        print(f\"Parsing and formatting metadata for snapshot {snapshot_id} from the input file. Target study is: {study_name}\")\n",
    "        study_id = study_lookup.get(study_name)\n",
    "        dataset_id = dataset_lookup.get(consent_group_name)\n",
    "        if study_id and dataset_id:\n",
    "            consent_group_dict = {\n",
    "                        \"consentGroupName\": consent_group_name,\n",
    "                        \"datasetId\": dataset_id,\n",
    "                        \"numberOfParticipants\": input_entry[\"consentGroups.numberOfParticipants\"],\n",
    "                        \"dataLocation\": input_entry[\"consentGroups.dataLocation\"],\n",
    "                        \"url\": input_entry[\"consentGroups.url\"],\n",
    "                        \"fileTypes\": []\n",
    "                        #\"fileTypes\": format_file_types(input_entry[\"consentGroups.fileTypes.fileType\"], input_entry[\"consentGroups.fileTypes.functionalEquivalence\"]) --> Enumeration, exclude for now\n",
    "                }\n",
    "        else:\n",
    "            consent_group_dict = {\n",
    "                        \"consentGroupName\": consent_group_name,\n",
    "                        \"dataAccessCommitteeId\": 3,\n",
    "                        \"accessManagement\": input_entry[\"consentGroups.accessManagement\"],\n",
    "                        \"numberOfParticipants\": input_entry[\"consentGroups.numberOfParticipants\"],\n",
    "                        \"generalResearchUse\": input_entry[\"consentGroups.generalResearchUse\"],\n",
    "                        \"hmb\": input_entry[\"consentGroups.hmb\"],\n",
    "                        \"diseaseSpecificUse\": format_list(input_entry[\"consentGroups.diseaseSpecificUse\"], 0),\n",
    "                        \"gs\": input_entry[\"consentGroups.gs\"],\n",
    "                        \"poa\": input_entry[\"consentGroups.poa\"],\n",
    "                        \"nmds\": input_entry[\"consentGroups.nmds\"],\n",
    "                        \"gso\": input_entry[\"consentGroups.gso\"],\n",
    "                        \"pub\": input_entry[\"consentGroups.pub\"],\n",
    "                        \"col\": input_entry[\"consentGroups.col\"],\n",
    "                        \"irb\": input_entry[\"consentGroups.irb\"],\n",
    "                        \"npu\": input_entry[\"consentGroups.npu\"],\n",
    "                        \"otherPrimary\": input_entry[\"consentGroups.otherPrimary\"],\n",
    "                        \"otherSecondary\": input_entry[\"consentGroups.otherSecondary\"],\n",
    "                        #\"mor\": input_entry[\"consentGroups.mor\"], --> Date formatting validation for morDate, exclude for now\n",
    "                        #\"morDate\": input_entry[\"consentGroups.morDate\"], --> Date formatting validation, exclude for now\n",
    "                        \"dataLocation\": input_entry[\"consentGroups.dataLocation\"],\n",
    "                        \"url\": input_entry[\"consentGroups.url\"],\n",
    "                        \"fileTypes\": []\n",
    "                        #\"fileTypes\": format_file_types(input_entry[\"consentGroups.fileTypes.fileType\"], input_entry[\"consentGroups.fileTypes.functionalEquivalence\"]) --> Enumeration, exclude for now\n",
    "                }\n",
    "        study_dict = {}\n",
    "        consent_group_list = []\n",
    "        if study_name not in upload_dict.keys():\n",
    "            consent_group_list.append(consent_group_dict)\n",
    "            study_dict = {\n",
    "                \"studyName\": study_name,\n",
    "                #\"studyType\": input_entry[\"studyType\"], --> Enumeration, exclude for now\n",
    "                \"studyDescription\": input_entry[\"studyDescription\"],\n",
    "                \"dataTypes\": format_list(input_entry[\"dataTypes\"], 1),\n",
    "                \"phenotypeIndication\": input_entry[\"phenotypeIndication\"],\n",
    "                \"species\": input_entry[\"species\"],\n",
    "                \"piName\": input_entry[\"piName\"],\n",
    "                \"dataSubmitterUserId\": data_submitter_id,\n",
    "                \"dataCustodianEmail\": format_list(input_entry[\"dataCustodianEmail\"], 0),\n",
    "                \"publicVisibility\": input_entry[\"publicVisibility\"],\n",
    "                \"nihAnvilUse\": input_entry[\"nihAnvilUse\"],\n",
    "                \"submittingToAnvil\": input_entry[\"submittingToAnvil\"],\n",
    "                \"dbGaPPhsID\": input_entry[\"dbGaPPhsID\"],\n",
    "                \"dbGaPStudyRegistrationName\": input_entry[\"studyName\"],\n",
    "                #\"embargoReleaseDate\": input_entry[\"embargoReleaseDate\"], --> Date formatting validation, exclude for now\n",
    "                \"sequencingCenter\": input_entry[\"sequencingCenter\"],\n",
    "                \"piEmail\": input_entry[\"piEmail\"],\n",
    "                #\"piInstitution\": input_entry[\"piInstitution\"], --> Integer ID for registered institutions, exclude for now\n",
    "                \"piInstitution\": 0,\n",
    "                \"nihGrantContractNumber\": \"Unknown\", # Required currently\n",
    "                \"nihICsSupportingStudy\": format_list(input_entry[\"nihICsSupportingStudy\"], 0),\n",
    "                \"nihProgramOfficerName\": input_entry[\"nihProgramOfficerName\"],\n",
    "                \"nihInstitutionCenterSubmission\": input_entry[\"nihInstitutionCenterSubmission\"],\n",
    "                \"nihInstitutionalCertificationFileName\": input_entry[\"nihInstitutionalCertificationFileName\"],\n",
    "                \"nihGenomicProgramAdministratorName\": input_entry[\"nihGenomicProgramAdministratorName\"],\n",
    "                \"collaboratingSites\": format_list(input_entry[\"collaboratingSites\"], 0),\n",
    "                \"alternativeDataSharingPlan\": input_entry[\"alternativeDataSharingPlan\"],\n",
    "                \"consentGroups\": consent_group_list\n",
    "            }\n",
    "            upload_dict[study_name] = study_dict\n",
    "        else:\n",
    "            for consent_group in upload_dict[study_name][\"consentGroups\"]:\n",
    "                if consent_group[\"consentGroupName\"] != consent_group_dict[\"consentGroupName\"]:\n",
    "                    consent_group_list.append(consent_group)\n",
    "            consent_group_list.append(consent_group_dict)\n",
    "            study_dict = {\n",
    "                \"studyName\": study_name,\n",
    "                #\"studyType\": upload_dict[study_name][\"studyType\"], --> Enumeration, exclude for now\n",
    "                \"studyDescription\": upload_dict[study_name][\"studyDescription\"],\n",
    "                \"dataTypes\": upload_dict[study_name][\"dataTypes\"],\n",
    "                \"phenotypeIndication\": upload_dict[study_name][\"phenotypeIndication\"],\n",
    "                \"species\": upload_dict[study_name][\"species\"],\n",
    "                \"piName\": upload_dict[study_name][\"piName\"],\n",
    "                \"dataSubmitterUserId\": upload_dict[study_name][\"dataSubmitterUserId\"],\n",
    "                \"dataCustodianEmail\": upload_dict[study_name][\"dataCustodianEmail\"],\n",
    "                \"publicVisibility\": upload_dict[study_name][\"publicVisibility\"],\n",
    "                \"nihAnvilUse\": upload_dict[study_name][\"nihAnvilUse\"],\n",
    "                \"submittingToAnvil\": upload_dict[study_name][\"submittingToAnvil\"],\n",
    "                \"dbGaPPhsID\": upload_dict[study_name][\"dbGaPPhsID\"],\n",
    "                \"dbGaPStudyRegistrationName\": upload_dict[study_name][\"studyName\"],\n",
    "                #\"embargoReleaseDate\": upload_dict[study_name][\"embargoReleaseDate\"], --> Date formatting validation, exclude for now\n",
    "                \"sequencingCenter\": upload_dict[study_name][\"sequencingCenter\"],\n",
    "                \"piEmail\": upload_dict[study_name][\"piEmail\"],\n",
    "                #\"piInstitution\": upload_dict[study_name][\"piInstitution\"], --> Integer ID for registered institutions, exclude for now\n",
    "                \"piInstitution\": upload_dict[study_name][\"piInstitution\"],\n",
    "                \"nihGrantContractNumber\": upload_dict[study_name][\"nihGrantContractNumber\"],\n",
    "                \"nihICsSupportingStudy\": upload_dict[study_name][\"nihICsSupportingStudy\"],\n",
    "                \"nihProgramOfficerName\": upload_dict[study_name][\"nihProgramOfficerName\"],\n",
    "                \"nihInstitutionCenterSubmission\": upload_dict[study_name][\"nihInstitutionCenterSubmission\"],\n",
    "                \"nihInstitutionalCertificationFileName\": upload_dict[study_name][\"nihInstitutionalCertificationFileName\"],\n",
    "                \"nihGenomicProgramAdministratorName\": upload_dict[study_name][\"nihGenomicProgramAdministratorName\"],\n",
    "                \"collaboratingSites\": upload_dict[study_name][\"collaboratingSites\"],\n",
    "                \"alternativeDataSharingPlan\": upload_dict[study_name][\"alternativeDataSharingPlan\"],\n",
    "                \"consentGroups\": consent_group_list\n",
    "            }\n",
    "            upload_dict[study_name] = study_dict\n",
    "    results_log.append([\"Input File Formatting\", \"Succeeded\", \"\"])\n",
    "except Exception as e:\n",
    "    msg = f\"Error parsing and formatting input file: {str(e)}\"\n",
    "    results_log.append([\"Input File Formatting\", \"Failed\", msg])\n",
    "    print(msg)\n",
    "#     return results_log\n",
    "\n",
    "# Loop through studies and dataset to upload\n",
    "for study in upload_dict.keys():\n",
    "    print(f\"Uploading data for study {study} into DUOS\")\n",
    "    # For studies that don't exist in DUOS, create a new study\n",
    "    if not study_lookup.get(study):\n",
    "        print(\"Study does NOT currently exist in DUOS. Creating new study and dataset records...\")\n",
    "        try:\n",
    "            new_study_response = requests.post(\n",
    "                url=f\"https://consent.dsde-dev.broadinstitute.org/api/dataset/v3\",\n",
    "                headers={\"Authorization\": f\"Bearer {token}\"},\n",
    "                files = {\n",
    "                    \"dataset\": json.dumps(upload_dict[study]),\n",
    "                    \"alternativeDataSharingPlan\": \"\",\n",
    "                    \"consentGroups[0].nihInstitutionalCertificationFile\": \"\"  \n",
    "                }\n",
    "            ).json()\n",
    "            if new_study_response.get(\"studyId\"):\n",
    "                study_id = new_study_response[\"studyId\"]\n",
    "                msg = f\"Study registration succeeded! Study Id: {study_id}\"\n",
    "                results_log.append([f\"New Study Registration - {study}\", \"Succeeded\", msg])\n",
    "                print(msg)\n",
    "            else:\n",
    "                err_msg = new_study_response[\"message\"]\n",
    "                msg = f\"Study registration failed: {err_msg}\"\n",
    "                results_log.append([f\"New Study Registration - {study}\", \"Failed\", msg])\n",
    "                print(msg)\n",
    "        except Exception as e:\n",
    "            msg = f\"Study registration failed: {str(e)}\"\n",
    "            results_log.append([f\"New Study Registration - {study}\", \"Failed\", msg])\n",
    "            print(msg)\n",
    "\n",
    "    # For studies that already exist in DUOS, lookup the study ID and update the existing study\n",
    "    else:\n",
    "        print(\"Study currently exists in DUOS. Updating study and dataset records...\")\n",
    "        try:\n",
    "            # Add dataset IDs for existing datasets to avoid validation failures\n",
    "            temp_dict = upload_dict[study].copy()\n",
    "#                 updated_consent_group_list = []\n",
    "#                 for consent_group in temp_dict[\"consentGroups\"]:\n",
    "#                     if consent_group[\"consentGroupName\"] in dataset_lookup.keys():\n",
    "#                         temp_cg = consent_group.copy()\n",
    "#                         temp_cg[\"datasetId\"] = dataset_lookup.get(consent_group[\"consentGroupName\"])\n",
    "#                         updated_consent_group_list.append(temp_cg)\n",
    "#                     else:\n",
    "#                         updated_consent_group_list.append(consent_group)\n",
    "#                 temp_dict[\"consentGroups\"] = updated_consent_group_list\n",
    "            # Update study in DUOS\n",
    "            study_id = study_lookup.get(study)\n",
    "            update_study_response = requests.put(\n",
    "                url=f\"https://consent.dsde-dev.broadinstitute.org/api/dataset/study/{study_id}\",\n",
    "                headers={\"Authorization\": f\"Bearer {token}\"},\n",
    "                files = {\n",
    "                    \"dataset\": json.dumps(temp_dict),\n",
    "                    \"alternativeDataSharingPlan\": \"\",\n",
    "                    \"consentGroups[0].nihInstitutionalCertificationFile\": \"\"  \n",
    "                }\n",
    "            ).json()   \n",
    "            if update_study_response.get(\"studyId\"):\n",
    "                study_id = update_study_response[\"studyId\"]\n",
    "                msg = f\"Study registration succeeded! Study Id: {study_id}\"\n",
    "                results_log.append([f\"New Study Registration - {study}\", \"Succeeded\", msg])\n",
    "                print(msg)\n",
    "            else:\n",
    "                err_msg = update_study_response[\"message\"]\n",
    "                msg = f\"Study registration failed: {err_msg}\"\n",
    "                results_log.append([f\"New Study Registration - {study}\", \"Failed\", msg])\n",
    "                print(msg)\n",
    "        except Exception as e:\n",
    "            msg = f\"Study registration failed: {str(e)}\"\n",
    "            results_log.append([f\"Study Registration Update - {study}\", \"Failed\", msg])\n",
    "            print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "update_study_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Step 3: Attach DUOS IDs to Snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Add DUOS IDs Based on Snapshot Listed in DUOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4,
     82
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Functions\n",
    "#############################################\n",
    "\n",
    "def link_duos_ids_to_snapshots(snapshot_id_list, env, token):\n",
    "    results_log = []\n",
    "\n",
    "    # Determine the target URL from the env variable\n",
    "    if env == \"prod\":\n",
    "        url = \"https://consent.dsde-prod.broadinstitute.org\"\n",
    "    else:\n",
    "        url = \"https://consent.dsde-dev.broadinstitute.org\"\n",
    "\n",
    "    # Pull a list of existing datasets and studies from DUOS and build lookup dicts\n",
    "    print(\"Building lookup between Snapshot and DUOS ID...\")\n",
    "    try:\n",
    "        datasets = requests.get(\n",
    "            url=f\"{url}/api/dataset/v2?asCustodian=false\",\n",
    "            headers={\"Authorization\": f\"Bearer {token}\"}\n",
    "        ).json()\n",
    "        snapshot_lookup = {}\n",
    "        for dataset_entry in datasets:\n",
    "            url = \"\"\n",
    "            snapshot = False\n",
    "            for prop_entry in dataset_entry[\"properties\"]:\n",
    "                if prop_entry[\"propertyName\"] == \"URL\":\n",
    "                    url = prop_entry[\"propertyValue\"]\n",
    "                elif prop_entry[\"propertyName\"] == \"Data Location\" and prop_entry[\"propertyValue\"] == \"TDR Location\":\n",
    "                    snapshot = True\n",
    "            if snapshot == True:\n",
    "                snapshot_id = re.search(\"([a-z0-9]{8}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{12})\", url, re.IGNORECASE).group(1)\n",
    "                duos_id = dataset_entry[\"datasetIdentifier\"]\n",
    "                snapshot_lookup[snapshot_id] = duos_id\n",
    "        results_log.append([\"Snapshot Lookup Creation\", \"Succeeded\", \"\"])\n",
    "    except Exception as e:\n",
    "        msg = f\"Error building lookup between Snapshot and DUOS ID: {str(e)}\"\n",
    "        results_log.append([\"Snapshot Lookup Creation\", \"Failed\", msg])\n",
    "        print(msg)\n",
    "        return results_log\n",
    "\n",
    "    # Loop through input snapshots and link DUOS IDs to them\n",
    "    print(\"Linking DUOS IDs to Snapshots...\")\n",
    "    api_client = refresh_tdr_api_client()\n",
    "    snapshots_api = data_repo_client.SnapshotsApi(api_client=api_client)\n",
    "    for snapshot_id in snapshot_id_list:\n",
    "        print(f\"\\tProcessing snapshot ID = {snapshot_id}\")\n",
    "        duos_id = snapshot_lookup.get(snapshot_id)\n",
    "        if duos_id:\n",
    "            attempt_counter = 0\n",
    "            while attempt_counter <= 2:\n",
    "                try:\n",
    "                    response = snapshots_api.link_duos_dataset_to_snapshot(id=snapshot_id, duos_id=duos_id).to_dict()\n",
    "                    if response.get(\"linked\"):\n",
    "                        results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id} - {duos_id})\", \"Success\", \"\"])\n",
    "                        break\n",
    "                    elif response.get(\"message\"):\n",
    "                        response_message = response.get(\"message\")\n",
    "                        msg = f\"Error linking DUOS ID to Snapshot: {response_message}\"\n",
    "                        if attempt_counter >= 2:\n",
    "                            results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id} - {duos_id})\", \"Failed\", msg])\n",
    "                            break\n",
    "                except Exception as e:\n",
    "                    msg = f\"Error linking DUOS ID to Snapshot: {str(e)}\"\n",
    "                    if attempt_counter >= 2:\n",
    "                        results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id} - {duos_id})\", \"Failed\", msg])\n",
    "                    sleep(5)\n",
    "                    attempt_counter += 1  \n",
    "        else:\n",
    "            results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id})\", \"Failed\", \"No DUOS ID found for the snapshot.\"])\n",
    "    return results_log\n",
    "\n",
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# User token (use gcloud auth print-access-token to get this)\n",
    "token = \"ya29.a0AfB_byClR4y1hu-puSsus_6GAqS1QIjjVBwqD4nGzTsztXyBjJPI3sqMV2XZAeWwZRMuzfok1z0Wi7DSgVQQXCu2NWLmoWtThjLPCP0L-XsFxWpcQd-3wvqkyDKksRYANcvM8JU-OAFI_1QGGG10izNsZNqjVRkBoRS5FxvtK10aCgYKAV8SARMSFQHGX2MicJfxXq-2q_73f9tt0uv0Sw0178\"\n",
    "\n",
    "# Environment\n",
    "env = \"prod\"\n",
    "\n",
    "# Snapshot list\n",
    "snapshot_id_list = [\n",
    "    '737d454c-88be-477f-ae2c-ef473e2106ce',\n",
    "    '253e2b36-1674-482b-bfbd-4e0b05cdfe63',\n",
    "    '3f53e841-ca9d-4b55-b390-590718533561',\n",
    "    '01cf2450-604b-43e5-9f4e-9ec4e0bf0a61',\n",
    "    '85b0b351-cd0a-4efe-95a4-e39273c42831',\n",
    "    'c9037419-367e-439c-a247-b0dae7c24146',\n",
    "    'd7b2b2c6-72fd-4084-af34-a86edfe3ac47',\n",
    "    'd63a63ce-24c8-413a-89c0-4bd4c82370c0',\n",
    "    '1bb208f2-ecf3-4589-a9bd-b6e94178584d',\n",
    "    '5773565d-ad7c-4f51-8b4f-f1ee5dffc08a',\n",
    "    '2e5c5fe3-3af4-4c34-a85e-af6b4135f089',\n",
    "    '27068295-b3c0-4260-9447-9ca96814d46f',\n",
    "    '060c707a-2f0d-4730-bbd6-d25489abfcf6',\n",
    "    '7e59197f-b859-4279-add3-de24bbc7e52b',\n",
    "    '624fef99-e4ce-4c12-a3d9-90995b5da970',\n",
    "    'a68d3145-81c2-41f8-9944-5e4a5058934a',\n",
    "    'a3b18d45-96c2-4526-8fde-65ab3265868f',\n",
    "    '3ec72891-87d2-431f-850c-e52013330ea8',\n",
    "    '87d02347-d169-4ce0-9027-3c8e11e48c40',\n",
    "    '61b6ae23-ca19-4d31-bad3-2281a8528886',\n",
    "    '7c4edc65-bfe6-4ede-a68a-c0b9d2564f29',\n",
    "    'f330517e-46fd-4de3-8063-015b524a7324',\n",
    "    'f0d8bb27-1695-4faf-8b27-4b95260b8f17',\n",
    "    '17d14df1-cb64-4aae-8049-c1728a3c0c81',\n",
    "    '434f85e2-4435-483c-8099-b03c8ba794ed',\n",
    "    '5bba97dc-d6ab-4329-912f-148c8b807056',\n",
    "    '4c722626-c559-4f5a-84bd-8d7d46983e1e',\n",
    "    '6df525e1-b143-4e6f-b667-80c783ae1b66',\n",
    "    '079eb53c-e2b6-4da6-ab5f-fc2136a3ecc1',\n",
    "    '1a26532c-16e6-4f1c-81f9-8f07a8181421',\n",
    "    '3ac713b5-3645-4381-ac66-ecbc281a2ab8',\n",
    "    '4911bd18-5db9-418a-9dc0-0ea28ae937d6',\n",
    "    'bbd04481-0b9d-4c21-ba65-a43638116e0f',\n",
    "    '2b78a3ac-8bca-4938-bc7c-26a60f9c04ac',\n",
    "    '4bb891fc-fcae-40cc-bf59-73716de7e04e',\n",
    "    '574e0d42-e712-4a86-be7a-4b3a95187bcd',\n",
    "    '56078c29-a393-4c60-9e04-3674e02fe729',\n",
    "    '099d2585-1379-4333-b3b1-ffc0d26d95c5',\n",
    "    'ab71d294-4ba9-44d4-8051-913b3d5ccff3',\n",
    "    '90fe2016-e79c-456c-a5f9-3a31149fcd65',\n",
    "    'e43974fd-cee1-4d8c-a436-6846d7d24129',\n",
    "    '0d607d21-c9c7-4852-83e3-76825176ee0a',\n",
    "    '0a356156-961d-4829-b9b5-c07fbc73dacc',\n",
    "    '18a28450-31ec-4e4a-a305-dbbdd226ae3c',\n",
    "    'f7d225d9-1675-483d-a1eb-9ef750301cd4',\n",
    "    'd4b02f5f-7a62-4cad-8ffc-d3deb0fab445',\n",
    "    '4c8ce027-8094-4f5d-bf62-22b1d51b3c1e',\n",
    "    'c753046a-cf9b-4813-be68-cb3b9dd9866e',\n",
    "    'eb7948be-1007-4b0e-b9b6-a5c40bbb9596',\n",
    "    '7639a9e0-275c-49a8-80c1-cdb01ce23e1c',\n",
    "    'aa2bfacc-c28c-4192-960c-b1389cf68516',\n",
    "    'd7349942-f8ff-4ad6-b075-8f39652a7789',\n",
    "    'b9e0de2a-4085-4226-a073-1744914cbbd4',\n",
    "    '44b1f60b-e74c-4430-9378-d4a75e2de72f',\n",
    "    'a4c62d7f-34f0-4e2e-9e46-c762d3ab0ff2',\n",
    "    '6a5b3be6-d1de-4f23-a431-b08e7ab231b8',\n",
    "    '5208772d-21f9-46b0-8167-0b05b57296b8',\n",
    "    '36690013-e8bc-43a5-9ba9-83317537557c',\n",
    "    '172bada7-f1c5-41c4-836d-05381beaed9a',\n",
    "    '9a1e873b-b1db-4d3e-a83b-ed6c5b3f3ecc',\n",
    "    '2c6de04e-104d-42c8-8448-97d74985dacb',\n",
    "    '452bcafd-ab45-4e24-b5e0-13fcf22b0755',\n",
    "    'fbafdd31-21a0-44c5-ae4d-724839beff61',\n",
    "    '2a1882d9-88ca-4849-bcc1-f6914f593407',\n",
    "    '3838993f-59ba-4dec-8110-ac3ea387ab91',\n",
    "    'bf2f4106-cee9-419c-b4d1-d7b03a6293d5',\n",
    "    'a6c36f5e-b86c-4164-85ae-8bf0df2e4a90',\n",
    "    '11a7572f-02b9-4f88-8c2c-802dfb1f94b7',\n",
    "    '5e547934-c339-410e-a013-dfefed50f4b8',\n",
    "    'ffa84feb-ca0e-43d3-a04d-a402a8e24a3b',\n",
    "    '2be072bd-2153-4050-9358-e4b95297a9bf',\n",
    "    '7c19d852-e36a-4353-afea-10e501601d9a',\n",
    "    'fd3843fe-ee5d-4784-b0d2-6673f9886d30',\n",
    "    '84703c54-a9dd-400c-9701-2fc40922e3e3',\n",
    "    '00297802-e20a-413f-b389-a6f764b6600e',\n",
    "    'c853d4c0-d4be-433d-964e-e30bdc35480e',\n",
    "    '3e85b06a-a6ea-4ce8-a655-44b1fce12138',\n",
    "    '6e674477-522f-4adc-8c50-76910a6a282b',\n",
    "    '504089f1-c59d-48fe-84ef-858bd3eb3043',\n",
    "    '0565b2e4-ade1-46e7-80bf-ca647a89a8b8',\n",
    "    '1cf943bc-9ffe-4fd0-a92d-6fdcf68da743',\n",
    "    'bb11d621-e471-4ca9-b9ae-cf06c99db297',\n",
    "    '7b875b4b-a6c5-4c92-a252-cd5ff203089e',\n",
    "    '97b3d565-3c32-4fd5-be49-c16f0bae84e7',\n",
    "    'ea08adf0-2383-41ae-a91a-88c7b8f6f42b',\n",
    "    '5b8c745a-972b-455c-8021-ee24fdbce9a5',\n",
    "    'bebf0200-8458-4467-b001-ff436564e942',\n",
    "    '1c16f983-c090-457a-aca7-4181d16e225b',\n",
    "    'b259ac6c-3358-4faa-abfe-c9d614b76915',\n",
    "    '1a119cfe-3178-4f06-800b-b2aec50218b8',\n",
    "    '33c73ae8-f829-438d-bdb1-da0be8f3773f',\n",
    "    '3d6afb8e-dbcd-4972-8281-ae546b23356c',\n",
    "    '42fd7b4a-461d-4a4f-bb02-856e7124dce1',\n",
    "    '08f28ada-3fa1-41f3-a7eb-5b4ff8325145',\n",
    "    '189a0802-8538-41f8-ad51-8bb2a736783b',\n",
    "    'e0dc36c3-ff48-4ab5-881f-899578e08dd4',\n",
    "    '9052b5fc-8ac8-41ea-8a82-6860b8d2c33d',\n",
    "    'b8bc131f-68d6-4c56-bd37-55c1b0e27d2e',\n",
    "]\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "\n",
    "results = link_duos_ids_to_snapshots(snapshot_id_list, env, token)\n",
    "df_results = pd.DataFrame(results, columns = [\"Item\", \"Status\", \"Message\"])\n",
    "print(\"\\nLinking Results:\")\n",
    "display(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Add DUOS IDs Directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     4
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linking DUOS IDs to Snapshots...\n",
      "\tProcessing snapshot ID = 74cb5b41-63ac-45b3-a9cc-18fcbbaccb3b\n",
      "\tProcessing snapshot ID = e66e025f-e07c-4f0d-93ed-3ac609b570d5\n",
      "\n",
      "Linking Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>Status</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DUOS ID to Snapshot Linkage (74cb5b41-63ac-45b3-a9cc-18fcbbaccb3b - DUOS-000159)</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DUOS ID to Snapshot Linkage (e66e025f-e07c-4f0d-93ed-3ac609b570d5 - DUOS-000186)</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Item                                        Status  Message\n",
       "0  DUOS ID to Snapshot Linkage (74cb5b41-63ac-45b3-a9cc-18fcbbaccb3b - DUOS-000159)  Success        \n",
       "1  DUOS ID to Snapshot Linkage (e66e025f-e07c-4f0d-93ed-3ac609b570d5 - DUOS-000186)  Success        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################################\n",
    "## Functions\n",
    "#############################################\n",
    "\n",
    "def direct_link_duos_ids_to_snapshots(snapshot_duos_list):\n",
    "    results_log = []\n",
    "\n",
    "    # Loop through input snapshots and link DUOS IDs to them\n",
    "    print(\"Linking DUOS IDs to Snapshots...\")\n",
    "    api_client = refresh_tdr_api_client()\n",
    "    snapshots_api = data_repo_client.SnapshotsApi(api_client=api_client)\n",
    "    for entry in snapshot_duos_list:\n",
    "        snapshot_id = entry[0] \n",
    "        duos_id = entry[1]\n",
    "        print(f\"\\tProcessing snapshot ID = {snapshot_id}\")\n",
    "        if duos_id:\n",
    "            attempt_counter = 0\n",
    "            while attempt_counter <= 2:\n",
    "                try:\n",
    "                    response = snapshots_api.link_duos_dataset_to_snapshot(id=snapshot_id, duos_id=duos_id).to_dict()\n",
    "                    if response.get(\"linked\"):\n",
    "                        results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id} - {duos_id})\", \"Success\", \"\"])\n",
    "                        break\n",
    "                    elif response.get(\"message\"):\n",
    "                        response_message = response.get(\"message\")\n",
    "                        msg = f\"Error linking DUOS ID to Snapshot: {response_message}\"\n",
    "                        if attempt_counter >= 2:\n",
    "                            results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id} - {duos_id})\", \"Failed\", msg])\n",
    "                            break\n",
    "                except Exception as e:\n",
    "                    msg = f\"Error linking DUOS ID to Snapshot: {str(e)}\"\n",
    "                    if attempt_counter >= 2:\n",
    "                        results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id} - {duos_id})\", \"Failed\", msg])\n",
    "                    sleep(5)\n",
    "                    attempt_counter += 1  \n",
    "        else:\n",
    "            results_log.append([f\"DUOS ID to Snapshot Linkage ({snapshot_id})\", \"Failed\", \"No DUOS ID found for the snapshot.\"])\n",
    "    return results_log\n",
    "\n",
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# Snapshot list\n",
    "snapshot_duos_list = [\n",
    "    #['snapshot_id', 'duos_id']\n",
    "    ['74cb5b41-63ac-45b3-a9cc-18fcbbaccb3b', 'DUOS-000159'],\n",
    "    ['e66e025f-e07c-4f0d-93ed-3ac609b570d5', 'DUOS-000186'],\n",
    "]\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "\n",
    "results = direct_link_duos_ids_to_snapshots(snapshot_duos_list)\n",
    "df_results = pd.DataFrame(results, columns = [\"Item\", \"Status\", \"Message\"])\n",
    "print(\"\\nLinking Results:\")\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Script Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Fetch parameters from snapshot/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "snapshot_id = \"099d2585-1379-4333-b3b1-ffc0d26d95c5\"\n",
    "\n",
    "# Retrieve snapshot details\n",
    "api_client = refresh_tdr_api_client()\n",
    "datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "snapshots_api = data_repo_client.SnapshotsApi(api_client=api_client)\n",
    "snapshot_details = snapshots_api.retrieve_snapshot(id=snapshot_id).to_dict()\n",
    "dataset_id = snapshot_details[\"source\"][0][\"dataset\"][\"id\"]\n",
    "phs_id = snapshot_details[\"source\"][0][\"dataset\"][\"phs_id\"]\n",
    "\n",
    "# Retrieve dataset details\n",
    "dataset_details = datasets_api.retrieve_dataset(id=dataset_id, include=[\"PROPERTIES\"]).to_dict()\n",
    "if dataset_details[\"properties\"].get(\"auth_domains\"):\n",
    "    auth_domain = dataset_details[\"properties\"][\"auth_domains\"][0]\n",
    "if dataset_details[\"properties\"].get(\"source_workspaces\"):\n",
    "    source_workspace = dataset_details[\"properties\"][\"source_workspaces\"][0]\n",
    "\n",
    "# Print output\n",
    "print(phs_id)\n",
    "print(source_workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Pulling Workspace Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "ws_project = \"anvil-datastorage\"\n",
    "ws_name = \"AnVIL_GREGOR_RELEASE_01_HMB\"\n",
    "\n",
    "# Establish credentials\n",
    "creds, project = google.auth.default()\n",
    "auth_req = google.auth.transport.requests.Request()\n",
    "creds.refresh(auth_req)\n",
    "\n",
    "# Pull workspace attributes\n",
    "ws_attributes = requests.get(\n",
    "    url=f\"https://api.firecloud.org/api/workspaces/{ws_project}/{ws_name}?fields=workspace.attributes,workspace.authorizationDomain,workspace.googleProject,workspace.bucketName\",\n",
    "    headers={\"Authorization\": f\"Bearer {creds.token}\"}\n",
    ").json()\n",
    "\n",
    "# Map to schema\n",
    "terra_dict = {}\n",
    "terra_dict[\"studyName\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:projectName\")\n",
    "terra_dict[\"studyType\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:studyDesign\")\n",
    "#terra_dict[\"studyDescription\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"description\")\n",
    "terra_dict[\"dataTypes\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:dataCategory\")[\"items\"]\n",
    "terra_dict[\"phenotypeIndication\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:indication\")\n",
    "terra_dict[\"species\"] = \"Homo sapiens\"\n",
    "terra_dict[\"piName\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:datasetOwner\")\n",
    "terra_dict[\"dataCustodianEmail\"] = ws_attributes[\"workspace\"][\"attributes\"].get(\"library:contactEmail\")\n",
    "if ws_attributes[\"workspace\"][\"attributes\"].get(\"tag:tags\"):\n",
    "    for tag in ws_attributes[\"workspace\"][\"attributes\"].get(\"tag:tags\")[\"items\"]:\n",
    "        if \"Consortium:\" in tag:\n",
    "            terra_dict[\"consortium\"] = tag.split(\":\")[1].strip()\n",
    "        elif \"dbGaP:\" in tag:\n",
    "            terra_dict[\"dbGaPPhsID\"] = tag.split(\":\")[1].strip()\n",
    "terra_dict[\"consentGroups.consentCode\"] = ws_attributes[\"workspace\"][\"attributes\"][\"library:dataUseRestriction\"] \n",
    "terra_dict[\"consentGroups.fileTypes.fileType\"] = ws_attributes[\"workspace\"][\"attributes\"][\"library:datatype\"][\"items\"]\n",
    "\n",
    "# View schema\n",
    "print(terra_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ws_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ws_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## dbGaP XML Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "phs_id = \"phs003047\"\n",
    "#phs_id = \"phs000693\"\n",
    "\n",
    "# Pull and parse XML\n",
    "phs_short = phs_id.replace(\"phs\", \"\")\n",
    "dbgap_url = \"https://dbgap.ncbi.nlm.nih.gov/ss/dbgapssws.cgi?request=Study&phs=\" + phs_short\n",
    "response = requests.get(url=dbgap_url)\n",
    "xml_data = xmltodict.parse(response.text)\n",
    "\n",
    "# Map to schema\n",
    "dbgap_xml_dict = {}\n",
    "if isinstance(xml_data[\"dbgapss\"][\"Study\"], list):\n",
    "    study_data = xml_data[\"dbgapss\"][\"Study\"][0]\n",
    "else:\n",
    "    study_data = xml_data[\"dbgapss\"][\"Study\"] \n",
    "dbgap_xml_dict[\"studyName\"] = study_data[\"StudyInfo\"].get(\"StudyNameEntrez\")\n",
    "dbgap_xml_dict[\"studyDescription\"] = study_data[\"StudyInfo\"].get(\"Description\")\n",
    "dbgap_xml_dict[\"dbGaPPhsID\"] = phs_id\n",
    "dbgap_xml_dict[\"dbGaPStudyRegistrationName\"] = study_data[\"StudyInfo\"].get(\"StudyNameEntrez\")\n",
    "for ap_entry in study_data[\"Authority\"][\"Persons\"][\"Person\"]:\n",
    "    if ap_entry[\"Role\"] == \"PI\":\n",
    "        dbgap_xml_dict[\"piName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "        dbgap_xml_dict[\"piEmail\"] = ap_entry[\"@email\"]\n",
    "        dbgap_xml_dict[\"piInstitution\"] = ap_entry[\"Organization\"]\n",
    "    elif ap_entry[\"Role\"] == \"PO\" and ap_entry[\"Organization\"] == \"NIH\":\n",
    "        dbgap_xml_dict[\"nihProgramOfficerName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "    elif ap_entry[\"Role\"] == \"GPA\" and ap_entry[\"Organization\"] == \"NIH\":\n",
    "        dbgap_xml_dict[\"nihGenomicProgramAdministratorName\"] = ap_entry[\"@lname\"] + \", \" + ap_entry[\"@fname\"]\n",
    "ic_list = []\n",
    "if isinstance(study_data[\"Authority\"][\"ICs\"][\"IC\"], list):\n",
    "    for ic_entry in study_data[\"Authority\"][\"ICs\"][\"IC\"]:\n",
    "        ic_list.append(ic_entry[\"@name\"])\n",
    "else:\n",
    "    ic_list.append(study_data[\"Authority\"][\"ICs\"][\"IC\"][\"@name\"])\n",
    "dbgap_xml_dict[\"nihICsSupportingStudy\"] = ic_list\n",
    "dbgap_xml_dict[\"numberOfParticipants\"] = study_data.get(\"@num_participants\")\n",
    "dbgap_xml_dict[\"embargoReleaseDate\"] = study_data[\"Policy\"].get(\"@pub-embargo\")\n",
    "\n",
    "# View schema\n",
    "print(dbgap_xml_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "study_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "study_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## dbGaP Study API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "study_uid = 483191234\n",
    "\n",
    "# Pull and parse JSON\n",
    "dbgap_study_url = \"https://submit.ncbi.nlm.nih.gov/dbgap/api/v1/study_config/\" + str(study_uid)\n",
    "response = requests.get(url=dbgap_study_url)\n",
    "study_api_data = json.loads(response.text)\n",
    "\n",
    "# Map to schema\n",
    "dbgap_study_api_dict = {}\n",
    "if study_api_data.get(\"error\") == None:\n",
    "    dbgap_study_api_dict[\"studyName\"] = study_api_data[\"data\"].get(\"report_name\")\n",
    "    dbgap_study_api_dict[\"studyDescription\"] = study_api_data[\"data\"].get(\"description\")\n",
    "    dbgap_study_api_dict[\"phenotypeIndication\"] = study_api_data[\"data\"].get(\"primary_disease\")\n",
    "    dbgap_study_api_dict[\"studyType\"] = study_api_data[\"data\"].get(\"study_design\")\n",
    "    for attr_entry in study_api_data[\"data\"].get(\"attribution\"):\n",
    "        if attr_entry.get(\"title\") == \"Principal Investigator\":\n",
    "            dbgap_study_api_dict[\"piName\"] = attr_entry.get(\"name\")\n",
    "            dbgap_study_api_dict[\"piInstitution\"] = attr_entry.get(\"institute\")\n",
    "            break\n",
    "\n",
    "# View schema\n",
    "print(dbgap_study_api_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "study_api_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## dbGaP FHIR API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "#phs_id = \"phs003047\"\n",
    "phs_id = \"phs000693\"\n",
    "\n",
    "# Pull and parse JSON\n",
    "dbgap_fhir_url = \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/ResearchStudy?_format=json&_id=\" + phs_id\n",
    "response = requests.get(url=dbgap_fhir_url)\n",
    "fhir_data = json.loads(response.text)\n",
    "\n",
    "# Map to schema\n",
    "dbgap_fhir_dict = {}\n",
    "dbgap_fhir_dict[\"studyName\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"title\")\n",
    "dbgap_fhir_dict[\"studyDescription\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"description\")\n",
    "dbgap_fhir_dict[\"dbGaPPhsID\"] = phs_id\n",
    "dbgap_fhir_dict[\"dbGaPStudyRegistrationName\"] = fhir_data[\"entry\"][0][\"resource\"].get(\"title\")\n",
    "dbgap_fhir_dict[\"nihICsSupportingStudy\"] = fhir_data[\"entry\"][0][\"resource\"][\"sponsor\"].get(\"display\")\n",
    "# studyType\n",
    "for cat_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"category\"):\n",
    "    for coding_entry in cat_entry.get(\"coding\"):\n",
    "        if coding_entry.get(\"system\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/CodeSystem/ResearchStudy-StudyDesign\":\n",
    "            value = coding_entry.get(\"display\") if coding_entry.get(\"display\") else coding_entry.get(\"code\")\n",
    "            if dbgap_fhir_dict.get(\"studyType\") and value:\n",
    "                dbgap_fhir_dict[\"studyType\"] += f\", {value}\"\n",
    "            elif value:\n",
    "                dbgap_fhir_dict[\"studyType\"] = value\n",
    "# dataTypes\n",
    "dt_list = []\n",
    "for ext_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "    if ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-MolecularDataTypes\":\n",
    "        for inner_ext_entry in ext_entry.get(\"extension\"):\n",
    "            if inner_ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-MolecularDataTypes-MolecularDataType\":\n",
    "                for coding_entry in inner_ext_entry[\"valueCodeableConcept\"].get(\"coding\"):\n",
    "                    dt_list.append(coding_entry.get(\"code\"))\n",
    "dbgap_fhir_dict[\"dataTypes\"] = dt_list\n",
    "# phenotypeIndication\n",
    "for focus_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"focus\"):\n",
    "    for coding_entry in focus_entry.get(\"coding\"):\n",
    "        value = coding_entry.get(\"display\") if coding_entry.get(\"display\") else coding_entry.get(\"code\")\n",
    "        if dbgap_fhir_dict.get(\"phenotypeIndication\") and value:\n",
    "            dbgap_fhir_dict[\"phenotypeIndication\"] += f\", {value}\"\n",
    "        elif value:\n",
    "            dbgap_fhir_dict[\"phenotypeIndication\"] = value\n",
    "# numberOfParticipants\n",
    "for ext_entry in fhir_data[\"entry\"][0][\"resource\"].get(\"extension\"):\n",
    "    if ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-Content\":\n",
    "        for inner_ext_entry in ext_entry.get(\"extension\"):\n",
    "            if inner_ext_entry.get(\"url\") == \"https://dbgap-api.ncbi.nlm.nih.gov/fhir/x1/StructureDefinition/ResearchStudy-Content-NumSubjects\":\n",
    "                dbgap_fhir_dict[\"numberOfParticipants\"] = inner_ext_entry[\"valueCount\"].get(\"code\")\n",
    "\n",
    "# View schema\n",
    "print(dbgap_fhir_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fhir_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Delete Studies from DUOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "token = \"ya29.a0AfB_byAm_jdIP_OjUewqvX_GmDcapjF4wxeRuDs_SEytpi_Z-ebuH4dGI_I4SJiojb_fF-sLP-nE29uhHl9c5KK2-bp1KM_XuPTBRWBddINlwijoJWjQs0LdD5nZ0D0LjPEVkVJOeEGzHgC46qOOgh74Wr1I_kZ-zS1ZAbqEAKwaCgYKAeESARMSFQHGX2MibOjNTp9U33mTJt6rW3H2dg0178\"\n",
    "study_id_list = [\n",
    "    \n",
    "]\n",
    "\n",
    "# Delete studies\n",
    "for study_id in study_id_list:\n",
    "    print(f\"Deleting study ID {study_id}\")\n",
    "    response = requests.delete(\n",
    "        url=f\"https://consent.dsde-dev.broadinstitute.org/api/dataset/study/{study_id}\",\n",
    "        headers={\"Authorization\": f\"Bearer {token}\"} \n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        print(\"Study deleted successfully.\")\n",
    "    else:\n",
    "        msg = response.json()[\"message\"]\n",
    "        print(f\"Error deleting study: {msg}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Build Lookup of Datasets and Studies in DUOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "token = \"ya29.a0AfB_byAm_jdIP_OjUewqvX_GmDcapjF4wxeRuDs_SEytpi_Z-ebuH4dGI_I4SJiojb_fF-sLP-nE29uhHl9c5KK2-bp1KM_XuPTBRWBddINlwijoJWjQs0LdD5nZ0D0LjPEVkVJOeEGzHgC46qOOgh74Wr1I_kZ-zS1ZAbqEAKwaCgYKAeESARMSFQHGX2MibOjNTp9U33mTJt6rW3H2dg0178\"\n",
    "user_id = 5100 # Set to None to return all datasets/studies, otherwise will filter on those created or updated by the specified user\n",
    "\n",
    "# Pull a list of existing datasets and studies from DUOS and build lookup dicts\n",
    "datasets = requests.get(\n",
    "    url=f\"https://consent.dsde-dev.broadinstitute.org/api/dataset/v2?asCustodian=false\",\n",
    "    headers={\"Authorization\": f\"Bearer {token}\"}\n",
    ").json()\n",
    "study_lookup = {}\n",
    "dataset_lookup = {}\n",
    "if user_id:\n",
    "    for dataset_entry in datasets:\n",
    "        created_user = dataset_entry.get(\"createUserId\") if dataset_entry.get(\"createUserId\") else 0\n",
    "        updated_user = dataset_entry.get(\"updateUserId\") if dataset_entry.get(\"createUserId\") else 0\n",
    "        if dataset_entry[\"study\"].get(\"name\") and (created_user == user_id or updated_user == user_id):\n",
    "            if not study_lookup.get(dataset_entry[\"study\"][\"name\"]):\n",
    "                study_lookup[dataset_entry[\"study\"][\"name\"]] = dataset_entry[\"study\"][\"studyId\"]\n",
    "        if dataset_entry.get(\"name\") and (created_user == user_id or updated_user == user_id):\n",
    "            dataset_lookup[dataset_entry[\"name\"]] = dataset_entry[\"dataSetId\"]\n",
    "else:\n",
    "    for dataset_entry in datasets:\n",
    "        if dataset_entry[\"study\"].get(\"name\"):\n",
    "            if not study_lookup.get(dataset_entry[\"study\"][\"name\"]):\n",
    "                study_lookup[dataset_entry[\"study\"][\"name\"]] = dataset_entry[\"study\"][\"studyId\"]\n",
    "        if dataset_entry.get(\"name\"):\n",
    "            dataset_lookup[dataset_entry[\"name\"]] = dataset_entry[\"dataSetId\"]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "study_list = []\n",
    "for key, val in study_lookup.items():\n",
    "    study_list.append(val)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "study_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
