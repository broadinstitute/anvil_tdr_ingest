{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional modules (one time effort per cloud environment)\n",
    "!pip install --upgrade import_ipynb data_repo_client urllib3 xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ingest_pipeline_utilities.ipynb\n",
      "Version 1.0.40: 4/9/2024 11:23am - Nate Calvanese - Fixed file inventory bug when fileref fields contained mix of remote and nonremote files.\n",
      "importing Jupyter notebook from source_files_creation.ipynb\n",
      "Version 1.0.9: 2/25/2023 3:15pm - Nate Calvanese - Replaced FAPI with utils functions\n",
      "importing Jupyter notebook from build_file_inventory.ipynb\n",
      "Version 2.0.3: 10/6/2023 9:29am - Nate Calvanese - Tweaked file extension parsing logic\n",
      "importing Jupyter notebook from process_table_data.ipynb\n",
      "Version: 1.0.10: 1/12/2024 11:25am - Nate Calvanese - Made max_combined_rec_ref_size configurable\n",
      "importing Jupyter notebook from build_mapping_query.ipynb\n",
      "Version 1.0.13: 2/1/2024 4:16pm - Nate Calvanese - Updated logic to not include field in select statement when source table cant be joined to\n",
      "importing Jupyter notebook from output_data_validation.ipynb\n",
      "Version 2.0.7: 12/13/2023 1:13pm -- Replaced deprecated df append with pd.concat\n",
      "importing Jupyter notebook from resolve_dangling_foreign_keys.ipynb\n",
      "Version 1.0.3: 03/12/2024 12:12pm - Nate Calvanese - Fixed a bug introduced in V1.0.2 update\n",
      "importing Jupyter notebook from infer_file_relationships.ipynb\n",
      "Version 1.0.3: 12/11/2023 1:25pm - Nate Calvanese - Fixed bug in query logic to correct source_datarepo_row_ids\n",
      "importing Jupyter notebook from identify_supplementary_files.ipynb\n",
      "Version 1.0.2: 10/4/2023 10:40am - Nate Calvanese - Updated query logic and added validation\n"
     ]
    }
   ],
   "source": [
    "## imports and environment variables\n",
    "\n",
    "# Imports\n",
    "import import_ipynb\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import data_repo_client\n",
    "from google.cloud import bigquery\n",
    "import ingest_pipeline_utilities as utils\n",
    "import build_file_inventory as bfi\n",
    "import identify_supplementary_files as isf\n",
    "import logging\n",
    "from time import sleep\n",
    "import datetime\n",
    "from google.cloud import storage\n",
    "import math\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# Configure logging format\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s: %(message)s\", datefmt=\"%m/%d/%Y %I:%M:%S %p\", level=logging.INFO)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "# Environment variables\n",
    "ws_name = os.environ[\"WORKSPACE_NAME\"]\n",
    "ws_project = os.environ[\"WORKSPACE_NAMESPACE\"]\n",
    "ws_bucket = os.environ[\"WORKSPACE_BUCKET\"]\n",
    "ws_bucket_name = re.sub('^gs://', '', ws_bucket)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create new snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Script to create new full view snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {}\n",
    "params[\"profile_id\"] = \"e0e03e48-5b96-45ec-baa4-8cc1ebf74c61\"\n",
    "params[\"snapshot_readers_list\"] = [\"azul-anvil-prod@firecloud.org\", \"auth-domain\"]\n",
    "params[\"anvil_schema_version\"] = \"ANV5\"\n",
    "\n",
    "# Loop through datasets and create new snapshot\n",
    "dataset_id_run_list = [\n",
    "'93b2ac60-2208-4ef8-a1c2-68a623e45807',\n",
    "'f9224ea2-dd31-421d-80d4-f35082ef8d68',\n",
    "'3376a8b6-7ef6-4191-97ab-a547da0d330d',\n",
    "'0b25d09e-b2d9-4452-9810-1d0ef777f9d6',\n",
    "'6ac178b7-a923-407f-8cd8-1733e1b2ebd5',\n",
    "'4b341ba9-49a5-43a2-9b7e-cc96beb59946',\n",
    "'841970b7-bed0-4a75-a28a-a4cc59740a84',\n",
    "'a5f53fc8-8f9b-4e9a-af63-6f8c54d478b2',\n",
    "'ed82e510-37aa-47f6-88f0-b2ba33e0fdb0',\n",
    "'9a06c401-da3f-41b4-b38b-238796fcae09',\n",
    "'2a81cd6f-aa6e-436b-b4ba-68d5f713fb07',\n",
    "'5e0e8f9a-ce97-4b18-9540-3015c61e393c',\n",
    "'1c8ba244-1c7f-433a-825b-d2d34d018dcf',\n",
    "'6d18aafc-0240-499c-902e-a72a5b98ff0a',\n",
    "'74d1e549-5ae8-4410-9428-f8f2cc85fa80',\n",
    "'033fc1e1-0337-4656-bbe1-3f06fef641e9',\n",
    "'629e31cb-dd7b-4345-abf2-fa23c6c65a09',\n",
    "'0132f320-830d-40d0-a4da-06a5d5f9e8d9',\n",
    "'bb7d6408-941a-4da6-8613-36498bc6d91b',\n",
    "'d40af129-c13f-45b2-92f0-d0e8fa5cc1c9',\n",
    "'ecd2d2f9-2b6f-4743-8d04-c9bb554a96cb',\n",
    "]\n",
    "results = []\n",
    "for dataset in dataset_id_run_list:\n",
    "    dataset_id = dataset\n",
    "    try:\n",
    "        api_client = utils.refresh_tdr_api_client()\n",
    "        datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "        dataset_info = datasets_api.retrieve_dataset(id=dataset_id, include=[\"SCHEMA\", \"ACCESS_INFORMATION\", \"PROPERTIES\"]).to_dict()\n",
    "        dataset_name = dataset_info[\"name\"]\n",
    "        phs_id = dataset_info[\"phs_id\"]\n",
    "        consent_name = dataset_info[\"properties\"][\"consent_name\"]\n",
    "        auth_domains = dataset_info[\"properties\"][\"auth_domains\"]\n",
    "        src_workspaces = dataset_info[\"properties\"][\"source_workspaces\"]\n",
    "    except:\n",
    "        dataset_name = \"\"\n",
    "    if dataset_name:\n",
    "        params[\"ws_bucket\"] = ws_bucket\n",
    "        params[\"dataset_id\"] = dataset_id\n",
    "        params[\"dataset_name\"] = dataset_name\n",
    "        params[\"phs_id\"] = phs_id\n",
    "        params[\"consent_name\"] = consent_name\n",
    "        params[\"auth_domains\"] = auth_domains\n",
    "        params[\"pipeline_results\"] = []\n",
    "        current_datetime = datetime.datetime.now()\n",
    "        current_datetime_string = current_datetime.strftime(\"%Y%m%d%H%M\")\n",
    "        params[\"snapshot_name\"] = params[\"dataset_name\"] + \"_\" + params[\"anvil_schema_version\"] + \"_\" + current_datetime_string \n",
    "        utils.create_and_share_snapshot(params)\n",
    "        int_df_results = pd.DataFrame(params[\"pipeline_results\"], columns = [\"Dataset\", \"Time\", \"Step\", \"Task\", \"Status\", \"Message\"])\n",
    "        errors = int_df_results[int_df_results[\"Status\"].str.contains(\"Error\")]\n",
    "        if len(errors) > 0:\n",
    "            results.append([dataset_id, \"Error\", \"\"])\n",
    "        else:\n",
    "            snapshot_id = re.search(\"{'id': '([a-z0-9]{8}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{4}-[a-z0-9]{12})'\", str(int_df_results[int_df_results[\"Task\"]==\"Create and Share Snapshot\"][\"Message\"]))[1]\n",
    "            results.append([dataset_id, \"Success\", snapshot_id])\n",
    "results_df = pd.DataFrame(results, columns = [\"dataset_id\", \"run_status\", \"snapshot_id\"])\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Verify Snapshots Have Properly Formatted DRS URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def validate_snapshot_drs_format(snapshot_id):\n",
    "    \n",
    "    # Retrieve snapshot information\n",
    "    api_client = utils.refresh_tdr_api_client()\n",
    "    snapshots_api = data_repo_client.SnapshotsApi(api_client=api_client)\n",
    "    try:\n",
    "        response = snapshots_api.retrieve_snapshot(id=snapshot_id, include=[\"ACCESS_INFORMATION\"]).to_dict()\n",
    "        bq_project = response[\"access_information\"][\"big_query\"][\"project_id\"]\n",
    "        bq_dataset = response[\"access_information\"][\"big_query\"][\"dataset_name\"]\n",
    "    except Exception as e:\n",
    "        return \"Failure - Issue Retrieving Snapshot Info\"\n",
    "    \n",
    "    # Determine if field exists for dataset, continue if so, fail otherwise\n",
    "    client = bigquery.Client()\n",
    "    query = \"\"\"SELECT COUNT(file_ref) AS rec_cnt, COUNT(CASE WHEN file_ref LIKE '%drs://drs.anv0:v2_%' THEN file_ref END) AS valid_cnt\n",
    "                FROM `{project}.{dataset}.anvil_file`\"\"\".format(project=bq_project, dataset=bq_dataset)\n",
    "    try:\n",
    "        df = client.query(query).result().to_dataframe()\n",
    "        if df[\"rec_cnt\"].values[0] == df[\"valid_cnt\"].values[0]:\n",
    "            return \"Success\"\n",
    "        else:\n",
    "            rec_cnt = df[\"rec_cnt\"].values[0]\n",
    "            valid_cnt = df[\"valid_cnt\"].values[0]\n",
    "            return f\"Failure: Only {valid_cnt} of {rec_cnt} records properly formatted\"\n",
    "    except Exception as e:\n",
    "        return \"Failure - BigQuery Error\"\n",
    "\n",
    "# Loop through datasets and validate is_supplementary field\n",
    "snapshot_id_list = [\n",
    "'c3d22305-b3f2-4561-a5b9-bed82ee742f4',\n",
    "'9fe2abd4-70b4-4eee-b00d-38726ced8620',\n",
    "'5329c25e-ccad-435d-9250-6fcc3ff88472',\n",
    "'ced601b2-9a11-40e9-8067-241e5a5996ed',\n",
    "'8165245c-2003-4ec7-bf57-731959022d47',\n",
    "'737d454c-88be-477f-ae2c-ef473e2106ce',\n",
    "'3bdbad9e-f9d4-4442-8606-791d490bf0af',\n",
    "'cd19195f-25a0-44b1-b47d-ec99141833fc',\n",
    "'b897e519-ba8b-4758-a263-6d57bd3b8e2b',\n",
    "'1d385cfc-4bed-4f52-8f7b-ea54fc44b4f7',\n",
    "'02d25240-823f-4b1d-8562-95385716a453',\n",
    "'1974a21b-c409-4736-a3d7-e195fa96c4eb',\n",
    "'99b46287-4790-492c-8a12-bea33f0f927c',\n",
    "'c6ef5822-3929-4ae7-b5bc-dc27528bf226',\n",
    "'08d19a7e-b868-4766-9f7e-d879d972cbd7',\n",
    "'35186e6d-2728-4a8e-b0ad-6b34d0fe480c',\n",
    "'b0d176bf-d094-4e33-a34b-b83a94de86ea',\n",
    "'cc6bacc8-29fa-4d97-8856-79f52ea50c6f',\n",
    "'85b721da-ad8e-4d82-93f0-0988f94af22e',\n",
    "'407c7800-3ab4-4b13-ba45-c6c13c1c2278',\n",
    "'2529f127-cff5-43ff-b879-06bc0e3468ff',\n",
    "'b511be0b-7dc5-4767-a891-37f43d04a5a5',\n",
    "'a7e031c3-62d4-46db-b2e2-0bdca6bbad65',\n",
    "'5bba97dc-d6ab-4329-912f-148c8b807056',\n",
    "'9cf61d88-d096-4981-b0c6-99db77554c01',\n",
    "'4c722626-c559-4f5a-84bd-8d7d46983e1e',\n",
    "'7c237e08-3329-4e64-bd2a-063be290e78b',\n",
    "'4117144f-92e7-454f-9263-dad5e128cadb',\n",
    "'ce2e7235-26e6-470f-8e05-298193b7f53d',\n",
    "'6df525e1-b143-4e6f-b667-80c783ae1b66',\n",
    "'92666b7c-4d50-4530-88e9-ea2d3da9d07a',\n",
    "'42644c25-fa23-4b4e-8fcc-907cd8dcef60',\n",
    "'155c11a9-638a-45c8-b172-7cf2e3e16fe6',\n",
    "'b3da9fec-08ad-4496-a9ac-1411388fb5cc',\n",
    "'0de07296-e3ff-4fe6-9183-9f421484197c',\n",
    "'1b6273c6-7769-4daf-abee-93b11b322c73',\n",
    "'ea50255a-45a4-4846-82e3-02b4f46f5b17',\n",
    "'eb7045e1-2286-49f1-bce6-21b5d7fa5c32',\n",
    "'b763c288-4132-434a-a6c9-25ad51b9d961',\n",
    "'b67702a8-307d-4b20-835e-c0245d0761e5',\n",
    "'88548251-e59e-4bc3-b71a-f1e9e2369919',\n",
    "'d3dc5627-503b-48a5-ad79-31ab6c2fd417',\n",
    "'ec14f8cd-5b1b-4124-a235-f11159984c7c',\n",
    "'6d9e1212-4fa6-4632-be8a-75c45a474dd3',\n",
    "'667eac9b-4e90-413d-80f3-d857b9829ab7',\n",
    "'c091ea30-1862-4b1f-8e92-087b441472c3',\n",
    "'43c86818-9bfe-46f2-9ae4-4a55a7baef1f',\n",
    "'ebdaca04-ef29-42f3-8486-a94dade81bf8',\n",
    "'f8781fbf-5fef-4481-8819-3df1bc724b7f',\n",
    "'830df9ed-e4a6-4c9a-a97a-aa080fb030e4',\n",
    "'84703c54-a9dd-400c-9701-2fc40922e3e3',\n",
    "'c1c674dd-056a-470c-8874-bf70d8fae3a8',\n",
    "'6a5b3be6-d1de-4f23-a431-b08e7ab231b8',\n",
    "'ffe34538-3ddd-48de-b4a2-94f9b2dad086',\n",
    "'2c6de04e-104d-42c8-8448-97d74985dacb',\n",
    "'2a1882d9-88ca-4849-bcc1-f6914f593407',\n",
    "'bf2f4106-cee9-419c-b4d1-d7b03a6293d5',\n",
    "'a6c36f5e-b86c-4164-85ae-8bf0df2e4a90',\n",
    "'7c19d852-e36a-4353-afea-10e501601d9a',\n",
    "'00297802-e20a-413f-b389-a6f764b6600e',\n",
    "'b8a455eb-827d-43a0-a89b-5d017747140f',\n",
    "'3e85b06a-a6ea-4ce8-a655-44b1fce12138',\n",
    "'9321b908-f2e4-437b-b53e-ed81754dcace',\n",
    "'172bada7-f1c5-41c4-836d-05381beaed9a',\n",
    "'133e902c-5ff0-4119-8078-db3e15006844',\n",
    "'452bcafd-ab45-4e24-b5e0-13fcf22b0755',\n",
    "'5e547934-c339-410e-a013-dfefed50f4b8',\n",
    "'ffa84feb-ca0e-43d3-a04d-a402a8e24a3b',\n",
    "'ff27037e-cb52-44ef-8979-f6e7ac3ed6f6',\n",
    "'c853d4c0-d4be-433d-964e-e30bdc35480e',\n",
    "'8fbe2def-b8ad-4b2d-90c9-0dd4517c67e1',\n",
    "'03e54581-8fd3-47c3-9143-55368d2e4e86',\n",
    "'9efae3c7-904c-48a8-939a-e82b46005ae1',\n",
    "'5955a235-5be6-47bc-8303-ed0c4e68f501',\n",
    "'e04edfef-69f8-47ff-8df9-dfff0e9218d2',\n",
    "'f2a7be5a-4f7a-4a96-935e-ca7592855b45',\n",
    "'7c90289b-be3e-4c9b-917a-d5e27d95dc15',\n",
    "'0f46a588-b4ff-4a69-99e9-0a0bcf052522',\n",
    "'cdd689fd-10f3-4cfa-b738-46549e689cac',\n",
    "'eb7948be-1007-4b0e-b9b6-a5c40bbb9596',\n",
    "'f20753f0-d09a-4b47-bffe-8f24ec354761',\n",
    "'4cff04f4-eff9-4a62-bc6e-691accfbd328',\n",
    "'9a61b980-4a33-465a-bc50-1aba00bc2cf6',\n",
    "'90fe2016-e79c-456c-a5f9-3a31149fcd65',\n",
    "'a4c62d7f-34f0-4e2e-9e46-c762d3ab0ff2',\n",
    "'28dc8121-5e55-46c2-8313-681de2298986',\n",
    "'dcc578ed-44bb-458f-8ff5-a78ca83f4616',\n",
    "'aa42debe-3747-4dcd-8bc9-24eb90673fa5',\n",
    "'5208772d-21f9-46b0-8167-0b05b57296b8',\n",
    "'a2da748b-fec8-4e10-88ee-de32cbe8dee1',\n",
    "'26df2a34-b10d-4361-ba2b-d9f966d09f61',\n",
    "'dd00a8ba-ac49-481b-8d79-0e440adafd77',\n",
    "'0df983d7-ed5e-44d2-acf1-686822b0cc7e',\n",
    "'28559e94-ed57-48c8-bc8b-6cc4ad659a61',\n",
    "'8b385bd3-52aa-48b9-be33-41f4d3fd4531',\n",
    "'ce1bf5c3-525e-455d-a1e9-dd5f3d68c9d3',\n",
    "'d0a6aa4c-821c-4bba-b53b-4f230ca3cda4',\n",
    "'d9e817a2-6657-433b-8b2f-73790561725c',\n",
    "'33c854eb-d228-4a82-8324-5e455ed1e447',\n",
    "]\n",
    "results = []\n",
    "for snapshot_id in snapshot_id_list:\n",
    "    status = validate_snapshot_drs_format(snapshot_id) \n",
    "    results.append([snapshot_id, status])\n",
    "    results_df = pd.DataFrame(results, columns = [\"snapshot_id\", \"validation_status\"])\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Add and populate anvil_file.is_supplementary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Script to patch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set base parameters\n",
    "params = {}\n",
    "params[\"profile_id\"] = \"e0e03e48-5b96-45ec-baa4-8cc1ebf74c61\"\n",
    "\n",
    "# Loop through datasets and process is_supplementary field\n",
    "dataset_id_list = [\n",
    "'8b2b1c92-66cf-403c-8eb0-03b523d1550e',\n",
    "'595b6755-e7ae-4e83-af2e-693c089aeec3',\n",
    "'84ac0d05-4be5-43e9-973e-ef999144d802',\n",
    "'732eaae3-b509-4a7a-8961-09d861e55253',\n",
    "'544f643d-b19f-4aa0-a6ec-a90e1a8681d6',\n",
    "'f85ea65e-1943-4bd6-a541-71c5d8465ca9',\n",
    "'280c5d6f-39a3-4d1d-aad2-a174451cd9b2',\n",
    "]\n",
    "results = []\n",
    "for dataset_id in dataset_id_list:\n",
    "    logging.info(f\"Patching dataset_id: {dataset_id}\")\n",
    "    params[\"t_output_dir\"] = \"ingest_pipeline/output/transformed/anvil/{}/table_data\".format(dataset_id)\n",
    "    output, status = isf.identify_supplementary_files(params, dataset_id)\n",
    "    results.append([dataset_id, status, output])\n",
    "    results_df = pd.DataFrame(results, columns = [\"dataset_id\", \"run_status\", \"output\"])\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Script to validate patch worked properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def validate_supp_file_flg(dataset_id):\n",
    "    \n",
    "    # Retrieve dataset information\n",
    "    src_schema_dict = {}\n",
    "    api_client = utils.refresh_tdr_api_client()\n",
    "    datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "    try:\n",
    "        response = datasets_api.retrieve_dataset(id=dataset_id, include=[\"SCHEMA\", \"ACCESS_INFORMATION\"]).to_dict()\n",
    "        src_schema_dict[\"tables\"] = response[\"schema\"][\"tables\"]\n",
    "        bq_project = response[\"access_information\"][\"big_query\"][\"project_id\"]\n",
    "        bq_dataset = response[\"access_information\"][\"big_query\"][\"dataset_name\"]\n",
    "    except Exception as e:\n",
    "        return \"Failure - Issue Retrieving Dataset Info\"\n",
    "    \n",
    "    # Determine if field exists for dataset, continue if so, fail otherwise\n",
    "    field_found = False\n",
    "    for table in src_schema_dict[\"tables\"]:\n",
    "        if table[\"name\"] == \"anvil_file\":\n",
    "            for col in table[\"columns\"]:\n",
    "                if col[\"name\"] == \"is_supplementary\":\n",
    "                    field_found = True\n",
    "                    break\n",
    "            break\n",
    "    if field_found == False:\n",
    "        return \"Failure - is_supplementary field not found\"\n",
    "    else:\n",
    "        client = bigquery.Client()\n",
    "        # Check field population\n",
    "        query = \"\"\"SELECT COUNT(*) AS rec_cnt, COUNT(is_supplementary) AS populated_cnt\n",
    "                    FROM `{project}.{dataset}.anvil_file`\"\"\".format(project=bq_project, dataset=bq_dataset)\n",
    "        try:\n",
    "            df = client.query(query).result().to_dataframe()\n",
    "            if df[\"rec_cnt\"].values[0] == df[\"populated_cnt\"].values[0]:\n",
    "                pass\n",
    "            else:\n",
    "                return \"Failure - is_supplementary field not populated\"\n",
    "        except Exception as e:\n",
    "            return \"Failure - BigQuery Error\"\n",
    "        # Check field logic\n",
    "        validation_query = \"\"\"\n",
    "            WITH activity_agg\n",
    "            AS\n",
    "            (\n",
    "              SELECT used_biosample_id, generated_file_id, used_file_id FROM `{project}.{dataset}.anvil_activity`\n",
    "              UNION ALL \n",
    "              SELECT [] AS used_biosample_id, generated_file_id, used_file_id FROM `{project}.{dataset}.anvil_alignmentactivity`\n",
    "              UNION ALL \n",
    "              SELECT used_biosample_id, generated_file_id, [] AS used_file_id FROM `{project}.{dataset}.anvil_assayactivity`\n",
    "              UNION ALL \n",
    "              SELECT used_biosample_id, generated_file_id, [] AS used_file_id FROM `{project}.{dataset}.anvil_sequencingactivity`\n",
    "              UNION ALL \n",
    "              SELECT [] AS used_biosample_id, generated_file_id, used_file_id FROM `{project}.{dataset}.anvil_variantcallingactivity`\n",
    "            ),\n",
    "            activity_exp \n",
    "            AS\n",
    "            (\n",
    "              SELECT file_id, int_file_id, biosample_id\n",
    "              FROM activity_agg\n",
    "                  LEFT JOIN UNNEST(used_biosample_id) AS biosample_id\n",
    "                  LEFT JOIN UNNEST(generated_file_id) as file_id\n",
    "                  LEFT JOIN UNNEST(used_file_id) as int_file_id\n",
    "            ),\n",
    "            activity_exp_tagged\n",
    "            AS\n",
    "            (\n",
    "              SELECT a.file_id, b.is_supplementary AS file_id_supp, int_file_id, c.is_supplementary AS int_file_id_supp, biosample_id\n",
    "              FROM activity_exp a\n",
    "                  LEFT JOIN  `{project}.{dataset}.anvil_file` b\n",
    "                  ON a.file_id = b.file_id\n",
    "                  LEFT JOIN  `{project}.{dataset}.anvil_file` c\n",
    "                  ON a.int_file_id = c.file_id \n",
    "            )\n",
    "            SELECT CASE WHEN file_id_supp = TRUE AND biosample_id IS NOT NULL THEN 'Supplemental File Linked to BioSample' WHEN (file_id_supp = TRUE AND int_file_id_supp = FALSE) OR (file_id_supp = FALSE AND int_file_id_supp = TRUE) THEN 'Supplemental File Linked to Non-Supplemental File' ELSE 'No Issue Found' END AS finding, COUNT(*) AS occurrences\n",
    "            FROM activity_exp_tagged\n",
    "            GROUP by finding\n",
    "            \"\"\".format(project=bq_project, dataset=bq_dataset)\n",
    "        try:\n",
    "            df = client.query(validation_query).result().to_dataframe()\n",
    "            records_json = json.loads(df.to_json(orient='records'))\n",
    "            supp_linked_to_biosample = 0\n",
    "            supp_linked_to_nonsupp = 0\n",
    "            non_issue_links = 0\n",
    "            for record in records_json:\n",
    "                if record[\"finding\"] == \"Supplemental File Linked to BioSample\":\n",
    "                    supp_linked_to_biosample = record[\"occurrences\"]\n",
    "                elif record[\"finding\"] == \"Supplemental File Linked to Non-Supplemental File\":\n",
    "                    supp_linked_to_nonsupp = record[\"occurrences\"]\n",
    "                else:\n",
    "                    non_issue_links = record[\"occurrences\"]\n",
    "            if supp_linked_to_biosample > 0 or supp_linked_to_nonsupp > 0:\n",
    "                err_msg = f\"Failure - Errors found when validating supplementary files flagged in the TDR dataset: Supplemental Files Linked to a Biosample: {str(supp_linked_to_biosample)} Supplemental Files Linked to a Non-Supplemental File: {str(supp_linked_to_nonsupp)} Links with No Issues: {str(non_issue_links)}\"\n",
    "                return err_msg\n",
    "        except Exception as e:\n",
    "            return \"Failure - BigQuery Error\"\n",
    "        return \"Success\"  \n",
    "\n",
    "# Loop through datasets and validate is_supplementary field\n",
    "dataset_id_list = [\n",
    "'8b2b1c92-66cf-403c-8eb0-03b523d1550e',\n",
    "'595b6755-e7ae-4e83-af2e-693c089aeec3',\n",
    "'84ac0d05-4be5-43e9-973e-ef999144d802',\n",
    "'732eaae3-b509-4a7a-8961-09d861e55253',\n",
    "'544f643d-b19f-4aa0-a6ec-a90e1a8681d6',\n",
    "'f85ea65e-1943-4bd6-a541-71c5d8465ca9',\n",
    "'280c5d6f-39a3-4d1d-aad2-a174451cd9b2',\n",
    "]\n",
    "results = []\n",
    "for dataset_id in dataset_id_list:\n",
    "    logging.info(f\"Validating dataset_id: {dataset_id}\")\n",
    "    status = validate_supp_file_flg(dataset_id) \n",
    "    results.append([dataset_id, status])\n",
    "    results_df = pd.DataFrame(results, columns = [\"dataset_id\", \"validation_status\"])\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Attempt to populate anvil_donor.organism_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Script to patch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def populate_organism_type(dataset_id):\n",
    "    logging.info(f\"Processing anvil_donor.organism_type for Dataset ID = {dataset_id}\")\n",
    "    \n",
    "    # Retrieve dataset information\n",
    "    logging.info(\"Retrieving necessary information from TDR.\")\n",
    "    api_client = utils.refresh_tdr_api_client()\n",
    "    datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "    try:\n",
    "        response = datasets_api.retrieve_dataset(id=dataset_id, include=[\"ACCESS_INFORMATION\"]).to_dict()\n",
    "        bq_project = response[\"access_information\"][\"big_query\"][\"project_id\"]\n",
    "        bq_dataset = response[\"access_information\"][\"big_query\"][\"dataset_name\"]\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error retrieving information from TDR. Exiting function. Error: {}\".format(e))\n",
    "        return \"Failure\"\n",
    "\n",
    "    # Re-process anvil_donor data to include organism_type (where available)\n",
    "    logging.info(\"Re-processing existing anvil_donor data to include organism_type value.\")\n",
    "    client = bigquery.Client()\n",
    "    target_file = \"anvil_donor.json\"\n",
    "    destination_dir = \"ingest_pipeline/output/transformed/anvil/{}/table_data\".format(dataset_id)\n",
    "    query = \"\"\"SELECT donor_id, \n",
    "    (SELECT MAX(CASE WHEN REGEXP_CONTAINS(value, '(h37|h38|h39|hg16|hg17|hg18|hg19|hs37|hs38|b37)') THEN 'Homo sapiens' END) AS organism_type FROM `{project}.{dataset}.workspace_attributes` WHERE attribute = 'library:reference') AS organism_type,\n",
    "    part_of_dataset_id, phenotypic_sex, reported_ethnicity, genetic_ancestry, source_datarepo_row_ids\n",
    "    FROM `{project}.{dataset}.anvil_donor`\"\"\".format(project=bq_project, dataset=bq_dataset)\n",
    "    try:\n",
    "        df = client.query(query).result().to_dataframe()\n",
    "        records_json = df.to_json(orient='records') \n",
    "        records_list = json.loads(records_json)\n",
    "        records_cnt = len(records_list)\n",
    "        with open(target_file, 'w') as outfile:\n",
    "            for idx, val in enumerate(records_list):\n",
    "                json.dump(val, outfile)\n",
    "                if idx < (records_cnt - 1):\n",
    "                    outfile.write('\\n')\n",
    "        !gsutil cp $target_file $ws_bucket/$destination_dir/ 2> stdout\n",
    "        !rm $target_file\n",
    "        logging.info(\"Successfully created new anvil_donor.json file.\")\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error creating new anvil_donor.json file. Exiting function. Error: {}\".format(str(e)))\n",
    "        return \"Failure\"\n",
    "\n",
    "    # Ingest updated anvil_donor data\n",
    "    logging.info(\"Ingesting updated anvil_donor data into TDR dataset.\")\n",
    "    source_full_file_path = \"{}/{}/{}\".format(ws_bucket, destination_dir, \"anvil_donor.json\")\n",
    "    ingest_request = {\n",
    "        \"table\": \"anvil_donor\",\n",
    "        \"profile_id\": \"e0e03e48-5b96-45ec-baa4-8cc1ebf74c61\",\n",
    "        \"ignore_unknown_values\": True,\n",
    "        \"resolve_existing_files\": True,\n",
    "        \"updateStrategy\": \"replace\",\n",
    "        \"format\": \"json\",\n",
    "        \"load_tag\": \"Ingest for {}\".format(dataset_id),\n",
    "        \"path\": source_full_file_path\n",
    "    }\n",
    "    attempt_counter = 0\n",
    "    while True:\n",
    "        try:\n",
    "            api_client = utils.refresh_tdr_api_client()\n",
    "            datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "            ingest_request_result, job_id = utils.wait_for_tdr_job(datasets_api.ingest_dataset(id=dataset_id, ingest=ingest_request))\n",
    "            logging.info(\"Ingest from file anvil_donor.json succeeded: {}\".format(str(ingest_request_result)[0:1000]))\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logging.error(\"Error on Dataset Ingest: {}\".format(str(e)))\n",
    "            attempt_counter += 1\n",
    "            if attempt_counter < 2:\n",
    "                logging.info(\"Retrying Dataset Ingest (attempt #{})...\".format(str(attempt_counter)))\n",
    "                sleep(10)\n",
    "                continue\n",
    "            else:\n",
    "                logging.error(\"Maximum number of retries exceeded. Exiting function.\")\n",
    "                return \"Failure\"\n",
    "\n",
    "    # Return success message if no failures recorded\n",
    "    logging.info(\"Function completed successfully.\")\n",
    "    return \"Success\"\n",
    "\n",
    "# Loop through datasets and process supplementary_file_flag\n",
    "dataset_id_list = [\n",
    "'d74b26d5-24bb-4696-84c3-bcd1f5f90b08',\n",
    "]\n",
    "results = []\n",
    "for dataset_id in dataset_id_list:\n",
    "    status = populate_organism_type(dataset_id) \n",
    "    results.append([dataset_id, status])\n",
    "    results_df = pd.DataFrame(results, columns = [\"dataset_id\", \"run_status\"])\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Script to examine organism_type population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def validate_organism_type(dataset_id):\n",
    "    \n",
    "    # Retrieve dataset information\n",
    "    src_schema_dict = {}\n",
    "    api_client = utils.refresh_tdr_api_client()\n",
    "    datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "    try:\n",
    "        response = datasets_api.retrieve_dataset(id=dataset_id, include=[\"SCHEMA\", \"ACCESS_INFORMATION\"]).to_dict()\n",
    "        src_schema_dict[\"tables\"] = response[\"schema\"][\"tables\"]\n",
    "        bq_project = response[\"access_information\"][\"big_query\"][\"project_id\"]\n",
    "        bq_dataset = response[\"access_information\"][\"big_query\"][\"dataset_name\"]\n",
    "    except Exception as e:\n",
    "        return \"Failure - Issue Retrieving Dataset Info\"\n",
    "    \n",
    "    # Determine if field exists for dataset, continue if so, fail otherwise\n",
    "    client = bigquery.Client()\n",
    "    query = \"\"\"SELECT COUNT(organism_type) AS populated_cnt\n",
    "                FROM `{project}.{dataset}.anvil_donor`\"\"\".format(project=bq_project, dataset=bq_dataset)\n",
    "    try:\n",
    "        df = client.query(query).result().to_dataframe()\n",
    "        if df[\"populated_cnt\"].values[0] > 0:\n",
    "            return \"Success - Field Populated\"\n",
    "        else:\n",
    "            return \"Success - Field Not Populated\"\n",
    "    except Exception as e:\n",
    "        return \"Failure - BigQuery Error\"\n",
    "\n",
    "# Loop through datasets and validate is_supplementary field\n",
    "dataset_id_list = [\n",
    "'d74b26d5-24bb-4696-84c3-bcd1f5f90b08',\n",
    "]\n",
    "results = []\n",
    "for dataset_id in dataset_id_list:\n",
    "    status = validate_organism_type(dataset_id) \n",
    "    results.append([dataset_id, status])\n",
    "    results_df = pd.DataFrame(results, columns = [\"dataset_id\", \"validation_status\"])\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Update references to md5-added files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to collect all datarepo rows for a particular table within a dataset\n",
    "def collect_all_datarepo_rows(dataset_id, table_name):\n",
    "    api_client = utils.refresh_tdr_api_client()\n",
    "    datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "    try:\n",
    "        response = datasets_api.retrieve_dataset(id=dataset_id, include=[\"ACCESS_INFORMATION\"]).to_dict()\n",
    "        bq_project = response[\"access_information\"][\"big_query\"][\"project_id\"]\n",
    "        bq_schema = response[\"access_information\"][\"big_query\"][\"dataset_name\"]\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error retrieving BQ project and schema: {}\".format(str(e)))\n",
    "    client = bigquery.Client()\n",
    "    query = \"SELECT datarepo_row_id FROM `{project}.{schema}.{table}`\".format(project = bq_project, schema = bq_schema, table = table_name)\n",
    "    try:\n",
    "        query_job = client.query(query)\n",
    "        results = [row[\"datarepo_row_id\"] for row in query_job]\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error retrieving datarepo_row_id list: {}\".format(str(e)))\n",
    "        raise Exception(e)\n",
    "\n",
    "# Function to delete rows from a dataset\n",
    "def delete_old_records(dataset_id, table, datarepo_row_ids):\n",
    "    logging.info(f\"Attempting to delete original {table} records.\")\n",
    "    if datarepo_row_ids:\n",
    "        data_deletion_payload = {\n",
    "            \"deleteType\": \"soft\",\n",
    "            \"specType\": \"jsonArray\",\n",
    "            \"tables\": [{\n",
    "              \"tableName\": table,\n",
    "              \"jsonArraySpec\": {\n",
    "                \"rowIds\": datarepo_row_ids\n",
    "              }\n",
    "            }]\n",
    "        }\n",
    "        api_client = utils.refresh_tdr_api_client()\n",
    "        datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "        try:\n",
    "            data_deletion_result, job_id = utils.wait_for_tdr_job(datasets_api.apply_dataset_data_deletion(id=dataset_id, data_deletion_request=data_deletion_payload))\n",
    "            logging.info(\"Result: {}\".format(data_deletion_result))\n",
    "        except Exception as e:\n",
    "            logging.info(\"Error: {}\".format(str(e)))\n",
    "            raise Exception(e)\n",
    "    else:\n",
    "        logging.info(\"No datarepo_row_ids specified for deletion.\")\n",
    "\n",
    "def ingest_updated_records(profile_id, dataset_id, table, records_dict):\n",
    "    logging.info(f\"Submitting ingest for updated {table} records.\")\n",
    "    \n",
    "    # Build, submit, and monitor ingest request\n",
    "    ingest_request = {\n",
    "        \"table\": table,\n",
    "        \"profile_id\": profile_id,\n",
    "        \"ignore_unknown_values\": True,\n",
    "        \"resolve_existing_files\": True,\n",
    "        \"updateStrategy\": \"replace\",\n",
    "        \"format\": \"array\",\n",
    "        \"bulkMode\": False,\n",
    "        \"load_tag\": f\"File ref fields patch for {table} in {dataset_id}\",\n",
    "        \"records\": records_dict\n",
    "    }\n",
    "    attempt_counter = 0\n",
    "    while True:\n",
    "        try:\n",
    "            api_client = utils.refresh_tdr_api_client()\n",
    "            datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "            ingest_request_result, job_id = utils.wait_for_tdr_job(datasets_api.ingest_dataset(id=dataset_id, ingest=ingest_request))\n",
    "            logging.info(\"Ingest succeeded: {}\".format(str(ingest_request_result)[0:1000]))\n",
    "            status = \"Success\"\n",
    "            return\n",
    "        except Exception as e:\n",
    "            logging.error(\"Error on ingest: {}\".format(str(e)))\n",
    "            attempt_counter += 1\n",
    "            if attempt_counter < 1:\n",
    "                logging.info(\"Retrying ingest (attempt #{})...\".format(str(attempt_counter)))\n",
    "                sleep(10)\n",
    "                continue\n",
    "            else:\n",
    "                logging.error(\"Maximum number of retries exceeded. Logging error.\")\n",
    "                status = \"Error\"\n",
    "                raise Exception(e)\n",
    "                \n",
    "def update_recs_w_file_refs(dataset_id):\n",
    "    logging.info(f\"Processing md5-added files for Dataset ID = {dataset_id}\")\n",
    "\n",
    "    ## Retrieve dataset information\n",
    "    logging.info(\"Retrieving necessary information from TDR.\")\n",
    "    src_schema_dict = {}\n",
    "    api_client = utils.refresh_tdr_api_client()\n",
    "    datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "    try:\n",
    "        response = datasets_api.retrieve_dataset(id=dataset_id, include=[\"SCHEMA\", \"ACCESS_INFORMATION\"]).to_dict()\n",
    "        src_schema_dict[\"tables\"] = response[\"schema\"][\"tables\"]\n",
    "        bq_project = response[\"access_information\"][\"big_query\"][\"project_id\"]\n",
    "        bq_dataset = response[\"access_information\"][\"big_query\"][\"dataset_name\"]\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error retrieving information from TDR. Exiting function. Error: {}\".format(e))\n",
    "        return \"Failure - Pre-processing\"\n",
    "\n",
    "    ## Parse TDR schema to identify file reference fields\n",
    "    table_dict = {}\n",
    "    for table in src_schema_dict[\"tables\"]:\n",
    "        if table[\"name\"] in [\"file_inventory\", \"anvil_file\"]:\n",
    "            continue\n",
    "        else:\n",
    "            col_list = []\n",
    "            for column in table[\"columns\"]:\n",
    "                if column[\"datatype\"] == \"fileref\":\n",
    "                    col_list.append([column[\"name\"], column[\"array_of\"]])\n",
    "            if col_list:\n",
    "                table_dict[table[\"name\"]] = col_list\n",
    "\n",
    "    ## Loop through tables and re-process impacted records\n",
    "    for table in table_dict.keys():\n",
    "        logging.info(f\"Processing updates for {table}.\")\n",
    "        # Retrieve relevant records from BigQuery\n",
    "        col_list = []\n",
    "        old_cols = \"\"\n",
    "        new_cols = \"\"\n",
    "        join_clause = \"\"\n",
    "        where_clause = \"\"\n",
    "        for idx, col in enumerate(table_dict[table]):\n",
    "            column_name = col[0]\n",
    "            col_list.append(column_name)\n",
    "            if idx == 0: \n",
    "                old_cols += column_name\n",
    "                where_clause += f\"t.{column_name} IN (SELECT file_ref FROM file_list)\"\n",
    "            else:\n",
    "                old_cols += \", \" + column_name\n",
    "                where_clause += f\" OR t.{column_name} IN (SELECT file_ref FROM file_list)\"\n",
    "            new_cols += f\", CASE WHEN t{idx}.source_name IS NOT NULL THEN TO_JSON(STRUCT(t{idx}.source_name AS sourcePath, t{idx}.target_path AS targetPath)) END AS {column_name}\"\n",
    "            join_clause += f\" LEFT JOIN load_hist t{idx} ON t.{column_name} = t{idx}.file_id\"\n",
    "\n",
    "        query = \"\"\"WITH \n",
    "            file_list AS (SELECT * FROM `{project}.{dataset}.file_inventory` WHERE md5_hash IS NULL),\n",
    "            load_hist AS (SELECT * FROM `{project}.{dataset}.datarepo_load_history` WHERE state = 'succeeded')\n",
    "            SELECT t.* EXCEPT({old_cols}){new_cols}\n",
    "            FROM `{project}.{dataset}.{table}` t {joins} WHERE {where}\"\"\".format(project=bq_project, dataset=bq_dataset, table=table, old_cols=old_cols, new_cols=new_cols, joins=join_clause, where=where_clause)\n",
    "        try:\n",
    "            client = bigquery.Client()\n",
    "            res = client.query(query).result()\n",
    "            if res.total_rows > 0:\n",
    "                logging.info(f\"{res.total_rows} records to process.\")\n",
    "                df = res.to_dataframe()\n",
    "                records_json = df.to_json(orient='records')\n",
    "                records_list = json.loads(records_json)\n",
    "            else:\n",
    "                logging.info(\"No records to process.\")\n",
    "                records_list = []\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error retrieving update records from BigQuery: {str(e)}\")\n",
    "            return \"Failure - Table Processing\"\n",
    "        # Ingest updated records back to TDR dataset\n",
    "        try:\n",
    "            datarepo_row_ids = []\n",
    "            for record in records_list:\n",
    "                datarepo_row_ids.append(record.pop(\"datarepo_row_id\", None))\n",
    "                for col in col_list:\n",
    "                    record[col] = json.loads(record[col])\n",
    "            if records_list:\n",
    "                ingest_updated_records(\"e0e03e48-5b96-45ec-baa4-8cc1ebf74c61\", dataset_id, table, records_list)\n",
    "                delete_old_records(dataset_id, table, datarepo_row_ids)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error replacing TDR records: {str(e)}\")\n",
    "            return \"Failure - Table Processing\"\n",
    "        \n",
    "    ## Re-process file_inventory\n",
    "    logging.info(f\"Processing updates for file_inventory.\")\n",
    "    # Retrieve relevant records from BigQuery\n",
    "    query = \"\"\"WITH \n",
    "        file_list AS (SELECT file_ref FROM `{project}.{dataset}.file_inventory` WHERE md5_hash IS NULL),\n",
    "        load_hist AS (SELECT * FROM `{project}.{dataset}.datarepo_load_history` WHERE state = 'succeeded')\n",
    "        SELECT t1.*, CASE WHEN t2.source_name IS NOT NULL THEN TO_JSON(STRUCT(t2.source_name AS sourcePath, t2.target_path AS targetPath)) END AS file_ref\n",
    "        FROM `{project}.{dataset}.file_inventory` t1\n",
    "          INNER JOIN load_hist t2 ON t1.file_ref = t2.file_id\n",
    "        WHERE file_ref IN (SELECT file_ref FROM file_list)\"\"\".format(project=bq_project, dataset=bq_dataset)\n",
    "    try:\n",
    "        client = bigquery.Client()\n",
    "        res = client.query(query).result()\n",
    "        if res.total_rows > 0:\n",
    "            logging.info(f\"{res.total_rows} records to process.\")\n",
    "            df = res.to_dataframe()\n",
    "            records_json = df.to_json(orient='records')\n",
    "            records_list = json.loads(records_json)\n",
    "        else:\n",
    "            logging.info(\"No records to process.\")\n",
    "            records_list = []\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error retrieving update records from BigQuery: {str(e)}\")\n",
    "        return \"Failure - File Inventory Processing\"\n",
    "    # Loop through records and update md5_hash from GCS metadata\n",
    "    try:\n",
    "        storage_client = storage.Client()\n",
    "        datarepo_row_ids = []\n",
    "        for record in records_list:\n",
    "            bucket = re.match('gs:\\/\\/([a-z0-9\\-]+)', record[\"uri\"]).group(1)\n",
    "            obj = re.match('gs:\\/\\/[a-z0-9\\-]+\\/([A-Za-z0-9\\-_\\/\\.]+)', record[\"uri\"]).group(1)\n",
    "            bucket = storage_client.bucket(bucket, user_project=\"anvil-datastorage\")\n",
    "            blob = bucket.get_blob(obj)\n",
    "            record[\"md5_hash\"] = blob.md5_hash\n",
    "            datarepo_row_ids.append(record.pop(\"datarepo_row_id\", None))\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error retrieving file metadata from GCS: {str(e)}\")\n",
    "        return \"Failure - File Inventory Processing\"\n",
    "    # Ingest updated records back to TDR dataset\n",
    "    try:\n",
    "        if records_list:\n",
    "            ingest_updated_records(\"e0e03e48-5b96-45ec-baa4-8cc1ebf74c61\", dataset_id, \"file_inventory\", records_list)\n",
    "            delete_old_records(dataset_id, \"file_inventory\", datarepo_row_ids)         \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error replacing TDR records: {str(e)}\")\n",
    "        return \"Failure - File Inventory Processing\"\n",
    "\n",
    "    ## Empty anvil_% tables\n",
    "    logging.info(\"Clearing out existing anvil_% tables\")\n",
    "    table_list = [\"anvil_activity\", \"anvil_alignmentactivity\", \"anvil_antibody\", \"anvil_assayactivity\", \"anvil_biosample\", \"anvil_diagnosis\", \"anvil_donor\", \"anvil_file\", \"anvil_sequencingactivity\", \"anvil_variantcallingactivity\"]\n",
    "    for table in table_list:\n",
    "        try:\n",
    "            datarepo_row_ids = collect_all_datarepo_rows(dataset_id, table)\n",
    "            if datarepo_row_ids:\n",
    "                delete_old_records(dataset_id, table, datarepo_row_ids)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error clearing out existing anvil_% records: {str(e)}\")\n",
    "            return \"Failure - anvil_% Record Deletion\"\n",
    "    \n",
    "    ## Re-run T pipeline without validation\n",
    "    params = {}\n",
    "    params[\"ws_name\"] = ws_name\n",
    "    params[\"ws_project\"] = ws_project\n",
    "    params[\"ws_bucket\"] = ws_bucket\n",
    "    params[\"ws_bucket_name\"] = ws_bucket_name\n",
    "    params[\"profile_id\"] = \"e0e03e48-5b96-45ec-baa4-8cc1ebf74c61\" \n",
    "    params[\"mapping_target\"] = \"anvil\"\n",
    "    params[\"skip_transforms\"] = False\n",
    "    params[\"transform_list_override\"] = [] # Leave empty to run transforms for all files, otherwise populate with target table names \n",
    "    params[\"skip_schema_extension\"] = False\n",
    "    params[\"skip_ingests\"] = False\n",
    "    params[\"ingest_list_override\"] = [] # Leave empty to run ingests for all files, otherwise populate with target table names\n",
    "    params[\"skip_file_relation_inference\"] = False\n",
    "    params[\"skip_dangling_fk_resolution\"] = False\n",
    "    params[\"skip_supplementary_file_identification\"] = False\n",
    "    params[\"skip_snapshot_creation\"] = False\n",
    "    params[\"snapshot_readers_list\"] = [\"azul-anvil-prod@firecloud.org\"] # Include \"auth-domain\" to add the auth domain(s) as a reader (if one exists)\n",
    "    params[\"skip_data_validation\"] = True\n",
    "    try:\n",
    "        api_client = utils.refresh_tdr_api_client()\n",
    "        datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "        dataset_info = datasets_api.retrieve_dataset(id=dataset_id, include=[\"SCHEMA\", \"ACCESS_INFORMATION\", \"PROPERTIES\"]).to_dict()\n",
    "        dataset_name = dataset_info[\"name\"]\n",
    "        phs_id = dataset_info[\"phs_id\"]\n",
    "        consent_name = dataset_info[\"properties\"][\"consent_name\"]\n",
    "        auth_domains = dataset_info[\"properties\"][\"auth_domains\"]\n",
    "        src_workspaces = dataset_info[\"properties\"][\"source_workspaces\"]\n",
    "    except:\n",
    "        dataset_name = \"\"\n",
    "        return \"Failure - Dataset Retrieval for T Pipeline\"\n",
    "    if dataset_name:\n",
    "        params[\"dataset_id\"] = dataset_id\n",
    "        params[\"dataset_name\"] = dataset_name\n",
    "        params[\"phs_id\"] = phs_id\n",
    "        params[\"consent_name\"] = consent_name\n",
    "        params[\"auth_domains\"] = auth_domains\n",
    "        utils.run_t_pipeline(params)\n",
    "    \n",
    "    # Return success message if no failures recorded\n",
    "    logging.info(\"Function completed successfully.\")\n",
    "    return \"Success\"\n",
    "\n",
    "# Loop through datasets and process md5 updates\n",
    "dataset_id_list = [\n",
    "'700303c2-fcef-48a5-9900-096bf34e2d83',\n",
    "'a715c70d-da92-43ee-a851-1a27277909a2',\n",
    "]\n",
    "results = []\n",
    "for dataset_id in dataset_id_list:\n",
    "    status = update_recs_w_file_refs(dataset_id) \n",
    "    results.append([dataset_id, status])\n",
    "    results_df = pd.DataFrame(results, columns = [\"dataset_id\", \"run_status\"])\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Testing\n",
    "# dataset_id = 'bc6075ac-5cfe-4613-8601-36ceb614939e'\n",
    "\n",
    "# logging.info(f\"Processing md5-added files for Dataset ID = {dataset_id}\")\n",
    "\n",
    "# ## Retrieve dataset information\n",
    "# logging.info(\"Retrieving necessary information from TDR.\")\n",
    "# src_schema_dict = {}\n",
    "# api_client = utils.refresh_tdr_api_client()\n",
    "# datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "# try:\n",
    "#     response = datasets_api.retrieve_dataset(id=dataset_id, include=[\"SCHEMA\", \"ACCESS_INFORMATION\"]).to_dict()\n",
    "#     src_schema_dict[\"tables\"] = response[\"schema\"][\"tables\"]\n",
    "#     bq_project = response[\"access_information\"][\"big_query\"][\"project_id\"]\n",
    "#     bq_dataset = response[\"access_information\"][\"big_query\"][\"dataset_name\"]\n",
    "# except Exception as e:\n",
    "#     logging.error(\"Error retrieving information from TDR. Exiting function. Error: {}\".format(e))\n",
    "#     #return \"Failure - Pre-processing\"\n",
    "\n",
    "# ## Parse TDR schema to identify file reference fields\n",
    "# table_dict = {}\n",
    "# for table in src_schema_dict[\"tables\"]:\n",
    "#     if table[\"name\"] in [\"file_inventory\", \"anvil_file\"]:\n",
    "#         continue\n",
    "#     else:\n",
    "#         col_list = []\n",
    "#         for column in table[\"columns\"]:\n",
    "#             if column[\"datatype\"] == \"fileref\":\n",
    "#                 col_list.append([column[\"name\"], column[\"array_of\"]])\n",
    "#         if col_list:\n",
    "#             table_dict[table[\"name\"]] = col_list\n",
    "\n",
    "# ## Loop through tables and re-process impacted records\n",
    "# for table in table_dict.keys():\n",
    "#     logging.info(f\"Processing updates for {table}.\")\n",
    "#     # Retrieve relevant records from BigQuery\n",
    "#     col_list = []\n",
    "#     old_cols = \"\"\n",
    "#     new_cols = \"\"\n",
    "#     join_clause = \"\"\n",
    "#     where_clause = \"\"\n",
    "#     for idx, col in enumerate(table_dict[table]):\n",
    "#         column_name = col[0]\n",
    "#         col_list.append(column_name)\n",
    "#         if idx == 0: \n",
    "#             old_cols += column_name\n",
    "#             where_clause += f\"t.{column_name} IN (SELECT file_ref FROM file_list)\"\n",
    "#         else:\n",
    "#             old_cols += \", \" + column_name\n",
    "#             where_clause += f\" OR t.{column_name} IN (SELECT file_ref FROM file_list)\"\n",
    "#         new_cols += f\", CASE WHEN t{idx}.source_name IS NOT NULL THEN TO_JSON(STRUCT(t{idx}.source_name AS sourcePath, t{idx}.target_path AS targetPath)) END AS {column_name}\"\n",
    "#         join_clause += f\" LEFT JOIN load_hist t{idx} ON t.{column_name} = t{idx}.file_id\"\n",
    "\n",
    "#     query = \"\"\"WITH \n",
    "#         file_list AS (SELECT * FROM `{project}.{dataset}.file_inventory` WHERE md5_hash IS NULL),\n",
    "#         load_hist AS (SELECT * FROM `{project}.{dataset}.datarepo_load_history` WHERE state = 'succeeded')\n",
    "#         SELECT t.* EXCEPT({old_cols}){new_cols}\n",
    "#         FROM `{project}.{dataset}.{table}` t {joins} WHERE {where}\"\"\".format(project=bq_project, dataset=bq_dataset, table=table, old_cols=old_cols, new_cols=new_cols, joins=join_clause, where=where_clause)\n",
    "#     try:\n",
    "#         client = bigquery.Client()\n",
    "#         res = client.query(query).result()\n",
    "#         if res.total_rows > 0:\n",
    "#             logging.info(f\"{res.total_rows} records to process.\")\n",
    "#             df = res.to_dataframe()\n",
    "#             records_json = df.to_json(orient='records')\n",
    "#             records_list = json.loads(records_json)\n",
    "#         else:\n",
    "#             logging.info(\"No records to process.\")\n",
    "#             records_list = []\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error retrieving update records from BigQuery: {str(e)}\")\n",
    "#         break\n",
    "#         #return \"Failure - Table Processing\"\n",
    "#     # Ingest updated records back to TDR dataset\n",
    "#     try:\n",
    "#         datarepo_row_ids = []\n",
    "#         for record in records_list:\n",
    "#             datarepo_row_ids.append(record.pop(\"datarepo_row_id\", None))\n",
    "#             for col in col_list:\n",
    "#                 record[col] = json.loads(record[col])\n",
    "#         if records_list:\n",
    "#             ingest_updated_records(\"e0e03e48-5b96-45ec-baa4-8cc1ebf74c61\", dataset_id, table, records_list)\n",
    "#             delete_old_records(dataset_id, table, datarepo_row_ids)\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error replacing TDR records: {str(e)}\")\n",
    "#         break\n",
    "#         #return \"Failure - Table Processing\"\n",
    "\n",
    "# # ## Re-process file_inventory\n",
    "# # logging.info(f\"Processing updates for file_inventory.\")\n",
    "# # # Retrieve relevant records from BigQuery\n",
    "# # query = \"\"\"WITH \n",
    "# #     file_list AS (SELECT file_ref FROM `{project}.{dataset}.file_inventory` WHERE md5_hash IS NULL),\n",
    "# #     load_hist AS (SELECT * FROM `{project}.{dataset}.datarepo_load_history` WHERE state = 'succeeded')\n",
    "# #     SELECT t1.*, CASE WHEN t2.source_name IS NOT NULL THEN TO_JSON(STRUCT(t2.source_name AS sourcePath, t2.target_path AS targetPath)) END AS file_ref\n",
    "# #     FROM `{project}.{dataset}.file_inventory` t1\n",
    "# #       INNER JOIN load_hist t2 ON t1.file_ref = t2.file_id\n",
    "# #     WHERE file_ref IN (SELECT file_ref FROM file_list)\"\"\".format(project=bq_project, dataset=bq_dataset)\n",
    "# # try:\n",
    "# #     client = bigquery.Client()\n",
    "# #     res = client.query(query).result()\n",
    "# #     if res.total_rows > 0:\n",
    "# #         logging.info(f\"{res.total_rows} records to process.\")\n",
    "# #         df = res.to_dataframe()\n",
    "# #         records_json = df.to_json(orient='records')\n",
    "# #         records_list = json.loads(records_json)\n",
    "# #     else:\n",
    "# #         logging.info(\"No records to process.\")\n",
    "# #         records_list = []\n",
    "# # except Exception as e:\n",
    "# #     logging.error(f\"Error retrieving update records from BigQuery: {str(e)}\")\n",
    "# #     #return \"Failure - File Inventory Processing\"\n",
    "# # # Loop through records and update md5_hash from GCS metadata\n",
    "# # try:\n",
    "# #     storage_client = storage.Client()\n",
    "# #     datarepo_row_ids = []\n",
    "# #     for record in records_list:\n",
    "# #         bucket = re.match('gs:\\/\\/([a-z0-9\\-]+)', record[\"uri\"]).group(1)\n",
    "# #         obj = re.match('gs:\\/\\/[a-z0-9\\-]+\\/([A-Za-z0-9\\-_\\/\\.]+)', record[\"uri\"]).group(1)\n",
    "# #         bucket = storage_client.bucket(bucket, user_project=\"anvil-datastorage\")\n",
    "# #         blob = bucket.get_blob(obj)\n",
    "# #         record[\"md5_hash\"] = blob.md5_hash\n",
    "# #         datarepo_row_ids.append(record.pop(\"datarepo_row_id\", None))\n",
    "# # except Exception as e:\n",
    "# #     logging.error(f\"Error retrieving file metadata from GCS: {str(e)}\")\n",
    "# #     #return \"Failure - File Inventory Processing\"\n",
    "# # # Ingest updated records back to TDR dataset\n",
    "# # try:\n",
    "# #     if records_list:\n",
    "# #         ingest_updated_records(\"e0e03e48-5b96-45ec-baa4-8cc1ebf74c61\", dataset_id, \"file_inventory\", records_list)\n",
    "# #         delete_old_records(dataset_id, \"file_inventory\", datarepo_row_ids)         \n",
    "# # except Exception as e:\n",
    "# #     logging.error(f\"Error replacing TDR records: {str(e)}\")\n",
    "# #     #return \"Failure - File Inventory Processing\"\n",
    "\n",
    "# # ## Empty anvil_% tables\n",
    "# # logging.info(\"Clearing out existing anvil_% tables\")\n",
    "# # table_list = [\"anvil_activity\", \"anvil_alignmentactivity\", \"anvil_antibody\", \"anvil_assayactivity\", \"anvil_biosample\", \"anvil_diagnosis\", \"anvil_donor\", \"anvil_file\", \"anvil_sequencingactivity\", \"anvil_variantcallingactivity\"]\n",
    "# # for table in table_list:\n",
    "# #     try:\n",
    "# #         datarepo_row_ids = collect_all_datarepo_rows(dataset_id, table)\n",
    "# #         if datarepo_row_ids:\n",
    "# #             delete_old_records(dataset_id, table, datarepo_row_ids)\n",
    "# #     except Exception as e:\n",
    "# #         logging.error(f\"Error clearing out existing anvil_% records: {str(e)}\")\n",
    "# #         break\n",
    "# #         #return \"Failure - anvil_% Record Deletion\"\n",
    "\n",
    "# # ## Re-run T pipeline without validation\n",
    "# # params = {}\n",
    "# # params[\"ws_name\"] = ws_name\n",
    "# # params[\"ws_project\"] = ws_project\n",
    "# # params[\"ws_bucket\"] = ws_bucket\n",
    "# # params[\"ws_bucket_name\"] = ws_bucket_name\n",
    "# # params[\"profile_id\"] = \"e0e03e48-5b96-45ec-baa4-8cc1ebf74c61\" \n",
    "# # params[\"mapping_target\"] = \"anvil\"\n",
    "# # params[\"skip_transforms\"] = False\n",
    "# # params[\"transform_list_override\"] = [] # Leave empty to run transforms for all files, otherwise populate with target table names \n",
    "# # params[\"skip_schema_extension\"] = False\n",
    "# # params[\"skip_ingests\"] = False\n",
    "# # params[\"ingest_list_override\"] = [] # Leave empty to run ingests for all files, otherwise populate with target table names\n",
    "# # params[\"skip_file_relation_inference\"] = False\n",
    "# # params[\"skip_dangling_fk_resolution\"] = False\n",
    "# # params[\"skip_supplementary_file_identification\"] = False\n",
    "# # params[\"skip_snapshot_creation\"] = False\n",
    "# # params[\"snapshot_readers_list\"] = [\"azul-anvil-prod@firecloud.org\"] # Include \"auth-domain\" to add the auth domain(s) as a reader (if one exists)\n",
    "# # params[\"skip_data_validation\"] = True\n",
    "# # try:\n",
    "# #     api_client = utils.refresh_tdr_api_client()\n",
    "# #     datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "# #     dataset_info = datasets_api.retrieve_dataset(id=dataset_id, include=[\"SCHEMA\", \"ACCESS_INFORMATION\", \"PROPERTIES\"]).to_dict()\n",
    "# #     dataset_name = dataset_info[\"name\"]\n",
    "# #     phs_id = dataset_info[\"phs_id\"]\n",
    "# #     consent_name = dataset_info[\"properties\"][\"consent_name\"]\n",
    "# #     auth_domains = dataset_info[\"properties\"][\"auth_domains\"]\n",
    "# #     src_workspaces = dataset_info[\"properties\"][\"source_workspaces\"]\n",
    "# # except:\n",
    "# #     dataset_name = \"\"\n",
    "# #     return \"Failure - Dataset Retrieval for T Pipeline\"\n",
    "# # if dataset_name:\n",
    "# #     params[\"dataset_id\"] = dataset_id\n",
    "# #     params[\"dataset_name\"] = dataset_name\n",
    "# #     params[\"phs_id\"] = phs_id\n",
    "# #     params[\"consent_name\"] = consent_name\n",
    "# #     params[\"auth_domains\"] = auth_domains\n",
    "# #     utils.run_t_pipeline(params)\n",
    "\n",
    "# # Return success message if no failures recorded\n",
    "# logging.info(\"Function completed successfully.\")\n",
    "# #return \"Success\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for idx, record in enumerate(records_list):\n",
    "#     if record[\"library_2_estimated_library_size\"]:\n",
    "#         print(str(idx) + \" - \" + str(record[\"library_2_estimated_library_size\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# records_list[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add new workspace files to the appropriate TDR dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to diff file inventories between TDR and source workspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     4
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/10/2024 02:46:15 PM - INFO: Processing dataset_id = d48adc59-8934-41bb-9720-63e71f1933be...\n",
      "04/10/2024 02:46:15 PM - INFO: Retrieving dataset details.\n",
      "04/10/2024 02:46:15 PM - INFO: Building and executing aggregate file diff query.\n",
      "04/10/2024 02:46:20 PM - INFO: Processing dataset_id = 80baf71d-28d0-4bca-81b7-49ddfadfa7a3...\n",
      "04/10/2024 02:46:20 PM - INFO: Retrieving dataset details.\n",
      "04/10/2024 02:46:20 PM - INFO: Building and executing aggregate file diff query.\n",
      "Aggregate Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>tdr_files</th>\n",
       "      <th>tdr_files_not_in_inv</th>\n",
       "      <th>inv_files_not_in_tdr</th>\n",
       "      <th>non_vds_inv_files_not_in_tdr</th>\n",
       "      <th>joint_call_vcf_files</th>\n",
       "      <th>status</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d48adc59-8934-41bb-9720-63e71f1933be</td>\n",
       "      <td>ANVIL_1000G_PRIMED_data_model_20240410</td>\n",
       "      <td>11493</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80baf71d-28d0-4bca-81b7-49ddfadfa7a3</td>\n",
       "      <td>ANVIL_GTEx_v10_hg38_20240410</td>\n",
       "      <td>153984</td>\n",
       "      <td>28135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dataset_id                            dataset_name               tdr_files  tdr_files_not_in_inv  inv_files_not_in_tdr  non_vds_inv_files_not_in_tdr  joint_call_vcf_files  status  message\n",
       "0  d48adc59-8934-41bb-9720-63e71f1933be  ANVIL_1000G_PRIMED_data_model_20240410    11493               23                   0                         0                         0           Success        \n",
       "1  80baf71d-28d0-4bca-81b7-49ddfadfa7a3            ANVIL_GTEx_v10_hg38_20240410   153984            28135                   0                         0                         0           Success        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################################\n",
    "## Functions\n",
    "#############################################\n",
    "\n",
    "def anvil_tdr_file_diff(dataset_id_list, print_queries, write_out_files):\n",
    "\n",
    "    # Loop through and process datasets\n",
    "    results = []\n",
    "    df_detailed_results = pd.DataFrame()\n",
    "    for dataset_id in dataset_id_list:\n",
    "\n",
    "        # Retrieve dataset information\n",
    "        logging.info(f\"Processing dataset_id = {dataset_id}...\")\n",
    "        api_client = utils.refresh_tdr_api_client()\n",
    "        datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "        try:\n",
    "            logging.info(\"Retrieving dataset details.\")\n",
    "            dataset_details = datasets_api.retrieve_dataset(id=dataset_id, include=[\"ACCESS_INFORMATION\", \"PROPERTIES\"]).to_dict()\n",
    "            dataset_name = dataset_details[\"name\"]\n",
    "            bq_project = dataset_details[\"access_information\"][\"big_query\"][\"project_id\"]\n",
    "            bq_dataset = dataset_details[\"access_information\"][\"big_query\"][\"dataset_name\"]\n",
    "            try:\n",
    "                source_workspace = dataset_details[\"properties\"][\"source_workspaces\"][0]\n",
    "            except:\n",
    "                source_workspace = \"\"\n",
    "        except Exception as e:\n",
    "            error_message = f\"Error retrieving dataset details: {str(e)}\"\n",
    "            logging.error(error_message)\n",
    "            results.append([dataset_id, \"\", 0, 0, \"Error\", error_message])\n",
    "\n",
    "        # Build and execute aggregate query\n",
    "        logging.info(\"Building and executing aggregate file diff query.\")\n",
    "        client = bigquery.Client()\n",
    "        query = f\"\"\"WITH files_all_workspaces\n",
    "                    AS\n",
    "                    (\n",
    "                      SELECT file_path\n",
    "                      FROM `broad-dsde-prod-analytics-dev.anvil_inventory_uscentral1.ref_object_inventory_20240405`\n",
    "                      WHERE file_path NOT LIKE '%/'\n",
    "                    ),\n",
    "                    files_source_workspace\n",
    "                    AS\n",
    "                    (\n",
    "                      SELECT file_path\n",
    "                      FROM `broad-dsde-prod-analytics-dev.anvil_inventory_uscentral1.ref_object_inventory_20240405`\n",
    "                      WHERE workspace_name = '{source_workspace}'\n",
    "                      AND billing_project = 'anvil-datastorage'\n",
    "                      AND file_path NOT LIKE '%/'\n",
    "                    ),\n",
    "                    files_tdr\n",
    "                    AS\n",
    "                    (\n",
    "                      SELECT uri AS file_path\n",
    "                      FROM `{bq_project}.{bq_dataset}.file_inventory`  \n",
    "                    )\n",
    "                    SELECT COUNT(CASE WHEN t0.file_path IS NOT NULL THEN 1 END) AS tdr_files,\n",
    "                    COUNT(CASE WHEN t0.file_path IS NOT NULL AND t1.file_path IS NULL THEN 1 END) AS tdr_files_not_in_inv,\n",
    "                    COUNT(CASE WHEN t0.file_path IS NULL AND t2.file_path IS NOT NULL THEN 1 END) AS inv_files_not_in_tdr,\n",
    "                    COUNT(CASE WHEN t0.file_path IS NULL AND t2.file_path IS NOT NULL AND t2.file_path NOT LIKE '%SubsetHailJointCall%' AND t2.file_path NOT LIKE '%.vds/%' THEN 1 END) AS non_vds_inv_files_not_in_tdr,\n",
    "                    COUNT(CASE WHEN t2.file_path IS NOT NULL AND t2.file_path LIKE '%SubsetHailJointCall%' AND t2.file_path LIKE '%.vcf%' THEN 1 END) AS joint_call_vcf_files\n",
    "                    FROM files_tdr t0 \n",
    "                      LEFT JOIN files_all_workspaces t1 ON t0.file_path = t1.file_path  \n",
    "                      FULL JOIN files_source_workspace t2 ON t0.file_path = t2.file_path\"\"\"\n",
    "        if print_queries:\n",
    "            print(\"Aggregate file diff query:\")\n",
    "            print(query)\n",
    "        try:\n",
    "            df = client.query(query).result().to_dataframe()\n",
    "            tdr_files = df[\"tdr_files\"].values[0]\n",
    "            tdr_files_not_in_inv = df[\"tdr_files_not_in_inv\"].values[0]\n",
    "            inv_files_not_in_tdr = df[\"inv_files_not_in_tdr\"].values[0] \n",
    "            non_vds_inv_files_not_in_tdr = df[\"non_vds_inv_files_not_in_tdr\"].values[0]\n",
    "            joint_call_vcf_files = df[\"joint_call_vcf_files\"].values[0]\n",
    "            results.append([dataset_id, dataset_name, tdr_files, tdr_files_not_in_inv, inv_files_not_in_tdr, non_vds_inv_files_not_in_tdr, joint_call_vcf_files, \"Success\", \"\"])\n",
    "        except Exception as e:\n",
    "            error_message = f\"BigQuery error: {str(e)}\"\n",
    "            logging.error(error_message)\n",
    "            results.append([dataset_id, dataset_name, 0, 0, 0, 0, 0, \"Error\", error_message]) \n",
    "        \n",
    "        # Build and execute details query\n",
    "        if write_out_files:\n",
    "            logging.info(\"Building and executing detailed file diff query.\")\n",
    "            client = bigquery.Client()\n",
    "            query = f\"\"\"WITH files_all_workspaces\n",
    "                        AS\n",
    "                        (\n",
    "                          SELECT file_path\n",
    "                          FROM `broad-dsde-prod-analytics-dev.anvil_inventory_uscentral1.ref_object_inventory_20240405`\n",
    "                          WHERE file_path NOT LIKE '%/'\n",
    "                        ),\n",
    "                        files_source_workspace\n",
    "                        AS\n",
    "                        (\n",
    "                          SELECT file_path\n",
    "                          FROM `broad-dsde-prod-analytics-dev.anvil_inventory_uscentral1.ref_object_inventory_20240405`\n",
    "                          WHERE workspace_name = '{source_workspace}'\n",
    "                          AND billing_project = 'anvil-datastorage'\n",
    "                          AND file_path NOT LIKE '%/'\n",
    "                        ),\n",
    "                        files_tdr\n",
    "                        AS\n",
    "                        (\n",
    "                          SELECT uri AS file_path\n",
    "                          FROM `{bq_project}.{bq_dataset}.file_inventory`  \n",
    "                        )\n",
    "                        SELECT '{dataset_id}' AS dataset_id, 'tdr_files_not_in_inv' AS metric, t0.file_path\n",
    "                        FROM files_tdr t0 \n",
    "                          LEFT JOIN files_all_workspaces t1 ON t0.file_path = t1.file_path  \n",
    "                          FULL JOIN files_source_workspace t2 ON t0.file_path = t2.file_path\n",
    "                        WHERE t0.file_path IS NOT NULL AND t1.file_path IS NULL\n",
    "                        UNION ALL\n",
    "                        SELECT '{dataset_id}' AS dataset_id, 'non_vds_inv_files_not_in_tdr' AS metric, t2.file_path\n",
    "                        FROM files_tdr t0 \n",
    "                          LEFT JOIN files_all_workspaces t1 ON t0.file_path = t1.file_path  \n",
    "                          FULL JOIN files_source_workspace t2 ON t0.file_path = t2.file_path\n",
    "                        WHERE t0.file_path IS NULL AND t2.file_path IS NOT NULL AND t2.file_path NOT LIKE '%SubsetHailJointCall%' AND t2.file_path NOT LIKE '%.vds/%'\"\"\"\n",
    "            if print_queries:\n",
    "                print(\"Detailed file diff query:\")\n",
    "                print(query)\n",
    "            try:\n",
    "                df = client.query(query).result().to_dataframe()\n",
    "                df_detailed_results = pd.concat([df_detailed_results, df])\n",
    "            except Exception as e:\n",
    "                error_message = f\"BigQuery error: {str(e)}\"\n",
    "                logging.error(error_message)\n",
    "\n",
    "    # Write out detailed results, if specified\n",
    "    if write_out_files:\n",
    "        destination_dir = \"ingest_pipeline/resources/file_inventory_diff/details\"\n",
    "        current_datetime_string = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "        output_file = f\"file_diffs_{current_datetime_string}.tsv\"\n",
    "        logging.info(f\"Writing out detailed file diff results out to {ws_bucket}/{destination_dir}/{output_file}\")\n",
    "        df_detailed_results.to_csv(output_file, index=False, sep=\"\\t\")\n",
    "        !gsutil cp $output_file $ws_bucket/$destination_dir/ 2> stdout\n",
    "        !rm $output_file\n",
    "    \n",
    "    # Display results\n",
    "    print(\"Aggregate Results:\")\n",
    "    results_df = pd.DataFrame(results, columns = [\"dataset_id\", \"dataset_name\", \"tdr_files\", \"tdr_files_not_in_inv\", \"inv_files_not_in_tdr\", \"non_vds_inv_files_not_in_tdr\", \"joint_call_vcf_files\", \"status\", \"message\"])\n",
    "    display(results_df)\n",
    "        \n",
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# List of datasets to process\n",
    "dataset_id_list = [\n",
    "    'd48adc59-8934-41bb-9720-63e71f1933be',\n",
    "    '80baf71d-28d0-4bca-81b7-49ddfadfa7a3',\n",
    "]\n",
    "\n",
    "# Variable to enable query printing, if desired\n",
    "print_queries = False\n",
    "\n",
    "# Variable to output files in addition to aggregation\n",
    "write_out_files = False\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "\n",
    "anvil_tdr_file_diff(dataset_id_list, print_queries, write_out_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to identify specific files that haven't been ingested into TDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Functions\n",
    "#############################################\n",
    "\n",
    "def identify_additional_files(dataset_id_list, file_exclusions, output_dir):\n",
    "    \n",
    "    # Loop through and process dataset_ids\n",
    "    logging.info(\"Starting identify_additional_files function...\")\n",
    "    agg_results = []\n",
    "    for dataset_id in dataset_id_list:\n",
    "        result = [dataset_id, \"Failure\", 0, 0, 0]\n",
    "        try:\n",
    "            # Retrieve dataset details\n",
    "            logging.info(f\"Processing dataset_id {dataset_id}...\")\n",
    "            logging.info(\"Retrieving dataset details.\")\n",
    "            api_client = utils.refresh_tdr_api_client()\n",
    "            datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "            dataset_details = datasets_api.retrieve_dataset(id=dataset_id, include=[\"ACCESS_INFORMATION\", \"PROPERTIES\"]).to_dict()\n",
    "            try:\n",
    "                source_workspaces = dataset_details[\"properties\"][\"source_workspaces\"]\n",
    "                bq_project = dataset_details[\"access_information\"][\"big_query\"][\"project_id\"]\n",
    "                bq_schema = dataset_details[\"access_information\"][\"big_query\"][\"dataset_name\"]\n",
    "            except Exception as e:\n",
    "                print(\"Failure - Issue Retrieving Dataset Info\") \n",
    "                continue\n",
    "\n",
    "            # Use source workspace(s) to find workspace bucket(s) to look for new files\n",
    "            logging.info(\"Determining source workspace bucket(s).\")\n",
    "            data_files_src_buckets = {}\n",
    "            for ws in source_workspaces:\n",
    "                try:\n",
    "                    ws_attributes = utils.get_workspace_attributes(\"anvil-datastorage\", ws)\n",
    "                    src_bucket = ws_attributes[\"bucketName\"] if ws_attributes.get(\"bucketName\") else \"\"\n",
    "                    if not src_bucket:\n",
    "                        print(\"Failure - Issue Retrieving Source Buckets\")\n",
    "                        continue\n",
    "                    elif src_bucket not in data_files_src_buckets:\n",
    "                        data_files_src_buckets[src_bucket] = {\n",
    "                            \"include_dirs\": [],\n",
    "                            \"exclude_dirs\": []\n",
    "                        }\n",
    "                except Exception as e:\n",
    "                    print(\"Failure - Issue Retrieving Source Buckets\")\n",
    "                    continue\n",
    "\n",
    "            # Pull existing file inventory from BigQuery\n",
    "            logging.info(\"Pulling existing file inventory records.\")\n",
    "            client = bigquery.Client()\n",
    "            query = \"\"\"SELECT uri FROM `{project}.{schema}.file_inventory`\"\"\".format(project = bq_project, schema = bq_schema)\n",
    "            file_list = []\n",
    "            try:\n",
    "                output = client.query(query).result()\n",
    "                if output.total_rows > 0:\n",
    "                    for row in output:\n",
    "                        file_list.append(row.uri)\n",
    "            except Exception as e:\n",
    "                print(\"Failure - Issue Retrieving Existing File Inventory Records\")\n",
    "                continue\n",
    "\n",
    "            # Build file inventory from workspace bucket(s)\n",
    "            logging.info(\"Building new file inventory.\")\n",
    "            ws_attributes = utils.get_workspace_attributes(ws_project, ws_name)\n",
    "            params = {}\n",
    "            params[\"data_files_src_buckets\"] = data_files_src_buckets\n",
    "            params[\"google_project\"] = ws_attributes[\"googleProject\"]\n",
    "            params[\"file_inventory_dir\"] = output_dir\n",
    "            params[\"global_file_exclusions\"] = []\n",
    "            inventory, retry_count = bfi.build_inventory(params)\n",
    "\n",
    "            # Diff files to ingest and collect summary stats\n",
    "            logging.info(\"Diffing new and existing file inventory records.\")\n",
    "            full_diff_list = []\n",
    "            exclude_list = []\n",
    "            include_list = []\n",
    "            for file in inventory:\n",
    "                file_excluded = False\n",
    "                if file[\"uri\"] not in file_list:\n",
    "                    full_diff_list.append(file)\n",
    "                    for exclude_term in file_exclusions:\n",
    "                        if exclude_term in file[\"uri\"]:\n",
    "                            exclude_list.append(file)\n",
    "                            file_excluded = True\n",
    "                            break\n",
    "                    if not file_excluded:\n",
    "                        include_list.append(file)\n",
    "            new_file_cnt = len(full_diff_list)\n",
    "            new_exclusion_file_cnt = len(exclude_list)\n",
    "            new_non_exclusion_file_cnt = len(include_list)\n",
    "            result = [dataset_id, \"Success\", new_file_cnt, new_exclusion_file_cnt, new_non_exclusion_file_cnt]\n",
    "\n",
    "            # Record diff files and write out to tsv \n",
    "            if len(include_list) > 0:\n",
    "                logging.info(\"Writing out inclusion results.\")\n",
    "                df_inventory = pd.DataFrame(include_list)\n",
    "                destination_dir = \"ingest_pipeline/resources/file_inventory_diff/output\"\n",
    "                output_file = f\"file_inventory_{dataset_id}.tsv\"\n",
    "                logging.info(f\"Writing inclusion results out to {ws_bucket}/{destination_dir}/{output_file}\")\n",
    "                df_inventory.to_csv(output_file, index=False, sep=\"\\t\")\n",
    "                !gsutil cp $output_file $ws_bucket/$destination_dir/ 2> stdout\n",
    "                !rm $output_file\n",
    "            else:\n",
    "                logging.info(\"No inclusion results to write out.\")\n",
    "        except:\n",
    "            logging.info(\"Unspecified error.\")\n",
    "            \n",
    "        # Write out agg_results\n",
    "        agg_results.append(result)\n",
    "        with open(\"file_diff_out.csv\", \"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(result)\n",
    "\n",
    "    # Display results\n",
    "    logging.info(\"Function 'identify_additional_files' finished successfully.\")\n",
    "    logging.info(\"\\nResults:\")\n",
    "    df_agg_results = pd.DataFrame(agg_results, columns =[\"Dataset ID\", \"Status\", \"New Files\", \"New Files (Exclusion List)\", \"New Files (Non-Exclusion List)\"])\n",
    "    display(df_agg_results)\n",
    "\n",
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# List of dataset IDs to analyze\n",
    "dataset_id_list = [\n",
    "    '8da05494-fe7a-4af5-b257-bada143ee426',\n",
    "    '8e88cabc-e713-44ed-a5d2-41935c3b4eb5',\n",
    "    'be8cfc23-cd19-46fb-92e1-a77ac380d7aa',\n",
    "    'f9224ea2-dd31-421d-80d4-f35082ef8d68',\n",
    "    '487016d8-ea02-4b20-a45f-7382139aa865',\n",
    "    'eb35085f-0cbf-4829-a3ad-acaa53a250b5',\n",
    "    '7577f264-8e84-440d-9346-7c4d5affda51',\n",
    "    'febd8561-4769-4f3b-b7c0-ae7ff6ede2e9',\n",
    "    'b8c5b185-8669-43d1-8ec7-c0f6d223d505',\n",
    "    '166746e8-ce26-4fa1-a587-443ca9fc59a1',\n",
    "    '49a97523-0a7a-4d5a-ae20-496f86de2032',\n",
    "    '583023a1-aa12-40e2-a964-8ad50ad400ba',\n",
    "    '73f7d2b4-86ec-4f7e-a1f9-37c7b023e3bf',\n",
    "]\n",
    "\n",
    "# List of file exclusions to apply\n",
    "file_exclusions = [\"SubsetHailJointCall\", \".vds/\"]\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"ingest_pipeline/resources/file_inventory_diff/output\"\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "\n",
    "identify_additional_files(dataset_id_list, file_exclusions, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Script to ingest missing workspace files into the appropriate TDR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Functions\n",
    "#############################################\n",
    "\n",
    "def ingest_additional_files(dataset_id_list, file_inventory_dir):\n",
    "    \n",
    "    # Loop through and process datasets\n",
    "    results = []\n",
    "    for dataset_id in dataset_id_list:\n",
    "\n",
    "        # Retrieve dataset details\n",
    "        logging.info(f\"Processing dataset_id {dataset_id}...\")\n",
    "        try:\n",
    "            logging.info(\"Retrieving dataset details.\")\n",
    "            api_client = utils.refresh_tdr_api_client()\n",
    "            datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "            dataset_details = datasets_api.retrieve_dataset(id=dataset_id, include=[\"ACCESS_INFORMATION\", \"PROPERTIES\"]).to_dict()\n",
    "            try:\n",
    "                source_workspaces = dataset_details[\"properties\"][\"source_workspaces\"]\n",
    "            except:\n",
    "                error_message = \"No source workspace found on dataset.\"\n",
    "                logging.info(error_message) \n",
    "                results.append([dataset_id, \"Failure\", error_message])\n",
    "        except Exception as e:\n",
    "            error_message = \"Issue Retrieving Dataset Info\"\n",
    "            logging.info(error_message) \n",
    "            results.append([dataset_id, \"Failure\", error_message])\n",
    "            continue\n",
    "\n",
    "        # Read in file inventory\n",
    "        logging.info(\"Reading in file inventory, if exists.\")\n",
    "        try: \n",
    "            file_inventory_name = f\"file_inventory_{dataset_id}.tsv\"\n",
    "            inventory_file_path = \"gs://\" + ws_bucket_name + \"/\" + file_inventory_dir + \"/\" + file_inventory_name\n",
    "            df_inv = pd.read_csv(inventory_file_path, delimiter = \"\\t\")\n",
    "            df_inv[\"file_ref\"] = df_inv.apply(lambda x: json.loads(x[\"file_ref\"].replace(\"\\'\", \"\\\"\")), axis=1)\n",
    "            df_inv = df_inv.replace(np.nan, None)\n",
    "            file_inventory = df_inv.to_dict(orient='records')\n",
    "            logging.info(\"File inventory populated successfully.\")\n",
    "        except Exception as e:\n",
    "            error_message = \"File inventory not populated. Unable to populate from file: {}\".format(e)\n",
    "            logging.info(error_message)\n",
    "            results.append([dataset_id, \"Failure\", error_message])\n",
    "            continue\n",
    "\n",
    "        # Build, submit, and monitor ingest request\n",
    "        logging.info(\"Building and submitting ingest request.\")\n",
    "        ingest_request = {\n",
    "            \"table\": \"file_inventory\",\n",
    "            \"profile_id\": \"e0e03e48-5b96-45ec-baa4-8cc1ebf74c61\" ,\n",
    "            \"ignore_unknown_values\": True,\n",
    "            \"resolve_existing_files\": True,\n",
    "            \"updateStrategy\": \"replace\",\n",
    "            \"format\": \"array\",\n",
    "            \"bulkMode\": True,\n",
    "            \"load_tag\": f\"Ingest for {source_workspaces[0]}\",\n",
    "            \"records\": file_inventory\n",
    "        }\n",
    "        attempt_counter = 0\n",
    "        while True:\n",
    "            try:\n",
    "                api_client = utils.refresh_tdr_api_client()\n",
    "                datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "                ingest_request_result, job_id = utils.wait_for_tdr_job(datasets_api.ingest_dataset(id=dataset_id, ingest=ingest_request))\n",
    "                logging.info(\"Ingest succeeded: {}\".format(str(ingest_request_result)[0:1000]))\n",
    "                results.append([dataset_id, \"Success\", None])\n",
    "                break\n",
    "            except Exception as e:\n",
    "                logging.error(\"Error on ingest: {}\".format(str(e)))\n",
    "                attempt_counter += 1\n",
    "                if attempt_counter < 1:\n",
    "                    logging.info(\"Retrying ingest (attempt #{})...\".format(str(attempt_counter)))\n",
    "                    sleep(10)\n",
    "                    continue\n",
    "                else:\n",
    "                    logging.error(\"Maximum number of retries exceeded. Logging error.\")\n",
    "                    results.append([dataset_id, \"Failure\", str(e)])\n",
    "                    break\n",
    "\n",
    "    # Display results\n",
    "    logging.info(\"\\nResults:\")\n",
    "    df_results = pd.DataFrame(results, columns =[\"Dataset ID\", \"Status\", \"Message\"])\n",
    "    display(df_results)\n",
    "\n",
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# List of dataset IDs to analyze\n",
    "dataset_id_list = [\n",
    "    '1c2fe11d-b020-4c54-8c71-1ea91623d626',\n",
    "    '902596ce-714e-49b3-8271-f3dfece52309',\n",
    "    '18b1a7a4-1724-4e10-95ca-fa35164c4801',\n",
    "    '63b229b5-e7c8-4fd3-bbc8-ecf344da70d4',\n",
    "    '352a503b-41eb-4a84-b257-68d70e55337e',\n",
    "    '737d39b8-2f99-4eac-bcda-a03996e08939',\n",
    "    'b8c5b185-8669-43d1-8ec7-c0f6d223d505',\n",
    "    '31e61d00-61cc-46f2-a793-8ea8dfbb0832',\n",
    "    '9737abab-2d09-4912-b300-f32553bda82c',\n",
    "    'c56f0a76-2b91-4860-8dff-63c9504bb0e2',\n",
    "    '732eaae3-b509-4a7a-8961-09d861e55253',\n",
    "    'b5d7c34a-c383-4fc7-aa4d-b6dc941cd41a',\n",
    "    'bcfe7f3b-3e63-45de-9e4d-144f9fc63753',\n",
    "]\n",
    "\n",
    "# File inventory directory\n",
    "file_inventory_dir = \"ingest_pipeline/resources/file_inventory_diff/output\"\n",
    "\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "\n",
    "ingest_additional_files(dataset_id_list, file_inventory_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to soft-delete tabular data records for files deleted at the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5,
     32
    ]
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Functions\n",
    "#############################################\n",
    "\n",
    "# Function to delete rows from a dataset\n",
    "def delete_datarepo_rows(dataset_id, table_name, datarepo_row_ids):\n",
    "    logging.info(\"Attempting to delete specified rows from {} for dataset {}\".format(table_name, dataset_id))\n",
    "    if datarepo_row_ids:\n",
    "        data_deletion_payload = {\n",
    "            \"deleteType\": \"soft\",\n",
    "            \"specType\": \"jsonArray\",\n",
    "            \"tables\": [{\n",
    "              \"tableName\": table_name,\n",
    "              \"jsonArraySpec\": {\n",
    "                \"rowIds\": datarepo_row_ids\n",
    "              }\n",
    "            }]\n",
    "        }\n",
    "        try:\n",
    "            api_client = utils.refresh_tdr_api_client()\n",
    "            datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "            data_deletion_result, job_id = utils.wait_for_tdr_job(datasets_api.apply_dataset_data_deletion(id=dataset_id, data_deletion_request=data_deletion_payload))\n",
    "            logging.info(\"Result: {}\".format(data_deletion_result))\n",
    "            return \"Success\"\n",
    "        except Exception as e:\n",
    "            logging.info(\"Error: {}\".format(str(e)))\n",
    "            return \"Failure\"\n",
    "    else:\n",
    "        logging.info(\"No datarepo_row_ids specified for deletion.\")\n",
    "        return \"Success\"\n",
    "\n",
    "# Function to evaluate and potentially remove deleted files\n",
    "def remove_deleted_files(dataset_id, file_uri_list):\n",
    "    # Retrieve dataset information\n",
    "    logging.info(f\"Processing dataset_id = {dataset_id}...\")\n",
    "    api_client = utils.refresh_tdr_api_client()\n",
    "    datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "    try:\n",
    "        logging.info(\"Retrieving dataset details.\")\n",
    "        dataset_details = datasets_api.retrieve_dataset(id=dataset_id, include=[\"ACCESS_INFORMATION\", \"PROPERTIES\", \"SCHEMA\"]).to_dict()\n",
    "        bq_project = dataset_details[\"access_information\"][\"big_query\"][\"project_id\"]\n",
    "        bq_dataset = dataset_details[\"access_information\"][\"big_query\"][\"dataset_name\"]\n",
    "        fileref_col_dict = {}\n",
    "        key_col_dict = {}\n",
    "        for table_entry in dataset_details[\"schema\"][\"tables\"]:\n",
    "            if table_entry[\"name\"] != \"file_inventory\" and \"anvil_\" not in table_entry[\"name\"]:\n",
    "                fileref_list = []\n",
    "                for idx, column_entry in enumerate(table_entry[\"columns\"]):\n",
    "                    if idx == 0:\n",
    "                        key_col_dict[table_entry[\"name\"]] = column_entry[\"name\"]\n",
    "                    if column_entry[\"datatype\"] == \"fileref\":\n",
    "                        fileref_list.append(column_entry[\"name\"])\n",
    "                if fileref_list:\n",
    "                    fileref_col_dict[table_entry[\"name\"]] = fileref_list\n",
    "    except Exception as e:\n",
    "        error_message = f\"Error retrieving dataset details: {str(e)}\"\n",
    "        logging.error(error_message)\n",
    "        results.append([dataset_id, \"Error\", error_message])\n",
    "\n",
    "    # Retrieving file_inventory records\n",
    "    logging.info(\"Fetching file_inventory records associated with the files to remove.\")\n",
    "    bad_row_ids = set()\n",
    "    bad_file_refs = set()\n",
    "    max_page_size = 1000\n",
    "    total_records_fetched = 0\n",
    "    total_bad_records = -1\n",
    "    filter_string = \"uri in ('\" + \"', '\".join(file_uri_list) + \"')\"\n",
    "    attempt_counter = 0\n",
    "    while True:\n",
    "        offset = total_records_fetched\n",
    "        if total_bad_records == -1:\n",
    "            page_size = max_page_size\n",
    "        else:\n",
    "            page_size = min(max_page_size, total_bad_records - total_records_fetched)\n",
    "        attempt_counter = 0\n",
    "        while True:\n",
    "            payload = {\n",
    "              \"offset\": offset,\n",
    "              \"limit\": max_page_size,\n",
    "              \"sort\": \"datarepo_row_id\",\n",
    "              \"direction\": \"asc\",\n",
    "              \"filter\": filter_string\n",
    "            }\n",
    "            try:\n",
    "                record_results = datasets_api.query_dataset_data_by_id(id=dataset_id, table=\"file_inventory\", query_data_request_model=payload).to_dict()\n",
    "                break\n",
    "            except Exception as e:\n",
    "                if attempt_counter < 2:\n",
    "                    sleep(10)\n",
    "                    attempt_counter += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    logging.error(\"Error retrieving file_inventory records\")\n",
    "                    break\n",
    "        if record_results.get(\"result\"):\n",
    "            total_bad_records = record_results[\"filtered_row_count\"]\n",
    "            total_records_fetched += len(record_results[\"result\"])\n",
    "            for result_entry in record_results[\"result\"]:\n",
    "                bad_row_ids.add(result_entry[\"datarepo_row_id\"])\n",
    "                bad_file_refs.add(result_entry[\"file_ref\"]) \n",
    "        else:\n",
    "            break\n",
    "        if total_records_fetched >= total_bad_records:\n",
    "            break\n",
    "\n",
    "    # Loop through tables with filerefs and look for bad file references\n",
    "    bad_records_dict = {}\n",
    "    for table in fileref_col_dict.keys():\n",
    "\n",
    "        # Build filter string\n",
    "        logging.info(f\"Checking the '{table}' table for bad file references.\")\n",
    "        filter_string = \"\"\n",
    "        for idx, field in enumerate(fileref_col_dict[table]):\n",
    "            base_filter_string = f\"{field} in ('\" + \"', '\".join(list(bad_file_refs)) + \"')\"\n",
    "            if idx == 0:\n",
    "                filter_string += f\"{base_filter_string}\"\n",
    "            else:\n",
    "                filter_string += f\"OR {base_filter_string}\"\n",
    "\n",
    "        # Find problematic records and record information\n",
    "        bad_records = []\n",
    "        max_page_size = 1000\n",
    "        total_records_fetched = 0\n",
    "        total_bad_records = -1\n",
    "        attempt_counter = 0\n",
    "        while True:\n",
    "            offset = total_records_fetched\n",
    "            if total_bad_records == -1:\n",
    "                page_size = max_page_size\n",
    "            else:\n",
    "                page_size = min(max_page_size, total_bad_records - total_records_fetched)\n",
    "            attempt_counter = 0\n",
    "            while True:\n",
    "                payload = {\n",
    "                  \"offset\": offset,\n",
    "                  \"limit\": max_page_size,\n",
    "                  \"sort\": \"datarepo_row_id\",\n",
    "                  \"direction\": \"asc\",\n",
    "                  \"filter\": filter_string\n",
    "                }\n",
    "                try:\n",
    "                    record_results = datasets_api.query_dataset_data_by_id(id=dataset_id, table=table, query_data_request_model=payload).to_dict()\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    if attempt_counter < 2:\n",
    "                        sleep(10)\n",
    "                        attempt_counter += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        logging.error(f\"Error retrieving records from table '{table}'\")\n",
    "                        break\n",
    "            if record_results.get(\"result\"):\n",
    "                total_bad_records = record_results[\"filtered_row_count\"]\n",
    "                total_records_fetched += len(record_results[\"result\"])\n",
    "                for result_entry in record_results[\"result\"]:\n",
    "                    bad_record = False\n",
    "                    bad_col_list = []\n",
    "                    for field in fileref_col_dict[table]:\n",
    "                        if result_entry[field] in bad_file_refs:\n",
    "                            bad_record = True\n",
    "                            bad_col_list.append(field)\n",
    "                    if bad_record:\n",
    "                        key_val = result_entry[key_col_dict[table]]\n",
    "                        bad_record_detail = key_val + \": \" + \", \".join(bad_col_list)\n",
    "                        bad_records.append(bad_record_detail)\n",
    "            else:\n",
    "                break\n",
    "            if total_records_fetched >= total_bad_records:\n",
    "                break\n",
    "\n",
    "        # Record results\n",
    "        if bad_records:\n",
    "            bad_records_dict[table] = bad_records\n",
    "\n",
    "    # If bad records outside of file_inventory are identified, report them out, otherwise delete bad file_inventory records\n",
    "    tabular_data_results = []\n",
    "    if bad_records_dict:\n",
    "        logging.info(\"Tabular data records with references to bad files found. Please review the output and correct. Will NOT soft-delete the records from the file_inventory table.\")\n",
    "        for key, val in bad_records_dict.items():\n",
    "            tabular_data_results.append([dataset_id, key, key_col_dict[key], val])\n",
    "        logging.info(\"Tabular data records with references to bad files:\")\n",
    "        tabular_results_df = pd.DataFrame(tabular_data_results, columns = [\"dataset_id\", \"table\", \"key_column\", \"key_vals_w_affected_cols\"])\n",
    "        display(tabular_results_df)    \n",
    "    else:\n",
    "        logging.info(\"No tabular data records with references to bad files found. Soft-deleting bad records from file_inventory.\")\n",
    "        delete_result = delete_datarepo_rows(dataset_id, \"file_inventory\", list(bad_row_ids)) \n",
    "    \n",
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# Dataset to update\n",
    "dataset_id = \"4b456e27-e78f-4ced-a6a1-887f2539ddbe\"\n",
    "\n",
    "# List of file URIs to remove from the dataset\n",
    "file_uri_list = [\n",
    "\n",
    "]\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "\n",
    "remove_deleted_files(dataset_id, file_uri_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script to Examine VDS Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/06/2024 12:19:36 AM - INFO: Examining VDS files in bucket: fc-secure-f5d884c0-a24c-46e6-8c29-cad7f5b158c7\n",
      "04/06/2024 12:19:48 AM - INFO: Examining VDS files in bucket: fc-secure-6513d7e1-2dbb-41a2-baea-3f7fdbcbb620\n",
      "04/06/2024 12:20:00 AM - INFO: Examining VDS files in bucket: fc-d3e9eb24-cb19-47d8-b2c6-d85fd34b4ff1\n",
      "04/06/2024 12:20:12 AM - INFO: Examining VDS files in bucket: fc-0ed1ef2d-1039-4c8a-a0a9-91c3e385200a\n",
      "04/06/2024 12:20:23 AM - INFO: Examining VDS files in bucket: fc-282a8e0b-df88-42de-9059-2b7447d9f9c7\n",
      "04/06/2024 12:20:36 AM - INFO: Examining VDS files in bucket: fc-secure-5efb4966-0994-41f8-a911-1d159c9bae1b\n",
      "04/06/2024 12:20:49 AM - INFO: Examining VDS files in bucket: fc-2836a560-113a-4239-acab-5cce58019b73\n",
      "04/06/2024 12:21:00 AM - INFO: Examining VDS files in bucket: fc-bb71bb7a-fdb1-427a-9e56-eb08b6fd7955\n",
      "04/06/2024 12:21:15 AM - INFO: Examining VDS files in bucket: fc-secure-e9b2e26a-3f73-4f5a-862f-c5b3be68703f\n",
      "04/06/2024 12:21:27 AM - INFO: Examining VDS files in bucket: fc-e7051891-25c8-4776-80ed-26b1af860277\n",
      "04/06/2024 12:21:40 AM - INFO: Examining VDS files in bucket: fc-4f070061-0bc2-4f9a-9fe9-869a739c9817\n",
      "04/06/2024 12:21:52 AM - INFO: Examining VDS files in bucket: fc-c1701683-c10e-4f73-a636-f774e8b650c2\n",
      "04/06/2024 12:22:03 AM - INFO: Examining VDS files in bucket: fc-secure-ccca1171-d3ee-42b3-8df8-aca336279cf3\n",
      "04/06/2024 12:22:14 AM - INFO: Examining VDS files in bucket: fc-2d61b7df-571f-4201-a674-1107c84711df\n",
      "04/06/2024 12:22:25 AM - INFO: Examining VDS files in bucket: fc-5d7cf59f-e361-4073-a6ad-16d8d78cc613\n",
      "04/06/2024 12:22:37 AM - INFO: Examining VDS files in bucket: fc-secure-70487b95-e89c-45ec-ad0a-e5382d625c33\n",
      "04/06/2024 12:22:47 AM - INFO: Examining VDS files in bucket: fc-2b68ae78-57af-4c65-8020-6f5ed4ae9408\n",
      "04/06/2024 12:22:59 AM - INFO: Examining VDS files in bucket: fc-secure-33bdfbdb-de58-474e-8591-dad501aa1995\n",
      "04/06/2024 12:23:09 AM - INFO: Examining VDS files in bucket: fc-2bcebe36-5d83-486a-947a-bbb5a606701d\n",
      "04/06/2024 12:23:21 AM - INFO: Examining VDS files in bucket: fc-secure-1fb85b31-9a1e-46ef-a206-41040d151f94\n",
      "04/06/2024 12:23:32 AM - INFO: Examining VDS files in bucket: fc-secure-ead0ff8d-eee9-4299-bb54-8404ffe9fa22\n",
      "04/06/2024 12:23:43 AM - INFO: Examining VDS files in bucket: fc-secure-d8de1fe3-972d-480f-a8a8-2bbc251add30\n",
      "04/06/2024 12:23:53 AM - INFO: Examining VDS files in bucket: fc-secure-4d47049d-9a31-435d-8c97-61cffce9a83b\n",
      "04/06/2024 12:24:11 AM - INFO: Examining VDS files in bucket: fc-secure-31d85e96-7fa0-4c2e-a89a-fe5c70845fd7\n",
      "04/06/2024 12:24:23 AM - INFO: Examining VDS files in bucket: fc-secure-68ff7cc9-274c-45d6-baad-75b9c5971a9c\n",
      "04/06/2024 12:24:37 AM - INFO: Examining VDS files in bucket: fc-secure-fdaa7a52-520b-461b-a2d2-e31bf92e8e86\n",
      "04/06/2024 12:24:49 AM - INFO: Examining VDS files in bucket: fc-secure-9c348df7-4da1-428a-a785-e06db3a9f208\n",
      "04/06/2024 12:25:00 AM - INFO: Examining VDS files in bucket: fc-secure-0de89e54-2149-4e06-81f9-da5af48c68a3\n",
      "04/06/2024 12:25:11 AM - INFO: Examining VDS files in bucket: fc-secure-986229e0-ac72-420d-bf0e-aa14dea63a05\n",
      "04/06/2024 12:25:21 AM - INFO: Examining VDS files in bucket: fc-secure-4931149d-9e71-4865-9f41-3e4c998ffb38\n",
      "04/06/2024 12:25:32 AM - INFO: Examining VDS files in bucket: fc-secure-13597242-de35-44e2-b8fb-b5fa0b983501\n",
      "04/06/2024 12:25:42 AM - INFO: Examining VDS files in bucket: fc-secure-75f95e44-299f-4666-bed3-46dd679b12d8\n",
      "04/06/2024 12:25:55 AM - INFO: Examining VDS files in bucket: fc-secure-240e1629-6d73-42ab-a373-1abeec17824c\n",
      "04/06/2024 12:26:05 AM - INFO: Examining VDS files in bucket: fc-secure-94c90c12-376d-419a-96d9-ed37e1b1a5bb\n",
      "04/06/2024 12:26:17 AM - INFO: Examining VDS files in bucket: fc-secure-6c21e787-1a4b-4235-b756-9ce6096fc815\n",
      "04/06/2024 12:26:27 AM - INFO: Examining VDS files in bucket: fc-secure-51198b17-37ae-44b7-8513-c11c4bfe3a9d\n",
      "04/06/2024 12:26:38 AM - INFO: Examining VDS files in bucket: fc-secure-59794551-d924-4ad7-905b-8727646d9aad\n",
      "04/06/2024 12:26:47 AM - INFO: Examining VDS files in bucket: fc-secure-8ec82876-176f-4f33-ae98-0a3cae871ed4\n",
      "04/06/2024 12:26:59 AM - INFO: Examining VDS files in bucket: fc-secure-8a282388-3c56-48c6-99c8-ea4b52c053b9\n",
      "04/06/2024 12:27:09 AM - INFO: Examining VDS files in bucket: fc-secure-3e71d768-9da9-4845-9e2c-7e909db92cb7\n",
      "04/06/2024 12:27:18 AM - INFO: Examining VDS files in bucket: fc-secure-0fc5a889-f57e-40a1-9859-c5b1e8a196d1\n",
      "04/06/2024 12:27:30 AM - INFO: Examining VDS files in bucket: fc-secure-0f948ad2-2ae8-433c-9f0c-941c4c5e4a89\n",
      "04/06/2024 12:27:40 AM - INFO: Examining VDS files in bucket: fc-secure-678eccb8-3463-4a72-8b57-69dfc8c77002\n",
      "04/06/2024 12:27:52 AM - INFO: Examining VDS files in bucket: fc-secure-221b863c-a724-42f3-9f90-2081b352799c\n",
      "04/06/2024 12:28:17 AM - INFO: Examining VDS files in bucket: fc-secure-21cd882f-8470-4c2e-93dc-536a908bae73\n",
      "04/06/2024 12:28:28 AM - INFO: Examining VDS files in bucket: fc-secure-e92b8081-5e6a-440c-af83-4d428f505529\n",
      "04/06/2024 12:28:47 AM - INFO: Examining VDS files in bucket: fc-secure-e0034430-99a3-4dde-99d3-a2330cd90f19\n",
      "04/06/2024 12:28:59 AM - INFO: Examining VDS files in bucket: fc-secure-315a127f-649d-4928-b4e0-cdca7d898e05\n",
      "04/06/2024 12:29:09 AM - INFO: Examining VDS files in bucket: fc-secure-550ffe2e-04fd-4763-b7d2-09f0c59083e4\n",
      "04/06/2024 12:29:20 AM - INFO: Examining VDS files in bucket: fc-secure-84e57da6-4df9-45de-9f82-8a550887a7fa\n",
      "04/06/2024 12:29:32 AM - INFO: Examining VDS files in bucket: fc-secure-2b4d5d05-d951-4e51-8ece-7e851660f91a\n",
      "04/06/2024 12:29:42 AM - INFO: Examining VDS files in bucket: fc-secure-bfe6497b-69a1-4917-8a7b-c9bd36cb4ae4\n",
      "04/06/2024 12:29:53 AM - INFO: Examining VDS files in bucket: fc-secure-3b588f92-0298-4ad6-b75d-fa16de8b718d\n",
      "04/06/2024 12:30:03 AM - INFO: Examining VDS files in bucket: fc-secure-fe950bf8-0470-4329-b8c9-8a42d0dd619d\n",
      "04/06/2024 12:30:15 AM - INFO: Examining VDS files in bucket: fc-secure-59d2af1f-3dc0-407b-b7ab-05cdcfa4da8f\n",
      "04/06/2024 12:30:27 AM - INFO: Examining VDS files in bucket: fc-secure-01106611-a0e9-41bb-ac13-27683ab2fc19\n",
      "04/06/2024 12:30:39 AM - INFO: Examining VDS files in bucket: fc-secure-7a160245-84eb-4383-80ed-f41c2411e702\n",
      "04/06/2024 12:30:57 AM - INFO: Examining VDS files in bucket: fc-secure-32a2f8aa-4f72-43e9-9450-bbf661bde5ef\n",
      "04/06/2024 12:31:11 AM - INFO: Examining VDS files in bucket: fc-secure-ce2baa61-748a-4dbc-a929-f256721b59b2\n",
      "04/06/2024 12:31:22 AM - INFO: Examining VDS files in bucket: fc-secure-ac202043-c5ef-4fb7-8ccb-62a274c1b8ec\n",
      "04/06/2024 12:31:32 AM - INFO: Examining VDS files in bucket: fc-secure-652024de-0ecd-4de3-8360-c8c5bfcafd72\n",
      "04/06/2024 12:31:43 AM - INFO: Examining VDS files in bucket: fc-secure-7c845669-3781-4ac0-bb59-1495d68d1d85\n",
      "04/06/2024 12:31:55 AM - INFO: Examining VDS files in bucket: fc-secure-330f768f-83c4-4570-ae46-0626b477d2b0\n",
      "04/06/2024 12:32:09 AM - INFO: Examining VDS files in bucket: fc-secure-dccff364-c2ff-42df-8c8e-f979a0472c11\n",
      "04/06/2024 12:32:21 AM - INFO: Examining VDS files in bucket: fc-secure-17d8dbc9-d1d8-4d5d-8eb7-c1b82bef24d8\n",
      "04/06/2024 12:32:32 AM - INFO: Examining VDS files in bucket: fc-secure-674fbd89-9eeb-4e43-8a6f-97d6e50708e0\n",
      "04/06/2024 12:32:42 AM - INFO: Examining VDS files in bucket: fc-secure-9f2f0267-2df4-44e9-a6ae-dd1d3a43cca5\n",
      "04/06/2024 12:32:53 AM - INFO: Examining VDS files in bucket: fc-secure-6bc832d1-a35b-4676-bf68-a5772e2be044\n",
      "04/06/2024 12:33:05 AM - INFO: Examining VDS files in bucket: fc-secure-e4b45d7c-3fee-479f-83e9-8c85312cb8da\n",
      "04/06/2024 12:33:15 AM - INFO: Examining VDS files in bucket: fc-secure-516245cb-7dcc-487d-acf7-43e5fb10085f\n",
      "04/06/2024 12:33:26 AM - INFO: Examining VDS files in bucket: fc-secure-ab235723-ed31-4242-b5ab-23c177a0e79c\n",
      "04/06/2024 12:33:37 AM - INFO: Examining VDS files in bucket: fc-secure-b9906df4-3012-4c7b-a008-3c5708885971\n",
      "04/06/2024 12:33:49 AM - INFO: Examining VDS files in bucket: fc-secure-05e511c4-0b47-41a5-a361-99f747cbef6c\n",
      "04/06/2024 12:34:01 AM - INFO: Examining VDS files in bucket: fc-secure-adba6cb8-c49c-405b-af7b-9980e4a9d36a\n",
      "04/06/2024 12:34:15 AM - INFO: Examining VDS files in bucket: fc-secure-98a7c433-bacc-44fd-96f6-faed04dd1c96\n",
      "04/06/2024 12:34:26 AM - INFO: Examining VDS files in bucket: fc-secure-fd756575-ba39-4893-8b85-b6dfbb376f3b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/06/2024 12:34:40 AM - INFO: Examining VDS files in bucket: fc-secure-a473f80e-97a6-4c19-bd68-e37266efb44d\n",
      "04/06/2024 12:34:52 AM - INFO: Examining VDS files in bucket: fc-secure-04e82709-08e0-4335-aaef-ba55089f6fd9\n",
      "04/06/2024 12:35:03 AM - INFO: Examining VDS files in bucket: fc-secure-ed823158-2149-493f-80d0-ff066cb14a85\n",
      "04/06/2024 12:35:14 AM - INFO: Examining VDS files in bucket: fc-secure-bcc5d428-aed0-4814-aefc-f717b97d5106\n",
      "04/06/2024 12:35:26 AM - INFO: Examining VDS files in bucket: fc-secure-de72ef13-9b7f-44db-9428-5df489d327ce\n",
      "04/06/2024 12:35:37 AM - INFO: Examining VDS files in bucket: fc-secure-35c81df8-8bdf-467a-af6f-fb807185b82e\n",
      "04/06/2024 12:35:48 AM - INFO: Examining VDS files in bucket: fc-secure-39458ab6-c2d3-49e2-b6d5-8bb3bae9a245\n",
      "04/06/2024 12:36:00 AM - INFO: Examining VDS files in bucket: fc-secure-124c02b9-69b7-468c-b3d7-4a07aee74dc5\n",
      "04/06/2024 12:36:11 AM - INFO: Examining VDS files in bucket: fc-secure-a065288d-5bb4-441c-95e9-0ffb20a6cf40\n",
      "04/06/2024 12:36:25 AM - INFO: Examining VDS files in bucket: fc-secure-ee694ec4-cb3d-441d-95f7-e6d586419484\n",
      "04/06/2024 12:36:36 AM - INFO: Examining VDS files in bucket: fc-secure-bd923846-0b8b-4018-8706-44b2a8e213b4\n",
      "04/06/2024 12:36:48 AM - INFO: Examining VDS files in bucket: fc-secure-4c07a18a-8c79-4b81-acbe-91083298f1e4\n",
      "04/06/2024 12:36:58 AM - INFO: Examining VDS files in bucket: fc-secure-21c6905e-06c8-45f2-b6ed-ffba467f7f75\n",
      "04/06/2024 12:37:11 AM - INFO: Examining VDS files in bucket: fc-secure-538d85ea-c436-43f9-b001-4db614ed96bf\n",
      "04/06/2024 12:37:22 AM - INFO: Examining VDS files in bucket: fc-secure-d87970dd-adb0-4b99-a204-ae6fbd457d12\n",
      "04/06/2024 12:37:45 AM - INFO: Examining VDS files in bucket: fc-secure-5f916770-fded-4540-b4b6-49f88b8e05fc\n",
      "04/06/2024 12:37:57 AM - INFO: Examining VDS files in bucket: fc-secure-0aedc988-3736-496c-b7ac-20cca5b3ceb9\n",
      "04/06/2024 12:38:11 AM - INFO: Examining VDS files in bucket: fc-secure-d4bead53-0db1-4e25-87da-c02be5819368\n",
      "04/06/2024 12:38:29 AM - INFO: Examining VDS files in bucket: fc-secure-86cbdfa9-cbc0-40fb-adfa-3dd467ae1062\n",
      "04/06/2024 12:38:41 AM - INFO: Examining VDS files in bucket: fc-secure-d157fd3c-57ff-4640-a084-cecda832e575\n",
      "04/06/2024 12:38:52 AM - INFO: Examining VDS files in bucket: fc-secure-08bb70e6-9fa1-40dc-8822-41d73945c053\n",
      "04/06/2024 12:39:06 AM - INFO: Examining VDS files in bucket: fc-secure-6a2f53f1-6712-48a9-a7b2-3289b8df877b\n",
      "04/06/2024 12:39:16 AM - INFO: Examining VDS files in bucket: fc-secure-55225e12-ec4c-42e0-a5d1-986c87c6d129\n",
      "04/06/2024 12:39:28 AM - INFO: Examining VDS files in bucket: fc-secure-89bba08d-ef3b-47bb-9c9b-a937d7550a97\n",
      "04/06/2024 12:39:43 AM - INFO: Examining VDS files in bucket: fc-secure-bf34568b-1c38-4c43-8a21-59630b969553\n",
      "04/06/2024 12:40:03 AM - INFO: Examining VDS files in bucket: fc-secure-8a297961-e042-4d02-826f-0322b3d7fbff\n",
      "04/06/2024 12:40:14 AM - INFO: Examining VDS files in bucket: fc-secure-9befa92f-ef34-4fcf-8df5-d085656e26dd\n",
      "04/06/2024 12:40:24 AM - INFO: Examining VDS files in bucket: fc-secure-870d27c3-a758-4535-b8dd-5fc0514c5215\n",
      "04/06/2024 12:40:35 AM - INFO: Examining VDS files in bucket: fc-secure-980cd412-6b18-480a-b2f2-ad1543c06a91\n",
      "04/06/2024 12:40:51 AM - INFO: Examining VDS files in bucket: fc-secure-16e0c63c-847a-42ef-91ca-3523b3668357\n",
      "04/06/2024 12:41:03 AM - INFO: Examining VDS files in bucket: fc-secure-c53831f7-0431-44e5-abe6-308270690c3b\n",
      "04/06/2024 12:41:12 AM - INFO: Examining VDS files in bucket: fc-secure-51a26e99-63eb-442a-869d-87ecbc60c814\n",
      "04/06/2024 12:41:23 AM - INFO: Examining VDS files in bucket: fc-secure-e5676c90-7028-4b68-b620-c6944514d52c\n",
      "04/06/2024 12:41:35 AM - INFO: Examining VDS files in bucket: fc-secure-977aa72f-e9ce-4fb6-b32b-c675b4ef25d5\n",
      "04/06/2024 12:41:50 AM - INFO: Examining VDS files in bucket: fc-secure-d7a002ea-7e1e-45fd-8e76-456fce471f17\n",
      "04/06/2024 12:42:01 AM - INFO: Examining VDS files in bucket: fc-secure-6537d7f6-f29f-432b-b66e-8cf2204b7920\n",
      "04/06/2024 12:42:13 AM - INFO: Examining VDS files in bucket: fc-secure-b2669acd-7139-464f-af53-af7215c068aa\n",
      "04/06/2024 12:42:27 AM - INFO: Examining VDS files in bucket: fc-secure-cb3eeabf-f0ef-497e-9bc6-b5a27be4fec2\n",
      "04/06/2024 12:42:37 AM - INFO: Examining VDS files in bucket: fc-secure-2180b508-ce9d-4535-aa9f-f07d5917025c\n",
      "04/06/2024 12:42:48 AM - INFO: Examining VDS files in bucket: fc-secure-7e0893cd-4f31-41e4-b1d2-3e656097824a\n",
      "04/06/2024 12:42:57 AM - INFO: Examining VDS files in bucket: fc-secure-f8b9ce8d-efc0-4aa1-ad71-c0378d8d7194\n",
      "04/06/2024 12:43:07 AM - INFO: Examining VDS files in bucket: fc-secure-b2f4e185-a21a-434a-9494-d1fabaaaf7c0\n",
      "04/06/2024 12:43:17 AM - INFO: Examining VDS files in bucket: fc-secure-1355eb72-b00f-4796-8892-ac271b699503\n",
      "04/06/2024 12:43:28 AM - INFO: Examining VDS files in bucket: fc-secure-68b7e62f-132b-4818-bf64-6c38ec9152ab\n",
      "04/06/2024 12:43:37 AM - INFO: Examining VDS files in bucket: fc-secure-dae591de-00ad-478c-9440-88034a1b8cb9\n",
      "04/06/2024 12:43:48 AM - INFO: Examining VDS files in bucket: fc-secure-7e9fe869-643a-4828-a1b7-0245e34745ae\n",
      "04/06/2024 12:43:58 AM - INFO: Examining VDS files in bucket: fc-secure-228fd6fd-e0f7-4895-a246-3b055be27aa1\n",
      "04/06/2024 12:44:11 AM - INFO: Examining VDS files in bucket: fc-secure-e99706c4-48f9-4a69-baf4-70d1c5eaac5c\n",
      "04/06/2024 12:44:24 AM - INFO: Examining VDS files in bucket: fc-secure-d2c84e56-8f0d-420a-96a4-942e92009433\n",
      "04/06/2024 12:44:36 AM - INFO: Examining VDS files in bucket: fc-secure-589e3f7a-7b24-46cf-aefd-63b05155d826\n",
      "04/06/2024 12:44:47 AM - INFO: Examining VDS files in bucket: fc-secure-3fdbe020-6bdb-4668-bcb8-0d0df9d4ba8a\n",
      "04/06/2024 12:45:14 AM - INFO: Examining VDS files in bucket: fc-secure-b31156cd-4993-4f69-a8f4-9a99c2697965\n",
      "04/06/2024 12:46:25 AM - INFO: Examining VDS files in bucket: fc-secure-73036e74-c8b0-4e6f-9f4f-ca55b599d5d1\n",
      "04/06/2024 12:46:37 AM - INFO: Examining VDS files in bucket: fc-secure-3c4843c0-b83f-4ba1-9bba-9c9a599f3ffb\n",
      "04/06/2024 12:46:51 AM - INFO: Examining VDS files in bucket: fc-secure-91f9e579-b064-4992-8b00-c789ca48f861\n",
      "04/06/2024 12:47:07 AM - INFO: Examining VDS files in bucket: fc-secure-ac588f86-da2d-4a92-9f45-be2aeedd5fac\n",
      "04/06/2024 12:47:17 AM - INFO: Examining VDS files in bucket: fc-secure-2fa3df40-c189-41ee-b5ba-484a0b77ef77\n",
      "04/06/2024 12:47:29 AM - INFO: Examining VDS files in bucket: fc-secure-00737009-4e0f-454d-bb02-4b70566a0ed2\n",
      "04/06/2024 12:47:38 AM - INFO: Examining VDS files in bucket: fc-secure-36dfb67b-d2fc-47a1-a94c-225d72e08afd\n",
      "04/06/2024 12:47:49 AM - INFO: Examining VDS files in bucket: fc-secure-55efa443-810c-48c8-90bb-f07beba0e560\n",
      "04/06/2024 12:47:59 AM - INFO: Examining VDS files in bucket: fc-secure-43207dac-0905-4fdd-b816-a34bd2ccebdd\n",
      "04/06/2024 12:48:12 AM - INFO: Examining VDS files in bucket: fc-secure-fba19c6f-984e-4616-b253-6d9e6ea5cec5\n",
      "04/06/2024 12:48:21 AM - INFO: Examining VDS files in bucket: fc-secure-1614d6d2-d053-4de0-9b97-cc4b0762f547\n",
      "04/06/2024 12:48:31 AM - INFO: Examining VDS files in bucket: fc-secure-c40af798-8afc-4ab3-9b66-946955811d3b\n",
      "04/06/2024 12:48:41 AM - INFO: Examining VDS files in bucket: fc-secure-abc7f058-0260-4e82-a911-abfec3dcb676\n",
      "04/06/2024 12:48:51 AM - INFO: Examining VDS files in bucket: fc-secure-29cd113f-7eca-4526-aa52-dde1b8cb41d0\n",
      "04/06/2024 12:49:01 AM - INFO: Examining VDS files in bucket: fc-secure-877e6c8c-72ef-46d0-b3f3-37dd175771fe\n",
      "04/06/2024 12:49:10 AM - INFO: Examining VDS files in bucket: fc-secure-0eba3dae-89be-4642-8982-9a80a7428cd2\n",
      "04/06/2024 12:49:22 AM - INFO: Examining VDS files in bucket: fc-secure-0ca0c5e6-26ca-47ea-b509-ec4eaa058fc6\n",
      "04/06/2024 12:49:34 AM - INFO: Examining VDS files in bucket: fc-secure-bee7792c-ef35-478d-a9bb-c8f2054c335c\n",
      "04/06/2024 12:49:45 AM - INFO: Examining VDS files in bucket: fc-secure-72a949c5-0b7d-45c9-96c3-ff4d25815ed5\n",
      "04/06/2024 12:49:56 AM - INFO: Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>bucket</th>\n",
       "      <th>status</th>\n",
       "      <th>total_vds_file_count</th>\n",
       "      <th>vds_file_in_jointcall_ws_count</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fc-secure-f5d884c0-a24c-46e6-8c29-cad7f5b158c7</td>\n",
       "      <td>Success</td>\n",
       "      <td>969335</td>\n",
       "      <td>969335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fc-secure-6513d7e1-2dbb-41a2-baea-3f7fdbcbb620</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fc-d3e9eb24-cb19-47d8-b2c6-d85fd34b4ff1</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fc-0ed1ef2d-1039-4c8a-a0a9-91c3e385200a</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fc-282a8e0b-df88-42de-9059-2b7447d9f9c7</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fc-secure-5efb4966-0994-41f8-a911-1d159c9bae1b</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fc-2836a560-113a-4239-acab-5cce58019b73</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fc-bb71bb7a-fdb1-427a-9e56-eb08b6fd7955</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fc-secure-e9b2e26a-3f73-4f5a-862f-c5b3be68703f</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc-e7051891-25c8-4776-80ed-26b1af860277</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fc-4f070061-0bc2-4f9a-9fe9-869a739c9817</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fc-c1701683-c10e-4f73-a636-f774e8b650c2</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fc-secure-ccca1171-d3ee-42b3-8df8-aca336279cf3</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fc-2d61b7df-571f-4201-a674-1107c84711df</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fc-5d7cf59f-e361-4073-a6ad-16d8d78cc613</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fc-secure-70487b95-e89c-45ec-ad0a-e5382d625c33</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fc-2b68ae78-57af-4c65-8020-6f5ed4ae9408</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fc-secure-33bdfbdb-de58-474e-8591-dad501aa1995</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fc-2bcebe36-5d83-486a-947a-bbb5a606701d</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fc-secure-1fb85b31-9a1e-46ef-a206-41040d151f94</td>\n",
       "      <td>Success</td>\n",
       "      <td>969324</td>\n",
       "      <td>969324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>fc-secure-ead0ff8d-eee9-4299-bb54-8404ffe9fa22</td>\n",
       "      <td>Success</td>\n",
       "      <td>43563</td>\n",
       "      <td>43563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fc-secure-d8de1fe3-972d-480f-a8a8-2bbc251add30</td>\n",
       "      <td>Success</td>\n",
       "      <td>43567</td>\n",
       "      <td>43567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>fc-secure-4d47049d-9a31-435d-8c97-61cffce9a83b</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>fc-secure-31d85e96-7fa0-4c2e-a89a-fe5c70845fd7</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>fc-secure-68ff7cc9-274c-45d6-baad-75b9c5971a9c</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>fc-secure-fdaa7a52-520b-461b-a2d2-e31bf92e8e86</td>\n",
       "      <td>Success</td>\n",
       "      <td>43559</td>\n",
       "      <td>43559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>fc-secure-9c348df7-4da1-428a-a785-e06db3a9f208</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>fc-secure-0de89e54-2149-4e06-81f9-da5af48c68a3</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>fc-secure-986229e0-ac72-420d-bf0e-aa14dea63a05</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>fc-secure-4931149d-9e71-4865-9f41-3e4c998ffb38</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>fc-secure-13597242-de35-44e2-b8fb-b5fa0b983501</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>fc-secure-75f95e44-299f-4666-bed3-46dd679b12d8</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>fc-secure-240e1629-6d73-42ab-a373-1abeec17824c</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>fc-secure-94c90c12-376d-419a-96d9-ed37e1b1a5bb</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>fc-secure-6c21e787-1a4b-4235-b756-9ce6096fc815</td>\n",
       "      <td>Success</td>\n",
       "      <td>43562</td>\n",
       "      <td>43562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>fc-secure-51198b17-37ae-44b7-8513-c11c4bfe3a9d</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>fc-secure-59794551-d924-4ad7-905b-8727646d9aad</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>fc-secure-8ec82876-176f-4f33-ae98-0a3cae871ed4</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>fc-secure-8a282388-3c56-48c6-99c8-ea4b52c053b9</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>fc-secure-3e71d768-9da9-4845-9e2c-7e909db92cb7</td>\n",
       "      <td>Success</td>\n",
       "      <td>43562</td>\n",
       "      <td>43562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>fc-secure-0fc5a889-f57e-40a1-9859-c5b1e8a196d1</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>fc-secure-0f948ad2-2ae8-433c-9f0c-941c4c5e4a89</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>fc-secure-678eccb8-3463-4a72-8b57-69dfc8c77002</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>fc-secure-221b863c-a724-42f3-9f90-2081b352799c</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>fc-secure-21cd882f-8470-4c2e-93dc-536a908bae73</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>fc-secure-e92b8081-5e6a-440c-af83-4d428f505529</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>fc-secure-e0034430-99a3-4dde-99d3-a2330cd90f19</td>\n",
       "      <td>Success</td>\n",
       "      <td>43562</td>\n",
       "      <td>43562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>fc-secure-315a127f-649d-4928-b4e0-cdca7d898e05</td>\n",
       "      <td>Success</td>\n",
       "      <td>43559</td>\n",
       "      <td>43559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>fc-secure-550ffe2e-04fd-4763-b7d2-09f0c59083e4</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>fc-secure-84e57da6-4df9-45de-9f82-8a550887a7fa</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>fc-secure-2b4d5d05-d951-4e51-8ece-7e851660f91a</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>fc-secure-bfe6497b-69a1-4917-8a7b-c9bd36cb4ae4</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>fc-secure-3b588f92-0298-4ad6-b75d-fa16de8b718d</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>fc-secure-fe950bf8-0470-4329-b8c9-8a42d0dd619d</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>fc-secure-59d2af1f-3dc0-407b-b7ab-05cdcfa4da8f</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>fc-secure-01106611-a0e9-41bb-ac13-27683ab2fc19</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>fc-secure-7a160245-84eb-4383-80ed-f41c2411e702</td>\n",
       "      <td>Success</td>\n",
       "      <td>43565</td>\n",
       "      <td>43565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>fc-secure-32a2f8aa-4f72-43e9-9450-bbf661bde5ef</td>\n",
       "      <td>Success</td>\n",
       "      <td>43562</td>\n",
       "      <td>43562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>fc-secure-ce2baa61-748a-4dbc-a929-f256721b59b2</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>fc-secure-ac202043-c5ef-4fb7-8ccb-62a274c1b8ec</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>fc-secure-652024de-0ecd-4de3-8360-c8c5bfcafd72</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>fc-secure-7c845669-3781-4ac0-bb59-1495d68d1d85</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>fc-secure-330f768f-83c4-4570-ae46-0626b477d2b0</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>fc-secure-dccff364-c2ff-42df-8c8e-f979a0472c11</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>fc-secure-17d8dbc9-d1d8-4d5d-8eb7-c1b82bef24d8</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>fc-secure-674fbd89-9eeb-4e43-8a6f-97d6e50708e0</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>fc-secure-9f2f0267-2df4-44e9-a6ae-dd1d3a43cca5</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>fc-secure-6bc832d1-a35b-4676-bf68-a5772e2be044</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>fc-secure-e4b45d7c-3fee-479f-83e9-8c85312cb8da</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>fc-secure-516245cb-7dcc-487d-acf7-43e5fb10085f</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>fc-secure-ab235723-ed31-4242-b5ab-23c177a0e79c</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>fc-secure-b9906df4-3012-4c7b-a008-3c5708885971</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>fc-secure-05e511c4-0b47-41a5-a361-99f747cbef6c</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>fc-secure-adba6cb8-c49c-405b-af7b-9980e4a9d36a</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>fc-secure-98a7c433-bacc-44fd-96f6-faed04dd1c96</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>fc-secure-fd756575-ba39-4893-8b85-b6dfbb376f3b</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>fc-secure-a473f80e-97a6-4c19-bd68-e37266efb44d</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>fc-secure-04e82709-08e0-4335-aaef-ba55089f6fd9</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>fc-secure-ed823158-2149-493f-80d0-ff066cb14a85</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>fc-secure-bcc5d428-aed0-4814-aefc-f717b97d5106</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>fc-secure-de72ef13-9b7f-44db-9428-5df489d327ce</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>fc-secure-35c81df8-8bdf-467a-af6f-fb807185b82e</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>fc-secure-39458ab6-c2d3-49e2-b6d5-8bb3bae9a245</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>fc-secure-124c02b9-69b7-468c-b3d7-4a07aee74dc5</td>\n",
       "      <td>Success</td>\n",
       "      <td>43559</td>\n",
       "      <td>43559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>fc-secure-a065288d-5bb4-441c-95e9-0ffb20a6cf40</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>fc-secure-ee694ec4-cb3d-441d-95f7-e6d586419484</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>fc-secure-bd923846-0b8b-4018-8706-44b2a8e213b4</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>fc-secure-4c07a18a-8c79-4b81-acbe-91083298f1e4</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>fc-secure-21c6905e-06c8-45f2-b6ed-ffba467f7f75</td>\n",
       "      <td>Success</td>\n",
       "      <td>969336</td>\n",
       "      <td>969336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>fc-secure-538d85ea-c436-43f9-b001-4db614ed96bf</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>fc-secure-d87970dd-adb0-4b99-a204-ae6fbd457d12</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>fc-secure-5f916770-fded-4540-b4b6-49f88b8e05fc</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>fc-secure-0aedc988-3736-496c-b7ac-20cca5b3ceb9</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>fc-secure-d4bead53-0db1-4e25-87da-c02be5819368</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>fc-secure-86cbdfa9-cbc0-40fb-adfa-3dd467ae1062</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>fc-secure-d157fd3c-57ff-4640-a084-cecda832e575</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>fc-secure-08bb70e6-9fa1-40dc-8822-41d73945c053</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>fc-secure-6a2f53f1-6712-48a9-a7b2-3289b8df877b</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>fc-secure-55225e12-ec4c-42e0-a5d1-986c87c6d129</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>fc-secure-89bba08d-ef3b-47bb-9c9b-a937d7550a97</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>fc-secure-bf34568b-1c38-4c43-8a21-59630b969553</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>fc-secure-8a297961-e042-4d02-826f-0322b3d7fbff</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>fc-secure-9befa92f-ef34-4fcf-8df5-d085656e26dd</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>fc-secure-870d27c3-a758-4535-b8dd-5fc0514c5215</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>fc-secure-980cd412-6b18-480a-b2f2-ad1543c06a91</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>fc-secure-16e0c63c-847a-42ef-91ca-3523b3668357</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>fc-secure-c53831f7-0431-44e5-abe6-308270690c3b</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>fc-secure-51a26e99-63eb-442a-869d-87ecbc60c814</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>fc-secure-e5676c90-7028-4b68-b620-c6944514d52c</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>fc-secure-977aa72f-e9ce-4fb6-b32b-c675b4ef25d5</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>fc-secure-d7a002ea-7e1e-45fd-8e76-456fce471f17</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>fc-secure-6537d7f6-f29f-432b-b66e-8cf2204b7920</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>fc-secure-b2669acd-7139-464f-af53-af7215c068aa</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>fc-secure-cb3eeabf-f0ef-497e-9bc6-b5a27be4fec2</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>fc-secure-2180b508-ce9d-4535-aa9f-f07d5917025c</td>\n",
       "      <td>Success</td>\n",
       "      <td>43562</td>\n",
       "      <td>43562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>fc-secure-7e0893cd-4f31-41e4-b1d2-3e656097824a</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>fc-secure-f8b9ce8d-efc0-4aa1-ad71-c0378d8d7194</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>fc-secure-b2f4e185-a21a-434a-9494-d1fabaaaf7c0</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>fc-secure-1355eb72-b00f-4796-8892-ac271b699503</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>fc-secure-68b7e62f-132b-4818-bf64-6c38ec9152ab</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>fc-secure-dae591de-00ad-478c-9440-88034a1b8cb9</td>\n",
       "      <td>Success</td>\n",
       "      <td>43563</td>\n",
       "      <td>43563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>fc-secure-7e9fe869-643a-4828-a1b7-0245e34745ae</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>fc-secure-228fd6fd-e0f7-4895-a246-3b055be27aa1</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>fc-secure-e99706c4-48f9-4a69-baf4-70d1c5eaac5c</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>fc-secure-d2c84e56-8f0d-420a-96a4-942e92009433</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>fc-secure-589e3f7a-7b24-46cf-aefd-63b05155d826</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>fc-secure-3fdbe020-6bdb-4668-bcb8-0d0df9d4ba8a</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>fc-secure-b31156cd-4993-4f69-a8f4-9a99c2697965</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>fc-secure-73036e74-c8b0-4e6f-9f4f-ca55b599d5d1</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>fc-secure-3c4843c0-b83f-4ba1-9bba-9c9a599f3ffb</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>fc-secure-91f9e579-b064-4992-8b00-c789ca48f861</td>\n",
       "      <td>Success</td>\n",
       "      <td>43560</td>\n",
       "      <td>43560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>fc-secure-ac588f86-da2d-4a92-9f45-be2aeedd5fac</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>fc-secure-2fa3df40-c189-41ee-b5ba-484a0b77ef77</td>\n",
       "      <td>Success</td>\n",
       "      <td>43561</td>\n",
       "      <td>43561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>fc-secure-00737009-4e0f-454d-bb02-4b70566a0ed2</td>\n",
       "      <td>Success</td>\n",
       "      <td>43561</td>\n",
       "      <td>43561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>fc-secure-36dfb67b-d2fc-47a1-a94c-225d72e08afd</td>\n",
       "      <td>Success</td>\n",
       "      <td>43562</td>\n",
       "      <td>43562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>fc-secure-55efa443-810c-48c8-90bb-f07beba0e560</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>fc-secure-43207dac-0905-4fdd-b816-a34bd2ccebdd</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>fc-secure-fba19c6f-984e-4616-b253-6d9e6ea5cec5</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>fc-secure-1614d6d2-d053-4de0-9b97-cc4b0762f547</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>fc-secure-c40af798-8afc-4ab3-9b66-946955811d3b</td>\n",
       "      <td>Success</td>\n",
       "      <td>43559</td>\n",
       "      <td>43559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>fc-secure-abc7f058-0260-4e82-a911-abfec3dcb676</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>fc-secure-29cd113f-7eca-4526-aa52-dde1b8cb41d0</td>\n",
       "      <td>Success</td>\n",
       "      <td>43560</td>\n",
       "      <td>43560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>fc-secure-877e6c8c-72ef-46d0-b3f3-37dd175771fe</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>fc-secure-0eba3dae-89be-4642-8982-9a80a7428cd2</td>\n",
       "      <td>Success</td>\n",
       "      <td>43560</td>\n",
       "      <td>43560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>fc-secure-0ca0c5e6-26ca-47ea-b509-ec4eaa058fc6</td>\n",
       "      <td>Success</td>\n",
       "      <td>43561</td>\n",
       "      <td>43561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>fc-secure-bee7792c-ef35-478d-a9bb-c8f2054c335c</td>\n",
       "      <td>Success</td>\n",
       "      <td>43558</td>\n",
       "      <td>43558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>fc-secure-72a949c5-0b7d-45c9-96c3-ff4d25815ed5</td>\n",
       "      <td>Success</td>\n",
       "      <td>43560</td>\n",
       "      <td>43560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         bucket                      status   total_vds_file_count  vds_file_in_jointcall_ws_count  diff\n",
       "0    fc-secure-f5d884c0-a24c-46e6-8c29-cad7f5b158c7  Success         969335                     969335                0 \n",
       "1    fc-secure-6513d7e1-2dbb-41a2-baea-3f7fdbcbb620  Success          43558                      43558                0 \n",
       "2           fc-d3e9eb24-cb19-47d8-b2c6-d85fd34b4ff1  Success          43558                      43558                0 \n",
       "3           fc-0ed1ef2d-1039-4c8a-a0a9-91c3e385200a  Success          43558                      43558                0 \n",
       "4           fc-282a8e0b-df88-42de-9059-2b7447d9f9c7  Success          43558                      43558                0 \n",
       "5    fc-secure-5efb4966-0994-41f8-a911-1d159c9bae1b  Success          43558                      43558                0 \n",
       "6           fc-2836a560-113a-4239-acab-5cce58019b73  Success          43558                      43558                0 \n",
       "7           fc-bb71bb7a-fdb1-427a-9e56-eb08b6fd7955  Success          43558                      43558                0 \n",
       "8    fc-secure-e9b2e26a-3f73-4f5a-862f-c5b3be68703f  Success          43558                      43558                0 \n",
       "9           fc-e7051891-25c8-4776-80ed-26b1af860277  Success          43558                      43558                0 \n",
       "10          fc-4f070061-0bc2-4f9a-9fe9-869a739c9817  Success          43558                      43558                0 \n",
       "11          fc-c1701683-c10e-4f73-a636-f774e8b650c2  Success          43558                      43558                0 \n",
       "12   fc-secure-ccca1171-d3ee-42b3-8df8-aca336279cf3  Success          43558                      43558                0 \n",
       "13          fc-2d61b7df-571f-4201-a674-1107c84711df  Success          43558                      43558                0 \n",
       "14          fc-5d7cf59f-e361-4073-a6ad-16d8d78cc613  Success          43558                      43558                0 \n",
       "15   fc-secure-70487b95-e89c-45ec-ad0a-e5382d625c33  Success          43558                      43558                0 \n",
       "16          fc-2b68ae78-57af-4c65-8020-6f5ed4ae9408  Success          43558                      43558                0 \n",
       "17   fc-secure-33bdfbdb-de58-474e-8591-dad501aa1995  Success          43558                      43558                0 \n",
       "18          fc-2bcebe36-5d83-486a-947a-bbb5a606701d  Success          43558                      43558                0 \n",
       "19   fc-secure-1fb85b31-9a1e-46ef-a206-41040d151f94  Success         969324                     969324                0 \n",
       "20   fc-secure-ead0ff8d-eee9-4299-bb54-8404ffe9fa22  Success          43563                      43563                0 \n",
       "21   fc-secure-d8de1fe3-972d-480f-a8a8-2bbc251add30  Success          43567                      43567                0 \n",
       "22   fc-secure-4d47049d-9a31-435d-8c97-61cffce9a83b  Success          43558                      43558                0 \n",
       "23   fc-secure-31d85e96-7fa0-4c2e-a89a-fe5c70845fd7  Success          43558                      43558                0 \n",
       "24   fc-secure-68ff7cc9-274c-45d6-baad-75b9c5971a9c  Success          43558                      43558                0 \n",
       "25   fc-secure-fdaa7a52-520b-461b-a2d2-e31bf92e8e86  Success          43559                      43559                0 \n",
       "26   fc-secure-9c348df7-4da1-428a-a785-e06db3a9f208  Success          43558                      43558                0 \n",
       "27   fc-secure-0de89e54-2149-4e06-81f9-da5af48c68a3  Success          43558                      43558                0 \n",
       "28   fc-secure-986229e0-ac72-420d-bf0e-aa14dea63a05  Success          43558                      43558                0 \n",
       "29   fc-secure-4931149d-9e71-4865-9f41-3e4c998ffb38  Success          43558                      43558                0 \n",
       "30   fc-secure-13597242-de35-44e2-b8fb-b5fa0b983501  Success          43558                      43558                0 \n",
       "31   fc-secure-75f95e44-299f-4666-bed3-46dd679b12d8  Success          43558                      43558                0 \n",
       "32   fc-secure-240e1629-6d73-42ab-a373-1abeec17824c  Success          43558                      43558                0 \n",
       "33   fc-secure-94c90c12-376d-419a-96d9-ed37e1b1a5bb  Success          43558                      43558                0 \n",
       "34   fc-secure-6c21e787-1a4b-4235-b756-9ce6096fc815  Success          43562                      43562                0 \n",
       "35   fc-secure-51198b17-37ae-44b7-8513-c11c4bfe3a9d  Success          43558                      43558                0 \n",
       "36   fc-secure-59794551-d924-4ad7-905b-8727646d9aad  Success          43558                      43558                0 \n",
       "37   fc-secure-8ec82876-176f-4f33-ae98-0a3cae871ed4  Success          43558                      43558                0 \n",
       "38   fc-secure-8a282388-3c56-48c6-99c8-ea4b52c053b9  Success          43558                      43558                0 \n",
       "39   fc-secure-3e71d768-9da9-4845-9e2c-7e909db92cb7  Success          43562                      43562                0 \n",
       "40   fc-secure-0fc5a889-f57e-40a1-9859-c5b1e8a196d1  Success          43558                      43558                0 \n",
       "41   fc-secure-0f948ad2-2ae8-433c-9f0c-941c4c5e4a89  Success          43558                      43558                0 \n",
       "42   fc-secure-678eccb8-3463-4a72-8b57-69dfc8c77002  Success          43558                      43558                0 \n",
       "43   fc-secure-221b863c-a724-42f3-9f90-2081b352799c  Success          43558                      43558                0 \n",
       "44   fc-secure-21cd882f-8470-4c2e-93dc-536a908bae73  Success          43558                      43558                0 \n",
       "45   fc-secure-e92b8081-5e6a-440c-af83-4d428f505529  Success          43558                      43558                0 \n",
       "46   fc-secure-e0034430-99a3-4dde-99d3-a2330cd90f19  Success          43562                      43562                0 \n",
       "47   fc-secure-315a127f-649d-4928-b4e0-cdca7d898e05  Success          43559                      43559                0 \n",
       "48   fc-secure-550ffe2e-04fd-4763-b7d2-09f0c59083e4  Success          43558                      43558                0 \n",
       "49   fc-secure-84e57da6-4df9-45de-9f82-8a550887a7fa  Success          43558                      43558                0 \n",
       "50   fc-secure-2b4d5d05-d951-4e51-8ece-7e851660f91a  Success          43558                      43558                0 \n",
       "51   fc-secure-bfe6497b-69a1-4917-8a7b-c9bd36cb4ae4  Success          43558                      43558                0 \n",
       "52   fc-secure-3b588f92-0298-4ad6-b75d-fa16de8b718d  Success          43558                      43558                0 \n",
       "53   fc-secure-fe950bf8-0470-4329-b8c9-8a42d0dd619d  Success          43558                      43558                0 \n",
       "54   fc-secure-59d2af1f-3dc0-407b-b7ab-05cdcfa4da8f  Success          43558                      43558                0 \n",
       "55   fc-secure-01106611-a0e9-41bb-ac13-27683ab2fc19  Success          43558                      43558                0 \n",
       "56   fc-secure-7a160245-84eb-4383-80ed-f41c2411e702  Success          43565                      43565                0 \n",
       "57   fc-secure-32a2f8aa-4f72-43e9-9450-bbf661bde5ef  Success          43562                      43562                0 \n",
       "58   fc-secure-ce2baa61-748a-4dbc-a929-f256721b59b2  Success          43558                      43558                0 \n",
       "59   fc-secure-ac202043-c5ef-4fb7-8ccb-62a274c1b8ec  Success          43558                      43558                0 \n",
       "60   fc-secure-652024de-0ecd-4de3-8360-c8c5bfcafd72  Success          43558                      43558                0 \n",
       "61   fc-secure-7c845669-3781-4ac0-bb59-1495d68d1d85  Success          43558                      43558                0 \n",
       "62   fc-secure-330f768f-83c4-4570-ae46-0626b477d2b0  Success          43558                      43558                0 \n",
       "63   fc-secure-dccff364-c2ff-42df-8c8e-f979a0472c11  Success          43558                      43558                0 \n",
       "64   fc-secure-17d8dbc9-d1d8-4d5d-8eb7-c1b82bef24d8  Success          43558                      43558                0 \n",
       "65   fc-secure-674fbd89-9eeb-4e43-8a6f-97d6e50708e0  Success          43558                      43558                0 \n",
       "66   fc-secure-9f2f0267-2df4-44e9-a6ae-dd1d3a43cca5  Success          43558                      43558                0 \n",
       "67   fc-secure-6bc832d1-a35b-4676-bf68-a5772e2be044  Success          43558                      43558                0 \n",
       "68   fc-secure-e4b45d7c-3fee-479f-83e9-8c85312cb8da  Success          43558                      43558                0 \n",
       "69   fc-secure-516245cb-7dcc-487d-acf7-43e5fb10085f  Success          43558                      43558                0 \n",
       "70   fc-secure-ab235723-ed31-4242-b5ab-23c177a0e79c  Success          43558                      43558                0 \n",
       "71   fc-secure-b9906df4-3012-4c7b-a008-3c5708885971  Success          43558                      43558                0 \n",
       "72   fc-secure-05e511c4-0b47-41a5-a361-99f747cbef6c  Success          43558                      43558                0 \n",
       "73   fc-secure-adba6cb8-c49c-405b-af7b-9980e4a9d36a  Success          43558                      43558                0 \n",
       "74   fc-secure-98a7c433-bacc-44fd-96f6-faed04dd1c96  Success          43558                      43558                0 \n",
       "75   fc-secure-fd756575-ba39-4893-8b85-b6dfbb376f3b  Success          43558                      43558                0 \n",
       "76   fc-secure-a473f80e-97a6-4c19-bd68-e37266efb44d  Success          43558                      43558                0 \n",
       "77   fc-secure-04e82709-08e0-4335-aaef-ba55089f6fd9  Success          43558                      43558                0 \n",
       "78   fc-secure-ed823158-2149-493f-80d0-ff066cb14a85  Success          43558                      43558                0 \n",
       "79   fc-secure-bcc5d428-aed0-4814-aefc-f717b97d5106  Success          43558                      43558                0 \n",
       "80   fc-secure-de72ef13-9b7f-44db-9428-5df489d327ce  Success          43558                      43558                0 \n",
       "81   fc-secure-35c81df8-8bdf-467a-af6f-fb807185b82e  Success          43558                      43558                0 \n",
       "82   fc-secure-39458ab6-c2d3-49e2-b6d5-8bb3bae9a245  Success          43558                      43558                0 \n",
       "83   fc-secure-124c02b9-69b7-468c-b3d7-4a07aee74dc5  Success          43559                      43559                0 \n",
       "84   fc-secure-a065288d-5bb4-441c-95e9-0ffb20a6cf40  Success          43558                      43558                0 \n",
       "85   fc-secure-ee694ec4-cb3d-441d-95f7-e6d586419484  Success          43558                      43558                0 \n",
       "86   fc-secure-bd923846-0b8b-4018-8706-44b2a8e213b4  Success          43558                      43558                0 \n",
       "87   fc-secure-4c07a18a-8c79-4b81-acbe-91083298f1e4  Success          43558                      43558                0 \n",
       "88   fc-secure-21c6905e-06c8-45f2-b6ed-ffba467f7f75  Success         969336                     969336                0 \n",
       "89   fc-secure-538d85ea-c436-43f9-b001-4db614ed96bf  Success          43558                      43558                0 \n",
       "90   fc-secure-d87970dd-adb0-4b99-a204-ae6fbd457d12  Success          43558                      43558                0 \n",
       "91   fc-secure-5f916770-fded-4540-b4b6-49f88b8e05fc  Success          43558                      43558                0 \n",
       "92   fc-secure-0aedc988-3736-496c-b7ac-20cca5b3ceb9  Success          43558                      43558                0 \n",
       "93   fc-secure-d4bead53-0db1-4e25-87da-c02be5819368  Success          43558                      43558                0 \n",
       "94   fc-secure-86cbdfa9-cbc0-40fb-adfa-3dd467ae1062  Success          43558                      43558                0 \n",
       "95   fc-secure-d157fd3c-57ff-4640-a084-cecda832e575  Success          43558                      43558                0 \n",
       "96   fc-secure-08bb70e6-9fa1-40dc-8822-41d73945c053  Success          43558                      43558                0 \n",
       "97   fc-secure-6a2f53f1-6712-48a9-a7b2-3289b8df877b  Success          43558                      43558                0 \n",
       "98   fc-secure-55225e12-ec4c-42e0-a5d1-986c87c6d129  Success          43558                      43558                0 \n",
       "99   fc-secure-89bba08d-ef3b-47bb-9c9b-a937d7550a97  Success          43558                      43558                0 \n",
       "100  fc-secure-bf34568b-1c38-4c43-8a21-59630b969553  Success          43558                      43558                0 \n",
       "101  fc-secure-8a297961-e042-4d02-826f-0322b3d7fbff  Success          43558                      43558                0 \n",
       "102  fc-secure-9befa92f-ef34-4fcf-8df5-d085656e26dd  Success          43558                      43558                0 \n",
       "103  fc-secure-870d27c3-a758-4535-b8dd-5fc0514c5215  Success          43558                      43558                0 \n",
       "104  fc-secure-980cd412-6b18-480a-b2f2-ad1543c06a91  Success          43558                      43558                0 \n",
       "105  fc-secure-16e0c63c-847a-42ef-91ca-3523b3668357  Success          43558                      43558                0 \n",
       "106  fc-secure-c53831f7-0431-44e5-abe6-308270690c3b  Success          43558                      43558                0 \n",
       "107  fc-secure-51a26e99-63eb-442a-869d-87ecbc60c814  Success          43558                      43558                0 \n",
       "108  fc-secure-e5676c90-7028-4b68-b620-c6944514d52c  Success          43558                      43558                0 \n",
       "109  fc-secure-977aa72f-e9ce-4fb6-b32b-c675b4ef25d5  Success          43558                      43558                0 \n",
       "110  fc-secure-d7a002ea-7e1e-45fd-8e76-456fce471f17  Success          43558                      43558                0 \n",
       "111  fc-secure-6537d7f6-f29f-432b-b66e-8cf2204b7920  Success          43558                      43558                0 \n",
       "112  fc-secure-b2669acd-7139-464f-af53-af7215c068aa  Success          43558                      43558                0 \n",
       "113  fc-secure-cb3eeabf-f0ef-497e-9bc6-b5a27be4fec2  Success          43558                      43558                0 \n",
       "114  fc-secure-2180b508-ce9d-4535-aa9f-f07d5917025c  Success          43562                      43562                0 \n",
       "115  fc-secure-7e0893cd-4f31-41e4-b1d2-3e656097824a  Success          43558                      43558                0 \n",
       "116  fc-secure-f8b9ce8d-efc0-4aa1-ad71-c0378d8d7194  Success          43558                      43558                0 \n",
       "117  fc-secure-b2f4e185-a21a-434a-9494-d1fabaaaf7c0  Success          43558                      43558                0 \n",
       "118  fc-secure-1355eb72-b00f-4796-8892-ac271b699503  Success          43558                      43558                0 \n",
       "119  fc-secure-68b7e62f-132b-4818-bf64-6c38ec9152ab  Success          43558                      43558                0 \n",
       "120  fc-secure-dae591de-00ad-478c-9440-88034a1b8cb9  Success          43563                      43563                0 \n",
       "121  fc-secure-7e9fe869-643a-4828-a1b7-0245e34745ae  Success          43558                      43558                0 \n",
       "122  fc-secure-228fd6fd-e0f7-4895-a246-3b055be27aa1  Success          43558                      43558                0 \n",
       "123  fc-secure-e99706c4-48f9-4a69-baf4-70d1c5eaac5c  Success          43558                      43558                0 \n",
       "124  fc-secure-d2c84e56-8f0d-420a-96a4-942e92009433  Success          43558                      43558                0 \n",
       "125  fc-secure-589e3f7a-7b24-46cf-aefd-63b05155d826  Success          43558                      43558                0 \n",
       "126  fc-secure-3fdbe020-6bdb-4668-bcb8-0d0df9d4ba8a  Success          43558                      43558                0 \n",
       "127  fc-secure-b31156cd-4993-4f69-a8f4-9a99c2697965  Success          43558                      43558                0 \n",
       "128  fc-secure-73036e74-c8b0-4e6f-9f4f-ca55b599d5d1  Success          43558                      43558                0 \n",
       "129  fc-secure-3c4843c0-b83f-4ba1-9bba-9c9a599f3ffb  Success          43558                      43558                0 \n",
       "130  fc-secure-91f9e579-b064-4992-8b00-c789ca48f861  Success          43560                      43560                0 \n",
       "131  fc-secure-ac588f86-da2d-4a92-9f45-be2aeedd5fac  Success          43558                      43558                0 \n",
       "132  fc-secure-2fa3df40-c189-41ee-b5ba-484a0b77ef77  Success          43561                      43561                0 \n",
       "133  fc-secure-00737009-4e0f-454d-bb02-4b70566a0ed2  Success          43561                      43561                0 \n",
       "134  fc-secure-36dfb67b-d2fc-47a1-a94c-225d72e08afd  Success          43562                      43562                0 \n",
       "135  fc-secure-55efa443-810c-48c8-90bb-f07beba0e560  Success          43558                      43558                0 \n",
       "136  fc-secure-43207dac-0905-4fdd-b816-a34bd2ccebdd  Success          43558                      43558                0 \n",
       "137  fc-secure-fba19c6f-984e-4616-b253-6d9e6ea5cec5  Success          43558                      43558                0 \n",
       "138  fc-secure-1614d6d2-d053-4de0-9b97-cc4b0762f547  Success          43558                      43558                0 \n",
       "139  fc-secure-c40af798-8afc-4ab3-9b66-946955811d3b  Success          43559                      43559                0 \n",
       "140  fc-secure-abc7f058-0260-4e82-a911-abfec3dcb676  Success          43558                      43558                0 \n",
       "141  fc-secure-29cd113f-7eca-4526-aa52-dde1b8cb41d0  Success          43560                      43560                0 \n",
       "142  fc-secure-877e6c8c-72ef-46d0-b3f3-37dd175771fe  Success          43558                      43558                0 \n",
       "143  fc-secure-0eba3dae-89be-4642-8982-9a80a7428cd2  Success          43560                      43560                0 \n",
       "144  fc-secure-0ca0c5e6-26ca-47ea-b509-ec4eaa058fc6  Success          43561                      43561                0 \n",
       "145  fc-secure-bee7792c-ef35-478d-a9bb-c8f2054c335c  Success          43558                      43558                0 \n",
       "146  fc-secure-72a949c5-0b7d-45c9-96c3-ff4d25815ed5  Success          43560                      43560                0 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compare_vds_files(bucket):\n",
    "    \n",
    "    # Execute query\n",
    "    client = bigquery.Client()\n",
    "    query = f\"\"\"\n",
    "            WITH jointcall_files\n",
    "            AS\n",
    "            (\n",
    "              SELECT REGEXP_EXTRACT(name, r'.*\\.vds(.+)$') AS object_name, md5Hash, size\n",
    "              FROM `broad-dsde-prod-analytics-dev.anvil_inventory.object_metadata_26_02_2024__17_14_55` \n",
    "              WHERE bucket IN ('fc-secure-9e3357c0-389c-41d7-94ee-56673db6b75f', 'fc-secure-7e69c896-d6c0-4a4e-8490-42cb2d4fdebf')\n",
    "            ), \n",
    "            cohort_ws_files\n",
    "            AS\n",
    "            (\n",
    "              SELECT REGEXP_EXTRACT(name, r'.*\\.vds(.+)$') AS object_name, md5Hash, size\n",
    "              FROM `broad-dsde-prod-analytics-dev.anvil_inventory.object_metadata_26_02_2024__17_14_55` \n",
    "              WHERE bucket = '{bucket}'\n",
    "              AND name LIKE '%.vds%'\n",
    "            )\n",
    "            SELECT COUNT(DISTINCT c.object_name) AS total_vds_file_count, \n",
    "            COUNT(DISTINCT j.object_name) AS vds_file_in_jointcall_ws_count\n",
    "            FROM cohort_ws_files c\n",
    "              LEFT JOIN jointcall_files j\n",
    "              ON c.object_name = j.object_name \n",
    "              AND c.md5Hash = j.md5Hash\n",
    "              AND c.size = j.size\"\"\"\n",
    "    try:\n",
    "        df = client.query(query).result().to_dataframe()\n",
    "        total_vds_file_count = df[\"total_vds_file_count\"].values[0]\n",
    "        vds_file_in_jointcall_ws_count = df[\"vds_file_in_jointcall_ws_count\"].values[0] \n",
    "        diff = total_vds_file_count - vds_file_in_jointcall_ws_count\n",
    "        return \"Success\", total_vds_file_count, vds_file_in_jointcall_ws_count, diff\n",
    "    except Exception as e:\n",
    "        return \"Failure\", 0, 0, 0\n",
    "\n",
    "# Loop through datasets and validate is_supplementary field\n",
    "bucket_list = [\n",
    "    'fc-secure-f5d884c0-a24c-46e6-8c29-cad7f5b158c7',\n",
    "    'fc-secure-6513d7e1-2dbb-41a2-baea-3f7fdbcbb620',\n",
    "    'fc-d3e9eb24-cb19-47d8-b2c6-d85fd34b4ff1',\n",
    "    'fc-0ed1ef2d-1039-4c8a-a0a9-91c3e385200a',\n",
    "    'fc-282a8e0b-df88-42de-9059-2b7447d9f9c7',\n",
    "    'fc-secure-5efb4966-0994-41f8-a911-1d159c9bae1b',\n",
    "    'fc-2836a560-113a-4239-acab-5cce58019b73',\n",
    "    'fc-bb71bb7a-fdb1-427a-9e56-eb08b6fd7955',\n",
    "    'fc-secure-e9b2e26a-3f73-4f5a-862f-c5b3be68703f',\n",
    "    'fc-e7051891-25c8-4776-80ed-26b1af860277',\n",
    "    'fc-4f070061-0bc2-4f9a-9fe9-869a739c9817',\n",
    "    'fc-c1701683-c10e-4f73-a636-f774e8b650c2',\n",
    "    'fc-secure-ccca1171-d3ee-42b3-8df8-aca336279cf3',\n",
    "    'fc-2d61b7df-571f-4201-a674-1107c84711df',\n",
    "    'fc-5d7cf59f-e361-4073-a6ad-16d8d78cc613',\n",
    "    'fc-secure-70487b95-e89c-45ec-ad0a-e5382d625c33',\n",
    "    'fc-2b68ae78-57af-4c65-8020-6f5ed4ae9408',\n",
    "    'fc-secure-33bdfbdb-de58-474e-8591-dad501aa1995',\n",
    "    'fc-2bcebe36-5d83-486a-947a-bbb5a606701d',\n",
    "    'fc-secure-1fb85b31-9a1e-46ef-a206-41040d151f94',\n",
    "    'fc-secure-ead0ff8d-eee9-4299-bb54-8404ffe9fa22',\n",
    "    'fc-secure-d8de1fe3-972d-480f-a8a8-2bbc251add30',\n",
    "    'fc-secure-4d47049d-9a31-435d-8c97-61cffce9a83b',\n",
    "    'fc-secure-31d85e96-7fa0-4c2e-a89a-fe5c70845fd7',\n",
    "    'fc-secure-68ff7cc9-274c-45d6-baad-75b9c5971a9c',\n",
    "    'fc-secure-fdaa7a52-520b-461b-a2d2-e31bf92e8e86',\n",
    "    'fc-secure-9c348df7-4da1-428a-a785-e06db3a9f208',\n",
    "    'fc-secure-0de89e54-2149-4e06-81f9-da5af48c68a3',\n",
    "    'fc-secure-986229e0-ac72-420d-bf0e-aa14dea63a05',\n",
    "    'fc-secure-4931149d-9e71-4865-9f41-3e4c998ffb38',\n",
    "    'fc-secure-13597242-de35-44e2-b8fb-b5fa0b983501',\n",
    "    'fc-secure-75f95e44-299f-4666-bed3-46dd679b12d8',\n",
    "    'fc-secure-240e1629-6d73-42ab-a373-1abeec17824c',\n",
    "    'fc-secure-94c90c12-376d-419a-96d9-ed37e1b1a5bb',\n",
    "    'fc-secure-6c21e787-1a4b-4235-b756-9ce6096fc815',\n",
    "    'fc-secure-51198b17-37ae-44b7-8513-c11c4bfe3a9d',\n",
    "    'fc-secure-59794551-d924-4ad7-905b-8727646d9aad',\n",
    "    'fc-secure-8ec82876-176f-4f33-ae98-0a3cae871ed4',\n",
    "    'fc-secure-8a282388-3c56-48c6-99c8-ea4b52c053b9',\n",
    "    'fc-secure-3e71d768-9da9-4845-9e2c-7e909db92cb7',\n",
    "    'fc-secure-0fc5a889-f57e-40a1-9859-c5b1e8a196d1',\n",
    "    'fc-secure-0f948ad2-2ae8-433c-9f0c-941c4c5e4a89',\n",
    "    'fc-secure-678eccb8-3463-4a72-8b57-69dfc8c77002',\n",
    "    'fc-secure-221b863c-a724-42f3-9f90-2081b352799c',\n",
    "    'fc-secure-21cd882f-8470-4c2e-93dc-536a908bae73',\n",
    "    'fc-secure-e92b8081-5e6a-440c-af83-4d428f505529',\n",
    "    'fc-secure-e0034430-99a3-4dde-99d3-a2330cd90f19',\n",
    "    'fc-secure-315a127f-649d-4928-b4e0-cdca7d898e05',\n",
    "    'fc-secure-550ffe2e-04fd-4763-b7d2-09f0c59083e4',\n",
    "    'fc-secure-84e57da6-4df9-45de-9f82-8a550887a7fa',\n",
    "    'fc-secure-2b4d5d05-d951-4e51-8ece-7e851660f91a',\n",
    "    'fc-secure-bfe6497b-69a1-4917-8a7b-c9bd36cb4ae4',\n",
    "    'fc-secure-3b588f92-0298-4ad6-b75d-fa16de8b718d',\n",
    "    'fc-secure-fe950bf8-0470-4329-b8c9-8a42d0dd619d',\n",
    "    'fc-secure-59d2af1f-3dc0-407b-b7ab-05cdcfa4da8f',\n",
    "    'fc-secure-01106611-a0e9-41bb-ac13-27683ab2fc19',\n",
    "    'fc-secure-7a160245-84eb-4383-80ed-f41c2411e702',\n",
    "    'fc-secure-32a2f8aa-4f72-43e9-9450-bbf661bde5ef',\n",
    "    'fc-secure-ce2baa61-748a-4dbc-a929-f256721b59b2',\n",
    "    'fc-secure-ac202043-c5ef-4fb7-8ccb-62a274c1b8ec',\n",
    "    'fc-secure-652024de-0ecd-4de3-8360-c8c5bfcafd72',\n",
    "    'fc-secure-7c845669-3781-4ac0-bb59-1495d68d1d85',\n",
    "    'fc-secure-330f768f-83c4-4570-ae46-0626b477d2b0',\n",
    "    'fc-secure-dccff364-c2ff-42df-8c8e-f979a0472c11',\n",
    "    'fc-secure-17d8dbc9-d1d8-4d5d-8eb7-c1b82bef24d8',\n",
    "    'fc-secure-674fbd89-9eeb-4e43-8a6f-97d6e50708e0',\n",
    "    'fc-secure-9f2f0267-2df4-44e9-a6ae-dd1d3a43cca5',\n",
    "    'fc-secure-6bc832d1-a35b-4676-bf68-a5772e2be044',\n",
    "    'fc-secure-e4b45d7c-3fee-479f-83e9-8c85312cb8da',\n",
    "    'fc-secure-516245cb-7dcc-487d-acf7-43e5fb10085f',\n",
    "    'fc-secure-ab235723-ed31-4242-b5ab-23c177a0e79c',\n",
    "    'fc-secure-b9906df4-3012-4c7b-a008-3c5708885971',\n",
    "    'fc-secure-05e511c4-0b47-41a5-a361-99f747cbef6c',\n",
    "    'fc-secure-adba6cb8-c49c-405b-af7b-9980e4a9d36a',\n",
    "    'fc-secure-98a7c433-bacc-44fd-96f6-faed04dd1c96',\n",
    "    'fc-secure-fd756575-ba39-4893-8b85-b6dfbb376f3b',\n",
    "    'fc-secure-a473f80e-97a6-4c19-bd68-e37266efb44d',\n",
    "    'fc-secure-04e82709-08e0-4335-aaef-ba55089f6fd9',\n",
    "    'fc-secure-ed823158-2149-493f-80d0-ff066cb14a85',\n",
    "    'fc-secure-bcc5d428-aed0-4814-aefc-f717b97d5106',\n",
    "    'fc-secure-de72ef13-9b7f-44db-9428-5df489d327ce',\n",
    "    'fc-secure-35c81df8-8bdf-467a-af6f-fb807185b82e',\n",
    "    'fc-secure-39458ab6-c2d3-49e2-b6d5-8bb3bae9a245',\n",
    "    'fc-secure-124c02b9-69b7-468c-b3d7-4a07aee74dc5',\n",
    "    'fc-secure-a065288d-5bb4-441c-95e9-0ffb20a6cf40',\n",
    "    'fc-secure-ee694ec4-cb3d-441d-95f7-e6d586419484',\n",
    "    'fc-secure-bd923846-0b8b-4018-8706-44b2a8e213b4',\n",
    "    'fc-secure-4c07a18a-8c79-4b81-acbe-91083298f1e4',\n",
    "    'fc-secure-21c6905e-06c8-45f2-b6ed-ffba467f7f75',\n",
    "    'fc-secure-538d85ea-c436-43f9-b001-4db614ed96bf',\n",
    "    'fc-secure-d87970dd-adb0-4b99-a204-ae6fbd457d12',\n",
    "    'fc-secure-5f916770-fded-4540-b4b6-49f88b8e05fc',\n",
    "    'fc-secure-0aedc988-3736-496c-b7ac-20cca5b3ceb9',\n",
    "    'fc-secure-d4bead53-0db1-4e25-87da-c02be5819368',\n",
    "    'fc-secure-86cbdfa9-cbc0-40fb-adfa-3dd467ae1062',\n",
    "    'fc-secure-d157fd3c-57ff-4640-a084-cecda832e575',\n",
    "    'fc-secure-08bb70e6-9fa1-40dc-8822-41d73945c053',\n",
    "    'fc-secure-6a2f53f1-6712-48a9-a7b2-3289b8df877b',\n",
    "    'fc-secure-55225e12-ec4c-42e0-a5d1-986c87c6d129',\n",
    "    'fc-secure-89bba08d-ef3b-47bb-9c9b-a937d7550a97',\n",
    "    'fc-secure-bf34568b-1c38-4c43-8a21-59630b969553',\n",
    "    'fc-secure-8a297961-e042-4d02-826f-0322b3d7fbff',\n",
    "    'fc-secure-9befa92f-ef34-4fcf-8df5-d085656e26dd',\n",
    "    'fc-secure-870d27c3-a758-4535-b8dd-5fc0514c5215',\n",
    "    'fc-secure-980cd412-6b18-480a-b2f2-ad1543c06a91',\n",
    "    'fc-secure-16e0c63c-847a-42ef-91ca-3523b3668357',\n",
    "    'fc-secure-c53831f7-0431-44e5-abe6-308270690c3b',\n",
    "    'fc-secure-51a26e99-63eb-442a-869d-87ecbc60c814',\n",
    "    'fc-secure-e5676c90-7028-4b68-b620-c6944514d52c',\n",
    "    'fc-secure-977aa72f-e9ce-4fb6-b32b-c675b4ef25d5',\n",
    "    'fc-secure-d7a002ea-7e1e-45fd-8e76-456fce471f17',\n",
    "    'fc-secure-6537d7f6-f29f-432b-b66e-8cf2204b7920',\n",
    "    'fc-secure-b2669acd-7139-464f-af53-af7215c068aa',\n",
    "    'fc-secure-cb3eeabf-f0ef-497e-9bc6-b5a27be4fec2',\n",
    "    'fc-secure-2180b508-ce9d-4535-aa9f-f07d5917025c',\n",
    "    'fc-secure-7e0893cd-4f31-41e4-b1d2-3e656097824a',\n",
    "    'fc-secure-f8b9ce8d-efc0-4aa1-ad71-c0378d8d7194',\n",
    "    'fc-secure-b2f4e185-a21a-434a-9494-d1fabaaaf7c0',\n",
    "    'fc-secure-1355eb72-b00f-4796-8892-ac271b699503',\n",
    "    'fc-secure-68b7e62f-132b-4818-bf64-6c38ec9152ab',\n",
    "    'fc-secure-dae591de-00ad-478c-9440-88034a1b8cb9',\n",
    "    'fc-secure-7e9fe869-643a-4828-a1b7-0245e34745ae',\n",
    "    'fc-secure-228fd6fd-e0f7-4895-a246-3b055be27aa1',\n",
    "    'fc-secure-e99706c4-48f9-4a69-baf4-70d1c5eaac5c',\n",
    "    'fc-secure-d2c84e56-8f0d-420a-96a4-942e92009433',\n",
    "    'fc-secure-589e3f7a-7b24-46cf-aefd-63b05155d826',\n",
    "    'fc-secure-3fdbe020-6bdb-4668-bcb8-0d0df9d4ba8a',\n",
    "    'fc-secure-b31156cd-4993-4f69-a8f4-9a99c2697965',\n",
    "    'fc-secure-73036e74-c8b0-4e6f-9f4f-ca55b599d5d1',\n",
    "    'fc-secure-3c4843c0-b83f-4ba1-9bba-9c9a599f3ffb',\n",
    "    'fc-secure-91f9e579-b064-4992-8b00-c789ca48f861',\n",
    "    'fc-secure-ac588f86-da2d-4a92-9f45-be2aeedd5fac',\n",
    "    'fc-secure-2fa3df40-c189-41ee-b5ba-484a0b77ef77',\n",
    "    'fc-secure-00737009-4e0f-454d-bb02-4b70566a0ed2',\n",
    "    'fc-secure-36dfb67b-d2fc-47a1-a94c-225d72e08afd',\n",
    "    'fc-secure-55efa443-810c-48c8-90bb-f07beba0e560',\n",
    "    'fc-secure-43207dac-0905-4fdd-b816-a34bd2ccebdd',\n",
    "    'fc-secure-fba19c6f-984e-4616-b253-6d9e6ea5cec5',\n",
    "    'fc-secure-1614d6d2-d053-4de0-9b97-cc4b0762f547',\n",
    "    'fc-secure-c40af798-8afc-4ab3-9b66-946955811d3b',\n",
    "    'fc-secure-abc7f058-0260-4e82-a911-abfec3dcb676',\n",
    "    'fc-secure-29cd113f-7eca-4526-aa52-dde1b8cb41d0',\n",
    "    'fc-secure-877e6c8c-72ef-46d0-b3f3-37dd175771fe',\n",
    "    'fc-secure-0eba3dae-89be-4642-8982-9a80a7428cd2',\n",
    "    'fc-secure-0ca0c5e6-26ca-47ea-b509-ec4eaa058fc6',\n",
    "    'fc-secure-bee7792c-ef35-478d-a9bb-c8f2054c335c',\n",
    "    'fc-secure-72a949c5-0b7d-45c9-96c3-ff4d25815ed5',\n",
    "]\n",
    "results = []\n",
    "for bucket in bucket_list:\n",
    "    logging.info(f\"Examining VDS files in bucket: {bucket}\")\n",
    "    status, total_vds_file_count, vds_file_in_jointcall_ws_count, diff = compare_vds_files(bucket) \n",
    "    results.append([bucket, status, total_vds_file_count, vds_file_in_jointcall_ws_count, diff])\n",
    "    results_df = pd.DataFrame(results, columns = [\"bucket\", \"status\", \"total_vds_file_count\", \"vds_file_in_jointcall_ws_count\", \"diff\"])\n",
    "logging.info(\"Results:\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Identify and resolve records missing part_of_dataset_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Script to identify whether datasets need to be patched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     4
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/22/2024 06:30:26 PM - INFO: Processing dataset_id = f9224ea2-dd31-421d-80d4-f35082ef8d68...\n",
      "03/22/2024 06:30:26 PM - INFO: Retrieving dataset details.\n",
      "03/22/2024 06:30:26 PM - INFO: Checking whether patching is required for the anvil_donor table.\n",
      "03/22/2024 06:30:29 PM - INFO: Checking whether patching is required for the anvil_biosample table.\n",
      "03/22/2024 06:30:31 PM - INFO: Processing dataset_id = d7bcfc5d-e258-4bd6-a413-bb7a118e6bff...\n",
      "03/22/2024 06:30:31 PM - INFO: Retrieving dataset details.\n",
      "03/22/2024 06:30:32 PM - INFO: Checking whether patching is required for the anvil_donor table.\n",
      "03/22/2024 06:30:34 PM - INFO: Checking whether patching is required for the anvil_biosample table.\n",
      "03/22/2024 06:30:36 PM - INFO: Processing dataset_id = 6d18aafc-0240-499c-902e-a72a5b98ff0a...\n",
      "03/22/2024 06:30:36 PM - INFO: Retrieving dataset details.\n",
      "03/22/2024 06:30:36 PM - INFO: Checking whether patching is required for the anvil_donor table.\n",
      "03/22/2024 06:30:38 PM - INFO: Checking whether patching is required for the anvil_biosample table.\n",
      "03/22/2024 06:30:40 PM - INFO: \n",
      "Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Dataset ID</th>\n",
       "      <th>Table</th>\n",
       "      <th>Status</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f9224ea2-dd31-421d-80d4-f35082ef8d68</td>\n",
       "      <td>anvil_donor</td>\n",
       "      <td>Success</td>\n",
       "      <td>Patch Needed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f9224ea2-dd31-421d-80d4-f35082ef8d68</td>\n",
       "      <td>anvil_biosample</td>\n",
       "      <td>Success</td>\n",
       "      <td>No Patch Needed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d7bcfc5d-e258-4bd6-a413-bb7a118e6bff</td>\n",
       "      <td>anvil_donor</td>\n",
       "      <td>Success</td>\n",
       "      <td>Patch Needed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d7bcfc5d-e258-4bd6-a413-bb7a118e6bff</td>\n",
       "      <td>anvil_biosample</td>\n",
       "      <td>Success</td>\n",
       "      <td>No Patch Needed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6d18aafc-0240-499c-902e-a72a5b98ff0a</td>\n",
       "      <td>anvil_donor</td>\n",
       "      <td>Success</td>\n",
       "      <td>Patch Needed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6d18aafc-0240-499c-902e-a72a5b98ff0a</td>\n",
       "      <td>anvil_biosample</td>\n",
       "      <td>Success</td>\n",
       "      <td>No Patch Needed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dataset ID                   Table        Status      Message     \n",
       "0  f9224ea2-dd31-421d-80d4-f35082ef8d68      anvil_donor  Success     Patch Needed\n",
       "1  f9224ea2-dd31-421d-80d4-f35082ef8d68  anvil_biosample  Success  No Patch Needed\n",
       "2  d7bcfc5d-e258-4bd6-a413-bb7a118e6bff      anvil_donor  Success     Patch Needed\n",
       "3  d7bcfc5d-e258-4bd6-a413-bb7a118e6bff  anvil_biosample  Success  No Patch Needed\n",
       "4  6d18aafc-0240-499c-902e-a72a5b98ff0a      anvil_donor  Success     Patch Needed\n",
       "5  6d18aafc-0240-499c-902e-a72a5b98ff0a  anvil_biosample  Success  No Patch Needed"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################################\n",
    "## Functions\n",
    "#############################################\n",
    "\n",
    "def check_dataset_fk_field(dataset_id_list):\n",
    "    \n",
    "    # Loop through and process dataset IDs\n",
    "    results = []\n",
    "    for dataset_id in dataset_id_list:\n",
    "    \n",
    "        # Retrieve dataset information\n",
    "        logging.info(f\"Processing dataset_id = {dataset_id}...\")\n",
    "        api_client = utils.refresh_tdr_api_client()\n",
    "        datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "        try:\n",
    "            logging.info(\"Retrieving dataset details.\")\n",
    "            response = datasets_api.retrieve_dataset(id=dataset_id, include=[\"ACCESS_INFORMATION\"]).to_dict()\n",
    "            bq_project = response[\"access_information\"][\"big_query\"][\"project_id\"]\n",
    "            bq_dataset = response[\"access_information\"][\"big_query\"][\"dataset_name\"]\n",
    "        except Exception as e:\n",
    "            error_message = f\"Error retrieving dataset details: {str(e)}\"\n",
    "            logging.error(error_message)\n",
    "            results.append([dataset_id, \"All\", \"Failure\", error_message])\n",
    "            continue\n",
    "            \n",
    "        # Evaluate whether data needs to be reprocessed for the tables in question and reprocess if so \n",
    "        for table in [\"anvil_donor\", \"anvil_biosample\"]:\n",
    "            \n",
    "            # Evaluate whether a patch is needed\n",
    "            logging.info(f\"Checking whether patching is required for the {table} table.\")\n",
    "            patch_needed = False\n",
    "            client = bigquery.Client()\n",
    "            if table == \"anvil_donor\":\n",
    "                query = \"\"\"SELECT COUNT(*) AS null_cnt FROM `{project}.{dataset}.{src_table}` WHERE part_of_dataset_id IS NULL\"\"\".format(project=bq_project, dataset=bq_dataset, src_table = table)\n",
    "            else:\n",
    "                query = \"\"\"SELECT COUNT(*) AS null_cnt FROM `{project}.{dataset}.{src_table}` WHERE ARRAY_LENGTH(part_of_dataset_id) = 0\"\"\".format(project=bq_project, dataset=bq_dataset, src_table = table)\n",
    "            try:\n",
    "                df = client.query(query).result().to_dataframe()\n",
    "                if df[\"null_cnt\"].values[0] > 0:\n",
    "                    patch_needed = True\n",
    "            except Exception as e:\n",
    "                error_message = f\"BigQuery error: {str(e)}\"\n",
    "                results.append([dataset_id, table, \"Failure\", error_message])\n",
    "                continue\n",
    "                \n",
    "            # Patch dataset if needed\n",
    "            if patch_needed:\n",
    "                results.append([dataset_id, table, \"Success\", \"Patch Needed\"])\n",
    "            else:\n",
    "                results.append([dataset_id, table, \"Success\", \"No Patch Needed\"])\n",
    "                \n",
    "    # Display results\n",
    "    logging.info(\"\\nResults:\")\n",
    "    df_results = pd.DataFrame(results, columns =[\"Dataset ID\", \"Table\", \"Status\", \"Message\"])\n",
    "    display(df_results)\n",
    "\n",
    "\n",
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# List of dataset IDs to examine and patch if necessary\n",
    "dataset_id_list = [\n",
    "    'f9224ea2-dd31-421d-80d4-f35082ef8d68',\n",
    "    'd7bcfc5d-e258-4bd6-a413-bb7a118e6bff',\n",
    "    '6d18aafc-0240-499c-902e-a72a5b98ff0a',\n",
    "]\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "\n",
    "check_dataset_fk_field(dataset_id_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Script to patch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     4
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/22/2024 03:32:05 PM - INFO: Processing dataset_id = f9224ea2-dd31-421d-80d4-f35082ef8d68...\n",
      "03/22/2024 03:32:05 PM - INFO: Retrieving dataset details.\n",
      "03/22/2024 03:32:06 PM - INFO: Checking whether patching is required for the anvil_donor table.\n",
      "03/22/2024 03:32:09 PM - INFO: Patching anvil_donor table.\n",
      "03/22/2024 03:32:09 PM - INFO: Creating updated table data.\n",
      "03/22/2024 03:32:24 PM - INFO: Successfully created new anvil_donor.json file.\n",
      "03/22/2024 03:32:24 PM - INFO: Submitting ingest request for updated data.\n",
      "TDR Job ID: O_kzkIQwRfq5hAh6y9V0bg\n",
      "03/22/2024 03:32:54 PM - INFO: Ingest succeeded: {'dataset_id': 'f9224ea2-dd31-421d-80d4-f35082ef8d68', 'dataset': 'ANVIL_ALSCompute_Collection_GRU_20231016', 'table': 'anvil_donor', 'path': 'gs://fc-2a9eefc3-0302-427f-9ac3-82f078741c03/ingest_pipeline/output/transformed/anvil/f9224ea2-dd31-421d-80d4-f35082ef8d68/table_data/anvil_donor.json', 'load_tag': 'Ingest for f9224ea2-dd31-421d-80d4-f35082ef8d68', 'row_count': 7454, 'bad_row_count': 0, 'load_result': None}\n",
      "03/22/2024 03:32:54 PM - INFO: Checking whether patching is required for the anvil_biosample table.\n",
      "03/22/2024 03:32:56 PM - INFO: No patching required!\n",
      "03/22/2024 03:32:56 PM - INFO: \n",
      "Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Dataset ID</th>\n",
       "      <th>Table</th>\n",
       "      <th>Status</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f9224ea2-dd31-421d-80d4-f35082ef8d68</td>\n",
       "      <td>anvil_donor</td>\n",
       "      <td>Success</td>\n",
       "      <td>Records Patched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f9224ea2-dd31-421d-80d4-f35082ef8d68</td>\n",
       "      <td>anvil_biosample</td>\n",
       "      <td>Success</td>\n",
       "      <td>No Patch Needed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dataset ID                   Table        Status      Message     \n",
       "0  f9224ea2-dd31-421d-80d4-f35082ef8d68      anvil_donor  Success  Records Patched\n",
       "1  f9224ea2-dd31-421d-80d4-f35082ef8d68  anvil_biosample  Success  No Patch Needed"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################################\n",
    "## Functions\n",
    "#############################################\n",
    "\n",
    "def check_and_patch_dataset_fk_field(dataset_id_list):\n",
    "    \n",
    "    # Loop through and process dataset IDs\n",
    "    results = []\n",
    "    for dataset_id in dataset_id_list:\n",
    "    \n",
    "        # Retrieve dataset information\n",
    "        logging.info(f\"Processing dataset_id = {dataset_id}...\")\n",
    "        api_client = utils.refresh_tdr_api_client()\n",
    "        datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "        try:\n",
    "            logging.info(\"Retrieving dataset details.\")\n",
    "            response = datasets_api.retrieve_dataset(id=dataset_id, include=[\"ACCESS_INFORMATION\"]).to_dict()\n",
    "            bq_project = response[\"access_information\"][\"big_query\"][\"project_id\"]\n",
    "            bq_dataset = response[\"access_information\"][\"big_query\"][\"dataset_name\"]\n",
    "        except Exception as e:\n",
    "            error_message = f\"Error retrieving dataset details: {str(e)}\"\n",
    "            logging.error(error_message)\n",
    "            results.append([dataset_id, \"All\", \"Failure\", error_message])\n",
    "            continue\n",
    "            \n",
    "        # Evaluate whether data needs to be reprocessed for the tables in question and reprocess if so \n",
    "        for table in [\"anvil_donor\", \"anvil_biosample\"]:\n",
    "            \n",
    "            # Evaluate whether a patch is needed\n",
    "            logging.info(f\"Checking whether patching is required for the {table} table.\")\n",
    "            patch_needed = False\n",
    "            client = bigquery.Client()\n",
    "            if table == \"anvil_donor\":\n",
    "                query = \"\"\"SELECT COUNT(*) AS null_cnt FROM `{project}.{dataset}.{src_table}` WHERE part_of_dataset_id IS NULL\"\"\".format(project=bq_project, dataset=bq_dataset, src_table = table)\n",
    "            else:\n",
    "                query = \"\"\"SELECT COUNT(*) AS null_cnt FROM `{project}.{dataset}.{src_table}` WHERE ARRAY_LENGTH(part_of_dataset_id) = 0\"\"\".format(project=bq_project, dataset=bq_dataset, src_table = table)\n",
    "            try:\n",
    "                df = client.query(query).result().to_dataframe()\n",
    "                if df[\"null_cnt\"].values[0] > 0:\n",
    "                    patch_needed = True\n",
    "            except Exception as e:\n",
    "                error_message = f\"BigQuery error: {str(e)}\"\n",
    "                results.append([dataset_id, table, \"Failure\", error_message])\n",
    "                continue\n",
    "                \n",
    "            # Patch dataset if needed\n",
    "            if patch_needed:\n",
    "                logging.info(f\"Patching {table} table.\")\n",
    "                \n",
    "                # Reprocess table to populate missing values\n",
    "                client = bigquery.Client()\n",
    "                target_file = f\"{table}.json\"\n",
    "                destination_dir = f\"ingest_pipeline/output/transformed/anvil/{dataset_id}/table_data\"\n",
    "                if table == \"anvil_donor\":\n",
    "                    query = \"\"\"SELECT * EXCEPT(part_of_dataset_id), MAX(part_of_dataset_id) OVER (ORDER BY part_of_dataset_id DESC NULLS LAST) AS part_of_dataset_id \n",
    "                                FROM `{project}.{dataset}.{src_table}`\"\"\".format(project=bq_project, dataset=bq_dataset, src_table = table)\n",
    "                else:\n",
    "                    query = \"\"\"WITH dataset_id\n",
    "                                AS\n",
    "                                (\n",
    "                                  SELECT MAX(ARRAY_TO_STRING(part_of_dataset_id, \"\")) AS id\n",
    "                                  FROM `{project}.{dataset}.{src_table}` \n",
    "                                )\n",
    "                                SELECT * EXCEPT(part_of_dataset_id), [(SELECT MAX(id) FROM dataset_id)] AS part_of_dataset_id\n",
    "                                FROM `{project}.{dataset}.{src_table}`\"\"\".format(project=bq_project, dataset=bq_dataset, src_table = table)\n",
    "                logging.info(\"Creating updated table data.\")\n",
    "                try:\n",
    "                    df = client.query(query).result().to_dataframe()\n",
    "                    records_json = df.to_json(orient='records') \n",
    "                    records_list = json.loads(records_json)\n",
    "                    records_cnt = len(records_list)\n",
    "                    with open(target_file, 'w') as outfile:\n",
    "                        for idx, val in enumerate(records_list):\n",
    "                            json.dump(val, outfile)\n",
    "                            if idx < (records_cnt - 1):\n",
    "                                outfile.write('\\n')\n",
    "                    !gsutil cp $target_file $ws_bucket/$destination_dir/ 2> stdout\n",
    "                    !rm $target_file\n",
    "                    logging.info(f\"Successfully created new {table}.json file.\")\n",
    "                except Exception as e:\n",
    "                    error_message = f\"Error creating new json file. Exiting function. Error: {str(e)}\"\n",
    "                    logging.error(error_message)\n",
    "                    results.append([dataset_id, table, \"Failure\", error_message])\n",
    "                    continue\n",
    "            \n",
    "                # Ingest updated anvil_donor data\n",
    "                logging.info(\"Submitting ingest request for updated data.\")\n",
    "                source_full_file_path = \"{}/{}/{}\".format(ws_bucket, destination_dir, target_file)\n",
    "                ingest_request = {\n",
    "                    \"table\": table,\n",
    "                    \"profile_id\": \"e0e03e48-5b96-45ec-baa4-8cc1ebf74c61\",\n",
    "                    \"ignore_unknown_values\": True,\n",
    "                    \"resolve_existing_files\": True,\n",
    "                    \"updateStrategy\": \"replace\",\n",
    "                    \"format\": \"json\",\n",
    "                    \"load_tag\": \"Ingest for {}\".format(dataset_id),\n",
    "                    \"path\": source_full_file_path\n",
    "                }\n",
    "                attempt_counter = 0\n",
    "                while True:\n",
    "                    try:\n",
    "                        api_client = utils.refresh_tdr_api_client()\n",
    "                        datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "                        ingest_request_result, job_id = utils.wait_for_tdr_job(datasets_api.ingest_dataset(id=dataset_id, ingest=ingest_request))\n",
    "                        logging.info(\"Ingest succeeded: {}\".format(str(ingest_request_result)[0:1000]))\n",
    "                        results.append([dataset_id, table, \"Success\", \"Records Patched\"])\n",
    "                        break\n",
    "                    except Exception as e:\n",
    "                        logging.error(\"Error on Dataset Ingest: {}\".format(str(e)))\n",
    "                        attempt_counter += 1\n",
    "                        if attempt_counter < 2:\n",
    "                            logging.info(\"Retrying Dataset Ingest (attempt #{})...\".format(str(attempt_counter)))\n",
    "                            sleep(10)\n",
    "                            continue\n",
    "                        else:\n",
    "                            logging.error(\"Maximum number of retries exceeded. Exiting function.\")\n",
    "                            results.append([dataset_id, table, \"Failure\", str(e)])\n",
    "                            break\n",
    "            else:\n",
    "                logging.info(\"No patching required!\")\n",
    "                results.append([dataset_id, table, \"Success\", \"No Patch Needed\"])\n",
    "                \n",
    "    # Display results\n",
    "    logging.info(\"\\nResults:\")\n",
    "    df_results = pd.DataFrame(results, columns =[\"Dataset ID\", \"Table\", \"Status\", \"Message\"])\n",
    "    display(df_results)\n",
    "\n",
    "\n",
    "#############################################\n",
    "## Input Parameters\n",
    "#############################################\n",
    "\n",
    "# List of dataset IDs to examine and patch if necessary\n",
    "dataset_id_list = [\n",
    "    'f9224ea2-dd31-421d-80d4-f35082ef8d68',\n",
    "]\n",
    "\n",
    "#############################################\n",
    "## Execution\n",
    "#############################################\n",
    "\n",
    "check_and_patch_dataset_fk_field(dataset_id_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Patch Dataset Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Dataset-workspace list\n",
    "dataset_ws_list = [\n",
    "    ['9a32e23e-840d-4ba3-8cd9-392f48b8e9d2', 'AnVIL_CCDG_Baylor_CVD_HemStroke_GOCHA_DS_WGS'],\n",
    "    ['5069fc2c-b957-4130-adca-6eabae943867', 'AnVIL_CCDG_Baylor_CVD_HemStroke_WashU_DS_WGS'],\n",
    "    ['1939b7ae-fc6b-42a8-ad5f-dc51a1682a17', 'AnVIL_CCDG_Broad_CVD_AF_Darbar_UIC_Cases_Arrays'],\n",
    "    ['4e99b8e1-40b9-4fb2-90a0-d85e926ef31e', 'AnVIL_CCDG_Broad_CVD_AF_Darbar_UIC_Cases_WES'],\n",
    "    ['2cda53ba-b852-47e8-8f24-59ab8e9f1d1f', 'AnVIL_CCDG_Broad_CVD_AF_Darbar_UIC_Controls_Arrays'],\n",
    "    ['128332b6-5060-4ec4-b6a6-f53b54a810be', 'AnVIL_CCDG_Broad_CVD_AF_Darbar_UIC_Controls_WES'],\n",
    "    ['06f05f58-3c83-4f5c-bddd-bed7d2d1d147', 'AnVIL_CCDG_Broad_CVD_AF_EAST_WES'],\n",
    "    ['41cb9f29-4ba6-4690-821c-cb085e6b0f2f', 'AnVIL_CCDG_Broad_CVD_AF_Figtree_BioHeart_WES'],\n",
    "    ['9d796a02-e2aa-4c15-b8d6-1e90cd736681', 'AnVIL_CCDG_Broad_CVD_AF_Natale_TCAI_Arrays'],\n",
    "    ['7ea006d9-1e19-4678-b2e6-d4a1ea327f74', 'AnVIL_CCDG_Broad_CVD_AF_Natale_TCAI_WES'],\n",
    "    ['433e3a09-661a-46a5-96f2-dbb07bdc87f3', 'AnVIL_CCDG_Broad_CVD_AF_Olesen_Arrays'],\n",
    "    ['34fd3b22-ac73-47d2-8849-5877158ec072', 'AnVIL_CCDG_Broad_CVD_AF_Olesen_WES'],\n",
    "    ['a08dc7a6-f8ce-4205-95d2-83f614c2c32f', 'AnVIL_CCDG_Broad_CVD_AF_PEGASUS_HMB'],\n",
    "    ['7ce3270e-b2f2-47f4-a288-639751b2f87f', 'AnVIL_CCDG_Broad_CVD_AF_Roberts_UWO_WES'],\n",
    "    ['fcb03f4f-e685-4803-aadb-0e8940ff4f37', 'AnVIL_CCDG_Broad_CVD_AF_TMDU_Cases_Arrays'],\n",
    "    ['41d12dc1-8718-4439-b409-26cc23573107', 'AnVIL_CCDG_Broad_CVD_AF_TMDU_Cases_WES'],\n",
    "    ['c2f0e7cf-ac07-48f7-b5f1-497ee6c134b2', 'AnVIL_CCDG_Broad_CVD_AF_TMDU_Controls_Arrays'],\n",
    "    ['c4c49fcd-0c20-4cff-841a-cb58f5689c5b', 'AnVIL_CCDG_Broad_CVD_AF_TMDU_Controls_WES'],\n",
    "    ['9ee2a552-89f8-4a48-9c94-9fa26ebb7483', 'AnVIL_CCDG_Broad_CVD_AFib_Duke_WGS'],\n",
    "    ['425412ba-894a-4824-acb8-bf18fe4576e0', 'AnVIL_CCDG_Broad_CVD_AFib_GENAF_WGS'],\n",
    "    ['f22bd762-5c45-453e-bf22-b174514abb84', 'AnVIL_CCDG_Broad_CVD_AFib_Intermountain_WGS'],\n",
    "    ['0ee62643-b064-42f8-9b09-5d10eacd70a3', 'AnVIL_CCDG_Broad_CVD_AFib_JHU_WGS'],\n",
    "    ['c37b388c-7107-43d6-bee6-4e82b40ed271', 'AnVIL_CCDG_Broad_CVD_AFib_MPP_WGS'],\n",
    "    ['bf6f1d78-6a0d-4afb-aea6-17a3c34340db', 'AnVIL_CCDG_Broad_CVD_AFib_Penn_WGS'],\n",
    "    ['719f7581-21db-4aec-8c46-4a5811832710', 'AnVIL_CCDG_Broad_CVD_EOCAD_PROMIS_WGS'],\n",
    "    ['15be288e-53e1-41cb-8d20-8ea87efb9258', 'AnVIL_CCDG_Broad_MI_ATVB_DS_CVD_WES'],\n",
    "    ['8b8185d3-ba5c-4832-af23-3ff8ca6ed016', 'AnVIL_CCDG_Broad_MI_UnivUtah_DS_CVD_WES'],\n",
    "    ['140797da-dc94-4fc2-8b0b-f2e1dec7bd43', 'AnVIL_CCDG_Broad_NP_Autism_State-Sanders_WGS'],\n",
    "    ['8de6dae2-55ff-4287-9b75-5b2a950c1f44', 'AnVIL_CCDG_Broad_NP_Epilepsy_AUSALF_HMB_IRB_GSRS_GSA-MD'],\n",
    "    ['d3ed2595-b8be-40c8-b7b6-10a4997b9d2e', 'AnVIL_CCDG_Broad_NP_Epilepsy_AUSRMB_DS-EAED-MDS-NPU-IRB_GSA-MD'],\n",
    "    ['61803dc8-f649-43e5-ab15-d351f2cef629', 'AnVIL_CCDG_Broad_NP_Epilepsy_AUTMUV_DS_NS_MDS_NPU_GSA-MD'],\n",
    "    ['abe58d43-e1c7-4953-aa41-4d3b6f6cca44', 'AnVIL_CCDG_Broad_NP_Epilepsy_AUTMUV_DS_NS_NPU_ADLT_GSA-MD'],\n",
    "    ['395da421-e6e8-4a26-ac93-eb7050a7cb1f', 'AnVIL_CCDG_Broad_NP_Epilepsy_GHAKNT_GRU_GSA-MD'],\n",
    "    ['615f6246-1c39-4e44-a9d4-c7133a2ae62d', 'AnVIL_CCDG_Broad_NP_Epilepsy_HKOSB_GRU_GSA-MD'],\n",
    "    ['21384132-1697-4e9b-b863-a6492d13285d', 'AnVIL_CCDG_Broad_NP_Epilepsy_KENKIL_GRU_GSA-MD'],\n",
    "    ['b7fb531e-25a4-427c-9679-b7bdc3d03535', 'AnVIL_CCDG_Broad_NP_Epilepsy_TWNCGM_HMB-NPU-ADULTS_WES'],\n",
    "    ['608d793e-a78b-4872-a50c-21a9eaa60ec3', 'AnVIL_CCDG_Broad_NP_Epilepsy_USACCF_HMB-MDS_GSA-MD'],\n",
    "    ['af867604-d801-41cc-9949-017eb30a0cbf', 'AnVIL_CCDG_Broad_NP_Epilepsy_USALCH_HMB_MDS_GSA-MD'],\n",
    "    ['722e332c-fb1a-45fe-80c7-cc670f025b7f', 'AnVIL_CCDG_Broad_NP_Epilepsy_USAMGH_HMB_MDS_GSA-MD'],\n",
    "    ['1d140c76-a06b-42a0-bae8-b9e169ebe394', 'AnVIL_CCDG_Broad_NP_Epilepsy_USAMON_HMB_NPU_MDS_GSA-MD'],\n",
    "    ['3615e063-f24b-47f7-87cb-430e8aca8d0c', 'AnVIL_CCDG_Broad_NP_Epilepsy_USAUPN_GRU_NPU_WES'],\n",
    "    ['e642bca0-52fb-4ab3-ab3a-acaab83deda7', 'AnVIL_CCDG_Broad_NP_Epilepsy_USAUPN_GRU_WES'],\n",
    "    ['9ecc231f-e3d3-4417-a98a-c4db4c638161', 'AnVIL_CCDG_Broad_NP_Epilepsy_USAVANcontrols_HMB-GSO_WES'],\n",
    "    ['c911503c-f010-4c17-ac57-1d82e954bdc7', 'AnVIL_CCDG_Broad_NP_Epilepsy_ZAFAGN_DS-EPI-COMO-MDS_GSA-MD'],\n",
    "    ['3fb2d04a-d18b-4bdc-9372-99b992f2ae42', 'AnVIL_CCDG_Broad_NP_Epilepsy_ZAFAGN_DS-EPI-COMO-MDS_WES'],\n",
    "    ['a3ae33bb-8b3a-47e5-a2d1-a49c954776b3', 'AnVIL_CCDG_NYGC_NP_Autism_HMCA_WGS'],\n",
    "    ['0e65b131-fd14-4fce-908b-c5b89a71a9c1', 'AnVIL_CCDG_NYGC_NP_Autism_TASC_WGS'],\n",
    "    ['d56ae233-d6d2-483c-917e-1de0fe1cfeb7', 'AnVIL_CCDG_TOPMED_Broad_CVD_EOCAD_PROMIS_WGS'],\n",
    "    ['655e6a61-5400-4d8a-95bc-1506e026b289', 'AnVIL_CCDG_WashU_AI_T1D_T1DGC_WGS'],\n",
    "    ['1f2d14d4-1bd8-46fc-9d35-1a415e5f326a', 'AnVIL_CCDG_WashU_CVD-NP-AI_Controls_VCControls_WGS'],\n",
    "    ['64fd39fc-b32e-4b0a-8f83-4bf11b197462', 'AnVIL_CCDG_WashU_CVD_Brazil-CVD_WGS'],\n",
    "    ['158ebecd-4596-4541-b832-a137232b7036', 'AnVIL_CCDG_WashU_CVD_EOCAD_BioMe_WGS'],\n",
    "    ['1ccb95c3-1901-428e-b7bb-34495f41f4d2', 'AnVIL_CCDG_WashU_CVD_EOCAD_BioVu_WGS'],\n",
    "    ['02ff1051-cd1d-4bbb-a005-21384cbff846', 'AnVIL_CCDG_WashU_CVD_EOCAD_Cleveland_WGS'],\n",
    "    ['0144b0d3-a809-46df-8c67-7ce42bdd579a', 'AnVIL_CCDG_WashU_CVD_EOCAD_Duke_WGS'],\n",
    "    ['35a1009d-93a2-49b1-a801-fe84d6b7a2f5', 'AnVIL_CCDG_WashU_CVD_EOCAD_Emerge_WGS'],\n",
    "    ['50132478-c9fb-4dc5-86cd-d5dfab909393', 'AnVIL_CCDG_WashU_CVD_EOCAD_Emory_WGS'],\n",
    "    ['35064fc1-6c52-4005-8e99-cb0d6afd3f8c', 'AnVIL_CCDG_WashU_CVD_EOCAD_Finland-CHD_WGS'],\n",
    "    ['62cfdce6-2d4d-415c-a11e-5ab60131c668', 'AnVIL_CCDG_WashU_CVD_EOCAD_METSIM_WGS'],\n",
    "    ['c5c0893f-b254-4038-8d08-b28ef5a26b5d', 'AnVIL_CMG_Broad_Brain_Engle_WGS'],\n",
    "    ['b60876c5-d825-4303-befb-ffff55b92aba', 'AnVIL_CMG_Broad_Heart_Ware_WES'],\n",
    "]\n",
    "\n",
    "# Loop through and process\n",
    "for entry in dataset_ws_list:\n",
    "    # Pull dataset details\n",
    "    dataset_id = entry[0]\n",
    "    workspace_name = entry[1]\n",
    "    logging.info(f\"Processing dataset_id = {dataset_id}...\")\n",
    "    api_client = utils.refresh_tdr_api_client()\n",
    "    datasets_api = data_repo_client.DatasetsApi(api_client=api_client)\n",
    "    try:\n",
    "        logging.info(\"Retrieving dataset details.\")\n",
    "        dataset_details = datasets_api.retrieve_dataset(id=dataset_id, include=[\"PROPERTIES\"]).to_dict()\n",
    "        current_properties = dataset_details[\"properties\"]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error retrieving dataset details: {str(e)}\")\n",
    "    \n",
    "    # Update current propertie and patch dataset\n",
    "    if current_properties[\"source_workspaces\"] != workspace_name:\n",
    "        current_properties[\"source_workspaces\"] = [workspace_name]\n",
    "        try:\n",
    "            logging.info(\"Patching dataset.\")\n",
    "            resp = datasets_api.patch_dataset(id=dataset_id, dataset_patch_request_model={\"properties\": current_properties})\n",
    "        except Exception as e:\n",
    "            logging.error(\"Error on Dataset Patch: {}\".format(str(e)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
